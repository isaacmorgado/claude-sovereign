# Splice v3

Cloud-powered SaaS for Adobe Premiere Pro with AI-driven auto-cutting, take detection, and subscription billing.

## Monorepo Structure

```
/                         # Root
├── src/                  # Premiere Pro UXP Plugin
│   ├── components/
│   │   ├── panels/       # PluginApp (main container)
│   │   └── common/       # UI: Header, SelectionPanel, AIToolsPanel, AuthPanel, CuttingPanel
│   ├── types/            # TypeScript: plugin, api, premiere, audio, auto-cutting
│   ├── utils/
│   │   ├── api/          # premiere.ts, backend-client.ts, audio-processor.ts
│   │   ├── cutting/      # silence-detector.ts (gap detection, cut points)
│   │   └── helpers/      # formatters, validators, audio-utils
│   └── styles/           # Global CSS, Spectrum theming
│
├── backend/              # Node.js + Express API
│   └── src/
│       ├── routes/       # auth, billing, jobs, audio, usage
│       ├── controllers/  # Route handlers
│       ├── services/     # audio-service, take-detection-service
│       ├── workers/      # BullMQ: transcription, vocal-isolation, take-detection
│       ├── db/           # migrations/, repositories/
│       └── middleware/   # auth, rate-limit, usage-limit
│
├── dashboard/            # Next.js Web Dashboard
│   └── app/              # login, signup, dashboard (usage, billing, settings)
│
├── tests/                # Vitest unit + Playwright e2e
└── public/               # manifest.json, icons
```

## Tech Stack

| Layer     | Stack                                                             |
| --------- | ----------------------------------------------------------------- |
| Plugin    | Lit 3.2 + Spectrum Web Components + TypeScript                    |
| Backend   | Node.js + Express + PostgreSQL + BullMQ/Redis                     |
| Dashboard | Next.js + React                                                   |
| Audio     | Whisper/Deepgram (transcription) + Demucs/Dolby (vocal isolation) |
| Payments  | Stripe                                                            |

## Auto-Cutting Workflow

### User Flow

1. User selects clips in Premiere Pro timeline
2. Plugin extracts audio from selected clips
3. **Options:** Isolate vocals (optional), choose audio source for timeline
4. Backend transcribes audio (uses isolated vocals for accuracy if available)
5. LLM analyzes transcript to detect repeated takes (similar statements)
6. Cut silences (preserving natural pauses 150-500ms)
7. Color-code and label clips by take groups

### Audio Options (User-Selectable)

| Option | Values | Default | Description |
|--------|--------|---------|-------------|
| Isolate Audio | checkbox | off | Run vocal isolation on clips |
| Timeline Audio | Original / Isolated | Original | Which audio appears on timeline after cuts |

### Take Detection (LLM-Powered)

The LLM groups similar statements as takes:
```
Input: "Hey guys welcome back" at 0:05, "Hey guys, welcome back" at 0:45
Output: Take Group "Hey Guys Welcome" with Take 1, Take 2
```

### Clip Color Coding

| Takes | Label Index | Color | Meaning |
|-------|-------------|-------|---------|
| 1 | 13 | Green | Single take ✓ |
| 2 | 15 | Yellow | Minor retry |
| 3 | 7 | Mango | Multiple attempts |
| 4+ | 11 | Magenta | Many retakes |

### Silence Thresholds

| Duration | Action | Description |
|----------|--------|-------------|
| 150-500ms | KEEP | Natural pause (breath, comma, sentence) |
| >750ms | CUT | Dead air, between-take gap |
| >2000ms | CUT | Definitely cut (between takes) |
| Padding | 100ms | Buffer to avoid clipping words |

### Processing Pipeline

```
Selected Clips → Extract Audio → Upload to S3 →
  → Vocal Isolation (optional) → Transcription →
  → LLM Take Detection → Silence Detection →
  → Apply Cuts → Color & Label Clips
```

## Code Quality - Zero Tolerance

After editing ANY file, run:

```bash
npm run lint
npm run typecheck
```

Fix ALL errors/warnings before continuing.

## Current Focus

Section: Phase 3 - Auto-Cutting & Take Detection
Files: `backend/src/services/take-detection-service.ts`, `src/components/common/CuttingPanel.ts`

## Last Session (2025-12-16)

### Completed

- **End-to-end upload flow tested and working**
- **Added AUDIO_MOCK_MODE** for dev testing without external AI services:
  - `backend/.env`: `AUDIO_MOCK_MODE=true`
  - Workers return mock transcription/vocal isolation results
  - Files: `backend/src/workers/transcription-worker.ts`, `backend/src/workers/vocal-isolation-worker.ts`
- **Fixed job completion bugs**:
  - PostgreSQL NUMERIC returned as string → fixed with `parseFloat()` in `audio-service.ts:157`
  - INTEGER column received decimals → fixed with `Math.ceil()` in `user-repository.ts:59`
- **Added accurate audio duration extraction**:
  - Created `src/utils/helpers/audio-utils.ts` with Web Audio API extraction
  - Fallback chain: Web Audio API → HTML5 Audio → WAV header parsing → file-size estimate
  - Updated AIToolsPanel to use actual duration for usage checks
- **Implemented silence-based auto-cutting**:
  - Created `src/utils/cutting/silence-detector.ts` for gap detection from transcription segments
  - Added clip splitting API to `premiere.ts` (adjust outPoint + insert new clip)
  - Created `CuttingPanel` component with threshold config and cut preview
  - Wired CuttingPanel to AIToolsPanel - shows after transcription completes

### Test Credentials

- Email: `test2@example.com`
- Password: `TestPass123`

### Mock Mode (Development)

Set `AUDIO_MOCK_MODE=true` in `backend/.env` to test without external services.
Workers will return mock results instead of calling Whisper/Deepgram/Dolby/Demucs.

To use real services, set `AUDIO_MOCK_MODE=false` and configure:

- `DEEPGRAM_API_KEY` or `WHISPER_API_URL` for transcription
- `DOLBY_API_KEY` or `DEMUCS_API_URL` for vocal isolation

### S3 Setup (LocalStack - Already Configured)

LocalStack is configured in `docker-compose.yml` with auto-bucket creation.
Credentials in `backend/.env` are set for LocalStack (test/test).

To switch to real AWS S3, update `backend/.env`:

```
AWS_REGION=us-east-1
AWS_ACCESS_KEY_ID=your_real_key
AWS_SECRET_ACCESS_KEY=your_real_secret
S3_BUCKET_NAME=your-bucket-name
S3_ENDPOINT=  # Remove or comment out for real AWS
```

## Next Steps

1. **Add TakeGroup types** to `src/types/auto-cutting.ts`
2. **Backend: take-detection-service.ts** - LLM integration for grouping similar statements
3. **Backend: take-detection-worker.ts** - New BullMQ job type
4. **Plugin: Audio extraction** - Extract audio from selected clips
5. **Plugin: Clip colors & names** - setClipColor, setClipName APIs
6. **UI: CuttingPanel updates** - Audio options, take groups preview
7. Test complete flow in Premiere Pro

## Dev Server Commands

```bash
# Start all services (Postgres, Redis, LocalStack)
docker-compose up -d

# Plugin (Vite) - runs on port 3000 (or 3002 if port in use)
npm run dev

# Backend - runs on port 3001
cd backend && npm run dev

# Health check
curl http://localhost:3001/health

# Verify LocalStack S3
curl http://localhost:4566/_localstack/health
```

## Backend Client API

```typescript
import { backendClient } from '@/utils/api/backend-client'

// Auth
backendClient.login(email, password)
backendClient.register(email, password, name?)
backendClient.logout()
backendClient.getMe()
backendClient.isAuthenticated()
backendClient.onAuthChange(callback) // returns unsubscribe fn

// Usage
backendClient.getUsage()
backendClient.checkUsageLimit(minutes)
backendClient.canSubmitAudioJob(minutes)

// File Upload
backendClient.getPresignedUploadUrl(filename, contentType, fileSize)
backendClient.uploadFileToS3(file, presignedUrl)
backendClient.uploadFileToS3WithProgress(file, presignedUrl, onProgress?) // XHR with progress
backendClient.uploadFile(file) // convenience: presign + upload in one call
backendClient.uploadFileWithProgress(file, onProgress?) // convenience with progress callback

// Audio Jobs
backendClient.submitTranscription(audioUrl, durationMinutes)
backendClient.submitVocalIsolation(audioUrl, durationMinutes)
backendClient.submitTakeDetection(transcriptionResult) // NEW: LLM take detection
backendClient.getJobs(limit?, offset?)
backendClient.getJob(jobId)
backendClient.pollJobUntilComplete(jobId, onProgress?, {intervalMs?, maxAttempts?, signal?})

// Billing
backendClient.createCheckout(tier, interval?)
backendClient.createPortal()
backendClient.getBillingStatus()
```

## Key Patterns

| Area           | Pattern                                                                            |
| -------------- | ---------------------------------------------------------------------------------- |
| AuthPanel      | `isMounted` flag prevents async writes on unmounted component                      |
| AuthPanel      | `if (this.isLoading) return` prevents double-submission                            |
| AuthPanel      | `getSafePlanClass()` validates plan enum before CSS class use                      |
| SettingsPanel  | User prop passed from PluginApp, logout dispatches event                           |
| SettingsPanel  | Billing buttons call `backendClient.createCheckout/createPortal` and `window.open` |
| backend-client | Refresh token mutex prevents concurrent refresh race condition                     |
| backend-client | localStorage fallback for browser dev mode (no UXP)                                |
| tsconfig       | `useDefineForClassFields: false` fixes Lit decorator issue                         |
