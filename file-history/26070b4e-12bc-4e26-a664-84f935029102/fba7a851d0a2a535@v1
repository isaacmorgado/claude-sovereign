#!/usr/bin/env python3
"""
RunPod API Wrapper for Browser Automation Integration
Connects browser automation (Playwright) with RunPod abliterated models
"""
import os
import requests
import base64
import json
import sys
from typing import Dict, List, Optional
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

RUNPOD_API_KEY = os.getenv("RUNPOD_API_KEY")

if not RUNPOD_API_KEY:
    print("âŒ Error: RUNPOD_API_KEY not set!")
    print("Please set it: export RUNPOD_API_KEY='your_key'")
    print("Or add to .env file")
    sys.exit(1)

# Your endpoint configurations - CONFIGURED!
ENDPOINTS = {
    "architect": {
        "id": "1ememx9x9kg61c",
        "url": "https://api.runpod.ai/v2/1ememx9x9kg61c/openai/v1",
        "model": "huihui-ai/DeepSeek-R1-Distill-Qwen-32B-abliterated"
    },
    "code": {
        "id": "37gom8dbuz3n64",
        "url": "https://api.runpod.ai/v2/37gom8dbuz3n64/openai/v1",
        "model": "huihui-ai/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated"
    },
    "research": {
        "id": "ghj3ehldsv8c8n",
        "url": "https://api.runpod.ai/v2/ghj3ehldsv8c8n/openai/v1",
        "model": "huihui-ai/Huihui-Qwen3-Next-80B-A3B-Thinking-Abliterated"
    },
    "quick": {
        "id": "vns78p175ekxvj",
        "url": "https://api.runpod.ai/v2/vns78p175ekxvj/openai/v1",
        "model": "DavidAU/Qwen3-4B-Thinking-2507-Claude-4.5-Opus-High-Reasoning-Distill-Heretic-Abliterated"
    }
}


def call_runpod(model: str, prompt: str, temperature: float = 0.7, max_tokens: int = 4096) -> str:
    """
    Call RunPod endpoint with a prompt

    Args:
        model: Which model to use (architect/code/research/quick)
        prompt: The prompt to send
        temperature: Sampling temperature (0.0-1.0)
        max_tokens: Maximum tokens to generate

    Returns:
        Model response as string
    """
    if model not in ENDPOINTS:
        raise ValueError(f"Unknown model: {model}. Choose from: {list(ENDPOINTS.keys())}")

    endpoint = ENDPOINTS[model]

    headers = {
        "Authorization": f"Bearer {RUNPOD_API_KEY}",
        "Content-Type": "application/json"
    }

    data = {
        "model": endpoint["model"],
        "messages": [
            {"role": "user", "content": prompt}
        ],
        "temperature": temperature,
        "max_tokens": max_tokens
    }

    print(f"ðŸš€ Calling RunPod {model} model...")
    print(f"   Endpoint: {endpoint['id']}")

    try:
        response = requests.post(
            f"{endpoint['url']}/chat/completions",
            headers=headers,
            json=data,
            timeout=120
        )
        response.raise_for_status()
        result = response.json()

        if "choices" in result and len(result["choices"]) > 0:
            return result["choices"][0]["message"]["content"]
        else:
            return f"Error: Unexpected response format: {result}"

    except requests.exceptions.RequestException as e:
        return f"âŒ Error calling RunPod: {e}"


def screenshot_to_description(screenshot_path: str, context: str = "") -> str:
    """
    Convert screenshot to detailed description using GPT-4V
    (Your abliterated models don't have vision, so use GPT-4V for description step)

    Args:
        screenshot_path: Path to screenshot image
        context: Additional context about what to focus on

    Returns:
        Detailed description of the UI
    """
    import openai

    openai_key = os.getenv("OPENAI_API_KEY")
    if not openai_key:
        return "âŒ Error: OPENAI_API_KEY not set. Need vision model for screenshot analysis."

    client = openai.OpenAI(api_key=openai_key)

    # Read and encode screenshot
    with open(screenshot_path, "rb") as f:
        image_data = base64.b64encode(f.read()).decode()

    prompt = f"""Describe this UI/website screenshot in extreme detail for a developer to recreate it.

Include:
- Overall layout and structure
- All visible components and elements
- Colors (hex codes if possible)
- Typography (fonts, sizes, weights)
- Spacing and alignment
- Interactive elements (buttons, links, forms)
- Images and icons
- Any text content

{f'Focus especially on: {context}' if context else ''}

Be extremely detailed and precise."""

    print("ðŸ” Analyzing screenshot with GPT-4V...")

    try:
        response = client.chat.completions.create(
            model="gpt-4-vision-preview",
            messages=[{
                "role": "user",
                "content": [
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/png;base64,{image_data}"
                        }
                    },
                    {
                        "type": "text",
                        "text": prompt
                    }
                ]
            }],
            max_tokens=2048
        )

        return response.choices[0].message.content

    except Exception as e:
        return f"âŒ Error with GPT-4V: {e}"


def screenshot_to_code(screenshot_path: str, model: str = "code", instructions: str = "", context: str = "") -> str:
    """
    Convert screenshot to code using two-step process:
    1. GPT-4V describes the screenshot
    2. RunPod abliterated model generates code from description

    Args:
        screenshot_path: Path to screenshot image
        model: Which RunPod model to use for code generation
        instructions: Specific instructions for code generation
        context: Context about what to focus on in screenshot

    Returns:
        Generated code as string
    """
    print("ðŸ“¸ Screenshot to Code Pipeline Started...")
    print(f"   Screenshot: {screenshot_path}")
    print(f"   Model: {model}")

    # Step 1: Get description from vision model
    description = screenshot_to_description(screenshot_path, context)

    if description.startswith("âŒ"):
        return description

    print("âœ… Screenshot analyzed")

    # Step 2: Generate code from description
    code_prompt = f"""Based on this detailed UI description, generate production-ready code.

UI DESCRIPTION:
{description}

REQUIREMENTS:
{instructions if instructions else '''- Generate clean, modern HTML/CSS/JavaScript
- Use Tailwind CSS for styling
- Make it responsive
- Include all visible elements
- Match the description exactly
- Add helpful comments
- Use best practices'''}

Provide the complete code with proper formatting:"""

    print("ðŸ’» Generating code with RunPod...")

    code = call_runpod(
        model=model,
        prompt=code_prompt,
        temperature=0.3,
        max_tokens=8192
    )

    return code


def analyze_devtools(console_logs: Optional[str] = None,
                     network_requests: Optional[str] = None,
                     errors: Optional[str] = None,
                     model: str = "architect") -> str:
    """
    Analyze browser devtools data (console logs, network requests, errors)

    Args:
        console_logs: Console log output
        network_requests: Network request data
        errors: JavaScript errors
        model: Which model to use for analysis

    Returns:
        Analysis and recommendations
    """
    print("ðŸ”§ Analyzing DevTools data...")

    analysis_prompt = f"""Analyze these browser DevTools outputs and provide technical insights:

"""

    if console_logs:
        analysis_prompt += f"""
CONSOLE LOGS:
{console_logs}
"""

    if network_requests:
        analysis_prompt += f"""
NETWORK REQUESTS:
{network_requests}
"""

    if errors:
        analysis_prompt += f"""
ERRORS:
{errors}
"""

    analysis_prompt += """
Provide analysis on:
1. Any errors or warnings? What do they mean?
2. Performance issues or bottlenecks?
3. Security concerns (exposed data, insecure requests)?
4. API usage patterns and optimization opportunities?
5. Specific recommendations for fixing issues?

Be detailed and technical."""

    return call_runpod(
        model=model,
        prompt=analysis_prompt,
        temperature=0.7,
        max_tokens=4096
    )


def analyze_patterns(data: str, model: str = "research") -> str:
    """
    Analyze patterns in scraped data using Research model

    Args:
        data: JSON or text data to analyze
        model: Which model to use (default: research for deep analysis)

    Returns:
        Pattern analysis and insights
    """
    print("ðŸ”¬ Analyzing patterns...")

    prompt = f"""Analyze this data and identify patterns, trends, and insights:

DATA:
{data}

Provide:
1. Key patterns and trends
2. Psychological/behavioral insights
3. Anomalies or outliers
4. Actionable recommendations
5. Hidden connections or correlations

Be thorough and detailed."""

    return call_runpod(
        model=model,
        prompt=prompt,
        temperature=0.7,
        max_tokens=4096
    )


def main():
    """Command-line interface"""
    if len(sys.argv) < 2:
        print("""
RunPod API Wrapper - Browser Automation Integration

USAGE:
  python runpod_api.py <command> [args...]

COMMANDS:

  screenshot-to-code <screenshot_path> [model] [instructions]
    Convert screenshot to code using vision + RunPod models
    Example: python runpod_api.py screenshot-to-code screenshot.png code "Use React and TypeScript"

  analyze-devtools <console_file> <network_file> [errors_file] [model]
    Analyze browser devtools data
    Example: python runpod_api.py analyze-devtools console.json network.json errors.json architect

  analyze-patterns <data_file> [model]
    Analyze patterns in scraped data
    Example: python runpod_api.py analyze-patterns reddit_posts.json research

  ask <model> <question>
    Ask a question directly to a model
    Example: python runpod_api.py ask architect "Explain microservices architecture"

MODELS:
  architect - DeepSeek-R1-32B (architecture, debugging, reverse engineering)
  code      - Qwen3-Coder-30B (code generation, scripts)
  research  - Qwen3-Next-80B (deep analysis, patterns)
  quick     - Qwen3-4B (quick questions)

SETUP:
  1. Set RUNPOD_API_KEY environment variable
  2. Set OPENAI_API_KEY for screenshot analysis (vision)
  3. Update ENDPOINTS in this script with your RunPod endpoint IDs
""")
        sys.exit(1)

    command = sys.argv[1].lower()

    try:
        if command == "screenshot-to-code":
            if len(sys.argv) < 3:
                print("âŒ Error: screenshot path required")
                sys.exit(1)

            screenshot_path = sys.argv[2]
            model = sys.argv[3] if len(sys.argv) > 3 else "code"
            instructions = sys.argv[4] if len(sys.argv) > 4 else ""

            code = screenshot_to_code(screenshot_path, model, instructions)
            print("\n" + "="*80)
            print("GENERATED CODE:")
            print("="*80)
            print(code)

        elif command == "analyze-devtools":
            if len(sys.argv) < 4:
                print("âŒ Error: console and network files required")
                sys.exit(1)

            console_file = sys.argv[2]
            network_file = sys.argv[3]
            errors_file = sys.argv[4] if len(sys.argv) > 4 else None
            model = sys.argv[5] if len(sys.argv) > 5 else "architect"

            # Read files
            with open(console_file) as f:
                console_logs = f.read()

            with open(network_file) as f:
                network_requests = f.read()

            errors = None
            if errors_file:
                with open(errors_file) as f:
                    errors = f.read()

            analysis = analyze_devtools(console_logs, network_requests, errors, model)
            print("\n" + "="*80)
            print("ANALYSIS:")
            print("="*80)
            print(analysis)

        elif command == "analyze-patterns":
            if len(sys.argv) < 3:
                print("âŒ Error: data file required")
                sys.exit(1)

            data_file = sys.argv[2]
            model = sys.argv[3] if len(sys.argv) > 3 else "research"

            with open(data_file) as f:
                data = f.read()

            analysis = analyze_patterns(data, model)
            print("\n" + "="*80)
            print("PATTERN ANALYSIS:")
            print("="*80)
            print(analysis)

        elif command == "ask":
            if len(sys.argv) < 4:
                print("âŒ Error: model and question required")
                sys.exit(1)

            model = sys.argv[2]
            question = " ".join(sys.argv[3:])

            response = call_runpod(model, question)
            print("\n" + "="*80)
            print(f"RESPONSE FROM {model.upper()}:")
            print("="*80)
            print(response)

        else:
            print(f"âŒ Unknown command: {command}")
            print("Run without arguments to see usage")
            sys.exit(1)

    except FileNotFoundError as e:
        print(f"âŒ File not found: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
