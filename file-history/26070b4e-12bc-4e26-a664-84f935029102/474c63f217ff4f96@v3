{
    "python.defaultInterpreterPath": "/opt/homebrew/bin/python3",
    "claudeCode.preferredLocation": "panel",
    "editor.largeFileOptimizations": false,
    "http.systemCertificatesNode": true,
    "geminicodeassist.project": "hidef-zucchini-hjlpb",
    "editor.unicodeHighlight.ambiguousCharacters": false,
    "gitlens.ai.model": "vscode",
    "gitlens.ai.vscode.model": "copilot:gpt-4.1",
    "workbench.colorTheme": "Ayu Dark Bordered",
    "roo-cline.allowedCommands": [
        "git log",
        "git diff",
        "git show",
        "npm",
        "npm install",
        "printf",
        "mkdir",
        "cd",
        "curl",
        "ls",
        "echo",
        "uvx",
        "head",
        "grep-mcp",
        "which",
        "git",
        "node",
        "railway",
        "cat",
        "grep",
        "wc",
        "sleep"
    ],
    "roo-cline.deniedCommands": [],
    "komplete-kontrol.allowedCommands": [
        "git log",
        "git diff",
        "git show",
        "Run",
        "cd src",
        "npx vitest run services/automation/__tests__/AutomationManager.e2e.spec.ts",
        "cd",
        "npx",
        "npx vitest",
        "npx vitest run",
        "cat ~/Library/Application Support/Code/User/globalStorage/rooveterinaryinc.roo-cline/settings/mcp_settings.json",
        "cat",
        "find . -type f -name \"package.json\" -not -path \"*/node_modules/*\" -exec sed -i  s/@roo-code\\//@komplete-kontrol\\//g {} +",
        "find",
        "npx vitest run --reporter=basic 2>&1",
        "tail -30",
        "grep -r \"Roo Code Cloud\" --include=\"*.ts\" --include=\"*.tsx\" .",
        "wc -l",
        "grep",
        "wc",
        "do",
        "for pkg in \"@modelcontextprotocol/server-docker\" \"@modelcontextprotocol/server-postgres\" \"frida-mcp-server\" \"radare2-mcp\" \"mitmproxy-mcp-server\"",
        "if npm view \"$pkg\" version > /dev/null 2>&1",
        "npm search \"@modelcontextprotocol/server\" --json 2 > /dev/null",
        "head -100",
        "npm",
        "npm search",
        "head",
        "jq -r .[].name",
        "sort",
        "npm search @modelcontextprotocol",
        "jq",
        "npm search \"@modelcontextprotocol\" --json 2 > /dev/null",
        "curl -s \"https://registry.npmjs.org/-/v1/search?text=@modelcontextprotocol/server&size=50\"",
        "jq -r .objects[].package.name",
        "grep \"^@modelcontextprotocol/server-\"",
        "curl",
        "echo -n \"$pkg: \"",
        "npm view \"$pkg\" version 2 > /dev/null",
        "echo \"NOT FOUND\"",
        "done",
        "for",
        "for pkg",
        "for pkg in",
        "echo",
        "npm view",
        "for pkg in \"@modelcontextprotocol/server-github\" \"@modelcontextprotocol/server-puppeteer\" \"@modelcontextprotocol/server-brave-search\" \"@modelcontextprotocol/server-postgres\"",
        "timeout 5 npx",
        "echo TIMEOUT_OR_ERROR",
        "timeout 5",
        "timeout",
        "echo \"TIMEOUT_OR_ERROR\"",
        "head -20",
        "npm view mcp-docker repository homepage description main",
        "npm view mcp-docker",
        "which ghidra",
        "echo \"Ghidra not found in PATH\"",
        "which",
        "brew install --cask ghidra",
        "brew",
        "brew install",
        "cd ~/GhidraMCP",
        "ls -la",
        "ls",
        "pip3 install -r requirements.txt",
        "pip3 install",
        "pip3",
        "python3 bridge_mcp_ghidra.py --help 2>&1",
        "python3",
        "git",
        "git clone",
        "cd screenshot-to-code/backend",
        "cd looksmaxx-api",
        "uvicorn app.main:app --host 127.0.0.1 --port 8000",
        "uvicorn",
        "pip install -r requirements.txt",
        "pip",
        "pip install",
        "source venv/bin/activate",
        "source",
        "head -5",
        "find ~ -name \"mcp.json\" -path \"*KOMPLETE-KONTROL*\" 2 > /dev/null",
        "git add .",
        "git add",
        "git push -u origin main --force",
        "git push",
        "pnpm",
        "pnpm build",
        "pnpm build 2",
        "pnpm build 2>&1",
        "rm",
        "turbo",
        "turbo run",
        "turbo run bundle",
        "node"
    ],
    "komplete-kontrol.deniedCommands": [],

    // Roo Code - RunPod Abliterated Models Configuration
    // Using QUICK endpoint (cheapest) as default - switch URL to use other models
    "roo-cline.apiProvider": "openai-compatible",
    "roo-cline.openAiCompatibleApiKey": "rpa_8H2ANK7W7XGX7AN4H4LJX0AMQIUXJ3OO7T4S2XFX1ru6w3",
    "roo-cline.openAiCompatibleBaseUrl": "https://api.runpod.ai/v2/4s8uzmhs935609/openai/v1",
    "roo-cline.openAiCompatibleModelId": "DavidAU/Qwen3-4B-Thinking-2507-Claude-4.5-Opus-High-Reasoning-Distill-Heretic-Abliterated",

    // Other endpoints (change URL above to use):
    // Architect (32B): https://api.runpod.ai/v2/4oa1b4awkenwvn/openai/v1
    // Code (30B):      https://api.runpod.ai/v2/zvmsecj976oelz/openai/v1
    // Research (80B):  https://api.runpod.ai/v2/ghj3ehldsv8c8n/openai/v1

    // Keep Ollama config for backup
    "roo-cline.ollamaBaseUrl": "https://lu3h6pcpkdx2fs-11434.proxy.runpod.net",
    "roo-cline.ollamaModelId": "huihui_ai/deepseek-r1-abliterated:70b",

    "files.autoSave": "afterDelay",

    // RunPod GPU Monitor Extension
    "runpod.apiKey": "rpa_8H2ANK7W7XGX7AN4H4LJX0AMQIUXJ3OO7T4S2XFX1ru6w3",
    "runpod.refreshInterval": 30,
    "runpod.showCostInStatusBar": true,
    "runpod.endpoints": {
        "4oa1b4awkenwvn": {"name": "Architect", "gpu": "A100 80GB"},
        "zvmsecj976oelz": {"name": "Code", "gpu": "A100 80GB"},
        "ghj3ehldsv8c8n": {"name": "Research", "gpu": "A100 80GB"},
        "4s8uzmhs935609": {"name": "Quick", "gpu": "RTX 3090"}
    }
}