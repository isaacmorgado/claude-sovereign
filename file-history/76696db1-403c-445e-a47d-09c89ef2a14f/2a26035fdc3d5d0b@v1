# LibreChat Testing Results - 2026-01-15

## Test Environment
- **Location:** http://localhost:3080
- **Endpoint:** Featherless
- **MCP Servers:** 6 configured (55 tools total)
- **Models Tested:** 2 of 5

---

## Model Test Results

### ✅ Model 1: zetasepic/Qwen2.5-72B-Instruct-abliterated-v2

**Test Prompt:** "Deeply research using grep mcp, github mcp, and the internet to learn how to build a custom CLI tool for GoHighLevel"

**Status:** ✅ **SUCCESS**

**Response Quality:**
- Generated comprehensive guide with 6 steps
- Included code examples (Go, Cobra framework)
- Provided shell commands for GitHub searches
- Mentioned GoHighLevel API documentation
- Covered authentication, error handling, logging

**Response Content:**
1. Understand GoHighLevel Requirements
2. Set Up Development Environment (Install Go)
3. Leverage GitHub and Internet (search for relevant CLI tools and repos)
4. Build the CLI Tool (using Cobra framework)
5. Authentication and API Calls (Bearer token examples)
6. Error Handling and Logging (using logrus library)

**MCP Tools Used:**
- ⚠️ **No MCP tool calls detected in logs**
- Model generated response without explicitly calling grep, GitHub, or web search MCPs
- Response appears to be from model knowledge only

**Conversation ID:** 1a20302d-521b-44c2-abe6-772971c0666a

---

### ❌ Model 2: Qwen/Qwen3-Coder-30B-A3B-Instruct

**Test Prompt:** "Determine how google gemini can look for specific youtube videos, analyze the transcript and the video/audio itself and tell you what it is about so I can add this to my komplete-kontrol-cli project"

**Status:** ❌ **FAILED - Token Limit Error**

**Error Message:**
```
400 This model's maximum context length is 16384 tokens. However, you requested 32818 tokens (50 in the messages, 32768 in the completion). Please reduce the length of the messages or completion.
```

**Error Analysis:**
- Model context limit: 16384 tokens
- Requested: 32818 tokens (50 messages + 32768 completion)
- Root cause: `max_tokens` parameter in config likely set too high
- Current config: `max_tokens: 4096` in librechat.yaml
- Actual request: 32768 tokens (appears to be overriding config)

**MCP Tools Used:**
- ⚠️ **No MCP tool calls detected** (error occurred before completion)

**Conversation ID:** 4ad8bea4-d17a-4047-87ac-962c860b6728

---

## Models Not Yet Tested

### 3. Qwen/Qwen2.5-72B-Instruct
- **Type:** General purpose (non-abliterated)
- **Context:** 131K tokens
- **Use case:** General research, documentation

### 4. deepseek-ai/DeepSeek-R1-0528
- **Type:** Reasoning model with chain-of-thought
- **Context:** 32K tokens
- **Use case:** Complex problem-solving

### 5. deepseek-ai/DeepSeek-V3-0324
- **Type:** Fast general-purpose
- **Context:** 32K tokens
- **Use case:** Quick queries, code explanations

---

## MCP Tools Analysis

### Configuration Status
```bash
[MCP] Initialized with 6 configured servers and 55 tools.
```

**Available MCP Servers:**
1. **GitHub MCP** - 26 tools ✅
2. **Grep MCP** - 5 tools ✅
3. **Grep.app MCP** - 2 tools ✅
4. **DuckDuckGo Web Search** - 1 tool ✅
5. **Reddit MCP** - 20 tools ✅
6. **Tavily Deep Research** - 1 tool ✅

### MCP Tool Usage Observation

**Issue:** MCP tools are configured but NOT being called by models

**Evidence:**
- Log search for tool calls: `grep -iE "tool|mcp.*call|grep_|github_|duckduck"` returned NO results
- Models are responding from knowledge base only
- No evidence of web searches, GitHub searches, or grep operations

**Possible Causes:**
1. Models not prompted to use tools
2. LibreChat not passing tool definitions to models
3. Featherless endpoint may not support function calling
4. Models may need explicit instructions to use MCP tools

**Action Required:**
- Investigate Featherless tool support
- Check if custom endpoint supports function calling
- May need to enable tool use in librechat.yaml

---

## Configuration Issues

### Issue 1: Token Limit Configuration

**Problem:** Models requesting more tokens than context allows

**Current Configuration (librechat.yaml):**
```yaml
addParams:
  max_tokens: 4096
  temperature: 0.7
  top_p: 0.9
```

**Observed Behavior:**
- Config specifies 4096 max tokens
- Actual API requests using 32768 tokens
- Causing errors with models that have 16K context limits

**Solution Needed:**
- Reduce max_tokens to safe value (e.g., 2048-4096)
- Verify LibreChat isn't overriding this parameter
- Test with smaller token limits

### Issue 2: MCP Tools Not Being Invoked

**Problem:** Despite explicit prompts to "use grep mcp, github mcp, and the internet", models aren't calling MCP tools

**Current Configuration:**
- MCP servers: All 6 initialized successfully
- Tools available: 55 tools
- UI shows: "MCP Servers" button visible

**Possible Solutions:**
1. Check Featherless endpoint tool support
2. Add explicit function calling configuration
3. Test with OpenAI endpoint (known to support tools)
4. Verify MCP integration with custom endpoints

---

## Recommendations

### Immediate Actions

1. **Fix Token Limit Issue**
   ```yaml
   addParams:
     max_tokens: 2048  # Reduced from 4096
     temperature: 0.7
     top_p: 0.9
   ```

2. **Test Remaining Models** with simpler prompts to avoid token errors

3. **Investigate MCP Tool Support** for Featherless endpoint
   - Check Featherless API documentation for function calling
   - Test with OpenAI-compatible endpoints known to support tools
   - May need to add tool configuration to librechat.yaml

4. **Verify MCP Integration**
   - Check LibreChat docs for custom endpoint tool support
   - May need to enable tools explicitly for Featherless
   - Consider testing with built-in endpoints first (OpenAI, Anthropic)

### Testing Strategy

**Short-term:** Test with simple prompts that don't require MCP tools
- Example: "Explain how to use the Go Cobra library"
- Verify basic model functionality first

**Long-term:** Investigate and enable proper MCP tool integration
- Research Featherless function calling support
- Configure tool use if available
- Document working configuration

---

## Success Metrics

### ✅ Completed
- LibreChat running successfully
- Featherless endpoint configured
- All 5 models visible in UI
- At least 1 model working (abliterated model)
- MCP servers initialized (55 tools)

### ⚠️ Partial Success
- Models generate responses but don't use MCP tools
- Token limit issues with some models

### ❌ Not Working
- MCP tool invocation during prompts
- Some models hitting token limits

---

## Log Excerpts

### Successful Model Response
```
[Conversation: 1a20302d-521b-44c2-abe6-772971c0666a]
Model: zetasepic/Qwen2.5-72B-Instruct-abliterated-v2
Status: ✅ Success - Generated comprehensive guide
```

### Failed Model Response
```
[2026-01-15 06:30:26] ERROR: Operation aborted 400
This model's maximum context length is 16384 tokens.
However, you requested 32818 tokens (50 in messages, 32768 in completion).
Model: Qwen/Qwen3-Coder-30B-A3B-Instruct
Status: ❌ Failed - Token limit exceeded
```

### MCP Initialization
```
[2026-01-15 06:19:55] INFO: [MCP] Initialized with 6 configured servers and 55 tools.
[2026-01-15 06:19:55] INFO: [MCP][github] Initialized in: 1114ms
[2026-01-15 06:19:55] INFO: [MCP][grep] Initialized in: 1570ms
[2026-01-15 06:19:54] INFO: [MCP][websearch] Initialized in: 373ms
[2026-01-15 06:19:55] INFO: [MCP][grepapp] Initialized in: 417ms
[2026-01-15 06:19:55] INFO: [MCP][reddit] Initialized in: 443ms
[2026-01-15 06:19:55] INFO: [MCP][tavily] Initialized in: 458ms
```

---

## Next Steps

1. ✅ Update max_tokens in librechat.yaml
2. ⏳ Test remaining 3 models with simple prompts
3. ⏳ Research Featherless function calling support
4. ⏳ Document working MCP tool configuration (if possible)
5. ⏳ Create troubleshooting guide for common issues

---

**Test Date:** 2026-01-15 01:30 AM EST
**Tester:** Claude (automated testing via browser automation)
**Environment:** macOS, Docker LibreChat v0.8.2-rc2
