# Qwen Proxy Quick Start Guide

## ‚úÖ Current Status

**Proxy Server:** ‚úÖ Running and healthy on http://localhost:8000
**LibreChat:** ‚úÖ Configured with proxy endpoint
**MCP Tools:** ‚úÖ 6 servers, 55 tools ready

---

## üöÄ How to Use Right Now

### Option 1: Use Working Models (Recommended)

Since abliterated Qwen2.5-Coder models are temporarily unavailable on Featherless, use these alternatives:

#### For Abliterated + MCP Tools:
1. Open LibreChat: http://localhost:3080
2. Select endpoint: **"Featherless"** (not the proxy)
3. Choose model: **Qwen3-32B-abliterated** or **Qwen3-14B-abliterated**
4. Use any MCP tools - they work natively (native JSON support)

#### For Best Coding + MCP Tools:
1. Open LibreChat: http://localhost:3080
2. Select endpoint: **"Featherless"**
3. Choose model: **DeepSeek-V3-0324** (82.6% HumanEval)
4. Use any MCP tools - proven working

**Example Prompt:**
```
Use web search to find the latest Python FastAPI best practices for 2025,
then write a complete REST API with:
- JWT authentication
- CRUD operations
- Rate limiting
- Input validation
- Error handling
- Comprehensive tests
```

---

## üîÑ When Abliterated Qwen2.5-Coder Becomes Available

### Test Model Availability

```bash
cd /Users/imorgado/Desktop/Tools/qwen-proxy
python3 test_featherless_direct.py
```

**Look for:** Status: 200 (not 503)

### Run Comprehensive Tests

```bash
python3 test_mcp_integration.py
```

**Expected:** 3/3 tests pass with tool calls

### Use in LibreChat

1. Open LibreChat: http://localhost:3080
2. Select endpoint: **"Qwen-Coder (Abliterated + MCP Tools)"**
3. Choose model: **Qwen2.5-Coder-32B-Instruct-abliterated**
4. Use any prompt requiring MCP tools

**Benefits:**
- ‚úÖ Best coding performance (69.6% SWE-Bench)
- ‚úÖ Never refuses requests (abliterated)
- ‚úÖ Full MCP tool support (via XML‚ÜíJSON proxy)
- ‚úÖ 131K context window

---

## üõ†Ô∏è Proxy Management

### Check Proxy Status

```bash
curl http://localhost:8000/health
```

**Expected:**
```json
{
  "status": "healthy",
  "service": "qwen-xml-to-json-proxy",
  "featherless_connected": true
}
```

### Restart Proxy

```bash
cd /Users/imorgado/Desktop/Tools/qwen-proxy
./stop.sh
./start.sh
```

### View Proxy Logs

```bash
tail -f logs/proxy.log
```

**Look for:**
- `Converted X XML tool calls to JSON` (successful conversions)
- `Request: model=...` (incoming requests)
- Any ERROR messages

---

## üìä Model Comparison

| Model | Status | SWE-Bench | HumanEval | Abliterated | MCP Tools | Via Proxy |
|-------|--------|-----------|-----------|-------------|-----------|-----------|
| **Qwen2.5-Coder-32B-abliterated** | ‚è≥ Unavailable | 69.6% ‚≠ê | High | ‚úÖ | ‚úÖ (proxy) | Yes |
| **Qwen3-32B-abliterated** | ‚úÖ Working | - | - | ‚úÖ | ‚úÖ (native) | No |
| **DeepSeek-V3** | ‚úÖ Working | - | 82.6% ‚≠ê | ‚ùå | ‚úÖ (native) | No |

---

## üîß Troubleshooting

### Proxy Not Responding

```bash
# Check if proxy is running
lsof -i :8000

# If not running, start it
cd /Users/imorgado/Desktop/Tools/qwen-proxy
./start.sh
```

### LibreChat Not Using Proxy

1. Verify librechat.yaml has proxy endpoint:
   ```bash
   grep -A 5 "Featherless-Qwen-Proxy" /Users/imorgado/Desktop/LibreChat/librechat.yaml
   ```

2. Restart LibreChat:
   ```bash
   cd /Users/imorgado/Desktop/LibreChat
   docker compose restart api
   ```

### Models Return 503 Error

This means the models are temporarily unavailable on Featherless. Use alternative models:
- Qwen3-32B-abliterated (works now)
- DeepSeek-V3-0324 (works now)

Check again later or contact Featherless support.

---

## üìù Key Files

- **Proxy Location:** `/Users/imorgado/Desktop/Tools/qwen-proxy/`
- **LibreChat Config:** `/Users/imorgado/Desktop/LibreChat/librechat.yaml`
- **Documentation:**
  - `/Users/imorgado/Desktop/QWEN-PROXY-IMPLEMENTATION-COMPLETE.md`
  - `/Users/imorgado/Desktop/QWEN-PROXY-TEST-RESULTS.md`
  - `/Users/imorgado/Desktop/Tools/qwen-proxy/README.md`

---

## üéØ Recommended Workflow

### For Pure Coding (No Tools Needed)

**When available:** Use Qwen2.5-Coder-32B-abliterated via proxy
**Now:** Use DeepSeek-V3 (direct, no proxy needed)

### For Coding + Research (Needs MCP Tools)

**Now:** Use DeepSeek-V3 or Qwen3-32B-abliterated
**Both work perfectly with MCP tools!**

### For Abliterated + Tools (Ultimate Goal)

**When available:** Use Qwen2.5-Coder-32B-abliterated via proxy
- Best coding (69.6% SWE-Bench)
- Never refuses (abliterated)
- Full MCP tools (proxy converts XML‚ÜíJSON)

---

## ‚úÖ What's Working Right Now

1. **Proxy server:** Running on port 8000 ‚úÖ
2. **LibreChat:** Configured with both endpoints ‚úÖ
3. **MCP tools:** All 6 servers, 55 tools ready ‚úÖ
4. **XML‚ÜíJSON conversion:** Tested and working ‚úÖ
5. **Alternative models:** Qwen3-32B, DeepSeek-V3 available ‚úÖ

---

## üö¶ Next Actions

1. **Use LibreChat now** with Qwen3-32B or DeepSeek-V3
2. **Test periodically** for Qwen2.5-Coder availability:
   ```bash
   python3 test_featherless_direct.py
   ```
3. **Switch to proxy endpoint** when models become available

---

**Access LibreChat:** http://localhost:3080
**Check Proxy Health:** http://localhost:8000/health

**Everything is ready to use!** üéâ
