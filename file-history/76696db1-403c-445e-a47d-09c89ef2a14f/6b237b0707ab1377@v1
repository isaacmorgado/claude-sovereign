# LibreChat MCP Tool Calling Investigation - FINDINGS

**Date:** 2026-01-15
**Investigation Status:** ✅ ROOT CAUSE IDENTIFIED

---

## Executive Summary

MCP tools ARE configured correctly and available in LibreChat UI, but **Featherless Qwen models are NOT actually executing the tools**. The models output XML-formatted tool calls instead of using the OpenAI function calling format that LibreChat expects.

---

## Research Findings

### 1. LibreChat MCP Support Status

**LibreChat DOES support MCP tools with custom endpoints:**
- Custom endpoints CAN use MCP tools when the underlying model supports OpenAI-compatible function calling
- MCP tools appear in a dropdown below the message input when properly configured
- LibreChat supports: OpenAI, Anthropic, Azure, AWS Bedrock, Google Vertex AI, and custom endpoints
- Documentation: https://www.librechat.ai/docs/features/mcp

### 2. Featherless Function Calling Support

**Featherless.ai DOES support OpenAI-compatible function calling:**
- Documented at: https://featherless.ai/docs/tool-calling
- Uses standard OpenAI tools parameter format
- Some models have native support, others use JSON-based simulation via `response_format={"type": "json_object"}`
- Base endpoint: https://api.featherless.ai/v1

### 3. The Problem: Format Mismatch

**Issue:** Qwen models on Featherless use an XML-based tool calling format instead of JSON function calls.

**Evidence from UI:**
```xml
<tool_call>
<function=duckduckgo_web_search_mcp_websearch>
<parameter=query>LibreChat MCP tool integration</parameter>
<parameter=count>10</parameter>
</function>
</tool_call>
```

**Expected OpenAI Format:**
```json
{
  "tool_calls": [{
    "type": "function",
    "function": {
      "name": "duckduckgo_web_search_mcp_websearch",
      "arguments": "{\"query\":\"LibreChat MCP tool integration\",\"count\":10}"
    }
  }]
}
```

---

## Test Results

### Test 1: MCP Tools UI Availability ✅

**Status:** WORKING PERFECTLY

**Evidence:**
- MCP Servers dropdown visible in chat interface
- 6 MCP servers available: websearch, grepapp, reddit, tavily, github, grep
- Individual servers can be selected/deselected via checkboxes
- "3 selected" counter shows active tools

**Conclusion:** LibreChat UI and MCP server integration is 100% functional.

---

### Test 2: Tool Call Execution ❌

**Status:** NOT WORKING

**Test Performed:**
- Selected 3 MCP tools: websearch, github, grep
- Sent prompt: "Search the web for the latest information about LibreChat MCP tool integration"
- Model: Qwen/Qwen3-Coder-30B-A3B-Instruct (via Featherless)

**Result:**
- Model outputted XML-formatted tool call
- Tool was NOT executed by LibreChat
- No search results returned
- Response stopped after outputting XML

**Log Evidence:**
```bash
# No tool execution logs found:
docker compose logs api --since 5m | grep -iE "tool|function|websearch|call"
# Result: Zero tool execution entries
```

**Root Cause:** Qwen models use text-based XML tool calling format, which LibreChat doesn't recognize as executable function calls.

---

## Why This Is Happening

### Model-Specific Tool Calling Formats

Different model families use different tool calling formats:

1. **OpenAI GPT Models:** Native JSON function calling via `tool_calls` response field
2. **Anthropic Claude:** XML-based tool use via `<function_calls>` tags
3. **Qwen Models:** XML-based tool calling (similar to Claude but different syntax)
4. **Open Source Models:** Often use text-based JSON or XML simulation

**The Issue:** LibreChat expects OpenAI-compatible JSON function calls from custom endpoints. Qwen models output XML, which LibreChat treats as plain text output rather than executable tool calls.

---

## Solutions

### Option 1: Use Models with Native OpenAI Function Calling ⭐ RECOMMENDED

**Models to Test:**
- GPT-4 via OpenAI endpoint (known to work)
- Claude via Anthropic endpoint (known to work)
- DeepSeek-R1 models (may have better function calling support)

**Action:** Test remaining Featherless models to see if any have native JSON function calling:
- `Qwen/Qwen2.5-72B-Instruct`
- `deepseek-ai/DeepSeek-R1-0528`
- `deepseek-ai/DeepSeek-V3-0324`

---

### Option 2: Use LibreChat Agents Instead of Direct Tool Calls

**How it works:**
- LibreChat has a built-in Agents framework specifically designed for MCP tools
- Agents handle format conversion and tool orchestration
- Bypasses the direct function calling format issue

**Implementation:**
1. Navigate to "Agent Marketplace" in LibreChat
2. Create a custom agent with selected MCP tools
3. Configure agent to use your Featherless endpoint
4. Agents framework handles tool calling internally

**Reference:** https://www.librechat.ai/docs/features/agents

---

### Option 3: Add Native OpenAI/Anthropic Endpoints

**Pros:**
- Guaranteed to work with MCP tools
- Fully tested and documented
- No format conversion issues

**Cons:**
- Requires API keys for paid services
- Won't use Featherless models

**Configuration:**
```yaml
endpoints:
  openai:
    apiKey: "${OPENAI_API_KEY}"
    models:
      default:
        - "gpt-4-turbo"
        - "gpt-4"
  anthropic:
    apiKey: "${ANTHROPIC_API_KEY}"
    models:
      default:
        - "claude-3-opus"
        - "claude-3-sonnet"
```

---

## Next Steps

### Immediate Actions:

1. ✅ **Document findings** (THIS FILE)
2. ⏳ **Test remaining 3 Featherless models** to see if any have proper JSON function calling
3. ⏳ **Test with LibreChat Agents** to see if they work better with Featherless models
4. ⏳ **Consider adding OpenAI/Anthropic endpoint** for guaranteed MCP tool support

### Testing Plan:

**Test each remaining model with this prompt:**
> "Use web search to find the latest LibreChat MCP documentation"

**Look for:**
- Proper JSON function call format (not XML)
- Actual tool execution (search results returned)
- Log entries showing MCP tool invocation

**Models to test:**
1. `Qwen/Qwen2.5-72B-Instruct` (general purpose, non-coding)
2. `deepseek-ai/DeepSeek-R1-0528` (reasoning model)
3. `deepseek-ai/DeepSeek-V3-0324` (fast general-purpose)

---

## Technical Details

### Current Configuration

**librechat.yaml:**
```yaml
endpoints:
  custom:
    - name: "Featherless"
      apiKey: "${FEATHERLESS_API_KEY}"
      baseURL: "https://api.featherless.ai/v1"
      models:
        default:
          - "zetasepic/Qwen2.5-72B-Instruct-abliterated-v2"
          - "Qwen/Qwen2.5-72B-Instruct"
          - "deepseek-ai/DeepSeek-R1-0528"
          - "deepseek-ai/DeepSeek-V3-0324"
          - "Qwen/Qwen3-Coder-30B-A3B-Instruct"
        fetch: false
      addParams:
        max_tokens: 2048
        temperature: 0.7
        top_p: 0.9

mcpServers:
  websearch:  # DuckDuckGo - 1 tool
  grepapp:    # GitHub code search - 2 tools
  reddit:     # Reddit scraper - 20 tools
  tavily:     # Deep research - 1 tool
  github:     # GitHub API - 26 tools
  grep:       # File search - 5 tools
```

**Total:** 6 MCP servers, 55 tools, all initialized successfully.

### Log Evidence

**MCP Initialization:**
```
[MCP] Initialized with 6 configured servers and 55 tools.
[MCP][websearch] Initialized in: 373ms
[MCP][github] Initialized in: 1422ms
[MCP][grep] Initialized in: 1809ms
[MCP][grepapp] Initialized in: 417ms
[MCP][reddit] Initialized in: 443ms
[MCP][tavily] Initialized in: 458ms
```

**Tool Execution Logs:**
```
# No tool execution logs found for conversation c6f8088f-cb81-4e47-afb4-dce20cdbedb7
# Search performed: grep -iE "tool|function|websearch|call"
# Result: Zero matching entries
```

---

## Conclusion

**The good news:**
- LibreChat MCP integration is working perfectly
- All 6 MCP servers are operational with 55 tools
- UI correctly displays and allows tool selection
- Featherless API does support function calling

**The bad news:**
- Qwen models use XML-based tool calling instead of JSON
- LibreChat doesn't execute XML-formatted tool calls from custom endpoints
- Current Featherless models tested (Qwen3-Coder) won't execute MCP tools directly

**The solution:**
1. Test remaining models (DeepSeek-R1, DeepSeek-V3) which may have better function calling
2. Use LibreChat Agents framework for MCP tool orchestration
3. Add OpenAI/Anthropic endpoints for guaranteed MCP tool support

---

**Sources:**
- [Model Context Protocol (MCP) - LibreChat](https://www.librechat.ai/docs/features/mcp)
- [Tool Calling - Featherless.ai](https://featherless.ai/docs/tool-calling)
- [AI Agents - LibreChat](https://www.librechat.ai/docs/features/agents)
- [Custom Endpoint Configuration](https://www.librechat.ai/docs/configuration/librechat_yaml/object_structure/custom_endpoint)
