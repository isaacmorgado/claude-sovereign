# LibreChat Model Usage Guide - When to Use Each Model

**Date:** 2026-01-15
**Config:** 6 models optimized for different tasks

---

## Quick Reference

| Model | Size | Use For | Abliterated | MCP Tools | Best Feature |
|-------|------|---------|-------------|-----------|--------------|
| **Qwen3-32B** | 32B | Architecture research | ✅ | ✅ | Largest abliterated with tools |
| **Qwen3-14B** | 14B | General research | ✅ | ✅ | Balanced size + tools |
| **Qwen2.5-Coder-32B** | 32B | Pure coding | ✅ | ❌ | 69.6% SWE-Bench, 131K context |
| **QwQ-32B** | 32B | Complex reasoning | ✅ | ❌ | High-level problem solving |
| **DeepSeek-V3** | 67B | Coding + research | ❌ | ✅ | 82.6% HumanEval + tools |
| **DeepSeek-R1** | - | Reasoning + research | ❌ | ✅ | Chain-of-thought + tools |

---

## Decision Tree

### Do you need abliteration (uncensored responses)?

**YES → Continue to next question**

### Do you need MCP tools (web search, GitHub, grep)?

**YES → Abliterated + MCP Tools:**
- Architecture research → **Qwen3-32B-abliterated**
- General research → **Qwen3-14B-abliterated**

**NO → Abliterated, No Tools:**
- Pure coding → **Qwen2.5-Coder-32B-abliterated** (BEST coding performance)
- Reasoning/problem-solving → **QwQ-32B-abliterated**

### Don't need abliteration but need best performance?

**Coding + MCP Tools:**
- **DeepSeek-V3** (82.6% HumanEval, 67B parameters, proven tool execution)

**Reasoning + MCP Tools:**
- **DeepSeek-R1** (chain-of-thought reasoning)

---

## Model Details

### 1. roslein/Qwen3-32B-abliterated

**Use For:**
- Architecture research
- System design
- Large codebase analysis
- When you need the largest abliterated model with tool support

**Strengths:**
- 32B parameters (largest abliterated with MCP tools)
- 32K context window
- Full MCP tool integration (grep, GitHub, web search)
- Uncensored responses

**Limitations:**
- Not specialized for pure coding (use Qwen2.5-Coder for that)

**Example Prompts:**
```
Use web search and GitHub to research microservices architecture patterns for 2025

Analyze this codebase structure using grep MCP and suggest improvements

Search GitHub for examples of distributed systems using Rust
```

---

### 2. mlabonne/Qwen3-14B-abliterated

**Use For:**
- General research tasks
- Documentation writing
- Code explanations
- Quick queries with tool support

**Strengths:**
- 14B parameters (balanced size/performance)
- 32K context window
- Fast response times
- Full MCP tool integration
- Uncensored responses

**Limitations:**
- Smaller than 32B variant
- Not specialized for pure coding

**Example Prompts:**
```
Use web search to find best practices for React Server Components 2025

Search GitHub for modern authentication patterns in Next.js apps

Use grep MCP to analyze error handling in this project
```

---

### 3. huihui-ai/Qwen2.5-Coder-32B-Instruct-abliterated ⭐ **BEST FOR PURE CODING**

**Use For:**
- Complex code generation
- Refactoring large codebases
- Algorithm implementation
- Production-ready code
- When you DON'T need external tools

**Strengths:**
- **69.6% SWE-Bench Verified** (production-ready code)
- **131K context window** (largest in config)
- "Open-source leader for coding" (2025)
- Surpasses DeepSeek-Coder-33B
- Versatile across languages (Python, JS, C++, Rust, Go)
- Uncensored responses

**Limitations:**
- ❌ **Cannot use MCP tools** (XML tool format, incompatible)
- Use DeepSeek-V3 when you need tools

**Example Prompts:**
```
Write a complete REST API in FastAPI with authentication, rate limiting, and tests

Refactor this React component to use modern patterns and TypeScript

Implement a distributed cache with Redis and handle all edge cases

Create a CLI tool in Rust for parsing and transforming JSON files
```

**When NOT to use:**
- When you need web search, GitHub search, or grep tools
- When you need to research while coding
- Switch to DeepSeek-V3 for those tasks

---

### 4. huihui-ai/QwQ-32B-abliterated

**Use For:**
- Complex mathematical reasoning
- Problem-solving challenges
- Algorithm design
- Logical puzzles
- When you DON'T need external tools

**Strengths:**
- High-level reasoning capabilities
- Strong math and coding
- 131K context window
- Lightweight 32B package
- Uncensored responses

**Limitations:**
- ❌ **Cannot use MCP tools**
- Use DeepSeek-R1 when you need reasoning + tools

**Example Prompts:**
```
Design an algorithm to solve the traveling salesman problem efficiently

Analyze this complex system and identify potential bottlenecks

Solve this mathematical proof step by step

Design a data structure for efficient range queries with updates
```

---

### 5. deepseek-ai/DeepSeek-V3-0324 ⭐ **BEST FOR CODING + MCP TOOLS**

**Use For:**
- Coding tasks that require research
- When you need web search while coding
- GitHub code examples integration
- Complex debugging with external references
- When abliteration isn't required

**Strengths:**
- **82.6% HumanEval** (matches Sonnet 4.5/GLM 4.7)
- **67B parameters** (most powerful in config)
- **Proven MCP tool execution** (tested successfully)
- Won 5 out of 7 coding benchmarks
- Strong reasoning capabilities
- 64K context window

**Limitations:**
- ❌ **Not abliterated** (may refuse some prompts)
- Use Qwen models when abliteration needed

**Example Prompts:**
```
Use web search to find the latest React 19 features, then implement them in this component

Search GitHub for examples of WebSocket implementation in Node.js and adapt for my use case

Use grep to find all API endpoints in this project, then generate OpenAPI documentation

Research best practices for database connection pooling, then implement it
```

**Why Choose Over Qwen2.5-Coder:**
- Need MCP tools (web search, GitHub, grep)
- Need to research while coding
- Larger model (67B vs 32B)
- Proven real-world tool execution

---

### 6. deepseek-ai/DeepSeek-R1-0528

**Use For:**
- Complex reasoning with tool support
- Research-heavy problem solving
- When you need chain-of-thought + tools
- Debugging complex issues

**Strengths:**
- Chain-of-thought reasoning
- Full MCP tool integration
- Good for research + analysis

**Limitations:**
- ❌ **Not abliterated**
- Not as strong at pure coding as DeepSeek-V3 or Qwen2.5-Coder

**Example Prompts:**
```
Use web search to research this error, analyze possible causes, and suggest a fix

Search GitHub for similar issues and their solutions, then apply to my case

Use grep to analyze this codebase and reason about the bug's root cause
```

---

## Workflow Examples

### Scenario 1: Building a New Feature (No External Research Needed)

**Task:** Implement user authentication with JWT tokens

**Model:** Qwen2.5-Coder-32B-abliterated

**Why:**
- Pure coding task
- No need for web search or GitHub examples
- Best coding performance (69.6% SWE-Bench)
- 131K context for large implementation

**Prompt:**
```
Implement a complete user authentication system with:
- JWT token generation and validation
- Password hashing with bcrypt
- Refresh token rotation
- Rate limiting on login attempts
- Session management
- Complete error handling
- TypeScript types
- Unit tests
```

---

### Scenario 2: Building a Feature (Needs Research)

**Task:** Implement real-time collaboration with WebSockets

**Model:** DeepSeek-V3-0324

**Why:**
- Need to research latest WebSocket patterns
- Need GitHub code examples
- Best coding + MCP tools (82.6% HumanEval)

**Prompt:**
```
Use web search to find the latest WebSocket best practices for 2025.
Search GitHub for production-ready WebSocket implementations in Node.js.
Then implement a real-time collaboration system with:
- WebSocket server setup
- Connection pooling
- State synchronization
- Conflict resolution
- Reconnection handling
- Complete TypeScript implementation
```

---

### Scenario 3: Architecture Research

**Task:** Design microservices architecture

**Model:** Qwen3-32B-abliterated

**Why:**
- Architecture-focused task
- Need web search for patterns
- Need GitHub examples
- Largest abliterated model with tools

**Prompt:**
```
Use web search to research microservices architecture patterns for 2025.
Use GitHub MCP to find examples of successful microservices implementations.
Then design a microservices architecture for an e-commerce platform including:
- Service boundaries
- Communication patterns
- Data consistency strategies
- Deployment architecture
- Monitoring and observability
```

---

### Scenario 4: Complex Algorithm (No Tools Needed)

**Task:** Design efficient data structure

**Model:** QwQ-32B-abliterated

**Why:**
- Pure reasoning task
- No external research needed
- High-level problem solving

**Prompt:**
```
Design a data structure that supports:
- O(log n) insert, delete, and search
- O(1) findMin and findMax
- O(k) range queries for k elements
- Efficient memory usage

Provide:
1. Detailed design explanation
2. Time complexity analysis
3. Space complexity analysis
4. Implementation in Python
5. Edge cases handling
```

---

### Scenario 5: Debugging with Research

**Task:** Fix complex production bug

**Model:** DeepSeek-V3-0324

**Why:**
- Need to research error messages
- Need GitHub for similar issues
- Need grep to analyze codebase
- Best reasoning + tools

**Prompt:**
```
Use grep MCP to analyze all error handling in this project.
Use web search to research this error: "ENAMETOOLONG: name too long".
Search GitHub for similar issues and their solutions.

Then:
1. Identify root cause
2. Explain why it happens
3. Provide fix with tests
4. Suggest preventive measures
```

---

## Performance Comparison Summary

### Pure Coding Performance

1. **Qwen2.5-Coder-32B** - 69.6% SWE-Bench ⭐ **BEST**
2. **DeepSeek-V3** - 82.6% HumanEval
3. **Qwen3-32B** - Good for architecture

### Coding + Tools Performance

1. **DeepSeek-V3** - 82.6% HumanEval + Proven tools ⭐ **BEST**
2. **Qwen3-32B** - Largest abliterated with tools
3. **Qwen3-14B** - Balanced size with tools

### Context Window

1. **Qwen2.5-Coder-32B** - 131K ⭐ **LARGEST**
2. **QwQ-32B** - 131K
3. **DeepSeek-V3** - 64K
4. **Qwen3** models - 32K

---

## Quick Decision Matrix

### I need...

**Best possible coding + no tools needed:**
→ Qwen2.5-Coder-32B-abliterated

**Good coding + MCP tools + OK with non-abliterated:**
→ DeepSeek-V3-0324

**Architecture research + MCP tools + abliterated:**
→ Qwen3-32B-abliterated

**General research + MCP tools + abliterated:**
→ Qwen3-14B-abliterated

**Complex reasoning + no tools + abliterated:**
→ QwQ-32B-abliterated

**Reasoning + MCP tools + OK with non-abliterated:**
→ DeepSeek-R1-0528

---

## Configuration Applied

All 6 models are now active in LibreChat at `http://localhost:3080`

**To restart LibreChat:**
```bash
cd /Users/imorgado/Desktop/LibreChat
docker compose restart api
```

**To verify models loaded:**
```bash
docker compose logs api | grep "models loaded" | tail -5
```

---

## Next Steps

1. ✅ Configuration updated with all 6 models
2. ⏳ Restart LibreChat to load new models
3. ⏳ Test each model with appropriate tasks
4. ⏳ Document performance observations

---

**Pro Tip:** Start conversations by telling the model what tools you expect it to use:

```
Use web search and GitHub MCP to research...  (DeepSeek-V3 or Qwen3)
Implement this feature with full production quality...  (Qwen2.5-Coder)
Design the architecture for...  (Qwen3-32B)
Solve this algorithmic problem...  (QwQ-32B)
```
