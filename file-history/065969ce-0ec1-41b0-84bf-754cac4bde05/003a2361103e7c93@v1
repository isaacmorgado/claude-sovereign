#!/usr/bin/env python3
"""
Complete kenkais.com scraper - explores all sections: Projects, Exclusive, Agency, Resources
"""

import asyncio
import time
import json
from playwright.async_api import async_playwright

SITE_URL = "https://www.kenkais.com/agency"
ACCESS_CODE = "9111"


async def scrape_section(page, section_name, section_url):
    """Scrape content from a specific section"""
    print(f"\n{'='*60}")
    print(f"Section: {section_name}")
    print(f"URL: {section_url}")
    print(f"{'='*60}")

    try:
        await page.goto(section_url)
        await page.wait_for_timeout(3000)

        # Take screenshot
        screenshot = f"kenkais_complete_{section_name.lower().replace(' ', '_')}.png"
        await page.screenshot(path=screenshot)

        # Expand dropdowns
        expanded = await page.evaluate("""
            () => {
                let count = 0;
                ['[aria-expanded="false"]', 'details:not([open])', '.collapsed'].forEach(sel => {
                    document.querySelectorAll(sel).forEach(el => {
                        try {
                            if (el.tagName === 'DETAILS') el.open = true;
                            else el.click();
                            count++;
                        } catch(e) {}
                    });
                });
                return count;
            }
        """)

        if expanded > 0:
            print(f"    âœ“ Expanded {expanded} dropdowns")
            await page.wait_for_timeout(1000)

        # Extract content
        content = await page.evaluate("() => document.body.innerText")
        print(f"    âœ“ Extracted {len(content)} characters")

        # Save
        filename = f"kenkais_complete_{section_name.lower().replace(' ', '_')}.txt"
        with open(filename, "w", encoding="utf-8") as f:
            f.write(f"# {section_name}\n\n")
            f.write(f"**URL**: {section_url}\n")
            f.write(f"**Extracted**: {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write("---\n\n")
            f.write(content)

        print(f"    âœ“ Saved to: {filename}")

        return {
            'section': section_name,
            'url': section_url,
            'file': filename,
            'screenshot': screenshot,
            'chars': len(content)
        }

    except Exception as e:
        print(f"    âŒ Error: {e}")
        return None


async def scrape_kenkais_complete():
    print("=" * 70)
    print("Kenkais.com COMPLETE Scraper")
    print("All Sections: Projects, Exclusive, Agency, Resources")
    print("=" * 70)
    print()

    async with async_playwright() as p:
        print("[1/3] Launching browser...")
        browser = await p.chromium.launch(
            headless=False,
            args=["--disable-blink-features=AutomationControlled"],
        )

        context = await browser.new_context(
            viewport={"width": 1920, "height": 1080},
            user_agent="Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36",
        )

        page = await context.new_page()

        await page.add_init_script("""
            Object.defineProperty(navigator, 'webdriver', {get: () => undefined});
        """)

        try:
            print("[2/3] Initial setup and code entry...")
            await page.goto(SITE_URL)
            await page.wait_for_timeout(3000)

            # Enter code
            try:
                code_input = await page.wait_for_selector('input[type="text"]', timeout=3000)
                if code_input:
                    for digit in ACCESS_CODE:
                        await code_input.type(digit)
                        await page.wait_for_timeout(200)
                    await page.keyboard.press("Enter")
                    await page.wait_for_timeout(2000)
                    print("    âœ“ Access code entered")
            except:
                print("    â„¹ï¸  No code prompt")

            # Close modal to see navigation
            try:
                await page.keyboard.press("Escape")
                await page.wait_for_timeout(1000)
                print("    âœ“ Modal closed")
            except:
                pass

            print("[3/3] Scraping all sections...")

            sections = [
                ("Projects", "https://www.kenkais.com/projects"),
                ("Exclusive", "https://www.kenkais.com/exclusive"),
                ("Agency", "https://www.kenkais.com/agency"),
                ("Resources", "https://www.kenkais.com/resources"),
            ]

            all_results = []

            for section_name, section_url in sections:
                result = await scrape_section(page, section_name, section_url)
                if result:
                    all_results.append(result)

            # Create summary
            print("\n" + "=" * 70)
            print("Creating comprehensive summary...")
            print("=" * 70)

            with open("kenkais_complete_summary.md", "w", encoding="utf-8") as f:
                f.write("# Kenkais.com Complete Extraction\n\n")
                f.write(f"**Extracted**: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"**Sections**: {len(all_results)}/4\n\n")
                f.write("---\n\n")

                f.write("## Sections Extracted\n\n")
                total_chars = 0
                for result in all_results:
                    f.write(f"### {result['section']}\n\n")
                    f.write(f"- **URL**: {result['url']}\n")
                    f.write(f"- **Content**: {result['chars']:,} characters\n")
                    f.write(f"- **File**: `{result['file']}`\n")
                    f.write(f"- **Screenshot**: `{result['screenshot']}`\n\n")
                    total_chars += result['chars']

                f.write(f"\n**Total Content**: {total_chars:,} characters\n\n")

                f.write("---\n\n")
                f.write("## Files Created\n\n")
                for result in all_results:
                    f.write(f"- `{result['file']}`\n")
                    f.write(f"- `{result['screenshot']}`\n")

            print(f"\nâœ… Complete! Extracted {len(all_results)} sections")
            print("ğŸ“„ Summary: kenkais_complete_summary.md")
            print()

            return all_results

        except Exception as e:
            print(f"\nâŒ Error: {e}")
            import traceback
            traceback.print_exc()

        finally:
            print("\nClosing in 15 seconds...")
            await asyncio.sleep(15)
            await browser.close()


if __name__ == "__main__":
    result = asyncio.run(scrape_kenkais_complete())

    if result and len(result) > 0:
        print("=" * 70)
        print("ğŸ‰ COMPLETE EXTRACTION SUCCESSFUL!")
        print("=" * 70)
        print()
        print(f"âœ… Extracted {len(result)} sections successfully")
        print("ğŸ“ Check kenkais_complete_* files for all content")
        print()
    else:
        print("=" * 70)
        print("âš ï¸  EXTRACTION INCOMPLETE")
        print("=" * 70)
