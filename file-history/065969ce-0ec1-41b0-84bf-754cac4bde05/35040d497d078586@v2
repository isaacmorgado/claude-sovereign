#!/usr/bin/env python3
"""
Simple scraper for kenkais.com agency courses
Uses manual browser interaction for reliability
"""

import asyncio
from crawl4ai import AsyncWebCrawler, CrawlerRunConfig, LLMExtractionStrategy, LLMConfig
from crawl4ai.async_configs import BrowserConfig

# API Keys
ZHIPUAI_API_KEY = "9a58c7331504f3cbaef3f2f95cb375b.BrfNpV8TbeF5tCaK"

# Site info
SITE_URL = "https://www.kenkais.com/agency"
PASSWORD = "9111"


async def scrape_kenkais():
    """Scrape kenkais courses with visible browser"""

    print("=" * 70)
    print("Kenkais.com Agency Course Scraper")
    print("=" * 70)
    print()
    print(f"Site: {SITE_URL}")
    print(f"Password: {PASSWORD}")
    print()
    print("The browser will open. Please:")
    print("1. Enter password: 9111")
    print("2. Browse to the courses you want to scrape")
    print("3. Come back here and press Enter")
    print()
    input("Press Enter to open browser...")
    print()

    # GLM-4-Long for comprehensive extraction
    llm_config = LLMConfig(
        provider="zhipu/glm-4-long",
        api_token=ZHIPUAI_API_KEY,
        temperature=0.7,
    )

    extraction_strategy = LLMExtractionStrategy(
        llm_config=llm_config,
        instruction="""
        Extract ALL courses from this page with complete information.

        For each course found, provide:
        - Course title
        - Course description
        - Topics covered
        - Duration/length
        - Price (if shown)
        - Prerequisites (if mentioned)
        - Learning outcomes/objectives
        - Course modules/sections
        - Instructor name (if shown)
        - Course URL/link

        Format as:

        ## Course: [Title]

        **Description**: [full description]

        **Topics**:
        - [topic 1]
        - [topic 2]
        ...

        **Duration**: [duration]
        **Price**: [price]
        **Prerequisites**: [prerequisites]

        **Learning Outcomes**:
        - [outcome 1]
        - [outcome 2]
        ...

        **Modules**:
        1. [module 1]
        2. [module 2]
        ...

        **Instructor**: [instructor name]
        **Link**: [course URL]

        ---

        Continue for all courses found on the page.
        If there are navigation elements to other course pages, mention them.
        """,
    )

    # Browser config - visible browser
    browser_config = BrowserConfig(
        headless=False,
        viewport_width=1920,
        viewport_height=1080,
    )

    async with AsyncWebCrawler(config=browser_config, verbose=True) as crawler:
        # Step 1: Open site
        print("Opening site...")
        print()

        initial_result = await crawler.arun(url=SITE_URL)

        print()
        print("=" * 70)
        print("BROWSER IS OPEN")
        print("=" * 70)
        print()
        print("üëâ In the browser window:")
        print("   1. Enter password: 9111")
        print("   2. Navigate to all the course pages")
        print("   3. Come back here when ready")
        print()
        print("Press Enter when you're on the page you want to scrape...")
        input()
        print()

        # Step 2: Extract from current page
        print("Extracting course information...")
        print()

        result = await crawler.arun(
            url=SITE_URL,
            config=CrawlerRunConfig(extraction_strategy=extraction_strategy),
        )

        if result and result.markdown:
            print("‚úÖ Extraction successful!")
            print(f"üìä Extracted: {len(result.markdown)} characters")
            print()

            # Save
            output_file = "kenkais_agency_courses.md"
            with open(output_file, "w", encoding="utf-8") as f:
                f.write("# Kenkais.com Agency Courses\n\n")
                f.write(f"**Source**: {SITE_URL}\n")
                f.write("**Model**: GLM-4-Long (ZhipuAI)\n\n")
                f.write("---\n\n")
                f.write(result.markdown)

            print(f"üíæ Saved to: {output_file}")
            print()

            # Preview
            print("=" * 70)
            print("Content Preview")
            print("=" * 70)
            print()
            preview_length = min(1500, len(result.markdown))
            print(result.markdown[:preview_length])
            if len(result.markdown) > 1500:
                print("\n... (see full output in file)")
            print()

            return result
        else:
            print("‚ùå No content extracted")
            print()
            print("The page might not have loaded properly.")
            print("Try running the script again and make sure:")
            print("1. You enter the password correctly")
            print("2. The page fully loads before pressing Enter")
            print("3. You're on the correct page with course content")
            return None


if __name__ == "__main__":
    result = asyncio.run(scrape_kenkais())

    if result:
        print("=" * 70)
        print("‚úÖ Scraping Complete!")
        print("=" * 70)
        print()
        print("Check kenkais_agency_courses.md for full results")
    else:
        print("=" * 70)
        print("‚ö†Ô∏è  Scraping Incomplete")
        print("=" * 70)
        print()
        print("Please try again")
