# Splice v2 - Implementation Plan

## 10-Week Full Product Development Timeline

**Project:** Premiere Pro Auto-Cut Plugin with SaaS Platform
**Start Date:** [TBD]
**Target Launch:** 10 weeks from start

---

## Executive Summary

This plan outlines a 10-week development timeline to build and launch Splice, a Premiere Pro plugin that automatically cuts silences, detects similar takes, and intelligently names clips. The platform includes a web dashboard for subscription management and a cloud backend for audio processing.

### Key Deliverables

| Week | Milestone | Deliverables |
|------|-----------|--------------|
| 1-2 | Foundation | Monorepo, auth, database, plugin scaffold |
| 3-4 | Core Backend | Audio processing, LLM integration, queue system |
| 5-6 | Plugin Development | Timeline manipulation, UI, backend integration |
| 7-8 | Payments & Dashboard | Stripe, usage tracking, web UI |
| 9 | Integration & Testing | E2E testing, bug fixes, performance |
| 10 | Launch Prep | Documentation, beta testing, deployment |

---

## Week 1-2: Foundation & Infrastructure

### Week 1: Project Setup & Authentication

#### Day 1-2: Monorepo Initialization
```bash
# Tasks
- [ ] Initialize pnpm workspace with Turborepo
- [ ] Set up apps/web (Next.js 15)
- [ ] Set up apps/api (NestJS)
- [ ] Set up apps/plugin (UXP scaffold)
- [ ] Configure shared packages (types, config)
- [ ] Set up ESLint, Prettier, TypeScript configs
```

**Folder Structure Created:**
```
splice_v2/
├── apps/
│   ├── web/                 # Next.js 15
│   ├── api/                 # NestJS
│   └── plugin/              # Premiere UXP
├── packages/
│   ├── shared/              # Shared types
│   ├── config/              # Shared configs
│   └── ui/                  # Shared components
├── turbo.json
├── pnpm-workspace.yaml
└── package.json
```

#### Day 3-4: Authentication System
```bash
# Frontend Auth (Clerk)
- [ ] Install and configure Clerk in Next.js
- [ ] Create sign-in/sign-up pages
- [ ] Set up middleware for protected routes
- [ ] Configure Clerk webhooks for user sync

# Backend Auth (NestJS)
- [ ] Implement JWT validation strategy
- [ ] Create API key generation system
- [ ] Build auth guards (JWT, API Key)
- [ ] Set up user sync from Clerk webhooks
```

#### Day 5: Database Setup
```bash
# PostgreSQL + Prisma
- [ ] Initialize Prisma in apps/api
- [ ] Design and create initial schema:
    - users
    - subscriptions
    - api_keys
    - usage_records
    - webhook_events
- [ ] Set up TimescaleDB for usage analytics
- [ ] Create seed data for development
```

**Database Schema (Prisma):**
```prisma
model User {
  id                String   @id @default(uuid())
  email             String   @unique
  clerkId           String   @unique
  stripeCustomerId  String?  @unique
  createdAt         DateTime @default(now())

  subscription      Subscription?
  apiKeys           ApiKey[]
  usageRecords      UsageRecord[]
}

model Subscription {
  id                    String   @id @default(uuid())
  userId                String   @unique
  stripeSubscriptionId  String   @unique
  status                String   // active, trialing, past_due, canceled
  tier                  String   // starter, pro, studio
  minutesIncluded       Int
  minutesUsed           Int      @default(0)
  currentPeriodStart    DateTime
  currentPeriodEnd      DateTime

  user                  User     @relation(fields: [userId], references: [id])
}

model ApiKey {
  id          String    @id @default(uuid())
  userId      String
  keyHash     String    @unique
  keyPrefix   String    // "sk_live_..."
  name        String
  lastUsedAt  DateTime?
  revokedAt   DateTime?
  createdAt   DateTime  @default(now())

  user        User      @relation(fields: [userId], references: [id])
}

model UsageRecord {
  id              String   @id @default(uuid())
  userId          String
  clipDurationMs  Int
  operationType   String   // voice_isolation, transcription, cut
  status          String   // pending, completed, failed
  createdAt       DateTime @default(now())

  user            User     @relation(fields: [userId], references: [id])
}
```

### Week 2: Core Infrastructure

#### Day 6-7: Redis & Queue System
```bash
# Redis Setup
- [ ] Configure Redis connection (Upstash or local)
- [ ] Implement rate limiting service
- [ ] Set up session/cache management

# BullMQ Queue System
- [ ] Create audio processing queue
- [ ] Create LLM processing queue
- [ ] Implement job retry strategies
- [ ] Set up queue monitoring (Bull Board)
```

**Queue Architecture:**
```typescript
// Queue definitions
const QUEUES = {
  AUDIO_PROCESSING: 'audio-processing',
  VOICE_ISOLATION: 'voice-isolation',
  TRANSCRIPTION: 'transcription',
  CLIP_NAMING: 'clip-naming',
  USAGE_TRACKING: 'usage-tracking'
};

// Job priorities
const PRIORITIES = {
  STUDIO: 1,    // Highest priority tier
  PRO: 2,
  STARTER: 3,
  TRIAL: 4      // Lowest priority
};
```

#### Day 8-9: Plugin Scaffold
```bash
# UXP Plugin Setup
- [ ] Initialize Bolt UXP with React
- [ ] Create manifest.json with permissions
- [ ] Build basic panel UI structure
- [ ] Test plugin loading in Premiere Pro
- [ ] Implement API communication layer
```

**Plugin Manifest (manifest.json):**
```json
{
  "manifestVersion": 6,
  "id": "com.splice.premiere",
  "name": "Splice - Auto Cut",
  "version": "1.0.0",
  "main": "index.html",
  "host": {
    "app": "PProCore",
    "minVersion": "24.0.0"
  },
  "entrypoints": [
    {
      "type": "panel",
      "id": "com.splice.premiere.panel",
      "label": "Splice",
      "minimumSize": { "width": 300, "height": 400 },
      "icons": [
        { "width": 24, "height": 24, "path": "icons/icon-24.png" }
      ]
    }
  ],
  "requiredPermissions": {
    "network": { "domains": ["https://api.splice.app", "https://*.splice.app"] },
    "localFileSystem": "request",
    "clipboard": "readAndWrite"
  }
}
```

#### Day 10: Environment & DevOps
```bash
# Development Environment
- [ ] Create docker-compose.yml for local development
- [ ] Set up environment variable management
- [ ] Configure GitHub repository
- [ ] Set up basic CI/CD with GitHub Actions
- [ ] Create development/staging/production configs
```

### Week 1-2 Deliverables Checklist
- [ ] Monorepo with Turborepo + pnpm
- [ ] Next.js 15 app with Clerk authentication
- [ ] NestJS API with JWT + API key auth
- [ ] PostgreSQL database with Prisma ORM
- [ ] Redis for caching and rate limiting
- [ ] BullMQ queue system configured
- [ ] UXP plugin scaffold loading in Premiere
- [ ] Docker development environment
- [ ] Basic CI/CD pipeline

---

## Week 3-4: Core Backend Services

### Week 3: Audio Processing Pipeline

#### Day 11-12: Audio Extraction Service
```bash
# FFmpeg Integration
- [ ] Set up fluent-ffmpeg wrapper
- [ ] Implement audio extraction from video
- [ ] Create format conversion utilities (to WAV)
- [ ] Build audio normalization pipeline
- [ ] Handle various input formats (MP4, MOV, MXF)
```

**Audio Extraction Service:**
```typescript
// services/audio-processor/src/extraction/audio-extractor.ts
interface ExtractionResult {
  audioPath: string;
  format: 'wav';
  sampleRate: number;
  channels: number;
  duration: number;
}

class AudioExtractor {
  async extract(videoPath: string): Promise<ExtractionResult> {
    // Extract audio track to WAV (16kHz mono for Whisper)
  }

  async normalize(audioPath: string): Promise<string> {
    // Normalize audio levels
  }
}
```

#### Day 13-14: Voice Isolation (ElevenLabs)
```bash
# ElevenLabs Integration
- [ ] Implement ElevenLabs API client
- [ ] Create voice isolation service
- [ ] Handle audio upload/download
- [ ] Implement retry logic for API failures
- [ ] Add usage tracking per request
```

**Voice Isolation Service:**
```typescript
// services/audio-processor/src/isolation/elevenlabs.ts
interface IsolationResult {
  isolatedAudioPath: string;
  originalAudioPath: string;
  processingTimeMs: number;
}

class ElevenLabsIsolation {
  private apiKey: string;
  private baseUrl = 'https://api.elevenlabs.io/v1';

  async isolateVoice(audioBuffer: Buffer): Promise<Buffer> {
    const formData = new FormData();
    formData.append('audio', audioBuffer, 'audio.wav');

    const response = await fetch(`${this.baseUrl}/audio-isolation`, {
      method: 'POST',
      headers: { 'xi-api-key': this.apiKey },
      body: formData
    });

    return Buffer.from(await response.arrayBuffer());
  }
}
```

#### Day 15: Silence Detection
```bash
# Silence Detection
- [ ] Implement FFmpeg silencedetect filter
- [ ] Create Silero VAD integration (backup)
- [ ] Build natural pause detection logic
- [ ] Define configurable thresholds
- [ ] Return cut points with timestamps
```

**Silence Detection Algorithm:**
```typescript
interface CutPoint {
  startTime: number;  // ms
  endTime: number;    // ms
  type: 'silence' | 'pause';
  confidence: number;
}

interface SilenceConfig {
  silenceThreshold: number;    // -30dB default
  minSilenceDuration: number;  // 500ms default
  naturalPauseMin: number;     // 150ms - preserve natural pauses
  naturalPauseMax: number;     // 400ms
}

class SilenceDetector {
  async detectSilences(audioPath: string, config: SilenceConfig): Promise<CutPoint[]> {
    // 1. Run FFmpeg silencedetect
    // 2. Filter out natural pauses (150-400ms)
    // 3. Return cut points for actual silences
  }
}
```

### Week 4: LLM Integration

#### Day 16-17: Transcription Service
```bash
# Whisper Integration
- [ ] Set up Faster-Whisper (local) or Whisper API (cloud)
- [ ] Implement transcription with word timestamps
- [ ] Create transcription caching (Redis)
- [ ] Handle multiple languages (auto-detect)
- [ ] Return structured transcript with timings
```

**Transcription Service:**
```typescript
interface TranscriptWord {
  word: string;
  start: number;  // ms
  end: number;    // ms
  confidence: number;
}

interface TranscriptResult {
  text: string;
  words: TranscriptWord[];
  language: string;
  duration: number;
}

class TranscriptionService {
  async transcribe(audioPath: string): Promise<TranscriptResult> {
    // Check cache first (audio hash)
    const hash = await this.hashAudio(audioPath);
    const cached = await this.cache.get(`transcript:${hash}`);
    if (cached) return cached;

    // Transcribe with Whisper
    const result = await this.whisper.transcribe(audioPath);

    // Cache result
    await this.cache.set(`transcript:${hash}`, result, 30 * 24 * 60 * 60);

    return result;
  }
}
```

#### Day 18-19: Similar Take Detection
```bash
# Embedding & Similarity
- [ ] Set up pgvector extension in PostgreSQL
- [ ] Implement text-embedding-3-small client
- [ ] Create embedding storage and retrieval
- [ ] Build similarity search (cosine distance)
- [ ] Implement take grouping algorithm
```

**Similar Take Detection:**
```typescript
interface TakeGroup {
  groupId: string;
  color: string;           // Premiere label color
  clips: {
    clipId: string;
    transcript: string;
    similarity: number;
  }[];
}

class SimilarTakeDetector {
  private similarityThreshold = 0.85;

  async findSimilarTakes(transcripts: Map<string, string>): Promise<TakeGroup[]> {
    // 1. Generate embeddings for all transcripts
    const embeddings = await this.generateEmbeddings(transcripts);

    // 2. Store in pgvector
    await this.storeEmbeddings(embeddings);

    // 3. Find similar pairs (cosine similarity > 0.85)
    const similarPairs = await this.findSimilarPairs();

    // 4. Group into take groups using clustering
    const groups = this.clusterIntoGroups(similarPairs);

    // 5. Assign Premiere colors to each group
    return this.assignColors(groups);
  }
}
```

**Premiere Color Mapping:**
```typescript
const PREMIERE_COLORS = [
  { name: 'Violet', index: 0 },
  { name: 'Iris', index: 1 },
  { name: 'Caribbean', index: 2 },
  { name: 'Lavender', index: 3 },
  { name: 'Cerulean', index: 4 },
  { name: 'Forest', index: 5 },
  { name: 'Rose', index: 6 },
  { name: 'Mango', index: 7 },
  { name: 'Purple', index: 8 },
  { name: 'Blue', index: 9 },
  { name: 'Teal', index: 10 },
  { name: 'Magenta', index: 11 },
  { name: 'Tan', index: 12 },
  { name: 'Green', index: 13 },
  { name: 'Brown', index: 14 },
  { name: 'Yellow', index: 15 }
];
```

#### Day 20: Clip Naming Service
```bash
# LLM Naming
- [ ] Implement GPT-4o-mini client
- [ ] Create clip naming prompts
- [ ] Build batch naming for efficiency
- [ ] Implement semantic caching
- [ ] Handle naming conflicts (Clip 1, Clip 2)
```

**Clip Naming Service:**
```typescript
interface ClipName {
  clipId: string;
  name: string;        // "Clip 1 - Hey Guys Welcome"
  groupNumber: number; // 1, 2, 3... for similar takes
}

class ClipNamingService {
  async generateNames(
    transcripts: Map<string, string>,
    takeGroups: TakeGroup[]
  ): Promise<ClipName[]> {
    const names: ClipName[] = [];

    for (const group of takeGroups) {
      let clipNumber = 1;

      for (const clip of group.clips) {
        // Extract first few words for name
        const firstWords = this.extractFirstWords(clip.transcript, 5);

        names.push({
          clipId: clip.clipId,
          name: `Clip ${clipNumber} - ${firstWords}`,
          groupNumber: clipNumber
        });

        clipNumber++;
      }
    }

    return names;
  }

  private extractFirstWords(text: string, count: number): string {
    return text.split(' ').slice(0, count).join(' ');
  }
}
```

### Week 3-4 Deliverables Checklist
- [ ] Audio extraction from video (FFmpeg)
- [ ] Voice isolation via ElevenLabs API
- [ ] Silence detection with natural pause preservation
- [ ] Whisper transcription with word timestamps
- [ ] Text embeddings with text-embedding-3-small
- [ ] pgvector similarity search
- [ ] Take grouping algorithm
- [ ] GPT-4o-mini clip naming
- [ ] Redis caching for transcripts and embeddings

---

## Week 5-6: Premiere Pro Plugin

### Week 5: Core Plugin Functionality

#### Day 21-22: Authentication & API Layer
```bash
# Plugin Auth
- [ ] Implement OAuth 2.0 PKCE flow
- [ ] Create secure token storage
- [ ] Build API client with retry logic
- [ ] Handle token refresh
- [ ] Implement offline detection (show message)
```

**Plugin Auth Flow:**
```typescript
// apps/plugin/src/services/auth.ts
class PluginAuth {
  private tokenStorage: SecureStorage;

  async login(): Promise<void> {
    // 1. Generate PKCE code verifier and challenge
    const { verifier, challenge } = this.generatePKCE();

    // 2. Open browser to auth URL
    const authUrl = `${API_URL}/auth/plugin?challenge=${challenge}`;
    await shell.openExternal(authUrl);

    // 3. Listen for callback with auth code
    const code = await this.waitForCallback();

    // 4. Exchange code for tokens
    const tokens = await this.exchangeCode(code, verifier);

    // 5. Store tokens securely
    await this.tokenStorage.set('tokens', tokens);
  }

  async getApiKey(): Promise<string> {
    const tokens = await this.tokenStorage.get('tokens');
    return tokens.apiKey;
  }
}
```

#### Day 23-24: Clip Selection & Timeline Access
```bash
# Premiere API Integration
- [ ] Get selected clips from timeline
- [ ] Read clip metadata (duration, position, name)
- [ ] Access audio tracks
- [ ] Implement clip duplication
- [ ] Create bin management (Originals folder)
```

**Timeline Service:**
```typescript
// apps/plugin/src/services/timeline.ts
import { app } from 'premierepro';

interface SelectedClip {
  id: string;
  name: string;
  startTime: number;
  endTime: number;
  duration: number;
  trackIndex: number;
  hasAudio: boolean;
  projectItemId: string;
}

class TimelineService {
  async getSelectedClips(): Promise<SelectedClip[]> {
    const project = await app.project;
    const sequence = await project.activeSequence;

    if (!sequence) {
      throw new Error('No active sequence');
    }

    const selectedItems: SelectedClip[] = [];
    const videoTracks = await sequence.videoTracks;

    for (let i = 0; i < videoTracks.length; i++) {
      const track = videoTracks[i];
      const clips = await track.clips;

      for (const clip of clips) {
        if (await clip.isSelected()) {
          selectedItems.push({
            id: clip.nodeId,
            name: await clip.name,
            startTime: await clip.start.seconds,
            endTime: await clip.end.seconds,
            duration: await clip.duration.seconds,
            trackIndex: i,
            hasAudio: await this.hasAudioComponent(clip),
            projectItemId: (await clip.projectItem).nodeId
          });
        }
      }
    }

    return selectedItems;
  }

  async createOriginalsFolder(): Promise<ProjectItem> {
    const project = await app.project;
    const rootItem = await project.rootItem;

    // Check if folder exists
    const children = await rootItem.children;
    for (const child of children) {
      if (await child.name === 'Originals') {
        return child;
      }
    }

    // Create new folder
    return await rootItem.createBin('Originals');
  }

  async moveToOriginals(clip: SelectedClip): Promise<void> {
    const folder = await this.createOriginalsFolder();
    const project = await app.project;
    const projectItem = await project.getProjectItemByNodeId(clip.projectItemId);
    await projectItem.moveBin(folder);
  }
}
```

#### Day 25: Audio Export
```bash
# Audio Export for Processing
- [ ] Export audio from selected clips
- [ ] Handle multiple audio tracks
- [ ] Create temp file management
- [ ] Implement progress tracking
- [ ] Handle large files (chunking)
```

**Audio Export:**
```typescript
// apps/plugin/src/services/audio-export.ts
class AudioExporter {
  async exportAudio(clip: SelectedClip): Promise<string> {
    const project = await app.project;
    const projectItem = await project.getProjectItemByNodeId(clip.projectItemId);

    // Get source path
    const sourcePath = await projectItem.getMediaPath();

    // Extract audio using FFmpeg (via backend)
    const audioPath = await this.api.extractAudio({
      sourcePath,
      startTime: clip.startTime,
      endTime: clip.endTime
    });

    return audioPath;
  }
}
```

### Week 6: Plugin UI & Backend Integration

#### Day 26-27: React UI Components
```bash
# Plugin UI
- [ ] Create main panel layout
- [ ] Build clip selection display
- [ ] Implement processing options (checkboxes)
- [ ] Create progress indicator
- [ ] Build results display (cut points, names)
- [ ] Add settings panel (threshold adjustments)
```

**Plugin UI Components:**
```tsx
// apps/plugin/src/panels/MainPanel.tsx
import React, { useState } from 'react';
import { useSelectedClips } from '../hooks/useSelectedClips';
import { useProcessing } from '../hooks/useProcessing';

const MainPanel: React.FC = () => {
  const { clips, loading: clipsLoading } = useSelectedClips();
  const { process, progress, status } = useProcessing();

  const [options, setOptions] = useState({
    isolateVoice: true,
    keepOriginalAudio: false
  });

  const handleProcess = async () => {
    await process(clips, options);
  };

  return (
    <div className="panel">
      <header>
        <h1>Splice</h1>
        <UserBadge />
      </header>

      <section className="clips">
        <h2>Selected Clips ({clips.length})</h2>
        <ClipList clips={clips} />
      </section>

      <section className="options">
        <Checkbox
          label="Isolate Voice"
          checked={options.isolateVoice}
          onChange={(v) => setOptions({ ...options, isolateVoice: v })}
        />
        <Checkbox
          label="Keep Original Audio"
          checked={options.keepOriginalAudio}
          onChange={(v) => setOptions({ ...options, keepOriginalAudio: v })}
        />
      </section>

      <section className="actions">
        <Button
          onClick={handleProcess}
          disabled={clips.length === 0 || status === 'processing'}
        >
          {status === 'processing' ? 'Processing...' : 'Process Clips'}
        </Button>
      </section>

      {status === 'processing' && (
        <ProgressBar progress={progress} />
      )}

      {status === 'complete' && (
        <ResultsPanel />
      )}
    </div>
  );
};
```

#### Day 28-29: Timeline Manipulation
```bash
# Apply Results to Timeline
- [ ] Apply cuts to clips (razor tool equivalent)
- [ ] Set clip names
- [ ] Apply color labels
- [ ] Handle ripple delete of silences
- [ ] Preserve transitions and effects
```

**Timeline Manipulation:**
```typescript
// apps/plugin/src/services/timeline-manipulation.ts
interface ProcessingResult {
  clipId: string;
  cutPoints: CutPoint[];
  newName: string;
  colorIndex: number;  // Premiere color label index
  keepOriginalAudio: boolean;
}

class TimelineManipulator {
  async applyResults(results: ProcessingResult[]): Promise<void> {
    const project = await app.project;
    const sequence = await project.activeSequence;

    for (const result of results) {
      // 1. Get the original clip
      const clip = await this.getClipById(result.clipId);

      // 2. Move original to "Originals" bin
      await this.timelineService.moveToOriginals(clip);

      // 3. Create subclips based on cut points
      const subclips = await this.createSubclips(clip, result.cutPoints);

      // 4. Apply names and colors
      for (let i = 0; i < subclips.length; i++) {
        const subclip = subclips[i];
        await subclip.setName(`${result.newName} - Part ${i + 1}`);
        await subclip.projectItem.setColorLabel(result.colorIndex);
      }

      // 5. Insert subclips on timeline (replacing original position)
      await this.insertSubclips(subclips, clip.startTime, clip.trackIndex);
    }
  }

  async createSubclips(clip: SelectedClip, cutPoints: CutPoint[]): Promise<Clip[]> {
    const subclips: Clip[] = [];
    let currentTime = clip.startTime;

    for (const cut of cutPoints) {
      // Skip silence sections
      if (cut.type === 'silence') {
        continue;
      }

      // Create subclip for non-silence section
      const subclip = await this.createSubclip(
        clip,
        currentTime,
        currentTime + (cut.endTime - cut.startTime) / 1000
      );
      subclips.push(subclip);
      currentTime = cut.endTime / 1000;
    }

    return subclips;
  }
}
```

#### Day 30: End-to-End Integration
```bash
# Full Pipeline Test
- [ ] Connect all services end-to-end
- [ ] Test with real Premiere Pro project
- [ ] Handle edge cases (no audio, very short clips)
- [ ] Implement error handling and recovery
- [ ] Add usage tracking integration
```

### Week 5-6 Deliverables Checklist
- [ ] OAuth 2.0 PKCE authentication in plugin
- [ ] Secure API key storage
- [ ] Clip selection from timeline
- [ ] Audio export to backend
- [ ] React UI with progress indicators
- [ ] Processing options (voice isolation, keep audio)
- [ ] Timeline manipulation (cuts, names, colors)
- [ ] Move originals to bin
- [ ] End-to-end processing flow working

---

## Week 7-8: Payments & Web Dashboard

### Week 7: Stripe Integration

#### Day 31-32: Stripe Setup
```bash
# Stripe Configuration
- [ ] Create Stripe account and products
- [ ] Set up 3 subscription tiers (Starter, Pro, Studio)
- [ ] Configure usage-based billing (minutes)
- [ ] Set up Customer Portal
- [ ] Create webhook endpoints
```

**Stripe Products:**
```typescript
const STRIPE_PRODUCTS = {
  STARTER: {
    name: 'Starter',
    priceId: 'price_starter_monthly',
    amount: 2999,  // $29.99
    minutes: 60,
    features: ['Voice isolation', 'Auto-cut', 'Smart naming']
  },
  PRO: {
    name: 'Pro',
    priceId: 'price_pro_monthly',
    amount: 4999,  // $49.99
    minutes: 150,
    features: ['Everything in Starter', 'Priority processing', 'Batch export']
  },
  STUDIO: {
    name: 'Studio',
    priceId: 'price_studio_monthly',
    amount: 7999,  // $79.99
    minutes: 400,
    features: ['Everything in Pro', 'Team sharing', 'API access']
  }
};
```

#### Day 33-34: Checkout & Portal
```bash
# Checkout Implementation
- [ ] Create checkout session endpoint
- [ ] Build pricing page UI
- [ ] Implement success/cancel flows
- [ ] Create billing portal redirect
- [ ] Handle subscription status changes
```

**Checkout Flow:**
```typescript
// apps/api/src/modules/subscriptions/subscriptions.controller.ts
@Controller('subscriptions')
export class SubscriptionsController {
  @Post('checkout')
  async createCheckout(
    @CurrentUser() user: User,
    @Body() body: { priceId: string }
  ) {
    const session = await this.stripe.checkout.sessions.create({
      customer: user.stripeCustomerId,
      mode: 'subscription',
      line_items: [{ price: body.priceId, quantity: 1 }],
      success_url: `${APP_URL}/dashboard?checkout=success`,
      cancel_url: `${APP_URL}/pricing`,
      subscription_data: {
        trial_period_days: 7  // 7-day trial
      }
    });

    return { url: session.url };
  }

  @Post('portal')
  async createPortal(@CurrentUser() user: User) {
    const session = await this.stripe.billingPortal.sessions.create({
      customer: user.stripeCustomerId,
      return_url: `${APP_URL}/dashboard/billing`
    });

    return { url: session.url };
  }
}
```

#### Day 35: Webhook Handling
```bash
# Stripe Webhooks
- [ ] Implement webhook signature verification
- [ ] Handle subscription created/updated/deleted
- [ ] Handle payment succeeded/failed
- [ ] Implement idempotency
- [ ] Sync subscription status to database
```

### Week 8: Web Dashboard

#### Day 36-37: Dashboard UI
```bash
# Dashboard Pages
- [ ] Create dashboard layout (sidebar, header)
- [ ] Build overview page with usage stats
- [ ] Create billing page with plan details
- [ ] Build settings page (profile, API keys)
- [ ] Implement usage history chart
```

**Dashboard Pages:**
```
/dashboard                 # Overview with usage stats
/dashboard/billing         # Current plan, usage, upgrade
/dashboard/settings        # Profile, API keys
/dashboard/history         # Processing history
```

#### Day 38-39: Usage Tracking
```bash
# Usage System
- [ ] Implement minute tracking per user
- [ ] Create usage alerts (80%, 100%)
- [ ] Build overage handling
- [ ] Create usage reset on billing cycle
- [ ] Add usage API for plugin
```

**Usage Tracking:**
```typescript
// apps/api/src/modules/usage/usage.service.ts
class UsageService {
  async trackUsage(userId: string, durationMs: number): Promise<void> {
    const minutes = Math.ceil(durationMs / 60000);
    const subscription = await this.getSubscription(userId);

    // Check if user has minutes remaining
    if (subscription.minutesUsed + minutes > subscription.minutesIncluded) {
      // Calculate overage
      const overage = (subscription.minutesUsed + minutes) - subscription.minutesIncluded;
      await this.recordOverage(userId, overage);
    }

    // Update usage
    await this.prisma.subscription.update({
      where: { userId },
      data: {
        minutesUsed: { increment: minutes }
      }
    });

    // Check for alerts
    const usagePercent = ((subscription.minutesUsed + minutes) / subscription.minutesIncluded) * 100;
    if (usagePercent >= 80 && subscription.minutesUsed / subscription.minutesIncluded < 0.8) {
      await this.sendUsageAlert(userId, '80%');
    }
  }

  async getUsageStatus(userId: string): Promise<UsageStatus> {
    const subscription = await this.getSubscription(userId);
    return {
      minutesUsed: subscription.minutesUsed,
      minutesIncluded: subscription.minutesIncluded,
      percentUsed: (subscription.minutesUsed / subscription.minutesIncluded) * 100,
      overageMinutes: Math.max(0, subscription.minutesUsed - subscription.minutesIncluded),
      resetsAt: subscription.currentPeriodEnd
    };
  }
}
```

#### Day 40: Rate Limiting
```bash
# Rate Limiting Implementation
- [ ] Implement tier-based rate limits
- [ ] Create rate limit headers
- [ ] Build rate limit exceeded handling
- [ ] Add rate limit status to plugin
```

**Rate Limits by Tier:**
```typescript
const RATE_LIMITS = {
  TRIAL: { requestsPerMinute: 5, concurrentJobs: 1 },
  STARTER: { requestsPerMinute: 20, concurrentJobs: 2 },
  PRO: { requestsPerMinute: 60, concurrentJobs: 5 },
  STUDIO: { requestsPerMinute: 120, concurrentJobs: 10 }
};
```

### Week 7-8 Deliverables Checklist
- [ ] Stripe products and prices configured
- [ ] Checkout session creation
- [ ] Customer portal integration
- [ ] Webhook handlers with idempotency
- [ ] Dashboard overview page
- [ ] Billing page with plan management
- [ ] Settings page with API keys
- [ ] Usage tracking and alerts
- [ ] Rate limiting by tier
- [ ] Usage display in plugin

---

## Week 9: Integration & Testing

### Day 41-42: End-to-End Testing
```bash
# E2E Test Suite
- [ ] Test complete flow: select → process → apply
- [ ] Test authentication flow
- [ ] Test subscription/payment flow
- [ ] Test usage tracking accuracy
- [ ] Test rate limiting
```

**E2E Test Scenarios:**
```typescript
describe('Splice E2E', () => {
  it('should process clips end-to-end', async () => {
    // 1. Authenticate plugin
    // 2. Select clips in Premiere
    // 3. Start processing
    // 4. Wait for completion
    // 5. Verify timeline changes
    // 6. Verify usage recorded
  });

  it('should handle subscription limits', async () => {
    // 1. Use up all minutes
    // 2. Attempt to process more
    // 3. Verify upgrade prompt shown
  });

  it('should color code similar takes', async () => {
    // 1. Process clips with similar content
    // 2. Verify same color assigned
    // 3. Verify sequential naming
  });
});
```

### Day 43-44: Bug Fixes & Edge Cases
```bash
# Bug Fixing
- [ ] Fix any issues from E2E testing
- [ ] Handle edge cases:
    - Empty audio tracks
    - Very short clips (<1 second)
    - Very long clips (>30 minutes)
    - Network failures mid-processing
    - Concurrent processing requests
- [ ] Add input validation
- [ ] Improve error messages
```

### Day 45: Performance Optimization
```bash
# Performance
- [ ] Optimize audio processing pipeline
- [ ] Implement batch processing
- [ ] Add request caching
- [ ] Optimize database queries
- [ ] Profile and fix bottlenecks
```

### Week 9 Deliverables Checklist
- [ ] Full E2E test suite passing
- [ ] All edge cases handled
- [ ] Error messages are user-friendly
- [ ] Performance meets targets (<30s for 5min clip)
- [ ] No critical bugs remaining

---

## Week 10: Launch Preparation

### Day 46-47: Documentation
```bash
# User Documentation
- [ ] Create plugin installation guide
- [ ] Write user manual with screenshots
- [ ] Create FAQ document
- [ ] Build troubleshooting guide
- [ ] Create video tutorials
```

### Day 48-49: Beta Testing
```bash
# Beta Program
- [ ] Recruit 10-20 beta testers
- [ ] Collect feedback via form/Discord
- [ ] Address critical feedback
- [ ] Monitor error logs
- [ ] Track usage patterns
```

### Day 50: Production Deployment
```bash
# Launch Checklist
- [ ] Deploy backend to production (Railway/Render)
- [ ] Deploy frontend to Vercel
- [ ] Configure production environment variables
- [ ] Set up monitoring (Sentry, LogRocket)
- [ ] Configure alerting
- [ ] Submit plugin to Adobe Marketplace (if applicable)
- [ ] Announce launch
```

**Production Checklist:**
```markdown
## Pre-Launch
- [ ] All secrets rotated for production
- [ ] Database backups configured
- [ ] SSL certificates valid
- [ ] Rate limiting tested at scale
- [ ] Stripe webhooks pointing to production
- [ ] Monitoring dashboards set up
- [ ] On-call rotation established

## Launch Day
- [ ] Deploy to production
- [ ] Smoke test all features
- [ ] Monitor error rates
- [ ] Watch server resources
- [ ] Be available for quick fixes

## Post-Launch
- [ ] Monitor user feedback
- [ ] Track conversion rates
- [ ] Review error logs daily
- [ ] Plan first iteration based on feedback
```

### Week 10 Deliverables Checklist
- [ ] User documentation complete
- [ ] Video tutorials created
- [ ] Beta feedback incorporated
- [ ] Production infrastructure ready
- [ ] Monitoring and alerting configured
- [ ] Launch announcement prepared
- [ ] Support channels ready (email, Discord)

---

## Resource Allocation

### Team Requirements (Ideal)

| Role | Count | Responsibilities |
|------|-------|-----------------|
| Full-stack Developer | 1-2 | Backend, frontend, plugin |
| DevOps | 0.5 | Infrastructure, CI/CD |
| Designer | 0.5 | UI/UX, marketing assets |

### Solo Developer Adjustments

If building alone, prioritize:
1. **Week 1-4**: Focus on backend + API (most complex)
2. **Week 5-6**: Plugin development (requires Premiere)
3. **Week 7-8**: Dashboard (can use templates)
4. **Week 9-10**: Testing + polish

Use these shortcuts:
- Use Clerk's pre-built components (save 1-2 days)
- Use shadcn/ui templates (save 2-3 days)
- Use Stripe's hosted checkout/portal (save 2-3 days)
- Start with Whisper API instead of self-hosted (save 1-2 days)

---

## Risk Mitigation

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|------------|
| Adobe API limitations | Medium | High | Early prototyping in Week 1 |
| ElevenLabs API changes | Low | Medium | Abstract behind interface |
| Scope creep | High | Medium | Strict feature freeze after Week 2 |
| Performance issues | Medium | High | Early load testing in Week 8 |
| Low beta adoption | Medium | Medium | Start recruiting in Week 6 |

---

## Success Metrics

### Launch Goals
- [ ] 100 users sign up in first week
- [ ] 20 paid conversions in first month
- [ ] <5% error rate in processing
- [ ] <30s average processing time for 5min clip
- [ ] >4.0 star rating on feedback

### Technical KPIs
- API response time: <200ms (p95)
- Processing time: <6s per minute of audio
- Uptime: >99.5%
- Error rate: <1%

---

## Next Steps

Ready to begin implementation? Here's how to start:

```bash
# Day 1 - Initialize the project
mkdir splice_v2 && cd splice_v2
pnpm init
pnpm add -D turbo

# Create workspace structure
mkdir -p apps/{web,api,plugin} packages/{shared,config,ui}

# Initialize apps
cd apps/web && pnpm create next-app . --typescript --tailwind --app
cd ../api && nest new . --package-manager pnpm
cd ../plugin && # Initialize UXP project
```

Shall I begin implementing Week 1?
