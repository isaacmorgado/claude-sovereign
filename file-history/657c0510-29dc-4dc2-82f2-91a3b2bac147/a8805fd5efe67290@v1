# Quick Model Reference Card

## One-Command Model Switching

| Command | Model | Best For |
|---------|-------|----------|
| `/kimi` | Kimi K2 (1T) | Agentic coding, autonomous tasks |
| `/qwen` | Qwen 2.5 72B | Complex reasoning, long context |
| `/dolphin` | Dolphin-3 | Creative writing, unrestricted |
| `/whiterabbit` | WhiteRabbitNeo | Pentesting, security research |
| `/llama70b` | Llama 3 70B | High quality, balanced |
| `/llama8b` | Llama 3 8B | Fast responses |
| `/glm` | GLM-4 | Multilingual (26 languages) |
| `/gemini` | Gemini 2.0 Flash | Fast, Google AI |
| `/sonnet` | Claude Sonnet 4.5 | Default, most capable |

## Model Stats

### Kimi K2 ⭐ NEW
- **Params**: 1 trillion (32B active MoE)
- **Context**: 128K tokens
- **Speed**: Fast
- **Cost**: Free (Featherless)
- **Specialty**: Agentic coding (65.8% on SWE-bench)
- **Tools**: Full support (emulated)

### Qwen 2.5 72B
- **Params**: 72.7 billion
- **Context**: 128K tokens
- **Speed**: Medium
- **Cost**: Free (Featherless)
- **Specialty**: Best reasoning
- **Tools**: Full support (emulated)

### Dolphin-3 Venice
- **Params**: 24 billion
- **Context**: 32K tokens
- **Speed**: Fast
- **Cost**: Free (Featherless)
- **Specialty**: Creative writing (2.20% refusal rate)
- **Tools**: Full support (emulated)

### WhiteRabbitNeo 13B
- **Params**: 13 billion
- **Context**: 32K tokens
- **Speed**: Fast
- **Cost**: Free (Featherless)
- **Specialty**: Pentesting (1.7M security samples)
- **Tools**: Full support (emulated)

### GLM-4
- **Params**: 9 billion
- **Context**: 128K tokens
- **Speed**: Fast
- **Cost**: Free (Z.AI)
- **Specialty**: Multilingual (26 languages)
- **Tools**: Native support

### Claude Sonnet 4.5
- **Params**: Unknown
- **Context**: Variable
- **Speed**: Medium
- **Cost**: Paid (your API key)
- **Specialty**: General purpose, most capable
- **Tools**: Native support

## All Models Support

✅ **MCP Tools** - Browser, Gemini, GitHub, etc.
✅ **Agent Spawning** - Task tool with 10+ specialists
✅ **Skills** - /research, /build, /chrome, etc.
✅ **Parallel Execution** - Multiple tools at once
✅ **Memory System** - Persistent context

## Usage

```bash
# Start Claude Code with proxy
clauded

# Inside Claude, switch models instantly
/kimi           # Switch to Kimi K2
/qwen           # Switch to Qwen 2.5 72B
/dolphin        # Switch to Dolphin-3
/whiterabbit    # Switch to WhiteRabbitNeo
/sonnet         # Switch back to Claude

# See all available models
/models
```

## When to Use Each Model

| Task | Recommended Model | Why |
|------|------------------|-----|
| Autonomous coding | `/kimi` | Best SWE-bench score, agentic design |
| Complex reasoning | `/qwen` | 72B params, exceptional quality |
| Creative writing | `/dolphin` | Most uncensored, narrative memory |
| Security research | `/whiterabbit` | Trained on security data |
| Fast responses | `/llama8b` | Lightweight, quick |
| Multilingual | `/glm` | 26 languages native |
| General tasks | `/sonnet` | Most balanced |

## Cost Comparison

| Model | Cost | Provider |
|-------|------|----------|
| Kimi K2 | **FREE** | Featherless |
| Qwen 2.5 72B | **FREE** | Featherless |
| Dolphin-3 | **FREE** | Featherless |
| WhiteRabbitNeo | **FREE** | Featherless |
| Llama 3 (8B/70B) | **FREE** | Featherless |
| GLM-4 | **FREE** | Z.AI |
| Gemini | **FREE** | Google (OAuth) |
| Claude | **PAID** | Anthropic |

## Performance Rankings

### Coding (SWE-bench Verified)
1. **Kimi K2** - 65.8% ⭐
2. Claude Sonnet 4 - ~60%
3. Qwen 2.5 72B - ~55%
4. Llama 3 70B - ~45%

### Reasoning (Complex Tasks)
1. **Qwen 2.5 72B** ⭐
2. Claude Sonnet 4.5
3. Kimi K2
4. Llama 3 70B

### Creative Writing
1. **Dolphin-3 Venice** ⭐
2. Claude Opus 4.5
3. Llama 3 70B
4. Qwen 2.5 72B

### Security/Pentesting
1. **WhiteRabbitNeo** ⭐
2. Dolphin-3 Venice
3. Claude Sonnet (with safety restrictions)

---

**Last Updated**: 2026-01-12
**Total Models**: 9 (7 free + 2 paid)
