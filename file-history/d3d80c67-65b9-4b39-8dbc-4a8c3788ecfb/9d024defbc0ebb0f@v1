/**
 * SPLICE Backend Server
 *
 * Main entry point for the SPLICE backend API.
 * Orchestrates the audio analysis pipeline.
 *
 * Slices:
 * - Slice 4: Transcription (services/transcription.js)
 * - Slice 5: Take Detection (services/takeDetection.js)
 */

require('dotenv').config();

const express = require('express');
const cors = require('cors');
const fs = require('fs');
const https = require('https');
const path = require('path');

// Import slice services
const { transcribeAudio } = require('./services/transcription');
const { detectTakes } = require('./services/takeDetection');
const { detectSilences } = require('./services/silenceDetection');
const { detectAudioSilences, isFFprobeInstalled } = require('./services/ffprobeSilence');
const { processXMLFile } = require('./services/xmlProcessor');
const { isolateVocals, isReplicateConfigured } = require('./services/vocalIsolation');

// =============================================================================
// Server Configuration
// =============================================================================

const app = express();
const PORT = process.env.PORT || 3847;

// HTTPS certificates (generated by mkcert)
const httpsOptions = {
  key: fs.readFileSync(path.join(__dirname, 'localhost+1-key.pem')),
  cert: fs.readFileSync(path.join(__dirname, 'localhost+1.pem'))
};

app.use(cors());
app.use(express.json());

// =============================================================================
// Routes
// =============================================================================

/**
 * GET / - API information
 */
app.get('/', (req, res) => {
  res.json({
    service: 'splice-backend',
    version: '0.2.0',
    endpoints: {
      'GET /': 'This info',
      'GET /health': 'Health check',
      'GET /ffprobe-check': 'Check if FFprobe is installed',
      'POST /analyze': 'Analyze WAV file { wavPath }',
      'POST /silences': 'Detect silences via Whisper gaps { wavPath, threshold: 0.5 }',
      'POST /silences-audio': 'Detect silences via FFprobe { wavPath, threshold: -30, minDuration: 0.5, padding: 0.1 }',
      'POST /process-xml': 'Process FCP XML { xmlPath, silences, removeGaps: true }'
    }
  });
});

/**
 * GET /health - Health check
 */
app.get('/health', (req, res) => {
  res.json({ status: 'ok', service: 'splice-backend' });
});

/**
 * POST /analyze - Main analysis endpoint
 *
 * Pipeline:
 * 1. Validate input (wavPath)
 * 2. Slice 4: Transcribe audio with Groq Whisper
 * 3. Slice 5: Detect takes with GPT-4o-mini
 * 4. Return combined results
 */
app.post('/analyze', async (req, res) => {
  const { wavPath } = req.body;

  // Validate input
  if (!wavPath) {
    return res.status(400).json({ error: 'wavPath is required' });
  }

  if (!fs.existsSync(wavPath)) {
    return res.status(404).json({ error: `File not found: ${wavPath}` });
  }

  console.log(`[SPLICE] Analyzing: ${wavPath}`);

  try {
    // Slice 4 - Groq Whisper transcription
    const transcript = await transcribeAudio(wavPath);

    // Slice 5 - GPT-4o-mini take detection
    const takes = await detectTakes(transcript);

    res.json({
      success: true,
      wavPath,
      transcript,
      takes
    });
  } catch (err) {
    console.error('[SPLICE] Error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /silences - Detect silent gaps in audio
 *
 * Pipeline:
 * 1. Transcribe audio with Whisper (reuses transcription)
 * 2. Analyze gaps between segments
 * 3. Return silence regions
 */
app.post('/silences', async (req, res) => {
  const { wavPath, threshold = 0.5 } = req.body;

  if (!wavPath) {
    return res.status(400).json({ error: 'wavPath is required' });
  }

  if (!fs.existsSync(wavPath)) {
    return res.status(404).json({ error: `File not found: ${wavPath}` });
  }

  console.log(`[SPLICE] Detecting silences: ${wavPath} (threshold: ${threshold}s)`);

  try {
    const transcript = await transcribeAudio(wavPath);
    const silences = detectSilences(transcript.segments, threshold);

    res.json({
      success: true,
      wavPath,
      threshold,
      silences,
      count: silences.length,
      totalSilenceDuration: silences.reduce((sum, s) => sum + s.duration, 0).toFixed(2)
    });
  } catch (err) {
    console.error('[SPLICE] Silence detection error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /silences-audio - Detect silences using FFprobe audio analysis
 *
 * Uses actual audio levels (dB threshold) instead of transcript gaps.
 * More accurate for detecting silence vs background noise.
 */
app.post('/silences-audio', async (req, res) => {
  const {
    wavPath,
    threshold = -30,
    minDuration = 0.5,
    padding = 0.1
  } = req.body;

  if (!wavPath) {
    return res.status(400).json({ error: 'wavPath is required' });
  }

  if (!fs.existsSync(wavPath)) {
    return res.status(404).json({ error: `File not found: ${wavPath}` });
  }

  // Check FFprobe availability
  const ffprobeAvailable = await isFFprobeInstalled();
  if (!ffprobeAvailable) {
    return res.status(500).json({
      error: 'FFprobe not installed. Run: brew install ffmpeg'
    });
  }

  console.log(`[SPLICE] FFprobe silence detection: ${wavPath} (threshold: ${threshold}dB, min: ${minDuration}s)`);

  try {
    const silences = await detectAudioSilences(wavPath, {
      threshold,
      minDuration,
      padding
    });

    const totalDuration = silences.reduce((sum, s) => sum + s.duration, 0);

    res.json({
      success: true,
      wavPath,
      threshold,
      minDuration,
      padding,
      silences,
      count: silences.length,
      totalSilenceDuration: totalDuration.toFixed(2)
    });
  } catch (err) {
    console.error('[SPLICE] FFprobe silence detection error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /process-xml - Process FCP XML to split clips at silences
 *
 * Takes an FCP XML file and silence timestamps, splits clips
 * at silence boundaries, and optionally removes gaps.
 */
app.post('/process-xml', async (req, res) => {
  const {
    xmlPath,
    silences,
    removeGaps = true,
    outputPath = null
  } = req.body;

  if (!xmlPath) {
    return res.status(400).json({ error: 'xmlPath is required' });
  }

  if (!silences || !Array.isArray(silences)) {
    return res.status(400).json({ error: 'silences array is required' });
  }

  if (!fs.existsSync(xmlPath)) {
    return res.status(404).json({ error: `XML file not found: ${xmlPath}` });
  }

  console.log(`[SPLICE] Processing XML: ${xmlPath} with ${silences.length} silence(s)`);

  try {
    const result = await processXMLFile(xmlPath, silences, {
      outputPath,
      removeGaps
    });

    res.json({
      success: true,
      inputPath: xmlPath,
      outputPath: result.outputPath,
      stats: result.stats
    });
  } catch (err) {
    console.error('[SPLICE] XML processing error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * GET /ffprobe-check - Check if FFprobe is installed
 */
app.get('/ffprobe-check', async (req, res) => {
  const installed = await isFFprobeInstalled();
  res.json({
    installed,
    message: installed
      ? 'FFprobe is available'
      : 'FFprobe not found. Install with: brew install ffmpeg'
  });
});

// =============================================================================
// Start Server
// =============================================================================

https.createServer(httpsOptions, app).listen(PORT, () => {
  console.log(`[SPLICE] Backend running at https://127.0.0.1:${PORT}`);
  console.log(`[SPLICE] POST /analyze with { "wavPath": "/path/to/audio.wav" }`);
});
