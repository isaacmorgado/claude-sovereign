# SPLICE Continuation Prompt - Path to 95% FIRECUT Parity

## Session Context
This prompt continues work on SPLICE, an AI-powered Premiere Pro UXP plugin for auto-cutting. Use this to resume development with full context.

---

## Current State Summary

### What's Working (v3.5)
- 3 silence detection methods (Whisper gaps, FFprobe, RMS with auto-threshold)
- Profanity detection (4 languages, custom lists, 5 bleep options)
- Repetition/stutter detection (phrase matching + OpenAI refinement)
- Take detection (GPT-based speech segment identification)
- Multitrack/multicam analysis (speaker balancing, wide shot detection)
- Preview system (markers, filtering, keyboard shortcuts)
- Direct DOM sequence building (zero XML steps)
- Billing/credits system (Stripe integration)
- Vocal isolation (Demucs via Replicate)

### Current Parity: ~65-70%

---

## CRITICAL GAPS FOR 95% PARITY

### Priority 1: MUST HAVE (Blocking Features)

#### 1.1 Filler Word Detection Endpoint
**Impact:** HIGH | **Effort:** LOW
```
Current: Filler words (um, uh, like, you know) only filtered in stutter detection
Missing: Standalone endpoint to detect and remove filler words as silences

Files to modify:
- splice-backend/services/repetitionDetection.js (extract filler logic)
- splice-backend/server.js (add POST /fillers endpoint)

Implementation:
1. Extract fillerWords set to shared constant
2. Create detectFillers(transcript, options) function
3. Return segments with start/end times for each filler
4. Add endpoint with options: { includePartialMatches, customFillers }
```

#### 1.2 Batch Processing
**Impact:** CRITICAL | **Effort:** HIGH
```
Current: Single file per detection request
Missing: Process multiple clips in one operation

Files to create/modify:
- splice-backend/services/batchProcessor.js (new)
- splice-backend/server.js (add POST /batch/silences, /batch/analyze)
- splice-plugin/js/batch.js (new UI module)
- splice-plugin/index.html (batch queue section)

Implementation:
1. Job queue with progress tracking per file
2. Parallel processing (configurable concurrency)
3. Aggregate results + individual file status
4. Resume capability for failed jobs
```

#### 1.3 Caption/Subtitle Export (SRT/VTT)
**Impact:** HIGH | **Effort:** MEDIUM
```
Current: Word-level timestamps available but not exported
Missing: Export to industry-standard caption formats

Files to create:
- splice-backend/services/captionExporter.js (new)
- splice-backend/server.js (add POST /export/srt, /export/vtt)

Implementation:
1. Convert transcript.words[] to SRT format (sequential numbering, timecodes)
2. VTT format with optional styling
3. Options: { maxLineLength, maxDuration, speakerLabels }
```

#### 1.4 OpenAI API Retry Logic + Better Errors
**Impact:** HIGH | **Effort:** LOW
```
Current: Connection errors fail silently, quota errors masked
Added: Basic error messages in transcription.js

Still missing:
- Retry with exponential backoff (3 attempts)
- Timeout configuration
- Rate limit handling (429 responses)

File to modify:
- splice-backend/services/transcription.js

Implementation:
async function withRetry(fn, maxRetries = 3) {
  for (let i = 0; i < maxRetries; i++) {
    try {
      return await fn();
    } catch (err) {
      if (i === maxRetries - 1) throw err;
      if (err.status === 429) await sleep(2 ** i * 1000);
      else if (err.code === 'ECONNRESET') await sleep(1000);
      else throw err;
    }
  }
}
```

### Priority 2: SHOULD HAVE (Competitive Features)

#### 2.1 Preset Profiles
**Impact:** MEDIUM | **Effort:** MEDIUM
```
Missing: Pre-configured sensitivity settings for content types

Presets to implement:
- Podcast: threshold=-35dB, minSilence=0.8s, padding=0.15s
- Interview: threshold=-30dB, minSilence=0.5s, padding=0.1s, takesProtection=true
- Reaction: threshold=-25dB, minSilence=0.3s, padding=0.05s
- Music: threshold=-40dB, minSilence=1.5s (speech detection only)

Files to modify:
- splice-plugin/js/settings.js (add PRESETS constant)
- splice-plugin/index.html (preset dropdown)
- splice-plugin/js/main.js (apply preset on selection)
```

#### 2.2 Cache Size Limit + LRU Eviction
**Impact:** MEDIUM | **Effort:** LOW
```
Current: transcriptCache grows unbounded (memory leak potential)

File to modify:
- splice-backend/services/transcription.js

Implementation:
const MAX_CACHE_SIZE = 50;

function cacheSet(key, value) {
  if (transcriptCache.size >= MAX_CACHE_SIZE) {
    const oldest = transcriptCache.keys().next().value;
    transcriptCache.delete(oldest);
  }
  transcriptCache.set(key, value);
}
```

#### 2.3 Confidence Scores
**Impact:** MEDIUM | **Effort:** LOW
```
Missing: No accuracy metrics on detection results

Add to response objects:
- profanity: { confidence: 0.95, matchType: 'exact'|'variant' }
- repetition: { similarity: 0.85 }
- stutter: { gapMs: 150, repeatCount: 3 }

Files to modify:
- splice-backend/services/profanityDetection.js
- splice-backend/services/repetitionDetection.js
```

#### 2.4 EDL Export Format
**Impact:** MEDIUM | **Effort:** MEDIUM
```
Missing: Edit Decision List export for cross-application compatibility

File to create:
- splice-backend/services/edlExporter.js

EDL Format:
TITLE: SPLICE Export
FCM: NON-DROP FRAME

001  AX       V     C        00:00:00:00 00:00:05:15 00:00:00:00 00:00:05:15
* FROM CLIP NAME: interview.mp4
```

### Priority 3: NICE TO HAVE (Polish Features)

#### 3.1 Waveform Visualization
**Impact:** HIGH (UX) | **Effort:** HIGH
```
Missing: Audio peaks display in plugin

Would require:
- Canvas-based waveform rendering
- Audio buffer extraction from Premiere
- Threshold line overlay
- Real-time scrubbing

Note: May be limited by UXP sandbox constraints
```

#### 3.2 Speaker Diarization
**Impact:** HIGH | **Effort:** VERY HIGH
```
Missing: Automatic speaker identification

Would require:
- pyannote.audio or similar ML model
- Speaker embedding extraction
- Clustering algorithm
- Integration with multitrack analysis

Note: Consider third-party API (AssemblyAI, Deepgram)
```

#### 3.3 Breath Detection
**Impact:** MEDIUM | **Effort:** HIGH
```
Missing: Spectral analysis for mouth sounds

Would require:
- FFT analysis for breath frequencies (100-500Hz spikes)
- Trainable threshold
- Separate from silence detection
```

---

## IMMEDIATE FIXES FROM E2E TESTING

### Already Applied:
1. ✅ Better OpenAI error messages (quota, connection)
2. ✅ Cache utility functions (clearCache, getCacheStats)
3. ✅ E2E test suite (tests/transcription-e2e.test.js)

### Still Needed:
```javascript
// 1. Add retry logic to transcribeWithWords
// File: splice-backend/services/transcription.js:107

// 2. Add cache size limit
// File: splice-backend/services/transcription.js:17

// 3. Add timeout to OpenAI calls
// File: splice-backend/services/transcription.js:109
const transcription = await openai.audio.transcriptions.create({
  ...options,
  timeout: 60000  // 60 second timeout
});
```

---

## TESTING REQUIREMENTS

### Before Any Deploy:
```bash
# Run E2E tests
cd splice-backend && node tests/transcription-e2e.test.js

# Syntax check all services
node -c services/transcription.js
node -c services/profanityDetection.js
node -c services/repetitionDetection.js
node -c server.js

# Start server and verify health
node server.js &
curl -sk https://127.0.0.1:3847/health
```

### OpenAI API Status:
```bash
# Check quota (current issue - insufficient_quota)
curl https://api.openai.com/v1/models \
  -H "Authorization: Bearer $OPENAI_API_KEY"

# If quota error, add billing at:
# https://platform.openai.com/account/billing
```

---

## FILE REFERENCE

### Backend Services (splice-backend/services/)
| File | Lines | Purpose |
|------|-------|---------|
| transcription.js | 171 | Whisper + word timestamps |
| profanityDetection.js | 562 | Multi-language censoring |
| repetitionDetection.js | 625 | Phrase + stutter detection |
| takeDetection.js | 107 | GPT-based take identification |
| silenceDetection.js | 46 | Whisper gap analysis |
| ffprobeSilence.js | 149 | Audio-level silence |
| rmsSilenceDetection.js | 555 | Advanced RMS analysis |
| multitrackAnalysis.js | 725 | Multicam speaker detection |
| cutListGenerator.js | 368 | v3.5 JSON cut lists |
| usageTracking.js | ~300 | Billing + credits |

### Plugin (splice-plugin/js/)
| File | Purpose |
|------|---------|
| main.js | Core UI + workflow orchestration |
| builder.js | v3.5 direct DOM sequence building |
| settings.js | localStorage persistence |
| credits.js | Balance display + tier info |
| config.js | Backend URL configuration |

---

## QUICK START COMMANDS

```bash
# Navigate to project
cd /Users/imorgado/SPLICE/splice-backend

# Start development server
node server.js

# Run tests
node tests/transcription-e2e.test.js

# Check server health
curl -sk https://127.0.0.1:3847/health

# Test silence detection (with sample file)
curl -sk https://127.0.0.1:3847/silences-rms \
  -H "Content-Type: application/json" \
  -d '{"wavPath":"/tmp/splice_test/stutter_test.wav", "sensitivity": 50}'
```

---

## RECOMMENDED IMPLEMENTATION ORDER

### Week 1: Quick Wins
1. [ ] Filler word endpoint (2 hrs)
2. [ ] Cache size limit (1 hr)
3. [ ] Retry logic for OpenAI (2 hrs)
4. [ ] Confidence scores (2 hrs)

### Week 2: Core Features
5. [ ] Preset profiles UI (4 hrs)
6. [ ] SRT/VTT export (4 hrs)
7. [ ] EDL export (4 hrs)

### Week 3: Advanced
8. [ ] Batch processing backend (8 hrs)
9. [ ] Batch processing UI (8 hrs)

### Week 4: Polish
10. [ ] Waveform visualization research
11. [ ] Speaker diarization API evaluation
12. [ ] Performance optimization

---

## SUCCESS METRICS

| Metric | Current | Target (95% Parity) |
|--------|---------|---------------------|
| Silence detection methods | 3 | 3 ✅ |
| Language support | 4 | 4 ✅ |
| Batch processing | No | Yes |
| Export formats | 1 (JSON) | 3 (JSON, SRT, EDL) |
| Preset profiles | 0 | 4+ |
| Filler word removal | No | Yes |
| Retry logic | No | Yes |
| Waveform display | No | Optional |

---

*Generated: 2025-12-25*
*Based on: E2E testing + 3-agent codebase exploration*
