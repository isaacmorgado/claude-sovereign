const express = require('express');
const cors = require('cors');
const fs = require('fs');
const path = require('path');

const app = express();
const PORT = process.env.PORT || 3847;

app.use(cors());
app.use(express.json());

// Health check
app.get('/health', (req, res) => {
  res.json({ status: 'ok', service: 'splice-backend' });
});

// POST /analyze - Receive WAV path, transcribe with Groq Whisper
app.post('/analyze', async (req, res) => {
  const { wavPath } = req.body;

  if (!wavPath) {
    return res.status(400).json({ error: 'wavPath is required' });
  }

  // Verify file exists
  if (!fs.existsSync(wavPath)) {
    return res.status(404).json({ error: `File not found: ${wavPath}` });
  }

  console.log(`[SPLICE] Analyzing: ${wavPath}`);

  try {
    // TODO: Slice 4 - Groq Whisper transcription
    const transcript = await transcribeAudio(wavPath);

    // TODO: Slice 5 - GPT-4o-mini take detection
    const takes = await detectTakes(transcript);

    res.json({
      success: true,
      wavPath,
      transcript,
      takes
    });
  } catch (err) {
    console.error('[SPLICE] Error:', err);
    res.status(500).json({ error: err.message });
  }
});

// Placeholder: Groq Whisper transcription (Slice 4)
async function transcribeAudio(wavPath) {
  // TODO: Implement Groq Whisper API call
  // const Groq = require('groq-sdk');
  // const groq = new Groq({ apiKey: process.env.GROQ_API_KEY });
  // const transcription = await groq.audio.transcriptions.create({
  //   file: fs.createReadStream(wavPath),
  //   model: 'whisper-large-v3',
  //   response_format: 'verbose_json',
  // });

  console.log('[SPLICE] Transcription placeholder - returning mock data');
  return {
    text: '[MOCK] This is take one. Cut. Take two, that was better. Cut. Take three.',
    segments: [
      { start: 0.0, end: 2.5, text: 'This is take one.' },
      { start: 2.5, end: 3.0, text: 'Cut.' },
      { start: 3.5, end: 6.0, text: 'Take two, that was better.' },
      { start: 6.0, end: 6.5, text: 'Cut.' },
      { start: 7.0, end: 9.0, text: 'Take three.' }
    ]
  };
}

// Placeholder: GPT-4o-mini take detection (Slice 5)
async function detectTakes(transcript) {
  // TODO: Implement OpenAI GPT-4o-mini call for take detection
  console.log('[SPLICE] Take detection placeholder - returning mock data');
  return [
    { takeNumber: 1, start: 0.0, end: 2.5, isBest: false },
    { takeNumber: 2, start: 3.5, end: 6.0, isBest: true },
    { takeNumber: 3, start: 7.0, end: 9.0, isBest: false }
  ];
}

app.listen(PORT, () => {
  console.log(`[SPLICE] Backend running at http://localhost:${PORT}`);
  console.log(`[SPLICE] POST /analyze with { "wavPath": "/path/to/audio.wav" }`);
});
