// Premiere Pro API wrapper

import type {
  PremiereProject,
  PremiereSequence,
  PremiereClip,
  SelectionState,
} from '@/types/premiere'
import type { ClipSelection } from '@/types/plugin'
import { logger } from '../logger'

// Type declarations for UXP Premiere Pro API
declare const app: {
  project: {
    name: string
    path: string
    activeSequence: unknown
    sequences: unknown[]
  }
}

export async function getActiveProject(): Promise<PremiereProject | null> {
  try {
    // Access Premiere Pro's project through UXP API
    const project = app?.project
    if (!project) {
      logger.warn('No active project found')
      return null
    }

    return {
      name: project.name,
      path: project.path,
      sequences: await getSequences(),
      activeSequence: await getActiveSequence(),
    }
  } catch (error) {
    logger.error('Failed to get active project', error)
    return null
  }
}

export async function getActiveSequence(): Promise<PremiereSequence | null> {
  try {
    const sequence = app?.project?.activeSequence
    if (!sequence) {
      logger.debug('No active sequence')
      return null
    }

    // Map the Premiere sequence to our type
    return mapSequence(sequence)
  } catch (error) {
    logger.error('Failed to get active sequence', error)
    return null
  }
}

export async function getSequences(): Promise<PremiereSequence[]> {
  try {
    const sequences = app?.project?.sequences || []
    return sequences.map(mapSequence)
  } catch (error) {
    logger.error('Failed to get sequences', error)
    return []
  }
}

export async function getSelectedClips(): Promise<ClipSelection[]> {
  try {
    const sequence = await getActiveSequence()
    if (!sequence) return []

    const selectedClips: ClipSelection[] = []

    // Iterate through video tracks
    for (const track of sequence.videoTracks) {
      for (const clip of track.clips) {
        if (clip.isSelected) {
          selectedClips.push({
            id: clip.id,
            name: clip.name,
            startTime: clip.startTime,
            endTime: clip.endTime,
            trackIndex: track.index,
            type: 'video',
          })
        }
      }
    }

    // Iterate through audio tracks
    for (const track of sequence.audioTracks) {
      for (const clip of track.clips) {
        if (clip.isSelected) {
          selectedClips.push({
            id: clip.id,
            name: clip.name,
            startTime: clip.startTime,
            endTime: clip.endTime,
            trackIndex: track.index,
            type: 'audio',
          })
        }
      }
    }

    logger.debug('Selected clips retrieved', { count: selectedClips.length })
    return selectedClips
  } catch (error) {
    logger.error('Failed to get selected clips', error)
    return []
  }
}

export async function selectClipsByTimeRange(
  startTime: number,
  endTime: number,
  trackIndices?: number[]
): Promise<boolean> {
  try {
    const sequence = await getActiveSequence()
    if (!sequence) {
      logger.warn('No active sequence for selection')
      return false
    }

    // This would use the actual Premiere Pro API to select clips
    // The implementation depends on the specific UXP API available
    logger.info('Selecting clips by time range', { startTime, endTime, trackIndices })

    // Placeholder for actual implementation
    return true
  } catch (error) {
    logger.error('Failed to select clips by time range', error)
    return false
  }
}

export async function selectAllClipsInTrack(
  trackIndex: number,
  trackType: 'video' | 'audio'
): Promise<boolean> {
  try {
    const sequence = await getActiveSequence()
    if (!sequence) return false

    const tracks = trackType === 'video' ? sequence.videoTracks : sequence.audioTracks
    const track = tracks.find((t) => t.index === trackIndex)

    if (!track) {
      logger.warn('Track not found', { trackIndex, trackType })
      return false
    }

    // Select all clips in the track
    logger.info('Selecting all clips in track', {
      trackIndex,
      trackType,
      clipCount: track.clips.length,
    })
    return true
  } catch (error) {
    logger.error('Failed to select clips in track', error)
    return false
  }
}

export async function getSelectionState(): Promise<SelectionState> {
  try {
    const sequence = await getActiveSequence()
    if (!sequence) {
      return { clips: [], markers: [], tracks: [] }
    }

    const selectedClips: PremiereClip[] = []

    for (const track of [...sequence.videoTracks, ...sequence.audioTracks]) {
      selectedClips.push(...track.clips.filter((c) => c.isSelected))
    }

    return {
      clips: selectedClips,
      markers: [], // Would be populated from actual API
      tracks: [],
    }
  } catch (error) {
    logger.error('Failed to get selection state', error)
    return { clips: [], markers: [], tracks: [] }
  }
}

// Helper function to map raw sequence to typed structure
function mapSequence(sequence: unknown): PremiereSequence {
  const seq = sequence as Record<string, unknown>

  return {
    id: String(seq.sequenceID || seq.id || ''),
    name: String(seq.name || 'Untitled'),
    videoTracks: [],
    audioTracks: [],
    duration: Number(seq.end || 0) - Number(seq.start || 0),
    frameRate: {
      numerator: 24000,
      denominator: 1001,
      value: 23.976,
    },
  }
}

// ============================================================================
// Clip Splitting / Cutting API
// ============================================================================

export interface CutResult {
  success: boolean
  originalClipId: string
  newClipId?: string
  cutTime: number
  error?: string
}

export interface ApplyCutsResult {
  success: boolean
  cutsApplied: number
  cutsFailed: number
  results: CutResult[]
}

/**
 * Split a clip at a specific time position.
 * This simulates a "razor cut" by:
 * 1. Adjusting the original clip's out point to the cut time
 * 2. Inserting a new clip from the same source starting at the cut time
 *
 * @param clipId - The ID of the clip to split
 * @param cutTime - The time (in seconds) at which to make the cut
 * @param trackIndex - The track index where the clip resides
 * @param trackType - Whether it's a video or audio track
 */
export async function splitClipAtTime(
  clipId: string,
  cutTime: number,
  trackIndex: number,
  trackType: 'video' | 'audio'
): Promise<CutResult> {
  try {
    const sequence = app?.project?.activeSequence as Record<string, unknown> | undefined
    if (!sequence) {
      return { success: false, originalClipId: clipId, cutTime, error: 'No active sequence' }
    }

    // Get the appropriate track collection
    const tracks = (
      trackType === 'video' ? sequence.videoTracks : sequence.audioTracks
    ) as unknown[]
    if (!tracks || !Array.isArray(tracks)) {
      return { success: false, originalClipId: clipId, cutTime, error: 'Could not access tracks' }
    }

    const track = tracks[trackIndex] as Record<string, unknown> | undefined
    if (!track) {
      return { success: false, originalClipId: clipId, cutTime, error: 'Track not found' }
    }

    // Find the clip in the track
    const clips = track.clips as unknown[]
    if (!clips || !Array.isArray(clips)) {
      return { success: false, originalClipId: clipId, cutTime, error: 'Could not access clips' }
    }

    const clipIndex = clips.findIndex((c) => {
      const clip = c as Record<string, unknown>
      return String(clip.nodeId || clip.id) === clipId
    })

    if (clipIndex === -1) {
      return { success: false, originalClipId: clipId, cutTime, error: 'Clip not found' }
    }

    const clip = clips[clipIndex] as Record<string, unknown>

    // Validate cut time is within clip bounds
    const clipStart = Number(clip.start || 0)
    const clipEnd = Number(clip.end || 0)

    if (cutTime <= clipStart || cutTime >= clipEnd) {
      return {
        success: false,
        originalClipId: clipId,
        cutTime,
        error: 'Cut time is outside clip bounds',
      }
    }

    // Get the project item (source) for this clip
    const projectItem = clip.projectItem as Record<string, unknown> | undefined
    if (!projectItem) {
      return {
        success: false,
        originalClipId: clipId,
        cutTime,
        error: 'Could not get clip source',
      }
    }

    // Calculate the new in/out points
    // Original clip: keep in point, set out point to cut time
    // New clip: in point at cut time (relative to source), out point at original out

    const originalInPoint = Number(clip.inPoint || 0)
    const originalOutPoint = Number(clip.outPoint || 0)
    const cutTimeInSource = originalInPoint + (cutTime - clipStart)

    // Step 1: Adjust original clip's out point
    if (typeof clip.end === 'number') {
      ;(clip as { end: number }).end = cutTime
    }
    if (typeof clip.outPoint === 'number') {
      ;(clip as { outPoint: number }).outPoint = cutTimeInSource
    }

    // Step 2: Insert new clip from same source
    // Use the track's insertClip method if available
    const insertClip = track.insertClip as
      | ((
          projectItem: unknown,
          time: number,
          videoTrackIndex: number,
          audioTrackIndex: number
        ) => unknown)
      | undefined

    let newClipId: string | undefined

    if (typeof insertClip === 'function') {
      const newClip = insertClip.call(
        track,
        projectItem,
        cutTime,
        trackType === 'video' ? trackIndex : -1,
        trackType === 'audio' ? trackIndex : -1
      ) as Record<string, unknown> | undefined

      if (newClip) {
        // Set the new clip's in point to match where we cut
        if (typeof newClip.inPoint === 'number') {
          ;(newClip as { inPoint: number }).inPoint = cutTimeInSource
        }
        if (typeof newClip.outPoint === 'number') {
          ;(newClip as { outPoint: number }).outPoint = originalOutPoint
        }
        newClipId = String(newClip.nodeId || newClip.id || '')
      }
    } else {
      // Fallback: Try using sequence.insertClip or other API methods
      logger.warn('Track insertClip method not available, trying alternative')

      // Alternative approach using overwriteClip if available
      const overwriteClip = sequence.overwriteClip as
        | ((projectItem: unknown, time: number) => unknown)
        | undefined

      if (typeof overwriteClip === 'function') {
        const newClip = overwriteClip.call(sequence, projectItem, cutTime) as
          | Record<string, unknown>
          | undefined
        if (newClip) {
          newClipId = String(newClip.nodeId || newClip.id || '')
        }
      }
    }

    logger.info('Clip split completed', {
      originalClipId: clipId,
      newClipId,
      cutTime,
      trackIndex,
      trackType,
    })

    return {
      success: true,
      originalClipId: clipId,
      newClipId,
      cutTime,
    }
  } catch (error) {
    const errorMessage = error instanceof Error ? error.message : 'Unknown error'
    logger.error('Failed to split clip', { clipId, cutTime, error: errorMessage })
    return {
      success: false,
      originalClipId: clipId,
      cutTime,
      error: errorMessage,
    }
  }
}

/**
 * Apply multiple cuts to a clip at specified time positions.
 * Cuts are applied in reverse order (from end to start) to avoid
 * invalidating cut positions.
 *
 * @param clipId - The ID of the clip to cut
 * @param cutTimes - Array of times (in seconds) at which to make cuts
 * @param trackIndex - The track index where the clip resides
 * @param trackType - Whether it's a video or audio track
 */
export async function applyCutsToClip(
  clipId: string,
  cutTimes: number[],
  trackIndex: number,
  trackType: 'video' | 'audio'
): Promise<ApplyCutsResult> {
  // Sort cut times in descending order (apply from end to start)
  const sortedCutTimes = [...cutTimes].sort((a, b) => b - a)

  const results: CutResult[] = []

  for (const cutTime of sortedCutTimes) {
    // Since we cut from end to start, the original clip ID remains valid
    const result = await splitClipAtTime(clipId, cutTime, trackIndex, trackType)
    results.push(result)

    // If successful and we're cutting from end to start,
    // the original clip ID stays the same for the next cut
  }

  const cutsApplied = results.filter((r) => r.success).length
  const cutsFailed = results.filter((r) => !r.success).length

  logger.info('Applied cuts to clip', {
    clipId,
    totalCuts: cutTimes.length,
    cutsApplied,
    cutsFailed,
  })

  return {
    success: cutsFailed === 0,
    cutsApplied,
    cutsFailed,
    results,
  }
}

/**
 * Apply silence-based cuts to selected clips.
 * Uses transcription segments to detect silence gaps and cut at those points.
 */
export async function applySilenceCutsToSelection(cutTimes: number[]): Promise<ApplyCutsResult[]> {
  const selectedClips = await getSelectedClips()

  if (selectedClips.length === 0) {
    logger.warn('No clips selected for silence cutting')
    return []
  }

  const allResults: ApplyCutsResult[] = []

  for (const clip of selectedClips) {
    // Filter cut times to only those within this clip's bounds
    const clipCutTimes = cutTimes.filter((t) => t > clip.startTime && t < clip.endTime)

    if (clipCutTimes.length === 0) {
      continue
    }

    const result = await applyCutsToClip(clip.id, clipCutTimes, clip.trackIndex, clip.type)
    allResults.push(result)
  }

  return allResults
}

// ============================================================================
// Clip Labeling / Color API
// ============================================================================

// Premiere Pro label color indices (0-15)
export const PREMIERE_LABEL_COLORS = {
  VIOLET: 0,
  IRIS: 1,
  CARIBBEAN: 2,
  LAVENDER: 3,
  CERULEAN: 4,
  FOREST: 5,
  ROSE: 6,
  MANGO: 7,
  PURPLE: 8,
  BLUE: 9,
  TEAL: 10,
  MAGENTA: 11,
  TAN: 12,
  GREEN: 13,
  BROWN: 14,
  YELLOW: 15,
} as const

export type PremiereLabelColor = (typeof PREMIERE_LABEL_COLORS)[keyof typeof PREMIERE_LABEL_COLORS]

export interface ClipLabelResult {
  success: boolean
  clipId: string
  error?: string
}

/**
 * Set a clip's label color on the timeline.
 * Uses Premiere Pro's label color system (0-15).
 *
 * @param clipId - The ID of the clip to color
 * @param colorIndex - Label color index (0-15)
 * @param trackIndex - The track index where the clip resides
 * @param trackType - Whether it's a video or audio track
 */
export async function setClipLabelColor(
  clipId: string,
  colorIndex: PremiereLabelColor,
  trackIndex: number,
  trackType: 'video' | 'audio'
): Promise<ClipLabelResult> {
  try {
    const sequence = app?.project?.activeSequence as Record<string, unknown> | undefined
    if (!sequence) {
      return { success: false, clipId, error: 'No active sequence' }
    }

    const tracks = (
      trackType === 'video' ? sequence.videoTracks : sequence.audioTracks
    ) as unknown[]
    if (!tracks || !Array.isArray(tracks)) {
      return { success: false, clipId, error: 'Could not access tracks' }
    }

    const track = tracks[trackIndex] as Record<string, unknown> | undefined
    if (!track) {
      return { success: false, clipId, error: 'Track not found' }
    }

    const clips = track.clips as unknown[]
    if (!clips || !Array.isArray(clips)) {
      return { success: false, clipId, error: 'Could not access clips' }
    }

    const clip = clips.find((c) => {
      const cl = c as Record<string, unknown>
      return String(cl.nodeId || cl.id) === clipId
    }) as Record<string, unknown> | undefined

    if (!clip) {
      return { success: false, clipId, error: 'Clip not found' }
    }

    // Get the project item and set its label
    const projectItem = clip.projectItem as Record<string, unknown> | undefined
    if (projectItem) {
      // Try to set label color via project item
      const setColorLabel = projectItem.setColorLabel as ((colorIndex: number) => void) | undefined
      if (typeof setColorLabel === 'function') {
        setColorLabel.call(projectItem, colorIndex)
        logger.info('Set clip label color', { clipId, colorIndex })
        return { success: true, clipId }
      }

      // Alternative: set via label property
      if ('colorLabel' in projectItem) {
        ;(projectItem as { colorLabel: number }).colorLabel = colorIndex
        logger.info('Set clip label color via property', { clipId, colorIndex })
        return { success: true, clipId }
      }
    }

    // Try setting directly on the clip
    if ('colorLabel' in clip) {
      ;(clip as { colorLabel: number }).colorLabel = colorIndex
      logger.info('Set clip label color directly', { clipId, colorIndex })
      return { success: true, clipId }
    }

    return { success: false, clipId, error: 'No color label API available' }
  } catch (error) {
    const errorMessage = error instanceof Error ? error.message : 'Unknown error'
    logger.error('Failed to set clip label color', { clipId, colorIndex, error: errorMessage })
    return { success: false, clipId, error: errorMessage }
  }
}

/**
 * Rename a clip on the timeline.
 *
 * @param clipId - The ID of the clip to rename
 * @param name - The new name for the clip
 * @param trackIndex - The track index where the clip resides
 * @param trackType - Whether it's a video or audio track
 */
export async function setClipName(
  clipId: string,
  name: string,
  trackIndex: number,
  trackType: 'video' | 'audio'
): Promise<ClipLabelResult> {
  try {
    const sequence = app?.project?.activeSequence as Record<string, unknown> | undefined
    if (!sequence) {
      return { success: false, clipId, error: 'No active sequence' }
    }

    const tracks = (
      trackType === 'video' ? sequence.videoTracks : sequence.audioTracks
    ) as unknown[]
    if (!tracks || !Array.isArray(tracks)) {
      return { success: false, clipId, error: 'Could not access tracks' }
    }

    const track = tracks[trackIndex] as Record<string, unknown> | undefined
    if (!track) {
      return { success: false, clipId, error: 'Track not found' }
    }

    const clips = track.clips as unknown[]
    if (!clips || !Array.isArray(clips)) {
      return { success: false, clipId, error: 'Could not access clips' }
    }

    const clip = clips.find((c) => {
      const cl = c as Record<string, unknown>
      return String(cl.nodeId || cl.id) === clipId
    }) as Record<string, unknown> | undefined

    if (!clip) {
      return { success: false, clipId, error: 'Clip not found' }
    }

    // Try setName method (UXP API)
    const setNameMethod = clip.setName as ((name: string) => void) | undefined
    if (typeof setNameMethod === 'function') {
      setNameMethod.call(clip, name)
      logger.info('Set clip name', { clipId, name })
      return { success: true, clipId }
    }

    // Alternative: set name property directly
    if ('name' in clip) {
      ;(clip as { name: string }).name = name
      logger.info('Set clip name via property', { clipId, name })
      return { success: true, clipId }
    }

    return { success: false, clipId, error: 'No name setter API available' }
  } catch (error) {
    const errorMessage = error instanceof Error ? error.message : 'Unknown error'
    logger.error('Failed to set clip name', { clipId, name, error: errorMessage })
    return { success: false, clipId, error: errorMessage }
  }
}

/**
 * Apply take group colors and labels to clips on the timeline.
 * Matches clips by their time positions to the take groups.
 */
export interface TakeGroupInput {
  id: string
  label: string
  takes: {
    takeNumber: number
    startTime: number
    endTime: number
    text: string
  }[]
  colorIndex: number
}

export interface ApplyTakeGroupsResult {
  success: boolean
  clipsLabeled: number
  clipsFailed: number
  results: ClipLabelResult[]
}

export async function applyTakeGroupColors(
  takeGroups: TakeGroupInput[]
): Promise<ApplyTakeGroupsResult> {
  const selectedClips = await getSelectedClips()
  const results: ClipLabelResult[] = []
  let clipsLabeled = 0
  let clipsFailed = 0

  for (const group of takeGroups) {
    for (const take of group.takes) {
      // Find clip that matches this take's time position (with some tolerance)
      const tolerance = 0.5 // 500ms tolerance
      const matchingClip = selectedClips.find(
        (clip) =>
          Math.abs(clip.startTime - take.startTime) < tolerance &&
          Math.abs(clip.endTime - take.endTime) < tolerance
      )

      if (matchingClip) {
        // Set color
        const colorResult = await setClipLabelColor(
          matchingClip.id,
          group.colorIndex as PremiereLabelColor,
          matchingClip.trackIndex,
          matchingClip.type
        )

        // Set name: "Take 1 - Hey Guys"
        const takeName = `Take ${String(take.takeNumber)} - ${group.label}`
        const nameResult = await setClipName(
          matchingClip.id,
          takeName,
          matchingClip.trackIndex,
          matchingClip.type
        )

        const success = colorResult.success || nameResult.success
        results.push({
          success,
          clipId: matchingClip.id,
          error: success ? undefined : (colorResult.error ?? nameResult.error),
        })

        if (success) {
          clipsLabeled++
        } else {
          clipsFailed++
        }
      }
    }
  }

  logger.info('Applied take group colors', {
    groupCount: takeGroups.length,
    clipsLabeled,
    clipsFailed,
  })

  return {
    success: clipsFailed === 0,
    clipsLabeled,
    clipsFailed,
    results,
  }
}

// ============================================================================
// Audio Extraction API
// ============================================================================

export interface AudioExtractionOptions {
  format?: 'wav' | 'mp3' | 'aac'
  sampleRate?: 44100 | 48000 | 96000
  channels?: 1 | 2
  bitDepth?: 16 | 24 | 32
}

export interface ExtractedAudio {
  clipId: string
  clipName: string
  startTime: number
  endTime: number
  duration: number
  file: File
  sourcePath?: string
}

export interface AudioExtractionResult {
  success: boolean
  extractedFiles: ExtractedAudio[]
  combinedFile?: File
  totalDuration: number
  error?: string
}

export interface AudioExtractionProgress {
  phase: 'preparing' | 'exporting' | 'processing' | 'complete'
  clipIndex: number
  totalClips: number
  progress: number
  message: string
}

/**
 * Extract audio from selected clips in the timeline.
 * Uses Premiere Pro's export capabilities to render audio-only output.
 *
 * @param options - Audio format and quality settings
 * @param onProgress - Progress callback for UI updates
 */
export async function extractAudioFromClips(
  options: AudioExtractionOptions = {},
  onProgress?: (progress: AudioExtractionProgress) => void
): Promise<AudioExtractionResult> {
  const {
    format = 'wav',
    sampleRate = 48000,
    channels = 2,
    bitDepth = 24,
  } = options

  try {
    const selectedClips = await getSelectedClips()

    if (selectedClips.length === 0) {
      return {
        success: false,
        extractedFiles: [],
        totalDuration: 0,
        error: 'No clips selected in timeline',
      }
    }

    onProgress?.({
      phase: 'preparing',
      clipIndex: 0,
      totalClips: selectedClips.length,
      progress: 0,
      message: `Preparing to extract audio from ${selectedClips.length} clips...`,
    })

    const sequence = app?.project?.activeSequence as Record<string, unknown> | undefined
    if (!sequence) {
      return {
        success: false,
        extractedFiles: [],
        totalDuration: 0,
        error: 'No active sequence',
      }
    }

    // Calculate total timeline range from selected clips
    const minStart = Math.min(...selectedClips.map((c) => c.startTime))
    const maxEnd = Math.max(...selectedClips.map((c) => c.endTime))
    const totalDuration = maxEnd - minStart

    // Try to use sequence export for combined audio
    const exportResult = await exportSequenceAudio(
      sequence,
      minStart,
      maxEnd,
      { format, sampleRate, channels, bitDepth },
      (progress) => {
        onProgress?.({
          phase: 'exporting',
          clipIndex: 0,
          totalClips: selectedClips.length,
          progress: progress * 0.8,
          message: `Exporting audio: ${Math.round(progress * 100)}%`,
        })
      }
    )

    if (exportResult.success && exportResult.file) {
      onProgress?.({
        phase: 'complete',
        clipIndex: selectedClips.length,
        totalClips: selectedClips.length,
        progress: 1,
        message: 'Audio extraction complete',
      })

      return {
        success: true,
        extractedFiles: selectedClips.map((clip) => ({
          clipId: clip.id,
          clipName: clip.name,
          startTime: clip.startTime,
          endTime: clip.endTime,
          duration: clip.endTime - clip.startTime,
          file: exportResult.file!,
        })),
        combinedFile: exportResult.file,
        totalDuration,
      }
    }

    // Fallback: try to get source media paths for individual extraction
    const extractedFiles: ExtractedAudio[] = []

    for (let i = 0; i < selectedClips.length; i++) {
      const clip = selectedClips[i]

      onProgress?.({
        phase: 'processing',
        clipIndex: i,
        totalClips: selectedClips.length,
        progress: 0.8 + (i / selectedClips.length) * 0.2,
        message: `Processing clip ${i + 1}/${selectedClips.length}: ${clip.name}`,
      })

      const mediaPath = await getClipMediaPath(clip.id, clip.trackIndex, clip.type)
      if (mediaPath) {
        // Create a File object from the media path for source-based approach
        const audioFile = await extractAudioFromMediaPath(
          mediaPath,
          clip.startTime,
          clip.endTime - clip.startTime,
          { format, sampleRate, channels, bitDepth }
        )

        if (audioFile) {
          extractedFiles.push({
            clipId: clip.id,
            clipName: clip.name,
            startTime: clip.startTime,
            endTime: clip.endTime,
            duration: clip.endTime - clip.startTime,
            file: audioFile,
            sourcePath: mediaPath,
          })
        }
      }
    }

    onProgress?.({
      phase: 'complete',
      clipIndex: selectedClips.length,
      totalClips: selectedClips.length,
      progress: 1,
      message: extractedFiles.length > 0 ? 'Audio extraction complete' : 'No audio extracted',
    })

    return {
      success: extractedFiles.length > 0,
      extractedFiles,
      totalDuration,
      error: extractedFiles.length === 0 ? 'Could not extract audio from any clips' : undefined,
    }
  } catch (error) {
    const errorMessage = error instanceof Error ? error.message : 'Unknown error'
    logger.error('Failed to extract audio from clips', { error: errorMessage })
    return {
      success: false,
      extractedFiles: [],
      totalDuration: 0,
      error: errorMessage,
    }
  }
}

/**
 * Get the source media path for a clip on the timeline.
 */
async function getClipMediaPath(
  clipId: string,
  trackIndex: number,
  trackType: 'video' | 'audio'
): Promise<string | null> {
  try {
    const sequence = app?.project?.activeSequence as Record<string, unknown> | undefined
    if (!sequence) return null

    const tracks = (
      trackType === 'video' ? sequence.videoTracks : sequence.audioTracks
    ) as unknown[]
    if (!tracks || !Array.isArray(tracks)) return null

    const track = tracks[trackIndex] as Record<string, unknown> | undefined
    if (!track) return null

    const clips = track.clips as unknown[]
    if (!clips || !Array.isArray(clips)) return null

    const clip = clips.find((c) => {
      const cl = c as Record<string, unknown>
      return String(cl.nodeId || cl.id) === clipId
    }) as Record<string, unknown> | undefined

    if (!clip) return null

    const projectItem = clip.projectItem as Record<string, unknown> | undefined
    if (!projectItem) return null

    // Try getMediaPath method
    const getMediaPath = projectItem.getMediaPath as (() => string) | undefined
    if (typeof getMediaPath === 'function') {
      return getMediaPath.call(projectItem)
    }

    // Fallback: try treePath or filePath property
    const path = projectItem.treePath ?? projectItem.filePath ?? projectItem.mediaPath
    if (typeof path === 'string') {
      return path
    }

    return null
  } catch (error) {
    logger.error('Failed to get clip media path', { clipId, error })
    return null
  }
}

interface SequenceExportResult {
  success: boolean
  file?: File
  error?: string
}

/**
 * Export audio from a sequence time range using Adobe Media Encoder.
 */
async function exportSequenceAudio(
  sequence: Record<string, unknown>,
  startTime: number,
  endTime: number,
  options: AudioExtractionOptions,
  onProgress?: (progress: number) => void
): Promise<SequenceExportResult> {
  try {
    // Set sequence in/out points for export range
    const setInPoint = sequence.setInPoint as ((time: number) => void) | undefined
    const setOutPoint = sequence.setOutPoint as ((time: number) => void) | undefined

    if (typeof setInPoint === 'function' && typeof setOutPoint === 'function') {
      setInPoint.call(sequence, startTime)
      setOutPoint.call(sequence, endTime)
    }

    // Try using the encoder API if available
    const encoder = (globalThis as Record<string, unknown>).encoder as
      | Record<string, unknown>
      | undefined

    if (encoder) {
      const result = await exportViaEncoder(encoder, sequence, options, onProgress)
      if (result.success) {
        return result
      }
    }

    // Alternative: Try sequence.exportAsMediaDirect if available
    const exportMethod = sequence.exportAsMediaDirect as
      | ((
          outputPath: string,
          presetPath: string,
          workAreaType: number
        ) => Promise<boolean>)
      | undefined

    if (typeof exportMethod === 'function') {
      // Get temp file path
      const tempPath = await getTempAudioPath(options.format ?? 'wav')
      const presetPath = await getAudioExportPresetPath(options)

      onProgress?.(0.1)

      const exportSuccess = await exportMethod.call(sequence, tempPath, presetPath, 1)

      if (exportSuccess) {
        onProgress?.(0.9)
        const file = await readFileAsBlob(tempPath, options.format ?? 'wav')
        return { success: true, file }
      }
    }

    // Fallback: Check for sequence.exportSequence method
    const exportSequence = sequence.exportSequence as
      | ((outputPath: string, format: string) => Promise<boolean>)
      | undefined

    if (typeof exportSequence === 'function') {
      const tempPath = await getTempAudioPath(options.format ?? 'wav')
      onProgress?.(0.1)

      const success = await exportSequence.call(sequence, tempPath, 'audio')
      if (success) {
        onProgress?.(0.9)
        const file = await readFileAsBlob(tempPath, options.format ?? 'wav')
        return { success: true, file }
      }
    }

    return { success: false, error: 'No export method available' }
  } catch (error) {
    const errorMessage = error instanceof Error ? error.message : 'Export failed'
    logger.error('Sequence audio export failed', { error: errorMessage })
    return { success: false, error: errorMessage }
  }
}

/**
 * Export audio using Adobe Media Encoder API.
 */
async function exportViaEncoder(
  encoder: Record<string, unknown>,
  sequence: Record<string, unknown>,
  options: AudioExtractionOptions,
  onProgress?: (progress: number) => void
): Promise<SequenceExportResult> {
  try {
    const addSequence = encoder.addSequence as
      | ((sequence: unknown, outputPath: string, presetPath: string) => Promise<string>)
      | undefined

    if (typeof addSequence !== 'function') {
      return { success: false, error: 'Encoder addSequence not available' }
    }

    const tempPath = await getTempAudioPath(options.format ?? 'wav')
    const presetPath = await getAudioExportPresetPath(options)

    // Add to encoder queue
    const jobId = await addSequence.call(encoder, sequence, tempPath, presetPath)

    if (!jobId) {
      return { success: false, error: 'Failed to add to encoder queue' }
    }

    // Start encoding
    const startBatch = encoder.startBatch as (() => Promise<void>) | undefined
    if (typeof startBatch === 'function') {
      await startBatch.call(encoder)
    }

    // Wait for encoding to complete (poll encoder status)
    const result = await waitForEncoderJob(encoder, jobId, onProgress)

    if (result.success) {
      const file = await readFileAsBlob(tempPath, options.format ?? 'wav')
      return { success: true, file }
    }

    return result
  } catch (error) {
    const errorMessage = error instanceof Error ? error.message : 'Encoder export failed'
    return { success: false, error: errorMessage }
  }
}

/**
 * Wait for an encoder job to complete.
 */
async function waitForEncoderJob(
  encoder: Record<string, unknown>,
  jobId: string,
  onProgress?: (progress: number) => void
): Promise<{ success: boolean; error?: string }> {
  const maxAttempts = 600 // 10 minutes max
  const pollInterval = 1000

  for (let attempt = 0; attempt < maxAttempts; attempt++) {
    await new Promise((resolve) => setTimeout(resolve, pollInterval))

    const getJobStatus = encoder.getJobStatus as
      | ((jobId: string) => { status: string; progress: number })
      | undefined

    if (typeof getJobStatus === 'function') {
      const status = getJobStatus.call(encoder, jobId)

      onProgress?.(status.progress)

      if (status.status === 'complete') {
        return { success: true }
      }
      if (status.status === 'error' || status.status === 'failed') {
        return { success: false, error: 'Encoder job failed' }
      }
    } else {
      // No status API, assume quick completion
      return { success: true }
    }
  }

  return { success: false, error: 'Encoder job timed out' }
}

/**
 * Extract audio from a source media file.
 */
async function extractAudioFromMediaPath(
  mediaPath: string,
  _startOffset: number,
  _duration: number,
  _options: AudioExtractionOptions
): Promise<File | null> {
  try {
    // Check if we can access the file directly
    const fs = await import('uxp').then((m) => m.storage.localFileSystem).catch(() => null)

    if (!fs) {
      logger.warn('UXP filesystem not available for direct file access')
      return null
    }

    // For video files, we'd need to extract audio - this is complex in UXP
    // For audio files, we can read them directly
    const extension = mediaPath.split('.').pop()?.toLowerCase()
    const audioExtensions = ['wav', 'mp3', 'aac', 'm4a', 'aiff', 'flac']

    if (audioExtensions.includes(extension ?? '')) {
      // Direct audio file - read it
      const file = await readFileAsBlob(mediaPath, extension ?? 'wav')
      return file
    }

    // For video files, would need to use media encoder or other extraction method
    // This is a limitation in UXP - true audio extraction from video requires AME
    logger.info('Video file detected, audio extraction requires Media Encoder', { mediaPath })
    return null
  } catch (error) {
    logger.error('Failed to extract audio from media path', { mediaPath, error })
    return null
  }
}

/**
 * Get a temporary file path for audio export.
 */
async function getTempAudioPath(format: string): Promise<string> {
  try {
    const fs = await import('uxp').then((m) => m.storage.localFileSystem)
    const dataFolder = await fs.getDataFolder()
    const timestamp = Date.now()
    const filename = `splice_audio_${timestamp}.${format}`

    // Create the file to reserve the path
    await dataFolder.createFile(filename, { overwrite: true })

    // Return the path - we'll need to construct it
    // In UXP, the data folder is typically at a known location
    return `${filename}` // UXP will resolve this relative to data folder
  } catch {
    // Fallback to a basic temp path pattern
    return `/tmp/splice_audio_${Date.now()}.${format}`
  }
}

/**
 * Get the path to an audio export preset.
 */
async function getAudioExportPresetPath(options: AudioExtractionOptions): Promise<string> {
  // Adobe Media Encoder uses .epr preset files
  // For audio-only export, common presets include:
  // - Match Source - High bitrate for lossless
  // - WAV 48kHz 24-bit for professional audio

  const format = options.format ?? 'wav'
  const sampleRate = options.sampleRate ?? 48000

  // Return a generic preset path - Premiere will resolve this
  // In production, you'd want to bundle or locate actual preset files
  const presetName =
    format === 'wav'
      ? 'Match Source - Lossless'
      : format === 'mp3'
        ? 'Match Source - High Bitrate'
        : 'Match Source'

  // AME preset paths vary by OS and version
  // This is a placeholder - actual implementation would need to locate the preset
  logger.info('Using audio export preset', { presetName, format, sampleRate })
  return presetName
}

/**
 * Read a file from disk and return as a File object.
 */
async function readFileAsBlob(filePath: string, format: string): Promise<File> {
  try {
    const fs = await import('uxp').then((m) => m.storage.localFileSystem)
    const dataFolder = await fs.getDataFolder()

    // Try to get the file entry
    const entry = await dataFolder.getEntry(filePath)
    if (entry) {
      const content = await entry.read()
      const mimeType =
        format === 'wav'
          ? 'audio/wav'
          : format === 'mp3'
            ? 'audio/mpeg'
            : format === 'aac'
              ? 'audio/aac'
              : 'audio/x-m4a'

      const blob = new Blob([content], { type: mimeType })
      return new File([blob], `audio.${format}`, { type: mimeType })
    }
  } catch (error) {
    logger.error('Failed to read file as blob', { filePath, error })
  }

  // Fallback: create an empty placeholder file
  // This shouldn't happen in production
  const mimeType = format === 'wav' ? 'audio/wav' : 'audio/mpeg'
  return new File([], `audio.${format}`, { type: mimeType })
}

/**
 * Get the total duration of selected clips in seconds.
 */
export async function getSelectedClipsDuration(): Promise<number> {
  const clips = await getSelectedClips()
  if (clips.length === 0) return 0

  const minStart = Math.min(...clips.map((c) => c.startTime))
  const maxEnd = Math.max(...clips.map((c) => c.endTime))

  return maxEnd - minStart
}
