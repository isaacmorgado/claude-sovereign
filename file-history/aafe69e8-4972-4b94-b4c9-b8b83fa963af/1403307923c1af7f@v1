---
description: Quick reverse engineering commands with Claude Code prompts
argument-hint: "[target-type] [path/url] --action [extract|analyze|deobfuscate]"
allowed-tools: ["Bash", "Read", "Write", "Edit", "Glob", "Grep", "Task", "mcp__grep__searchGitHub", "WebSearch"]
---

# Reverse Engineering Command

> Extract, analyze, and understand any software. Chrome extensions, Electron apps, APIs, binaries.

Based on Ken Kai's Hacker courses + professional RE toolkit.

## Quick Usage

```
/re chrome ~/Downloads/extension.crx          # Extract Chrome extension
/re electron /Applications/Discord.app        # Extract Electron app source
/re deobfuscate ./bundle.min.js               # Make JS readable
/re macos /Applications/App.app               # Explore macOS app bundle
/re api https://api.target.com                # Reverse engineer API
/re scrape https://target.com/data            # Build scraper
/re automate "login and download report"      # Browser automation
```

## Instructions

Parse arguments: $ARGUMENTS

### Step 0: Load Knowledge Base

```bash
# Load Ken Kai RE prompts
cat ~/.claude/docs/re-prompts.md

# Load professional toolkit
cat ~/.claude/docs/reverse-engineering-toolkit.md
```

### Target: Chrome Extension

**Extract source code from any Chrome extension:**

1. **From installed extension:**
```bash
# Find extensions folder
ls ~/Library/Application\ Support/Google/Chrome/Default/Extensions/

# Extension ID from chrome://extensions (enable Developer mode)
```

2. **From CRX file:**
```
I have a CRX file at [path]. Extract it to a folder so I can read the source code. CRX files are ZIP files with a header - you may need to strip the header or just rename to .zip and unzip.
```

3. **Analyze the extension:**
```
I extracted a Chrome extension to [folder path]. Read the manifest.json and explain:
1. What permissions does it request and why?
2. What does the background script do?
3. What content scripts are injected and on which sites?
4. Are there any privacy concerns?
```

**Tools:** CRX Extractor extension, crxviewer.com, Chrome DevTools

### Target: Electron App

**Get source code from VS Code, Discord, Slack, etc:**

1. **Find and extract:**
```
Find the Electron app bundle for [App Name] in /Applications, locate the app.asar file, and extract it to ~/Desktop/[app-name]-source so I can analyze it.
```

2. **Manual extraction:**
```bash
# Install asar CLI
npm install -g @electron/asar

# Navigate to app
cd /Applications/AppName.app/Contents/Resources

# Extract
asar extract app.asar ./app-extracted
```

3. **Analyze:**
```
I extracted an Electron app to [folder path]. Read the package.json and main entry files. Explain:
1. What is the app's architecture?
2. What are the main features based on the code structure?
3. What interesting patterns or techniques does it use?
```

### Target: Obfuscated JavaScript

**Make minified/obfuscated code readable:**

1. **Quick beautify:**
```
I have a minified JavaScript file at [path]. Beautify it and make it readable. Add meaningful variable names where you can infer the purpose from context.
```

2. **Deep analysis:**
```
Analyze this obfuscated JavaScript file at [path]. Focus on:
1. What does the code do? Trace the main execution flow.
2. Identify any API calls, URLs, or external communications
3. Find any interesting functions or logic patterns
4. Suggest better variable names based on usage
```

3. **Tools:**
   - js-beautify (npm install -g js-beautify)
   - https://deobfuscate.io/
   - https://beautifier.io/
   - AST Explorer (astexplorer.net)

### Target: macOS App

**Explore any macOS application:**

1. **Basic exploration:**
```bash
# Right-click app â†’ Show Package Contents
# Or via terminal:
cd /Applications/AppName.app/Contents
ls -la
```

2. **Find resources:**
```
I want to explore the macOS app at [path]. Show me its bundle structure, find any interesting resources, config files, or embedded assets. Look in Contents/Resources and Contents/Frameworks.
```

3. **Key locations:**
   - `Contents/Info.plist` - App metadata
   - `Contents/Resources/` - Assets, configs
   - `Contents/MacOS/` - Main executable
   - `Contents/Frameworks/` - Dependencies

### Target: API Reverse Engineering

**Figure out how apps talk to servers:**

1. **Traffic capture:**
```
I want to understand how [app/website] communicates with its API. Help me set up mitmproxy to capture traffic, then analyze the requests and responses to document the API.
```

2. **Analyze patterns:**
```
I captured API traffic from [app]. The base URL is [url]. Analyze these requests and:
1. Document all endpoints discovered
2. Identify the authentication mechanism
3. Map request/response schemas
4. Note any rate limits or restrictions
```

3. **Build client:**
```
Based on my API research for [service], create a Python client that can:
1. Authenticate using [method]
2. Call the main endpoints I discovered
3. Handle rate limiting appropriately
4. Include error handling
```

### Target: Web Scraping

**Extract data from any website:**

1. **Simple scraper:**
```
Build a scraper for [website URL] that extracts [data description]. Handle pagination if needed and export to CSV/JSON.
```

2. **Authenticated scraping:**
```
I need to scrape data from [website] but it requires login. Build a scraper using Playwright that:
1. Logs in with credentials from .env
2. Navigates to [target page]
3. Extracts [data fields]
4. Handles pagination
5. Exports to [format]
```

3. **Anti-detection:**
```
The website is blocking my scraper. Add stealth measures:
- Random delays between requests
- Rotate user agents
- Use puppeteer-stealth if using browser automation
- Respect robots.txt and rate limits
```

### Target: Browser Automation

**Automate any browser task:**

1. **Describe the task:**
```
Build a Playwright automation that [describes workflow]. Include:
- Login handling if needed
- Screenshots at key steps for debugging
- Error handling with retries
- Logging of actions taken
```

2. **Example workflows:**
```
# Download reports
Automate: Login to [site], navigate to Reports, select last 30 days, download CSV, save to ~/Downloads/reports/

# Monitor prices
Automate: Check [product URL] every hour, extract price, append to prices.csv with timestamp

# Fill forms
Automate: Fill the form at [URL] with data from data.json, submit, capture confirmation
```

## Troubleshooting

| Problem | Solution |
|---------|----------|
| Extension folder empty | Try CRX Extractor instead of copying from installed |
| CRX won't unzip | Strip header bytes or use dedicated CRX tools |
| Code still unreadable | Try deobfuscate.io, check for source maps |
| Can't intercept HTTPS | Install mitmproxy CA cert on device/browser |
| SSL pinning blocks proxy | Use Frida/Objection to bypass |
| Rate limited | Add delays, rotate IPs, check for rate limit headers |
| Bot detected | Use puppeteer-stealth, match browser fingerprint |

## Professional Toolkit (50+ Tools)

###

## Integration

After RE research:
1. Document findings in `~/.claude/docs/api-research/[target].md`
2. Add to semantic memory: `~/.claude/hooks/memory-manager.sh add_fact "RE: [finding]"`
3. Create client/tool if useful
4. Update project architecture.md
