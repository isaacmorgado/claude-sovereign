/**
 * Slice 4: GPT-4o-mini Transcription Service
 *
 * Handles audio transcription using OpenAI's gpt-4o-mini-transcribe model.
 * 50% cheaper than Whisper ($0.003/min vs $0.006/min).
 * Returns timestamped segments for take detection.
 * Includes caching to avoid repeated API calls.
 */

const fs = require('fs');
const OpenAI = require('openai');

// Initialize OpenAI client
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

// In-memory cache: { wavPath: { mtime, result } }
const transcriptCache = new Map();

/**
 * Transcribe audio file using GPT-4o-mini-transcribe (with caching)
 * @param {string} wavPath - Path to the WAV file
 * @returns {Promise<{text: string, segments: Array, language: string, duration: number}>}
 */
async function transcribeAudio(wavPath) {
  // Check cache based on file modification time
  const stats = fs.statSync(wavPath);
  const mtime = stats.mtimeMs;

  const cached = transcriptCache.get(wavPath);
  if (cached && cached.mtime === mtime) {
    console.log('[SPLICE] Using cached transcription (file unchanged)');
    return cached.result;
  }

  console.log('[SPLICE] Starting GPT-4o-mini transcription...');

  // GPT-4o-mini-transcribe uses the same transcriptions API as Whisper
  // but only supports 'json' response format (not verbose_json)
  const transcription = await openai.audio.transcriptions.create({
    file: fs.createReadStream(wavPath),
    model: 'gpt-4o-mini-transcribe',
    response_format: 'json',
    language: 'en',
  });

  console.log(`[SPLICE] Transcription complete: ${transcription.text.slice(0, 100)}...`);

  // GPT-4o-mini-transcribe returns simpler response than verbose_json
  // We need to estimate segments from the text if not provided
  const result = {
    text: transcription.text,
    segments: transcription.segments || estimateSegments(transcription.text),
    language: transcription.language || 'en',
    duration: transcription.duration || 0
  };

  // Cache the result
  transcriptCache.set(wavPath, { mtime, result });
  console.log('[SPLICE] Transcription cached');

  return result;
}

/**
 * Estimate segments from text when not provided by API
 * Creates rough segments based on sentence boundaries
 * @param {string} text - Full transcript text
 * @returns {Array} Estimated segments
 */
function estimateSegments(text) {
  if (!text) return [];

  // Split by sentence boundaries
  const sentences = text.match(/[^.!?]+[.!?]+/g) || [text];

  // Create segments with estimated timing (will be refined by take detection)
  return sentences.map((sentence, index) => ({
    id: index,
    start: 0, // Will be refined by take detection
    end: 0,
    text: sentence.trim()
  }));
}

module.exports = { transcribeAudio };
