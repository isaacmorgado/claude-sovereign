# FaceIQ Labs Reverse Engineering Summary

**Date:** 2025-12-18
**Status:** Phase 1 Complete - Data Extraction
**Target:** https://beta.faceiqlabs.com

---

## Executive Summary

This document summarizes all findings from reverse engineering FaceIQ Labs facial analysis platform. The goal is to understand and potentially recreate the facial landmark detection and measurement calculation system.

**Key Finding:** All calculation formulas are server-side. The client JavaScript only handles UI and API calls.

---

## 1. Data Sources Analyzed

| Source | Location | Size | Contents |
|--------|----------|------|----------|
| HAR File | `~/Desktop/FACEIQ.har` | 71 MB | Full session network traffic |
| JS Bundles | `~/Desktop/FACEIQHAR/` | ~200+ files | Next.js webpack chunks |
| Capture JSON | `~/Downloads/faceiq-capture-*.json` | 367 KB | Client-side capture attempt |

---

## 2. API Endpoints Discovered

### Core Endpoints

| Endpoint | Method | Purpose | Auth Required |
|----------|--------|---------|---------------|
| `/api/auth/session` | GET | Session management | No |
| `/api/auth/callback/google` | GET | Google OAuth | No |
| `/api/faces` | GET/POST | Face image CRUD | Yes |
| `/api/side-landmarks` | POST | **Side profile landmark detection** | Yes |
| `/api/subscription` | GET | Quota/plan info | Yes |
| `/api/analysis/unlock` | POST | Premium feature unlock | Yes (Premium) |
| `/api/faces/[id]/surgery-consent` | POST | Surgery simulation | Yes (Premium) |

### Side Landmarks API Response Structure

```json
{
  "success": true,
  "data": {
    "rotationAngle": -0.411,        // Head rotation in radians
    "direction": "right",            // "left" or "right" profile
    "center": {"x": 381.04, "y": 479.53},
    "crop": {
      "x": 154, "y": 228,
      "width": 505, "height": 505,
      "scale": 2.029
    },
    "landmarks": [/* 106 {x,y} coordinate pairs */],
    "bbox": [317, 316, 495, 644]     // Bounding box
  }
}
```

### Subscription Response Structure

```json
{
  "subscription": null,
  "quotaUsage": {
    "mappings": {"used": 1, "limit": 20, "remaining": 19},
    "harmonyAnalysis": {"used": 0, "limit": 0, "remaining": 0},
    "dataExports": {"used": 0, "limit": 1, "remaining": 1}
  }
}
```

---

## 3. Landmark Data

### Side Profile: 106 Landmarks

Two complete captures of 106 landmark coordinates are stored in:
- `~/Desktop/reverse-engineer/landmark_data.json`

**Sample Coordinates (First 10 points):**
```json
[
  {"x": 484.79, "y": 623.10},  // Index 0 - Likely Menton (chin)
  {"x": 300.04, "y": 476.74},  // Index 1 - Posterior point (ear area)
  {"x": 365.39, "y": 618.20},  // Index 2 - Mandible contour
  {"x": 381.02, "y": 626.66},  // Index 3 - Mandible contour
  {"x": 398.08, "y": 632.74},  // Index 4 - Mandible contour
  {"x": 415.62, "y": 636.65},  // Index 5 - Mandible contour
  {"x": 434.08, "y": 638.67},  // Index 6 - Mandible contour
  {"x": 452.53, "y": 637.56},  // Index 7 - Mandible contour
  {"x": 469.84, "y": 632.60},  // Index 8 - Mandible contour
  {"x": 303.49, "y": 494.36}   // Index 9 - Ear/Temple area
]
```

### Landmark Names (from image URLs)

**Front Face Landmarks:**
- `hairline` - Trichion
- `leftEyePupil` / `rightEyePupil` - Pupil centers
- `leftEyeMedialCanthus` - Inner eye corner
- `leftEyeLateralCanthus` - Outer eye corner
- `leftEyeUpperEyelid` / `leftEyeLowerEyelid` - Eyelid margins
- `leftBrowHead` / `leftBrowArch` / `leftBrowTail` - Eyebrow points
- `leftUpperEyelidCrease` - Crease position
- `noseLeft` / `noseRight` - Alar base
- `lowerLip` - Vermilion border
- `chinBottom` - Menton
- `leftTemple` / `rightTemple` - Temporal points
- `leftOuterEar` / `rightOuterEar` - Tragion

**Cephalometric Reference Points:**
- Trichion (hairline)
- Glabella (between eyebrows)
- Nasion (bridge of nose)
- Pronasale (nose tip)
- Subnasale (base of nose)
- Pogonion (chin prominence)
- Menton (lowest chin point)
- Gonion (jaw angle)

---

## 4. Standard Calculation Formulas

These are industry-standard formulas used in facial analysis. FaceIQ likely uses similar calculations server-side.

### 4.1 FWHR (Facial Width-to-Height Ratio)

```javascript
function calculateFWHR(landmarks) {
  // Bizygomatic width (cheekbone to cheekbone)
  const width = distance(landmarks.zygion_left, landmarks.zygion_right);

  // Upper face height (nasion to upper lip)
  const height = distance(landmarks.nasion, landmarks.upper_lip);

  return width / height;
}

// Ideal values:
// Male: 1.8 - 2.1
// Female: 1.6 - 1.9
```

### 4.2 Golden Ratio

```javascript
const PHI = 1.618;

function goldenRatioScore(a, b) {
  const ratio = Math.max(a, b) / Math.min(a, b);
  const deviation = Math.abs(ratio - PHI) / PHI;
  return Math.max(0, 1 - deviation) * 100;
}

// Measurements to test:
// - Face length / Face width
// - Lip to chin / Nose to lip
// - Nose width / Mouth width
```

### 4.3 Facial Thirds

```javascript
function calculateFacialThirds(landmarks) {
  const upperThird = distance(landmarks.trichion, landmarks.glabella);
  const middleThird = distance(landmarks.glabella, landmarks.subnasale);
  const lowerThird = distance(landmarks.subnasale, landmarks.menton);

  const total = upperThird + middleThird + lowerThird;

  return {
    upper: (upperThird / total) * 100,   // Ideal: 33.3%
    middle: (middleThird / total) * 100, // Ideal: 33.3%
    lower: (lowerThird / total) * 100    // Ideal: 33.3%
  };
}
```

### 4.4 Canthal Tilt

```javascript
function calculateCanthalTilt(medialCanthus, lateralCanthus) {
  const deltaY = lateralCanthus.y - medialCanthus.y;
  const deltaX = lateralCanthus.x - medialCanthus.x;

  const angleRadians = Math.atan2(deltaY, deltaX);
  const angleDegrees = angleRadians * (180 / Math.PI);

  return angleDegrees;
}

// Positive value = positive canthal tilt (desirable)
// Ideal range: +4 to +8 degrees
```

### 4.5 Nasolabial Angle (Side Profile)

```javascript
function calculateNasolabialAngle(columella, subnasale, labraleSuperius) {
  return calculateAngle(columella, subnasale, labraleSuperius);
}

// Ideal range:
// Male: 90-95 degrees
// Female: 100-110 degrees
```

### 4.6 Gonial Angle (Side Profile)

```javascript
function calculateGonialAngle(condylion, gonion, menton) {
  return calculateAngle(condylion, gonion, menton);
}

// Ideal range: 120-130 degrees
```

### 4.7 Utility Functions

```javascript
// Distance between two points
function distance(p1, p2) {
  return Math.sqrt(
    Math.pow(p2.x - p1.x, 2) +
    Math.pow(p2.y - p1.y, 2)
  );
}

// Angle at vertex between two lines
function calculateAngle(p1, vertex, p2) {
  const v1 = { x: p1.x - vertex.x, y: p1.y - vertex.y };
  const v2 = { x: p2.x - vertex.x, y: p2.y - vertex.y };

  const dot = v1.x * v2.x + v1.y * v2.y;
  const cross = v1.x * v2.y - v1.y * v2.x;

  return Math.atan2(Math.abs(cross), dot) * (180 / Math.PI);
}

// Midpoint between two points
function midpoint(p1, p2) {
  return {
    x: (p1.x + p2.x) / 2,
    y: (p1.y + p2.y) / 2
  };
}
```

---

## 5. Tech Stack Identified

| Component | Technology |
|-----------|------------|
| Frontend | Next.js 14+ (App Router) |
| UI | React, Tailwind CSS |
| Face Detection | MediaPipe Face Landmarker (478 front landmarks) |
| Side Profile | Custom API (106 landmarks) |
| Auth | NextAuth.js with Google OAuth |
| Storage | Vercel Blob Storage |
| Bundler | Turbopack |

---

## 6. What We Know vs Don't Know

### Known ✅
- 106 side profile landmark coordinates (exact positions)
- Landmark names from UI images
- API endpoint structure and responses
- Standard facial analysis formulas
- Tech stack and architecture
- Subscription tiers and limits

### Unknown ❌
- **Exact landmark index mapping** (which index = which facial feature)
- **FaceIQ's proprietary formulas** (server-side)
- **Scoring/weighting algorithms**
- **"Harmony Analysis" calculations** (premium only)
- **Front face landmark processing** (MediaPipe raw → FaceIQ format)

---

## 7. Files Generated

| File | Description |
|------|-------------|
| `CALCULATION_ANALYSIS.md` | Detailed technical analysis |
| `landmark_data.json` | All 106 landmarks from 2 captures |
| `api_responses_extracted.json` | All API responses from HAR |
| `formula_extraction.json` | JS pattern analysis results |
| `FACEIQ_REVERSE_ENGINEERING_SUMMARY.md` | This summary |
| `CAPTURE_GUIDE.md` | Instructions for capturing data |
| `REBUILD_PLAN.md` | Architecture for recreation |
| `capture-scripts/capture-all.js` | Client-side capture script |
| `capture-scripts/bookmarklet.txt` | Bookmarklet version |
| `extract_har.py` | HAR file extraction script |
| `parse_har.py` | HAR parsing script |

---

## 8. Next Steps

### To Complete Recreation:

1. **Map Landmark Indices** - Analyze coordinate positions to determine which index corresponds to which facial feature

2. **Implement MediaPipe Integration** - Use Google's MediaPipe Face Landmarker for front face detection (478 landmarks)

3. **Build Calculation Engine** - Implement standard formulas with the mapped landmarks

4. **Create Side Profile Model** - Either:
   - Use existing model (dlib, face-api.js)
   - Train custom model
   - Use cloud API (AWS Rekognition, Google Vision)

5. **Design Scoring System** - Create scoring/rating based on deviation from ideal values

---

## 9. Recreation Feasibility

| Component | Feasibility | Notes |
|-----------|-------------|-------|
| Front Face Detection | ✅ Easy | MediaPipe is open source |
| Side Profile Detection | ⚠️ Medium | Need to find/train model |
| Basic Measurements | ✅ Easy | Standard formulas |
| Scoring System | ⚠️ Medium | Need to design own |
| UI/UX | ✅ Easy | Standard React/Next.js |
| "Harmony Analysis" | ❌ Hard | Proprietary, unknown |

---

*Summary generated: 2025-12-18*
*All data saved to: ~/Desktop/reverse-engineer/*
