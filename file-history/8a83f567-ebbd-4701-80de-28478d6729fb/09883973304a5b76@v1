# Complete FaceIQ-Style Facial Analysis Calculation Engine

## Prompt for AI Assistant

Copy everything below this line and paste it to a new AI conversation:

---

# BUILD REQUEST: Facial Analysis Calculation Engine

I need you to build a complete facial analysis calculation engine that replicates FaceIQ Labs functionality. I have reverse-engineered their system and captured all necessary data. Build this as a **TypeScript/JavaScript library** that can run in Node.js or browser.

## Project Location
Create all files in: `~/Desktop/reverse-engineer/faceiq-engine/`

## Available Reference Data

I have the following files from reverse engineering FaceIQ Labs:

### 1. Captured Landmark Data
**File:** `~/Desktop/reverse-engineer/landmark_data.json`
- Contains 106 side profile landmark coordinates from actual FaceIQ API responses
- Each landmark is `{x, y}` floating-point pixel coordinates

**File:** `~/Desktop/reverse-engineer/captured_api/251_POST_api_side-landmarks.json`
- Full API response with landmarks, rotation angle, bounding box, crop data

### 2. API Response Structures
**File:** `~/Desktop/reverse-engineer/captured_api/ALL_FACEIQ_RESPONSES.json`
- All captured API responses from mitmproxy session

### 3. Documentation
**File:** `~/Desktop/reverse-engineer/CALCULATION_ANALYSIS.md`
- Standard facial analysis formulas
- Landmark index mapping attempts
- API endpoint documentation

**File:** `~/Desktop/reverse-engineer/FACEIQ_REVERSE_ENGINEERING_SUMMARY.md`
- Complete reverse engineering summary
- All known information about FaceIQ

---

## LANDMARK MAPPING (106 Side Profile Points)

Based on coordinate analysis and standard cephalometric landmarks, here's the mapping to implement:

```typescript
// Side Profile Landmark Indices (106 points)
export const SIDE_LANDMARKS = {
  // Face Contour (0-16) - Jaw/Chin outline
  MENTON: 0,              // Chin bottom (lowest point)
  POGONION: 2,            // Chin prominence
  GNATHION: 3,            // Chin point
  MANDIBLE_CONTOUR: [2, 3, 4, 5, 6, 7, 8],  // Jaw line

  // Posterior Points (1, 9-16) - Ear/Back of head
  TRAGION: 1,             // Ear point
  EAR_CONTOUR: [9, 10, 11, 12, 13, 14, 15, 16],

  // Forehead/Hairline (17)
  TRICHION: 17,           // Hairline

  // Nose Profile (18-32)
  NASION: 25,             // Bridge of nose (deepest point)
  PRONASALE: 32,          // Nose tip
  SUBNASALE: 52,          // Base of nose
  COLUMELLA: 53,          // Nose columella
  NOSE_BRIDGE: [25, 26, 27, 28, 29, 30, 31, 32],
  NOSE_TIP_CONTOUR: [52, 53, 54, 55, 56, 57, 58, 59, 60],

  // Eye Region (33-51)
  EYE_LATERAL_CANTHUS: 33,   // Outer eye corner
  EYE_MEDIAL_CANTHUS: 35,    // Inner eye corner
  UPPER_EYELID: [37, 38, 39],
  LOWER_EYELID: [40, 41, 42],
  PUPIL: 34,
  BROW_HEAD: 44,          // Inner brow
  BROW_ARCH: 45,          // Brow peak
  BROW_TAIL: 46,          // Outer brow

  // Lip Region (52-75)
  LABRALE_SUPERIUS: 63,   // Upper lip top
  LABRALE_INFERIUS: 66,   // Lower lip bottom
  STOMION: 65,            // Lip meeting point
  UPPER_LIP_CONTOUR: [63, 64, 65],
  LOWER_LIP_CONTOUR: [66, 67, 68],

  // Additional Profile Points (76-105)
  GLABELLA: 76,           // Between eyebrows
  SELLION: 77,            // Deepest point of nasal bridge
  SOFT_TISSUE_NASION: 78,
  ORBITALE: 79,           // Lowest point of eye socket
  GONION: 85,             // Jaw angle
  CONDYLION: 86,          // Top of jaw joint
};

// Front Face Landmark Indices (MediaPipe 478 points)
export const FRONT_LANDMARKS = {
  // Key points from MediaPipe Face Mesh
  NOSE_TIP: 1,
  LEFT_EYE_INNER: 133,
  LEFT_EYE_OUTER: 33,
  RIGHT_EYE_INNER: 362,
  RIGHT_EYE_OUTER: 263,
  LEFT_CHEEK: 234,
  RIGHT_CHEEK: 454,
  UPPER_LIP: 13,
  LOWER_LIP: 14,
  CHIN: 152,
  FOREHEAD: 10,
  LEFT_EAR: 234,
  RIGHT_EAR: 454,
  LEFT_BROW_INNER: 107,
  LEFT_BROW_OUTER: 70,
  RIGHT_BROW_INNER: 336,
  RIGHT_BROW_OUTER: 300,
  NOSE_BRIDGE: 6,
  LEFT_NOSTRIL: 129,
  RIGHT_NOSTRIL: 358,
};
```

---

## MEASUREMENTS TO IMPLEMENT

### Front Face Measurements

```typescript
interface FrontFaceMeasurements {
  // Ratios
  fwhr: number;                    // Facial Width-to-Height Ratio
  facialIndex: number;             // Face height / Face width
  jawWidth: number;                // Bigonial width
  cheekboneWidth: number;          // Bizygomatic width

  // Thirds
  upperThird: number;              // Trichion to Glabella (%)
  middleThird: number;             // Glabella to Subnasale (%)
  lowerThird: number;              // Subnasale to Menton (%)

  // Fifths
  facialFifths: number[];          // 5 vertical sections

  // Symmetry
  overallSymmetry: number;         // 0-100%
  eyeSymmetry: number;
  browSymmetry: number;
  lipSymmetry: number;
  jawSymmetry: number;

  // Eye Measurements
  canthalTilt: number;             // Degrees
  interpupillaryDistance: number;  // Pixels
  palpebralFissureLength: number;  // Eye width
  intercanthalWidth: number;       // Between inner corners

  // Nose Measurements
  nasalWidth: number;
  nasalHeight: number;
  nasalIndex: number;              // Width / Height

  // Mouth Measurements
  lipRatio: number;                // Upper / Lower lip
  mouthWidth: number;
  philtrumLength: number;

  // Golden Ratio Scores
  goldenRatioScores: {
    faceHeightWidth: number;
    noseMouth: number;
    eyeSpacing: number;
    lipChin: number;
  };
}
```

### Side Profile Measurements

```typescript
interface SideProfileMeasurements {
  // Angles
  nasofrontalAngle: number;        // Forehead to nose bridge
  nasofacialAngle: number;         // Nose projection from face
  nasolabialAngle: number;         // Nose to upper lip (90-110° ideal)
  nasomental Angle: number;        // Nose tip to chin
  mentocervicalAngle: number;      // Chin to neck
  gonialAngle: number;             // Jaw angle (120-130° ideal)

  // Profile Analysis
  profileType: 'straight' | 'convex' | 'concave';
  facialConvexity: number;         // Glabella-Subnasale-Pogonion angle

  // Nose Profile
  nasalDorsumShape: 'straight' | 'convex' | 'concave';
  nasalProjection: number;         // Goode ratio
  nasalTipRotation: number;
  columellaLobularRatio: number;

  // Lip Analysis
  lipProjection: number;
  upperLipAngle: number;
  lowerLipAngle: number;

  // Chin Analysis
  chinProjection: number;          // Relative to nose
  chinHeight: number;

  // Jaw Analysis
  mandibularPlaneAngle: number;
  ramusalHeight: number;
}
```

---

## SCORING SYSTEM

Implement a bell curve scoring system where the ideal value is at the center:

```typescript
interface ScoringConfig {
  idealValue: number;
  standardDeviation: number;
  minScore: number;
  maxScore: number;
  weight: number;  // For overall harmony score
}

const SCORING_CONFIGS: Record<string, ScoringConfig> = {
  fwhr: {
    idealValue: 1.9,           // Ideal FWHR
    standardDeviation: 0.15,   // How much variation is acceptable
    minScore: 0,
    maxScore: 100,
    weight: 0.15               // 15% of overall score
  },
  canthalTilt: {
    idealValue: 6,             // +6 degrees ideal
    standardDeviation: 3,
    minScore: 0,
    maxScore: 100,
    weight: 0.10
  },
  facialThirds: {
    idealValue: 33.33,         // Equal thirds
    standardDeviation: 3,
    minScore: 0,
    maxScore: 100,
    weight: 0.10
  },
  nasolabialAngle: {
    idealValue: 102,           // Degrees (male: 95, female: 105)
    standardDeviation: 8,
    minScore: 0,
    maxScore: 100,
    weight: 0.08
  },
  gonialAngle: {
    idealValue: 125,           // Degrees
    standardDeviation: 5,
    minScore: 0,
    maxScore: 100,
    weight: 0.08
  },
  overallSymmetry: {
    idealValue: 100,           // Perfect symmetry
    standardDeviation: 5,
    minScore: 0,
    maxScore: 100,
    weight: 0.15
  },
  goldenRatio: {
    idealValue: 1.618,         // Phi
    standardDeviation: 0.1,
    minScore: 0,
    maxScore: 100,
    weight: 0.12
  },
  nosalIndex: {
    idealValue: 0.7,           // Width/Height
    standardDeviation: 0.08,
    minScore: 0,
    maxScore: 100,
    weight: 0.06
  },
  lipRatio: {
    idealValue: 0.5,           // Upper/Lower (1:2 ratio)
    standardDeviation: 0.1,
    minScore: 0,
    maxScore: 100,
    weight: 0.06
  },
  chinProjection: {
    idealValue: 0,             // On the line from nose
    standardDeviation: 3,      // mm deviation
    minScore: 0,
    maxScore: 100,
    weight: 0.05
  },
  noseProjection: {
    idealValue: 0.67,          // Goode ratio
    standardDeviation: 0.05,
    minScore: 0,
    maxScore: 100,
    weight: 0.05
  }
};

// Bell curve scoring function
function calculateScore(value: number, config: ScoringConfig): number {
  const z = (value - config.idealValue) / config.standardDeviation;
  const bellCurve = Math.exp(-0.5 * z * z);
  return config.minScore + (config.maxScore - config.minScore) * bellCurve;
}

// Overall harmony score (weighted average)
function calculateHarmonyScore(scores: Record<string, number>): number {
  let totalWeight = 0;
  let weightedSum = 0;

  for (const [key, score] of Object.entries(scores)) {
    const config = SCORING_CONFIGS[key];
    if (config) {
      weightedSum += score * config.weight;
      totalWeight += config.weight;
    }
  }

  return weightedSum / totalWeight;
}
```

---

## POPULATION DISTRIBUTION (Bell Curve Comparison)

Implement percentile ranking based on normal distribution:

```typescript
interface PopulationStats {
  mean: number;
  standardDeviation: number;
  sampleSize: number;
}

const POPULATION_STATS: Record<string, PopulationStats> = {
  harmonyScore: { mean: 65, standardDeviation: 12, sampleSize: 10000 },
  fwhr: { mean: 1.85, standardDeviation: 0.2, sampleSize: 10000 },
  canthalTilt: { mean: 4, standardDeviation: 4, sampleSize: 10000 },
  symmetry: { mean: 85, standardDeviation: 8, sampleSize: 10000 },
  goldenRatioMatch: { mean: 70, standardDeviation: 15, sampleSize: 10000 },
};

// Calculate percentile (where you fall on the bell curve)
function calculatePercentile(value: number, stats: PopulationStats): number {
  const z = (value - stats.mean) / stats.standardDeviation;
  return normalCDF(z) * 100;
}

// Standard normal CDF approximation
function normalCDF(z: number): number {
  const a1 =  0.254829592;
  const a2 = -0.284496736;
  const a3 =  1.421413741;
  const a4 = -1.453152027;
  const a5 =  1.061405429;
  const p  =  0.3275911;

  const sign = z < 0 ? -1 : 1;
  z = Math.abs(z) / Math.sqrt(2);

  const t = 1.0 / (1.0 + p * z);
  const y = 1.0 - (((((a5 * t + a4) * t) + a3) * t + a2) * t + a1) * t * Math.exp(-z * z);

  return 0.5 * (1.0 + sign * y);
}

// Generate bell curve data for visualization
function generateBellCurveData(stats: PopulationStats, userValue: number): BellCurveData {
  const points: {x: number, y: number}[] = [];

  for (let i = -4; i <= 4; i += 0.1) {
    const x = stats.mean + i * stats.standardDeviation;
    const y = (1 / (stats.standardDeviation * Math.sqrt(2 * Math.PI))) *
              Math.exp(-0.5 * Math.pow((x - stats.mean) / stats.standardDeviation, 2));
    points.push({ x, y });
  }

  return {
    points,
    userValue,
    userPercentile: calculatePercentile(userValue, stats),
    mean: stats.mean,
    standardDeviation: stats.standardDeviation
  };
}
```

---

## FILE STRUCTURE TO CREATE

```
~/Desktop/reverse-engineer/faceiq-engine/
├── package.json
├── tsconfig.json
├── src/
│   ├── index.ts                 # Main exports
│   ├── types/
│   │   ├── landmarks.ts         # Landmark type definitions
│   │   ├── measurements.ts      # Measurement interfaces
│   │   └── scoring.ts           # Scoring types
│   ├── constants/
│   │   ├── landmarkIndices.ts   # SIDE_LANDMARKS, FRONT_LANDMARKS
│   │   ├── idealValues.ts       # All ideal measurements
│   │   └── populationStats.ts   # Bell curve statistics
│   ├── utils/
│   │   ├── geometry.ts          # distance, angle, midpoint functions
│   │   ├── statistics.ts        # normalCDF, percentile functions
│   │   └── imageProcessing.ts   # Coordinate normalization
│   ├── measurements/
│   │   ├── frontFace.ts         # Front face measurement functions
│   │   ├── sideProfile.ts       # Side profile measurement functions
│   │   └── index.ts
│   ├── scoring/
│   │   ├── bellCurve.ts         # Bell curve scoring
│   │   ├── harmonyScore.ts      # Overall harmony calculation
│   │   ├── percentile.ts        # Population comparison
│   │   └── index.ts
│   └── analysis/
│       ├── FacialAnalyzer.ts    # Main analyzer class
│       ├── ReportGenerator.ts   # Generate analysis reports
│       └── index.ts
├── tests/
│   ├── measurements.test.ts
│   ├── scoring.test.ts
│   └── testData/
│       └── sampleLandmarks.json # Copy from captured data
└── examples/
    ├── analyzeFromLandmarks.ts
    └── generateReport.ts
```

---

## CORE IMPLEMENTATION REQUIREMENTS

### 1. Geometry Utilities (`src/utils/geometry.ts`)

```typescript
export function distance(p1: Point, p2: Point): number;
export function angle(p1: Point, vertex: Point, p2: Point): number;
export function midpoint(p1: Point, p2: Point): Point;
export function slope(p1: Point, p2: Point): number;
export function perpendicularDistance(point: Point, lineP1: Point, lineP2: Point): number;
export function normalizeCoordinates(landmarks: Point[], imageWidth: number, imageHeight: number): Point[];
```

### 2. Main Analyzer Class (`src/analysis/FacialAnalyzer.ts`)

```typescript
export class FacialAnalyzer {
  constructor(options?: AnalyzerOptions);

  // Input methods
  setFrontLandmarks(landmarks: Point[]): void;
  setSideLandmarks(landmarks: Point[]): void;
  setGender(gender: 'male' | 'female'): void;

  // Measurement methods
  calculateFrontMeasurements(): FrontFaceMeasurements;
  calculateSideMeasurements(): SideProfileMeasurements;

  // Scoring methods
  calculateScores(): MeasurementScores;
  calculateHarmonyScore(): number;
  calculatePercentiles(): PercentileResults;

  // Bell curve data
  getBellCurveData(measurement: string): BellCurveData;

  // Full analysis
  analyze(): FullAnalysisReport;
}
```

### 3. Report Generator (`src/analysis/ReportGenerator.ts`)

```typescript
export class ReportGenerator {
  constructor(analysis: FullAnalysisReport);

  toJSON(): string;
  toMarkdown(): string;
  toHTML(): string;

  // Individual sections
  getMeasurementsSection(): string;
  getScoresSection(): string;
  getPercentileSection(): string;
  getRecommendationsSection(): string;
}
```

---

## GENDER-SPECIFIC IDEAL VALUES

```typescript
export const IDEAL_VALUES = {
  male: {
    fwhr: { ideal: 1.9, range: [1.8, 2.1] },
    canthalTilt: { ideal: 4, range: [2, 7] },
    nasolabialAngle: { ideal: 95, range: [90, 100] },
    gonialAngle: { ideal: 125, range: [120, 130] },
    nasalIndex: { ideal: 0.7, range: [0.65, 0.75] },
    lipRatio: { ideal: 0.5, range: [0.4, 0.6] },
    facialConvexity: { ideal: 170, range: [165, 175] },
    chinProjection: { ideal: 0, range: [-3, 3] },
  },
  female: {
    fwhr: { ideal: 1.75, range: [1.6, 1.9] },
    canthalTilt: { ideal: 6, range: [4, 10] },
    nasolabialAngle: { ideal: 105, range: [100, 115] },
    gonialAngle: { ideal: 128, range: [125, 135] },
    nasalIndex: { ideal: 0.65, range: [0.6, 0.7] },
    lipRatio: { ideal: 0.5, range: [0.45, 0.55] },
    facialConvexity: { ideal: 168, range: [163, 173] },
    chinProjection: { ideal: -2, range: [-5, 1] },
  }
};
```

---

## EXAMPLE USAGE

```typescript
import { FacialAnalyzer, ReportGenerator } from 'faceiq-engine';

// Load landmarks from your detection system
const frontLandmarks = await detectFrontFace(image);
const sideLandmarks = await detectSideProfile(sideImage);

// Create analyzer
const analyzer = new FacialAnalyzer({ gender: 'male' });
analyzer.setFrontLandmarks(frontLandmarks);
analyzer.setSideLandmarks(sideLandmarks);

// Get full analysis
const analysis = analyzer.analyze();

console.log('Harmony Score:', analysis.harmonyScore);
console.log('FWHR:', analysis.measurements.front.fwhr);
console.log('Your percentile:', analysis.percentiles.overall);

// Generate report
const report = new ReportGenerator(analysis);
console.log(report.toMarkdown());

// Get bell curve data for visualization
const bellCurve = analyzer.getBellCurveData('harmonyScore');
// Use bellCurve.points for chart visualization
```

---

## REFERENCE FILES TO READ

Before building, read these files for context:

1. `~/Desktop/reverse-engineer/landmark_data.json` - Actual landmark coordinates
2. `~/Desktop/reverse-engineer/captured_api/251_POST_api_side-landmarks.json` - Full API response
3. `~/Desktop/reverse-engineer/CALCULATION_ANALYSIS.md` - Formula documentation
4. `~/Desktop/reverse-engineer/FACEIQ_REVERSE_ENGINEERING_SUMMARY.md` - Full context

---

## BUILD INSTRUCTIONS

1. Create the folder structure
2. Initialize npm package with TypeScript
3. Implement all utility functions first
4. Implement measurement calculations
5. Implement scoring system with bell curves
6. Create the main FacialAnalyzer class
7. Create tests using the captured landmark data
8. Create example scripts

Build everything as working, production-ready code. Include all necessary type definitions, error handling, and documentation comments.

---

END OF PROMPT
