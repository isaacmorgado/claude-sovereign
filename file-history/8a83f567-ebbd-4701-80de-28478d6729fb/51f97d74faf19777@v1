# Build FaceIQ Clone - Complete Web App

## Request

Recreate FaceIQ Labs (https://beta.faceiqlabs.com) as a Next.js web app with:
- Front face auto-detection using MediaPipe
- Side profile landmark detection
- Draggable landmark adjustment UI
- Bell curve scoring & comparison
- Complete user flow: Upload → Detect → Adjust → Results

## Reference Data Location

All reverse-engineered data is at `~/Desktop/reverse-engineer/`:

```
Key Files:
├── landmark_data.json                    # 106 side profile coordinates
├── captured_api/251_POST_api_side-landmarks.json  # Full API response format
├── captured_api/ALL_FACEIQ_RESPONSES.json         # All API structures
├── CALCULATION_ANALYSIS.md               # Formulas & measurements
├── BUILD_CALCULATION_ENGINE_PROMPT.md    # Scoring engine specs
└── FACEIQHAR/                           # Original JS/CSS/HTML from site
    └── */\_next/static/chunks/*.js       # Their bundled code
```

## Tech Stack

- Next.js 14 (App Router)
- TypeScript
- Tailwind CSS
- MediaPipe Face Landmarker (478 front landmarks)
- Canvas API for landmark visualization

## Project Structure

Create in `~/Desktop/reverse-engineer/faceiq-clone/`:

```
src/
├── app/
│   ├── page.tsx                 # Landing/upload
│   ├── analyze/
│   │   ├── front/page.tsx       # Front face detection
│   │   ├── side/page.tsx        # Side profile detection
│   │   └── results/page.tsx     # Scores & bell curves
│   └── layout.tsx
├── components/
│   ├── ImageUploader.tsx        # Drag & drop upload
│   ├── FaceDetector.tsx         # MediaPipe integration
│   ├── LandmarkEditor.tsx       # Draggable points on canvas
│   ├── LandmarkGuide.tsx        # Shows which point to place
│   ├── BellCurveChart.tsx       # Score visualization
│   └── ResultsCard.tsx          # Individual measurement display
├── hooks/
│   ├── useMediaPipe.ts          # MediaPipe Face Landmarker hook
│   └── useLandmarkEditor.ts     # Drag & drop landmark logic
├── lib/
│   ├── landmarks.ts             # Index mappings (from landmark_data.json)
│   ├── measurements.ts          # FWHR, angles, ratios calculations
│   ├── scoring.ts               # Bell curve scoring
│   └── constants.ts             # Ideal values by gender
├── types/
│   └── index.ts                 # TypeScript interfaces
└── public/
    └── landmarks/               # Guidance images for each landmark
        ├── front/
        │   ├── hairline.webp
        │   ├── leftEyePupil.webp
        │   ├── chinBottom.webp
        │   └── ...
        └── side/
            ├── nasion.webp
            ├── pronasale.webp
            ├── menton.webp
            └── ...
```

## Key Components

### 1. MediaPipe Integration (`hooks/useMediaPipe.ts`)

```typescript
// Use @mediapipe/tasks-vision FaceLandmarker
// Returns 478 normalized {x, y, z} coordinates
// Key indices: see BUILD_CALCULATION_ENGINE_PROMPT.md
```

### 2. Landmark Editor (`components/LandmarkEditor.tsx`)

- Canvas overlay on uploaded image
- Render landmarks as draggable circles
- Click to select, drag to move
- Prev/Next buttons to cycle landmarks
- Keyboard shortcuts (Arrow keys to nudge)

### 3. User Flow

```
1. Upload Front Photo → MediaPipe auto-detects 478 points
2. Show key landmarks for manual adjustment (20-30 points)
3. Upload Side Photo → Auto-detect or manual placement (106 points)
4. Calculate all measurements
5. Score against ideal values
6. Show bell curve percentile ranking
```

### 4. Landmark Guidance Images

FaceIQ shows example images for each landmark. Create/source similar images showing:
- Where on face to place the point
- Clear visual indicator
- Brief label (e.g., "Hairline", "Chin Bottom")

URLs found in HAR:
```
/images/landmarks/male/white/hairline.webp
/images/landmarks/male/white/leftEyePupil.webp
/images/landmarks/male/white/chinBottom.webp
/images/landmarks/male/white/leftEyeMedialCanthus.webp
/images/landmarks/male/white/leftBrowArch.webp
... (see CALCULATION_ANALYSIS.md for full list)
```

## Side Profile Detection Options

Since MediaPipe is for front faces, for side profile either:

1. **Manual placement** - User places 20-30 key points guided by images
2. **Use face-api.js** - Has some side profile support
3. **Custom API** - Build endpoint similar to FaceIQ's `/api/side-landmarks`
4. **Dlib** - Python backend with 68-point model

Recommend: Start with manual placement + guidance images.

## Measurements to Calculate

From `BUILD_CALCULATION_ENGINE_PROMPT.md`:

**Front Face:**
- FWHR, Facial Thirds, Canthal Tilt, Symmetry, Golden Ratios

**Side Profile:**
- Nasolabial Angle, Gonial Angle, Nose Projection, Chin Projection, Profile Type

## Scoring

Use bell curve from `BUILD_CALCULATION_ENGINE_PROMPT.md`:
- Calculate measurement → Compare to ideal → Score 0-100
- Show percentile on bell curve chart
- Calculate overall Harmony Score (weighted average)

## Build Instructions

1. `npx create-next-app@latest faceiq-clone --typescript --tailwind --app`
2. Install: `@mediapipe/tasks-vision`, `chart.js` or `recharts`
3. Copy landmark indices from `landmark_data.json`
4. Implement components in order: Uploader → Detector → Editor → Results
5. Add measurement calculations from `BUILD_CALCULATION_ENGINE_PROMPT.md`
6. Create guidance images or use placeholders

## Reference the Captured Data

Read these files to match FaceIQ's exact behavior:
- `landmark_data.json` - Exact coordinate format
- `captured_api/*.json` - API response structures
- `FACEIQHAR/` - Their actual UI code (minified but readable)

---

Build a working MVP that detects landmarks, allows adjustment, and shows scores with bell curve comparison.
