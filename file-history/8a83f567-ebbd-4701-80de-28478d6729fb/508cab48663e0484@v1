#!/usr/bin/env python3
"""Parse FACEIQ.har to extract API responses and landmark data"""

import json
import os
import sys

HAR_PATH = os.path.expanduser("~/Desktop/FACEIQ.har")
OUTPUT_DIR = os.path.expanduser("~/Desktop/reverse-engineer/api-data")

os.makedirs(OUTPUT_DIR, exist_ok=True)

print(f"Loading HAR file: {HAR_PATH}")
try:
    with open(HAR_PATH, 'r', encoding='utf-8') as f:
        har = json.load(f)
except Exception as e:
    print(f"Error loading HAR: {e}")
    sys.exit(1)

entries = har.get('log', {}).get('entries', [])
print(f"Total entries: {len(entries)}")

# Find all FaceIQ API calls
api_calls = []
for entry in entries:
    url = entry.get('request', {}).get('url', '')
    if 'faceiqlabs.com/api/' in url:
        api_calls.append(entry)

print(f"Found {len(api_calls)} FaceIQ API calls\n")

# Process each API call
for i, entry in enumerate(api_calls):
    request = entry.get('request', {})
    response = entry.get('response', {})

    method = request.get('method', 'UNKNOWN')
    url = request.get('url', '')
    status = response.get('status', 0)

    # Extract endpoint name
    endpoint = url.split('faceiqlabs.com')[1].split('?')[0] if 'faceiqlabs.com' in url else url

    print(f"\n{'='*60}")
    print(f"[{i}] {method} {endpoint}")
    print(f"Status: {status}")

    # Get response body
    content = response.get('content', {})
    body_text = content.get('text', '')

    if body_text:
        try:
            body = json.loads(body_text)

            # Save full response
            safe_name = endpoint.replace('/', '_').strip('_')
            filename = f"{i:02d}_{method}_{safe_name}.json"
            filepath = os.path.join(OUTPUT_DIR, filename)

            with open(filepath, 'w') as f:
                json.dump({
                    'endpoint': endpoint,
                    'method': method,
                    'status': status,
                    'request_body': None,
                    'response': body
                }, f, indent=2)

            print(f"Saved: {filename}")

            # Check for landmark data
            if 'landmarks' in str(body).lower():
                print("  -> CONTAINS LANDMARKS!")

                # Extract landmark details
                if isinstance(body, dict):
                    if 'data' in body and isinstance(body['data'], dict):
                        data = body['data']
                        landmarks = data.get('landmarks', [])
                        print(f"  -> Landmark count: {len(landmarks)}")
                        if landmarks and len(landmarks) > 0:
                            print(f"  -> First landmark: {landmarks[0]}")
                            print(f"  -> Last landmark: {landmarks[-1]}")

                        # Print other data keys
                        other_keys = [k for k in data.keys() if k != 'landmarks']
                        if other_keys:
                            print(f"  -> Other data keys: {other_keys}")
                            for key in other_keys:
                                val = data[key]
                                if not isinstance(val, (list, dict)) or len(str(val)) < 100:
                                    print(f"     {key}: {val}")

            # Check for calculation/score data
            score_keys = ['score', 'ratio', 'calculation', 'measurement', 'analysis', 'harmony']
            found_scores = [k for k in str(body.keys()).lower().split() if any(s in k for s in score_keys)]
            if found_scores:
                print(f"  -> Contains score-related keys!")

        except json.JSONDecodeError:
            print(f"  -> Non-JSON response (length: {len(body_text)})")

# Also check for subscription/features data
print("\n\n" + "="*60)
print("SUBSCRIPTION/FEATURE DATA:")
print("="*60)

for i, entry in enumerate(api_calls):
    url = entry.get('request', {}).get('url', '')
    if 'subscription' in url.lower() or 'unlock' in url.lower() or 'feature' in url.lower():
        content = entry.get('response', {}).get('content', {})
        body_text = content.get('text', '')
        if body_text:
            try:
                body = json.loads(body_text)
                print(f"\n[{i}] {url}")
                print(json.dumps(body, indent=2)[:1000])
            except:
                pass

print(f"\n\nAll data saved to: {OUTPUT_DIR}")
