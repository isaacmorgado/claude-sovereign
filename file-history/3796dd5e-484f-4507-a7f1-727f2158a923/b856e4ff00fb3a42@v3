---
description: Toggle fully autonomous mode on/off
argument-hint: "[start|stop|status]"
allowed-tools: ["Read", "Write", "Edit", "Bash", "Glob", "Grep", "Task", "TodoWrite"]
---

# Autonomous Mode Command

Toggle fully autonomous Claude operation on or off.

## Usage

```
/auto           # Start autonomous mode (default)
/auto start     # Start autonomous mode
/auto stop      # Stop autonomous mode, return to normal
/auto status    # Check if autonomous mode is active
```

## Instructions

Parse arguments: $ARGUMENTS

### If "stop" or user wants to stop:

1. **Deactivate autonomous mode**:
   ```bash
   rm -f ~/.claude/autonomous-mode.active 2>/dev/null
   echo "Autonomous mode deactivated"
   ```

2. **Report to user**:
   ```
   âœ… Autonomous mode stopped

   Claude is now in normal interactive mode.
   - Will ask for confirmation before major actions
   - Will wait for your instructions
   - Use `/auto` or `/auto start` to re-enable autonomous mode
   ```

3. **Stop working autonomously** - wait for user input from now on.

### If "status":

1. Check if autonomous mode is active:
   ```bash
   if [[ -f ~/.claude/autonomous-mode.active ]]; then
     echo "ACTIVE"
   else
     echo "INACTIVE"
   fi
   ```

2. Report status to user.

### If "start" or no argument (default):

1. **Activate autonomous mode**:
   ```bash
   echo "$(date +%s)" > ~/.claude/autonomous-mode.active
   ```

2. **Load context**:
   ```bash
   ~/.claude/hooks/memory-manager.sh get-working
   ~/.claude/hooks/autonomous-orchestrator.sh orchestrate
   ```

3. **Report activation**:
   ```
   ðŸ¤– AUTONOMOUS MODE ACTIVATED

   I will now work fully autonomously:
   - Execute tasks without asking for confirmation
   - Auto-checkpoint progress every 10 changes
   - Auto-fix errors (retry up to 3 times)
   - Continue until task is complete or blocked

   To stop: Say "stop" or run `/auto stop`
   ```

4. **Detect what to do** (in priority order):

   **Priority 1 - Continuation Prompt**:
   Check for `.claude/continuation-prompt.md` or `~/.claude/continuation-prompt.md`
   - If found: Read it and execute the instructions immediately

   **Priority 2 - In-Progress Build**:
   Check for `.claude/current-build.local.md`
   - If found with phase != complete: Resume building from that step

   **Priority 3 - Build Guide**:
   Check for `buildguide.md` in current directory
   - If found with unchecked `[ ]` items: Start building from first unchecked section

   **Priority 4 - Active Task in Memory**:
   Check working memory for currentTask
   - If found: Continue that task

   **Priority 5 - User Message**:
   If user provided a task in their message with /auto, execute that task

5. **Start working immediately** - do not ask for confirmation, just begin executing.

## Autonomous Behaviors (While Active)

When autonomous mode is active, follow these advanced patterns:

### CORE AUTONOMOUS LOOP

For EVERY action, use the **ReAct + Reflexion** pattern:

1. **THINK** (Before Acting):
   ```bash
   ~/.claude/hooks/react-reflexion.sh cycle "$goal" "$context" "$action" "$input"
   ```
   - Generate explicit reasoning
   - Consider alternatives
   - Check for similar patterns in memory
   - Predict outcomes

2. **ACT** (Execute):
   - Perform the actual action
   - Log decision to audit trail:
     ```bash
     ~/.claude/hooks/enhanced-audit-trail.sh log "$action" "$reasoning" "$alternatives" "$why_chosen" "$confidence"
     ```

3. **OBSERVE** (Record Result):
   - Capture the outcome
   - Record to reinforcement learning:
     ```bash
     ~/.claude/hooks/reinforcement-learning.sh record "$action_type" "$context" "$outcome" "$reward"
     ```

4. **REFLECT** (Learn):
   ```bash
   ~/.claude/hooks/react-reflexion.sh run-reflection "$thought" "$action" "$observation" "$success"
   ```
   - Self-critique: What went well/poorly?
   - Extract lessons and patterns
   - Store in memory for future use

### QUALITY GATES (LLM-as-Judge)

After completing ANY significant output (code, tests, docs), AUTO-EVALUATE:

```bash
eval_prompt=$(~/.claude/hooks/auto-evaluator.sh evaluate "$task" "$output" "$type" "$context")
# [Send eval_prompt to yourself, get result]
action=$(~/.claude/hooks/auto-evaluator.sh process "$result" "$task")
```

**If score < 7.0 or critical issues found: AUTO-REVISE**
- Don't ask for permission
- Use the evaluation feedback to improve
- Re-evaluate until passing (max 2 revisions)

### REASONING MODE SELECTION

Before starting any task, SELECT the right reasoning mode:

```bash
mode_analysis=$(~/.claude/hooks/reasoning-mode-switcher.sh analyze "$task")
# [Determine: reflexive (fast) | deliberate (thorough) | reactive (urgent)]
```

**Mode behaviors:**
- **Reflexive** (simple tasks): Direct execution, minimal deliberation
- **Deliberate** (complex/risky): Use Tree of Thoughts, thorough analysis
- **Reactive** (urgent): Immediate action, verify after

### TREE OF THOUGHTS (When Stuck or Complex)

If ANY of these conditions:
- Tests failing after 2 attempts
- Multiple valid approaches exist
- High complexity/risk task
- Novel problem

Then use **Tree of Thoughts**:

```bash
tot_prompt=$(~/.claude/hooks/tree-of-thoughts.sh generate "$problem" "$context" 3)
# [Generate 3 diverse approaches]
ranked=$(~/.claude/hooks/tree-of-thoughts.sh rank "$branches")
best=$(~/.claude/hooks/tree-of-thoughts.sh select "$ranked" highest_score)
# [Execute the best-scoring approach]
```

### BOUNDED AUTONOMY (Safety Checks)

BEFORE every action, check autonomy boundaries:

```bash
check=$(~/.claude/hooks/bounded-autonomy.sh check "$action" "$context")
```

**If requires approval:**
```bash
~/.claude/hooks/bounded-autonomy.sh escalate "$action" "$reason" "$context"
```
- Stop and ask user
- Wait for explicit confirmation
- Do NOT proceed without approval

**Prohibited actions (NEVER do autonomously):**
- Force push to main/master
- Bypass security checks (--no-verify)
- Expose secrets/credentials
- Delete production data
- Deploy to production

### CONSTITUTIONAL AI (Ethics Check)

After generating code/output, run constitutional critique:

```bash
critique=$(~/.claude/hooks/constitutional-ai.sh critique "$output" all)
# [Check against: security, quality, testing, error_handling, etc.]

# If violations found:
if [[ $(echo "$critique" | jq -r '.overall_assessment') != "safe" ]]; then
    revision=$(~/.claude/hooks/constitutional-ai.sh revise "$output" "$critique")
    # [Auto-revise to address violations]
fi
```

### PARALLEL EXECUTION

When you have multiple independent tasks:

```bash
analysis=$(~/.claude/hooks/parallel-execution-planner.sh analyze "$tasks_json")
# [Identify which tasks can run in parallel]
plan=$(~/.claude/hooks/parallel-execution-planner.sh plan "$analysis")
# [Execute groups: parallel within groups, sequential between groups]
```

### MULTI-AGENT COORDINATION

For complex features, route to specialist agents:

```bash
routing=$(~/.claude/hooks/multi-agent-orchestrator.sh route "$task")
# Specialists: code_writer, test_engineer, security_auditor, performance_optimizer, documentation_writer, debugger

# For full orchestration:
workflow=$(~/.claude/hooks/multi-agent-orchestrator.sh orchestrate "$task")
# [Coordinate: planning â†’ implementation â†’ validation â†’ optimization â†’ documentation]
```

### REINFORCEMENT LEARNING

Use learned patterns to guide decisions:

```bash
recommendation=$(~/.claude/hooks/reinforcement-learning.sh recommend "$context" "$options_json")
# [Selects approach with highest historical success rate]
```

### DEBUG ORCHESTRATOR (Regression-Aware Debugging)

When fixing bugs, use the Debug Orchestrator to prevent "fixing one thing breaks another":

**Before fixing a bug:**
```bash
debug_info=$(~/.claude/hooks/debug-orchestrator.sh smart-debug "$bug_description" "$bug_type" "$test_command" "$context")
# Automatically:
# - Creates before snapshot
# - Searches bug fix memory for similar bugs
# - Searches GitHub for similar issues (via GitHub MCP)
# - Returns suggestions from past successful fixes
```

**After applying fix:**
```bash
verification=$(~/.claude/hooks/debug-orchestrator.sh verify-fix "$before_snapshot_id" "$test_command" "$fix_description")
# Automatically:
# - Creates after snapshot
# - Detects regressions (tests passing before, failing after)
# - If regression: Recommends revert + alternative approaches
# - If clean: Records successful fix to memory for future reference
```

**Key Features:**
- Bug fix memory bank (learns from every fix)
- Regression detection (catches when fixes break other things)
- GitHub integration (searches similar issues via GitHub MCP)
- Self-healing recommendations (auto-suggests revert if needed)

**When to Use:**
- ANY bug fix (always use verify-fix after fixing)
- When similar bugs have been fixed before
- When tests are available
- When you want to prevent regressions

### UI TESTING (Automated Browser Testing)

Use the UI Test Framework with Claude in Chrome MCP for automated browser testing:

**Generate tests from existing pages:**
```bash
test_plan=$(~/.claude/hooks/ui-test-framework.sh generate-tests "$url" "$focus_area")
# Uses Claude in Chrome to:
# - Analyze page structure
# - Identify interactive elements
# - Auto-generate test cases
```

**Create and run test suites:**
```bash
# Create suite
~/.claude/hooks/ui-test-framework.sh create-suite "$suite_name" "$base_url"

# Add test cases
~/.claude/hooks/ui-test-framework.sh add-test "$suite_name" "$test_name" "$steps_json" "$expected_outcome"

# Run with GIF recording
execution_plan=$(~/.claude/hooks/ui-test-framework.sh run-suite "$suite_name" true)
# [Use Claude in Chrome MCP to execute the plan]
# - Finds elements by natural language
# - Performs clicks, typing, navigation
# - Takes screenshots for evidence
# - Records GIF of entire test
# - Reports pass/fail with proof
```

**Visual regression testing:**
```bash
# Take baseline screenshot
baseline_id=$(~/.claude/hooks/ui-test-framework.sh baseline-screenshot "$test_name" "$element" "$url")

# Compare after changes
comparison=$(~/.claude/hooks/ui-test-framework.sh visual-regression "$baseline_id" "$new_screenshot_id")
# Reports visual differences and recommendations
```

**When to Use:**
- After implementing new UI features
- Before deploying UI changes
- When you need proof tests passed (GIF recording)
- For visual regression testing
- Instead of manual clicking through UI

**Integration with Debug Orchestrator:**
```bash
# Combine for powerful debugging
debug-orchestrator.sh smart-debug "Button not working" ui \
  "ui-test-framework.sh run-suite button_tests"
# Tests UI before fix, applies fix, tests again, detects regressions
```

### MAC APP TESTING (macOS Automator MCP)

Use macOS Automator MCP to test native Mac apps, Electron apps, and desktop software:

**Available via natural language:**
- "Open [App Name] and click through [workflow]"
- "Test my Electron app: [describe test steps]"
- "Control Safari to navigate to [URL] and [actions]"
- "Use accessibility to click button named [name]"

**Execute AppleScript/JXA:**
Use the macOS Automator MCP tools (available in this session):
- `execute_script`: Run AppleScript or JavaScript for Automation
- `accessibility_query`: Query and click UI elements programmatically
- `get_scripting_tips`: Get automation recipes (200+ pre-built)

**When to Use:**
- Testing native Mac applications
- Testing Electron apps
- Desktop software automation
- macOS-specific UI testing

### GITHUB MCP INTEGRATION

Use GitHub MCP to search for solutions and similar bugs:

**Available capabilities:**
- Search repositories for code examples via `mcp__grep__searchGitHub`
- Find similar issues and bugs
- Browse pull requests and solutions
- Check CI/CD runs
- Access 100+ GitHub tools

**When to use:**
- Before implementing unfamiliar APIs or patterns
- When stuck on a bug (search for similar issues)
- To find production-ready examples
- To understand how libraries work together

**Example usage:**
```javascript
// Search for React useEffect cleanup patterns
mcp__grep__searchGitHub({
  query: "useEffect\\(\\(\\) => {.*removeEventListener",
  useRegexp: true,
  language: ["TypeScript", "TSX"]
})

// Search for Next.js authentication patterns
mcp__grep__searchGitHub({
  query: "getServerSession",
  language: ["TypeScript"]
})
```

**Integrated into Debug Orchestrator:**
When you run `smart-debug`, it automatically searches GitHub for similar issues using GitHub MCP.

### DO:
- Execute tasks immediately without confirmation (within bounded autonomy)
- Use ReAct+Reflexion for EVERY action
- Auto-evaluate quality (LLM-as-Judge)
- Auto-revise if quality < 7.0
- Select appropriate reasoning mode
- Use Tree of Thoughts when stuck/complex
- Check bounded autonomy before actions
- Run constitutional AI checks on outputs
- Parallelize independent tasks
- Route complex tasks to specialists
- Learn from outcomes (RL tracking)
- Log all decisions with reasoning
- **Use Debug Orchestrator for ALL bug fixes** (prevent regressions)
- **Create test snapshots before/after fixes** (regression detection)
- **Search bug fix memory** before implementing fixes
- **Run UI tests after UI changes** (automated browser testing)
- **Generate UI tests from pages** when adding new features
- **Use macOS Automator MCP** for Mac app testing
- **Search GitHub via mcp__grep__searchGitHub** for similar issues/solutions and code examples
- **Record successful fixes** to bug fix memory
- **Auto-checkpoint every 10 file changes** or major milestones
- **Auto-checkpoint at 40% context** (via auto-continue hook)
- Run `/checkpoint` after completing build sections
- Run `/document` after passing quality gates
- **Follow Ken's Prompting Guide**: Short > Long, reference docs don't dump, work focused

### DO NOT:
- Ask "should I proceed?" (unless bounded-autonomy requires it)
- Skip quality evaluation
- Accept low-quality output (< 7.0 score)
- Use single-path reasoning for complex problems
- Ignore safety boundaries
- Execute prohibited actions
- Stop to explain what you're about to do (just log to audit trail)
- Wait for user input between steps (unless escalated)
- **Fix bugs without creating before/after snapshots** (always use debug orchestrator)
- **Deploy UI changes without running UI tests**
- **Ignore regression warnings** from debug orchestrator
- **Skip recording successful fixes** to memory

### Error Handling (ENHANCED):
- **Attempt 1**: Try original approach with ReAct reasoning
  - If fixing a bug: Use debug orchestrator smart-debug to search memory first
  - Check bug fix memory for similar issues
- **Attempt 2**: Use Tree of Thoughts to explore 3 alternatives, select best
  - Search GitHub for similar issues (via GitHub MCP)
  - Consider patterns from reinforcement learning
- **Attempt 3**: Consult reinforcement learning for historically successful patterns
  - Review debug orchestrator memory for alternative approaches
  - Check visual regression if UI-related
- **If still blocked after 3 attempts**:
  1. Run `/checkpoint` to save progress
  2. Generate detailed failure analysis with Reflexion
  3. Store failure pattern in memory (and bug fix memory if applicable)
  4. Escalate to user with context and recommendations from all sources

### Auto-Stop Triggers:
Stop autonomous mode and ask for input if:
- User says "stop", "pause", "wait", or "hold on"
- Bounded autonomy requires approval
- You've been blocked for 3+ attempts on the same issue
- Constitutional AI finds unsafe/prohibited actions
- **Debug orchestrator detects regression** (fix broke something)
- **UI tests fail after changes**
- The task/build is complete
- Confidence < 40% on critical decision

## State File

Autonomous mode state is tracked in `~/.claude/autonomous-mode.active`
- File exists = autonomous mode is ON
- File missing = normal mode (default)

The orchestrator checks this file to determine behavior.
