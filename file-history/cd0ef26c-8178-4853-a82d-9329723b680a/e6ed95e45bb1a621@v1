# Browser Automation + RunPod Models Integration Guide

**How to use your abliterated RunPod models with browser automation, screenshots, console logs, and devtools**

Last Updated: 2026-01-05

---

## Overview

You want to:
- ‚úÖ Take screenshots of websites and convert them to code
- ‚úÖ Access browser console logs and devtools
- ‚úÖ Login to your accounts and maintain sessions
- ‚úÖ Use your abliterated RunPod models for analysis

**The Solution:** Combine browser automation tools with your RunPod API endpoints

---

## Architecture Options

### Option 1: Claude Code + Playwright MCP (Easiest)

**What it is:**
- Use Claude Code (the CLI tool you're using right now)
- Add Playwright MCP server for browser automation
- Claude Code can browse, screenshot, access console, login
- Send data to your RunPod models via API for analysis

**Pros:**
- ‚úÖ Official integration (Microsoft Playwright MCP)
- ‚úÖ Works out of the box
- ‚úÖ Can see Chrome window (not headless)
- ‚úÖ Access to console logs and network requests
- ‚úÖ Can handle logins (cookies persist)

**Cons:**
- ‚ùå Claude Code uses Anthropic API (not abliterated)
- ‚ùå Have to call RunPod separately for abliterated analysis

**How it works:**
```
1. Claude Code + Playwright MCP ‚Üí Browse websites, take screenshots
2. Extract data/screenshots
3. Send to RunPod API ‚Üí Abliterated model analyzes
4. Claude Code receives analysis ‚Üí Takes next action
```

### Option 2: Custom Python Script + Playwright (Full Control)

**What it is:**
- Write custom Python script
- Use Playwright for browser automation
- Call RunPod API directly for all AI decisions
- Full abliterated model control

**Pros:**
- ‚úÖ 100% uses your abliterated models
- ‚úÖ Complete control over workflow
- ‚úÖ No Anthropic API costs
- ‚úÖ Can customize everything

**Cons:**
- ‚ùå More code to write
- ‚ùå Have to implement screenshot-to-code logic yourself

### Option 3: Fork screenshot-to-code + Add RunPod Backend

**What it is:**
- Fork https://github.com/abi/screenshot-to-code
- Replace OpenAI/Anthropic API calls with RunPod endpoints
- Self-host with your abliterated models

**Pros:**
- ‚úÖ Full screenshot-to-code UI
- ‚úÖ Uses abliterated models
- ‚úÖ Keep all the nice features

**Cons:**
- ‚ùå Requires forking and maintaining
- ‚ùå Have to modify their codebase
- ‚ùå Updates require manual merging

---

## Recommended Setup: Hybrid Approach

**Best of both worlds:**

1. **Use Claude Code + Playwright MCP** for browser automation (I can do this now!)
2. **Call your RunPod models** when you need abliterated analysis
3. **Build custom scripts** for specific screenshot-to-code workflows

### Why This Works:

**Claude Code handles:**
- Browser navigation
- Taking screenshots
- Console log extraction
- DevTools network monitoring
- Form filling and login

**Your RunPod models handle:**
- Analyzing screenshots ‚Üí generating code (abliterated)
- Complex pattern analysis (abliterated)
- Research requiring uncensored responses

---

## Setup Guide

### Part 1: Enable Browser Automation in Claude Code

#### Step 1: Install Playwright MCP Server

```bash
# Install Node.js if not already installed
brew install node

# Install the official Playwright MCP server
npx @playwright/mcp install

# Or install globally
npm install -g @playwright/mcp
```

#### Step 2: Configure Claude Code MCP

Add to your Claude Code MCP settings (`~/.claude/mcp_settings.json` or project-specific):

```json
{
  "mcpServers": {
    "playwright": {
      "command": "npx",
      "args": ["-y", "@playwright/mcp"]
    }
  }
}
```

#### Step 3: Verify It Works

```bash
# Start Claude Code
claude

# In the session, ask:
# "Can you browse to example.com and take a screenshot?"
```

Claude Code will now be able to:
- Navigate websites
- Click buttons, fill forms
- Take screenshots
- Read console messages
- Monitor network requests
- Handle logins (cookies persist for session)

### Part 2: Connect to Your RunPod Models

#### Create API Wrapper Script

Save as `runpod_api.py`:

```python
#!/usr/bin/env python3
"""
RunPod API wrapper for calling abliterated models
"""
import os
import requests
import base64
import json

RUNPOD_API_KEY = os.getenv("RUNPOD_API_KEY")

# Your endpoint configurations
ENDPOINTS = {
    "architect": {
        "id": "YOUR_ENDPOINT_ID_1",
        "url": "https://api.runpod.ai/v2/YOUR_ENDPOINT_ID_1/openai/v1"
    },
    "code": {
        "id": "YOUR_ENDPOINT_ID_2",
        "url": "https://api.runpod.ai/v2/YOUR_ENDPOINT_ID_2/openai/v1"
    },
    "research": {
        "id": "YOUR_ENDPOINT_ID_3",
        "url": "https://api.runpod.ai/v2/YOUR_ENDPOINT_ID_3/openai/v1"
    }
}

def screenshot_to_code(screenshot_path: str, model: str = "code", instructions: str = ""):
    """
    Convert screenshot to code using abliterated model

    Args:
        screenshot_path: Path to screenshot image
        model: Which model to use (architect/code/research)
        instructions: Additional instructions for code generation

    Returns:
        Generated code as string
    """
    endpoint = ENDPOINTS[model]

    # Read and encode screenshot
    with open(screenshot_path, "rb") as f:
        image_data = base64.b64encode(f.read()).decode()

    # Construct prompt
    prompt = f"""You are analyzing a screenshot of a website/UI and converting it to code.

Instructions: {instructions if instructions else "Convert this screenshot to clean, modern HTML/CSS/JavaScript code."}

Requirements:
- Generate production-ready code
- Include all visible elements
- Match styling and layout exactly
- Use modern best practices
- Include responsive design
- Add helpful comments

Provide the complete code."""

    # Call RunPod endpoint
    headers = {
        "Authorization": f"Bearer {RUNPOD_API_KEY}",
        "Content-Type": "application/json"
    }

    # Note: If using vision-capable model, include image
    # Most abliterated models don't have vision, so describe the screenshot in text
    # OR use a separate vision model to describe it first

    data = {
        "model": "model-name-here",  # Your actual model name
        "messages": [
            {
                "role": "user",
                "content": prompt
            }
        ],
        "temperature": 0.3,
        "max_tokens": 4096
    }

    response = requests.post(
        f"{endpoint['url']}/chat/completions",
        headers=headers,
        json=data
    )

    response.raise_for_status()
    result = response.json()

    return result["choices"][0]["message"]["content"]


def analyze_with_devtools(console_logs: str, network_requests: str, model: str = "architect"):
    """
    Analyze console logs and network requests using abliterated model

    Args:
        console_logs: Console log output
        network_requests: Network request data
        model: Which model to use

    Returns:
        Analysis and recommendations
    """
    endpoint = ENDPOINTS[model]

    prompt = f"""Analyze these browser devtools outputs and provide insights:

CONSOLE LOGS:
{console_logs}

NETWORK REQUESTS:
{network_requests}

Analyze:
1. Any errors or warnings?
2. Performance issues?
3. Security concerns?
4. API usage patterns?
5. Recommendations for improvement?

Provide detailed technical analysis."""

    headers = {
        "Authorization": f"Bearer {RUNPOD_API_KEY}",
        "Content-Type": "application/json"
    }

    data = {
        "model": "model-name-here",
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.7,
        "max_tokens": 4096
    }

    response = requests.post(
        f"{endpoint['url']}/chat/completions",
        headers=headers,
        json=data
    )

    response.raise_for_status()
    result = response.json()

    return result["choices"][0]["message"]["content"]


if __name__ == "__main__":
    import sys

    if len(sys.argv) < 2:
        print("Usage:")
        print("  python runpod_api.py screenshot <path> [model] [instructions]")
        print("  python runpod_api.py analyze <console_logs_file> <network_file> [model]")
        sys.exit(1)

    command = sys.argv[1]

    if command == "screenshot":
        screenshot_path = sys.argv[2]
        model = sys.argv[3] if len(sys.argv) > 3 else "code"
        instructions = sys.argv[4] if len(sys.argv) > 4 else ""

        code = screenshot_to_code(screenshot_path, model, instructions)
        print(code)

    elif command == "analyze":
        console_file = sys.argv[2]
        network_file = sys.argv[3]
        model = sys.argv[4] if len(sys.argv) > 4 else "architect"

        with open(console_file) as f:
            console_logs = f.read()
        with open(network_file) as f:
            network_requests = f.read()

        analysis = analyze_with_devtools(console_logs, network_requests, model)
        print(analysis)
```

Make executable:
```bash
chmod +x runpod_api.py
```

### Part 3: Integration Workflow

#### Example 1: Screenshot to Code (Full Workflow)

Using Claude Code (me):

```
User: "Browse to https://example.com/pricing, take a screenshot, and convert it to code using my RunPod Code Writer model"

Claude Code:
1. Opens browser with Playwright
2. Navigates to URL
3. Takes screenshot ‚Üí saves as screenshot.png
4. Calls: python runpod_api.py screenshot screenshot.png code "Convert this pricing page to HTML/CSS"
5. Returns generated code to user
```

#### Example 2: Login + Extract Data + Analyze

```
User: "Login to my Reddit account, browse r/programming, extract post titles, and analyze patterns using my Researcher model"

Claude Code:
1. Opens Reddit
2. You manually login (I watch and save cookies)
3. I navigate to r/programming
4. Extract post titles to data.json
5. Call: python runpod_api.py analyze-patterns data.json research
6. RunPod Researcher model analyzes patterns
7. Return insights to you
```

#### Example 3: DevTools Analysis

```
User: "Browse to my app at localhost:3000, capture console errors and network requests, analyze with Architect model"

Claude Code:
1. Navigate to localhost:3000
2. Capture console messages ‚Üí console.log
3. Capture network requests ‚Üí network.json
4. Call: python runpod_api.py analyze console.log network.json architect
5. RunPod Architect analyzes issues
6. Provide debugging recommendations
```

---

## Vision Model Problem & Solution

### The Problem:

**Your abliterated models DON'T have vision capabilities**
- DeepSeek-R1: Text only
- Qwen3-Coder: Text only
- Qwen3-Next-80B: Text only
- Qwen3-4B: Text only

**But screenshot-to-code needs vision!**

### The Solution: Two-Step Process

#### Option A: Use Claude Opus 4.5 for Vision, RunPod for Code Gen

```python
def screenshot_to_code_hybrid(screenshot_path: str):
    """
    Step 1: Claude Opus 4.5 describes screenshot (has vision)
    Step 2: RunPod abliterated model generates code from description
    """

    # Step 1: Vision analysis with Claude
    import anthropic
    client = anthropic.Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))

    with open(screenshot_path, "rb") as f:
        image_data = base64.b64encode(f.read()).decode()

    # Claude describes the screenshot
    vision_response = client.messages.create(
        model="claude-opus-4.5-20251101",
        max_tokens=2048,
        messages=[{
            "role": "user",
            "content": [
                {
                    "type": "image",
                    "source": {
                        "type": "base64",
                        "media_type": "image/png",
                        "data": image_data
                    }
                },
                {
                    "type": "text",
                    "text": "Describe this UI in extreme detail for a developer to recreate it. Include: layout, colors, typography, spacing, components, interactions."
                }
            ]
        }]
    )

    description = vision_response.content[0].text

    # Step 2: RunPod generates code from description
    code_prompt = f"""Based on this detailed UI description, generate production-ready HTML/CSS/JavaScript code:

{description}

Requirements:
- Pixel-perfect match to description
- Modern, clean code
- Responsive design
- Best practices

Provide complete code:"""

    # Call your RunPod Code Writer
    headers = {
        "Authorization": f"Bearer {RUNPOD_API_KEY}",
        "Content-Type": "application/json"
    }

    data = {
        "model": "your-code-writer-model",
        "messages": [{"role": "user", "content": code_prompt}],
        "temperature": 0.3,
        "max_tokens": 8192
    }

    response = requests.post(
        "https://api.runpod.ai/v2/YOUR_ENDPOINT/openai/v1/chat/completions",
        headers=headers,
        json=data
    )

    return response.json()["choices"][0]["message"]["content"]
```

**Cost:**
- Claude vision: ~$0.03 per screenshot (cheap!)
- RunPod code gen: ~$0.40 (your cost)
- **Total: ~$0.43 per screenshot-to-code**

#### Option B: Use GPT-4 Vision (Cheaper than Claude)

Replace Claude with GPT-4V:

```python
import openai

client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

response = client.chat.completions.create(
    model="gpt-4-vision-preview",
    messages=[{
        "role": "user",
        "content": [
            {"type": "image_url", "image_url": f"data:image/png;base64,{image_data}"},
            {"type": "text", "text": "Describe this UI in detail..."}
        ]
    }]
)
```

**Cost:**
- GPT-4V: ~$0.01-0.02 per screenshot (cheaper!)
- RunPod code gen: ~$0.40
- **Total: ~$0.41-0.42 per screenshot-to-code**

#### Option C: Deploy Vision-Capable Model on RunPod

**Vision models you could deploy:**
- Qwen2-VL (7B-72B) - Has vision
- LLaVA models - Has vision
- CogVLM - Has vision

**Pros:**
- ‚úÖ Fully self-hosted
- ‚úÖ Can be abliterated
- ‚úÖ No external API

**Cons:**
- ‚ùå Additional endpoint to deploy
- ‚ùå Vision models need more VRAM
- ‚ùå More complex setup

---

## Account Access & Security

### How to Handle Logins Safely

**With Playwright MCP + Claude Code:**

```
# Option 1: Manual login (safest)
You: "Browse to reddit.com"
Claude Code: *Opens browser*
You: *Manually login yourself*
You: "Now extract data from r/programming"
Claude Code: *Uses your authenticated session*
```

Cookies persist for the session, so you only login once.

**Option 2: Environment Variables for Credentials**

```bash
# .env file (gitignored!)
REDDIT_USERNAME=your_username
REDDIT_PASSWORD=your_password
TWITTER_USERNAME=...
```

```python
from playwright.sync_api import sync_playwright
import os
from dotenv import load_dotenv

load_dotenv()

def login_reddit(page):
    page.goto("https://reddit.com/login")
    page.fill('input[name="username"]', os.getenv("REDDIT_USERNAME"))
    page.fill('input[name="password"]', os.getenv("REDDIT_PASSWORD"))
    page.click('button[type="submit"]')
    page.wait_for_url("**/reddit.com/**")

    # Save cookies for reuse
    cookies = page.context.cookies()
    with open("reddit_cookies.json", "w") as f:
        json.dump(cookies, f)
```

**Option 3: Saved Cookie Sessions**

```python
# Load previously saved cookies
with open("reddit_cookies.json") as f:
    cookies = json.load(f)

context = browser.new_context()
context.add_cookies(cookies)
page = context.new_page()
# Already logged in!
```

### Security Best Practices:

1. **Never commit credentials** - Use .env files
2. **Never send passwords to AI models** - Login manually or use env vars
3. **Use cookie sessions** - Login once, reuse cookies
4. **Scope access** - Only give AI access to specific accounts when needed
5. **Monitor activity** - Check what the AI is doing before it logs in

---

## Console Logs & DevTools Access

### Accessing Console Logs with Playwright

```python
from playwright.sync_api import sync_playwright

def capture_console_logs(url: str):
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=False)
        page = browser.new_page()

        # Capture console messages
        console_logs = []
        page.on("console", lambda msg: console_logs.append({
            "type": msg.type,
            "text": msg.text,
            "location": msg.location
        }))

        # Capture errors
        errors = []
        page.on("pageerror", lambda exc: errors.append(str(exc)))

        # Navigate
        page.goto(url)
        page.wait_for_load_state("networkidle")

        # Save logs
        with open("console_logs.json", "w") as f:
            json.dump({
                "console": console_logs,
                "errors": errors
            }, f, indent=2)

        browser.close()

        return console_logs, errors

# Use it
logs, errors = capture_console_logs("https://example.com")

# Send to RunPod for analysis
os.system("python runpod_api.py analyze console_logs.json - architect")
```

### Accessing Network Requests

```python
def capture_network(url: str):
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=False)
        page = browser.new_page()

        # Capture network requests
        requests = []
        page.on("request", lambda req: requests.append({
            "url": req.url,
            "method": req.method,
            "headers": req.headers,
            "post_data": req.post_data
        }))

        # Capture responses
        responses = []
        page.on("response", lambda res: responses.append({
            "url": res.url,
            "status": res.status,
            "headers": res.headers
        }))

        page.goto(url)
        page.wait_for_load_state("networkidle")

        # Save
        with open("network.json", "w") as f:
            json.dump({
                "requests": requests,
                "responses": responses
            }, f, indent=2)

        browser.close()

capture_network("https://example.com")
```

---

## Complete Example Workflows

### Workflow 1: Screenshot to Code (Full Stack)

```bash
#!/bin/bash
# screenshot-to-code-workflow.sh

URL="https://example.com/pricing"
OUTPUT_DIR="./output"
mkdir -p $OUTPUT_DIR

echo "Step 1: Taking screenshot with Playwright..."
python3 << EOF
from playwright.sync_api import sync_playwright

with sync_playwright() as p:
    browser = p.chromium.launch()
    page = browser.new_page()
    page.goto("$URL")
    page.screenshot(path="$OUTPUT_DIR/screenshot.png", full_page=True)
    browser.close()
EOF

echo "Step 2: Converting screenshot to code with RunPod..."
python3 runpod_api.py screenshot $OUTPUT_DIR/screenshot.png code "Convert this pricing page to modern HTML/CSS with Tailwind" > $OUTPUT_DIR/generated_code.html

echo "Step 3: Opening generated code..."
open $OUTPUT_DIR/generated_code.html

echo "‚úÖ Done! Check $OUTPUT_DIR/"
```

### Workflow 2: Login + Scrape + Analyze

```python
#!/usr/bin/env python3
"""
Reddit scraper with abliterated analysis
"""
from playwright.sync_api import sync_playwright
import json
import subprocess

def scrape_reddit_with_analysis():
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=False)
        page = browser.new_page()

        # Navigate to Reddit
        page.goto("https://reddit.com/login")

        print("Please login manually...")
        page.wait_for_url("**/reddit.com/**", timeout=120000)

        # Save cookies for next time
        cookies = page.context.cookies()
        with open("reddit_cookies.json", "w") as f:
            json.dump(cookies, f)

        # Navigate to subreddit
        page.goto("https://reddit.com/r/programming")
        page.wait_for_load_state("networkidle")

        # Extract posts
        posts = page.eval_on_selector_all(
            "[data-testid='post-container']",
            """elements => elements.map(el => ({
                title: el.querySelector('h3')?.textContent,
                url: el.querySelector('a[data-click-id="body"]')?.href,
                upvotes: el.querySelector('[id*="vote-arrows"]')?.textContent
            }))"""
        )

        # Save data
        with open("reddit_posts.json", "w") as f:
            json.dump(posts, f, indent=2)

        browser.close()

        # Analyze with RunPod Researcher model
        print("\nüî¨ Analyzing with RunPod Researcher model...")
        result = subprocess.run([
            "python3", "runpod_api.py", "analyze-patterns",
            "reddit_posts.json", "research"
        ], capture_output=True, text=True)

        print(result.stdout)

if __name__ == "__main__":
    scrape_reddit_with_analysis()
```

### Workflow 3: DevTools Monitoring + Debugging

```python
#!/usr/bin/env python3
"""
Monitor app, capture devtools, analyze with Architect model
"""
from playwright.sync_api import sync_playwright
import json
import subprocess

def debug_app():
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=False, devtools=True)
        page = browser.new_page()

        # Capture everything
        console_logs = []
        errors = []
        requests = []
        responses = []

        page.on("console", lambda msg: console_logs.append({
            "type": msg.type,
            "text": msg.text
        }))

        page.on("pageerror", lambda exc: errors.append(str(exc)))

        page.on("request", lambda req: requests.append({
            "url": req.url,
            "method": req.method
        }))

        page.on("response", lambda res: responses.append({
            "url": res.url,
            "status": res.status
        }))

        # Navigate to your app
        page.goto("http://localhost:3000")

        # Interact (or let user interact)
        print("Interact with your app. Press Enter when done...")
        input()

        # Save devtools data
        devtools_data = {
            "console": console_logs,
            "errors": errors,
            "requests": requests[:50],  # Limit to avoid huge files
            "responses": responses[:50]
        }

        with open("devtools_capture.json", "w") as f:
            json.dump(devtools_data, f, indent=2)

        browser.close()

        # Analyze with RunPod Architect
        print("\nüèóÔ∏è Analyzing with Architect model...")
        result = subprocess.run([
            "python3", "runpod_api.py", "analyze-devtools",
            "devtools_capture.json", "architect"
        ], capture_output=True, text=True)

        print(result.stdout)

if __name__ == "__main__":
    debug_app()
```

---

## Next Steps

1. **Install Playwright MCP** for Claude Code (if using me)
2. **Create runpod_api.py** wrapper script
3. **Test basic workflow**: Screenshot ‚Üí description ‚Üí code
4. **Add your specific use cases**
5. **Build custom scripts** for repeated workflows

---

## FAQ

### Can I use Roo Code for this?

**No.** Roo Code doesn't have browser automation. You need:
- Claude Code + Playwright MCP, OR
- Custom Python scripts with Playwright

### Do I need vision models?

**For screenshot-to-code:** Yes, or use hybrid approach (GPT-4V/Claude describes ‚Üí RunPod generates code)

**For devtools/console:** No, text-only models work fine

### Is it safe to give AI my login credentials?

**Best practice:** Login manually, let AI use the authenticated session. Never send passwords to AI models.

### Can I automate this completely?

**Yes**, but be careful with:
- Account security (use cookies, not passwords)
- Rate limiting (Reddit, Twitter have limits)
- Terms of Service (some sites prohibit automation)

---

## Resources

- Playwright Documentation: https://playwright.dev/
- Playwright MCP Server: https://github.com/microsoft/playwright-mcp
- screenshot-to-code: https://github.com/abi/screenshot-to-code
- RunPod API Docs: https://docs.runpod.io/

---

**Ready to start? Try the hybrid approach: Claude Code + Playwright for automation, RunPod for abliterated analysis!**
