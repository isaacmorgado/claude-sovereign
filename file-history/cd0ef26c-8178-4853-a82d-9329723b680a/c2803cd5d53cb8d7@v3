# Roo Code AI Model Selection & Setup Guide

**Complete guide for deploying abliterated models on RunPod and configuring Roo Code profiles**

---

## Table of Contents

1. [Model Overview & Comparison](#model-overview--comparison)
2. [When to Use Each Model](#when-to-use-each-model)
3. [Model Selection Decision Tree](#model-selection-decision-tree)
4. [RunPod Deployment Guide](#runpod-deployment-guide)
5. [Roo Code Configuration](#roo-code-configuration)
6. [Workflow Examples](#workflow-examples)
7. [Quick Reference Cards](#quick-reference-cards)
8. [Cost Analysis](#cost-analysis)

---

## Model Overview & Comparison

### Your Model Arsenal

| # | Profile Name | Model | Size | Cost/Hour | Primary Use Case |
|---|-------------|-------|------|-----------|------------------|
| **0** | ğŸŒŸ Claude Opus | claude-opus-4.5 | ~1T+ | $5-25/M tokens | Max quality (no abliteration) |
| **1** | ğŸ—ï¸ Architect | DeepSeek-R1-32B-abl | 32B | $1.44 | Understanding, Architecture, Debugging |
| **2** | ğŸ’» Code Writer | Qwen3-Coder-30B-abl | 30B | $1.44 | Code implementation, scripts |
| **3** | ğŸ”¬ Researcher | Qwen3-Next-80B-abl | 80B (3B active) | $2.50 | Deep research, pattern analysis |
| **4** | âš¡ Budget | Qwen3-4B-abl | 4B | $0.40 | Quick questions, simple tasks |

### Performance Comparison vs Claude Opus 4.5

| Metric | Claude Opus 4.5 | DeepSeek-R1-32B | Qwen3-Coder-30B | Qwen3-Next-80B | Qwen3-4B |
|--------|-----------------|-----------------|-----------------|----------------|----------|
| **SWE-bench** | 80.9% | ~55% | ~50-55% | ~60% | ~35% |
| **Reasoning** | Top tier | Very good | Good | Very good | Decent |
| **Coding** | Excellent | Good | Very good | Good | Fair |
| **Context** | 200K | 128K | 256K | 128K+ | 128K |
| **Uncensored** | âŒ | âœ… | âœ… | âœ… | âœ… |
| **Vision** | âœ… | âŒ | âŒ | âŒ | âŒ |

**Key Insight:** Abliterated distilled models are ~30-40% less capable than Opus 4.5, but offer uncensored access at significantly lower cost.

---

## When to Use Each Model

### ğŸŒŸ Claude Opus 4.5 (API)

**Model:** `claude-opus-4.5-20251101`
**Provider:** Anthropic API
**Cost:** $5 input / $25 output per million tokens

**âœ… Use When:**
- You DON'T need abliteration (most important!)
- Maximum quality required
- Complex agentic workflows
- Vision tasks (analyzing images, diagrams)
- Mission-critical production code
- Client-facing work
- 200K context needed

**âŒ Don't Use When:**
- You need uncensored/abliterated responses
- Budget is tight
- Privacy concerns with cloud APIs

**Example Tasks:**
- Production code for paying customers
- Analyzing architectural diagrams
- Mission-critical security implementations
- Complex multi-step agent workflows

---

### ğŸ—ï¸ Architect (DeepSeek-R1-32B-abliterated)

**Model:** `huihui-ai/DeepSeek-R1-Distill-Qwen-32B-abliterated`
**Recommended GPU:** A40 48GB (~$0.79/hr) or RTX 4090 24GB (~$0.69/hr)
**Cost:** ~$0.40/request avg (30-60 sec @ $0.79/hr with auto-scale)

**âœ… Primary Use Cases:**

#### 1. Architecture & System Design
- Planning microservices architecture
- Designing database schemas
- API architecture decisions
- System integration planning
- Choosing between architectural patterns
- Security architecture
- Infrastructure design

**Example Prompts:**
```
"Design a microservices architecture for an e-commerce platform with
user auth, product catalog, cart, and payment services. Consider
scalability, security, and fault tolerance."

"Should I use REST or GraphQL for this API? The system has complex
nested relationships and multiple client types."
```

#### 2. Reverse Engineering
- Understanding legacy codebases
- Analyzing unfamiliar code patterns
- Tracing execution flow
- Understanding complex algorithms
- Protocol reverse engineering
- Cryptographic analysis

**Example Prompts:**
```
"This function takes encrypted data and returns a transformed value.
Reverse engineer what algorithm it's using and explain each step."

"Analyze these network captures and reverse engineer the protocol
structure, authentication, and message formats."
```

#### 3. Debugging & Root Cause Analysis
- Complex bug investigation
- Performance bottleneck analysis
- Memory leak debugging
- Race condition analysis
- Logic error tracing

**Example Prompts:**
```
"I'm getting intermittent 500 errors in production. Here's the
stack trace and logs. What could be causing this?"

"This function works in dev but fails in production. Analyze
the differences and identify the root cause."
```

#### 4. Understanding Existing Code
- Code comprehension
- Documentation of legacy systems
- Learning unfamiliar codebases

**Stats:**
- Size: 32B parameters
- Context: 128K tokens
- Best for: Step-by-step reasoning
- Benchmarks: 72.6% AIME, 94.3% MATH-500

**âš ï¸ DON'T Use For:**
- Pure code generation (use Code Writer)
- Simple questions (use Budget)
- Deep research (use Researcher)

---

### ğŸ’» Code Writer (Qwen3-Coder-30B-abliterated)

**Model:** `huihui-ai/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated`
**Recommended GPU:** A40 48GB (~$0.79/hr) or A100 40GB (~$1.14/hr)
**Cost:** ~$0.40/request avg (30-60 sec @ $0.79/hr with auto-scale)

**âœ… Primary Use Cases:**

#### 1. Code Implementation
- Writing new functions/classes from scratch
- Implementing features with clear requirements
- Refactoring existing code
- Converting between languages
- Writing tests
- Code completion
- Bug fixes with known solutions

**Example Prompts:**
```
"Write a Python function that implements JWT authentication with
refresh tokens, including expiration handling and token validation."

"Refactor this React component to use hooks instead of class components,
maintaining all existing functionality."
```

#### 2. Scripts & Automation
- Build scripts
- Deployment automation
- Data processing scripts
- API integrations
- CLI tools
- DevOps automation

**Example Prompts:**
```
"Write a bash script that deploys a Docker container to AWS ECS,
including health checks and rollback on failure."

"Create a Python script that scrapes product data from this API,
transforms it, and loads it into PostgreSQL."
```

#### 3. Testing & Quality
- Unit tests
- Integration tests
- Performance optimization
- Code review improvements
- Security hardening

**Stats:**
- Size: 30B parameters
- Context: 256K tokens (native)
- Best for: Code generation
- Benchmarks: 67-69.6% SWE-bench, 55.2 LiveCodeBench

**âš ï¸ DON'T Use For:**
- Architecture decisions (use Architect)
- Understanding complex code (use Architect)
- Research tasks (use Researcher)

---

### ğŸ”¬ Researcher (Qwen3-Next-80B-Thinking-abliterated)

**Model:** `huihui-ai/Huihui-Qwen3-Next-80B-A3B-Thinking-Abliterated`
**Recommended GPU:** A100 40GB (~$1.14/hr) - MoE only needs 40GB VRAM
**Cost:** ~$0.57/request avg (30-60 sec @ $1.14/hr with auto-scale)

**âœ… Primary Use Cases:**

#### 1. Deep Research & Analysis
- Literature review
- Technical documentation analysis
- Market research
- Competitive analysis
- Academic research
- Complex problem exploration
- Multi-perspective analysis

**Example Prompts:**
```
"Research the trade-offs between serverless vs container-based
architectures for a data processing pipeline. Consider cost,
scalability, latency, and vendor lock-in."

"Compare different machine learning frameworks (PyTorch, TensorFlow,
JAX) for training large language models."
```

#### 2. Pattern Recognition
- Behavioral pattern analysis
- Psychological pattern identification
- Data trend analysis
- User behavior insights
- Anomaly detection

**Example Prompts:**
```
"Analyze these 10,000 user interaction logs and identify psychological
patterns in how users behave when they're about to churn vs when they
become power users."

"Examine these forum posts and identify psychological patterns in how
people communicate when they're lying vs telling the truth."
```

#### 3. Complex Architectural Planning
- Very complex system design
- Multi-system integration planning
- Enterprise architecture
- Migration strategy planning

**Example Prompts:**
```
"Design a migration strategy from a monolithic Rails app to
microservices. Plan the phases, identify risks, and create a
rollback strategy for each phase."
```

#### 4. Strategic Planning
- Multi-step problem solving
- Complex mathematical proofs
- Multi-stage optimization
- Long-term planning

**Stats:**
- Size: 80B total, 3B active (MoE)
- Context: 128K+ tokens
- Best for: Extended reasoning, deep analysis
- Special: "Thinking mode" for complex reasoning
- Efficiency: 10x faster than dense 80B

**âš ï¸ DON'T Use For:**
- Quick code snippets (use Code Writer)
- Simple questions (use Budget)
- When speed matters more than depth

---

### âš¡ Budget Assistant (Qwen3-4B-abliterated)

**Model:** `DavidAU/Qwen3-4B-Thinking-2507-Claude-4.5-Opus-High-Reasoning-Distill-Heretic-Abliterated`
**Recommended GPU:** RTX 3090 24GB (~$0.34/hr) or RTX 4090 24GB (~$0.69/hr)
**Cost:** ~$0.17/request avg (30 sec @ $0.34/hr with auto-scale)

**âœ… Primary Use Cases:**

#### 1. Quick Questions
- Syntax questions
- Simple explanations
- Quick lookups
- Basic debugging
- Documentation queries

**Example Prompts:**
```
"What's the syntax for Python list comprehension with conditions?"
"How do I format a date in JavaScript to YYYY-MM-DD?"
"What's the difference between == and === in JavaScript?"
```

#### 2. Draft Generation
- First pass at code (refine later)
- Initial brainstorming
- Outline creation
- Quick prototypes

#### 3. High-Volume Simple Tasks
- Code comments generation
- Simple refactoring
- Variable renaming
- Basic testing

**Stats:**
- Size: 4B parameters
- Context: 128K tokens
- Best for: Speed and cost efficiency
- Benchmarks: 81.3% AIME (impressive for 4B!)

**âš ï¸ DON'T Use For:**
- Complex code generation
- Deep analysis
- Architecture design
- Anything critical

**âš ï¸ Warning:** Model name is misleading - NOT actually distilled from Claude (violates ToS)

---

## Model Selection Decision Tree

### Main Decision Flow

```
START: What are you trying to do?
â”‚
â”œâ”€ Need UNCENSORED/ABLITERATED content?
â”‚  â”‚
â”‚  YES â†’ Continue below â†“
â”‚  â”‚
â”‚  NO â†’ Use Claude Opus 4.5 API
â”‚     â””â”€ Best quality (80.9% SWE-bench)
â”‚        Most capable overall
â”‚        Vision support
â”‚        200K context
â”‚        $5-25 per million tokens
â”‚
â”‚
â”œâ”€ TASK TYPE?
â”‚  â”‚
â”‚  â”œâ”€ [1] UNDERSTANDING / ANALYSIS
â”‚  â”‚   â”‚
â”‚  â”‚   â”œâ”€ Reverse Engineering?
â”‚  â”‚   â”‚   â†’ ğŸ—ï¸ Architect (DeepSeek-R1-32B)
â”‚  â”‚   â”‚      "Why does this code work this way?"
â”‚  â”‚   â”‚      "Trace this algorithm backwards"
â”‚  â”‚   â”‚      "Decode this protocol"
â”‚  â”‚   â”‚
â”‚  â”‚   â”œâ”€ System Design / Architecture?
â”‚  â”‚   â”‚   â†’ ğŸ—ï¸ Architect (DeepSeek-R1-32B)
â”‚  â”‚   â”‚      "Design a microservices architecture"
â”‚  â”‚   â”‚      "Plan this database schema"
â”‚  â”‚   â”‚      "Choose between X vs Y approach"
â”‚  â”‚   â”‚
â”‚  â”‚   â”œâ”€ Debugging / Root Cause?
â”‚  â”‚   â”‚   â†’ ğŸ—ï¸ Architect (DeepSeek-R1-32B)
â”‚  â”‚   â”‚      "Why is this failing?"
â”‚  â”‚   â”‚      "Find the bug in this code"
â”‚  â”‚   â”‚      "Analyze this error log"
â”‚  â”‚   â”‚
â”‚  â”‚   â””â”€ Understanding existing code?
â”‚  â”‚       â†’ ğŸ—ï¸ Architect (DeepSeek-R1-32B)
â”‚  â”‚          "Explain how this works"
â”‚  â”‚          "What does this function do?"
â”‚  â”‚
â”‚  â”œâ”€ [2] RESEARCH / DEEP ANALYSIS
â”‚  â”‚   â”‚
â”‚  â”‚   â”œâ”€ Deep research needed?
â”‚  â”‚   â”‚   â†’ ğŸ”¬ Researcher (Qwen3-Next-80B)
â”‚  â”‚   â”‚      "Compare 5 different approaches"
â”‚  â”‚   â”‚      "Research best practices for X"
â”‚  â”‚   â”‚      "Analyze this complex topic"
â”‚  â”‚   â”‚
â”‚  â”‚   â”œâ”€ Pattern recognition in data?
â”‚  â”‚   â”‚   â†’ ğŸ”¬ Researcher (Qwen3-Next-80B)
â”‚  â”‚   â”‚      "Find patterns in this dataset"
â”‚  â”‚   â”‚      "Identify psychological patterns"
â”‚  â”‚   â”‚      "Analyze user behavior trends"
â”‚  â”‚   â”‚
â”‚  â”‚   â”œâ”€ Strategic planning?
â”‚  â”‚   â”‚   â†’ ğŸ”¬ Researcher (Qwen3-Next-80B)
â”‚  â”‚   â”‚      "Plan a migration strategy"
â”‚  â”‚   â”‚      "Design multi-phase rollout"
â”‚  â”‚   â”‚
â”‚  â”‚   â””â”€ VERY complex architecture?
â”‚  â”‚       â†’ ğŸ”¬ Researcher (Qwen3-Next-80B)
â”‚  â”‚          "Enterprise-scale system design"
â”‚  â”‚          "Multi-system integration plan"
â”‚  â”‚
â”‚  â”œâ”€ [3] WRITING CODE
â”‚  â”‚   â”‚
â”‚  â”‚   â”œâ”€ Writing new code/features?
â”‚  â”‚   â”‚   â†’ ğŸ’» Code Writer (Qwen3-Coder-30B)
â”‚  â”‚   â”‚      "Implement this function"
â”‚  â”‚   â”‚      "Write a REST API endpoint"
â”‚  â”‚   â”‚      "Create this component"
â”‚  â”‚   â”‚
â”‚  â”‚   â”œâ”€ Refactoring existing code?
â”‚  â”‚   â”‚   â†’ ğŸ’» Code Writer (Qwen3-Coder-30B)
â”‚  â”‚   â”‚      "Refactor this to use hooks"
â”‚  â”‚   â”‚      "Optimize this algorithm"
â”‚  â”‚   â”‚      "Convert this to TypeScript"
â”‚  â”‚   â”‚
â”‚  â”‚   â”œâ”€ Writing scripts/automation?
â”‚  â”‚   â”‚   â†’ ğŸ’» Code Writer (Qwen3-Coder-30B)
â”‚  â”‚   â”‚      "Build a deployment script"
â”‚  â”‚   â”‚      "Create a data processing pipeline"
â”‚  â”‚   â”‚      "Write a CLI tool"
â”‚  â”‚   â”‚
â”‚  â”‚   â””â”€ Writing tests?
â”‚  â”‚       â†’ ğŸ’» Code Writer (Qwen3-Coder-30B)
â”‚  â”‚          "Write unit tests for this"
â”‚  â”‚          "Create integration tests"
â”‚  â”‚
â”‚  â””â”€ [4] QUICK / SIMPLE TASKS
â”‚      â”‚
â”‚      â”œâ”€ Simple question?
â”‚      â”‚   â†’ âš¡ Budget Assistant (Qwen3-4B)
â”‚      â”‚      "What's the syntax for X?"
â”‚      â”‚      "How do I use this API?"
â”‚      â”‚      "Quick explanation of Y?"
â”‚      â”‚
â”‚      â”œâ”€ Need a quick draft?
â”‚      â”‚   â†’ âš¡ Budget Assistant (Qwen3-4B)
â”‚      â”‚      "Rough sketch of this code"
â”‚      â”‚      "Basic outline of approach"
â”‚      â”‚
â”‚      â””â”€ High-volume simple tasks?
â”‚          â†’ âš¡ Budget Assistant (Qwen3-4B)
â”‚             "Generate 100 comments"
â”‚             "Simple variable renaming"
```

### Keyword Quick Reference

**Match keywords in your prompt to the right model:**

| Keywords in Your Prompt | Use This Model |
|-------------------------|----------------|
| "why", "how does", "explain", "trace", "decode" | ğŸ—ï¸ Architect |
| "reverse engineer", "analyze algorithm" | ğŸ—ï¸ Architect |
| "design", "architecture", "should I use X or Y" | ğŸ—ï¸ Architect |
| "debug", "error", "bug", "not working" | ğŸ—ï¸ Architect |
| "research", "compare", "analyze pros/cons" | ğŸ”¬ Researcher |
| "find patterns", "trends", "psychological" | ğŸ”¬ Researcher |
| "write", "implement", "create", "build", "code" | ğŸ’» Code Writer |
| "refactor", "optimize", "convert" | ğŸ’» Code Writer |
| "script", "automation", "tool" | ğŸ’» Code Writer |
| "syntax", "how do I", "quick question" | âš¡ Budget |

---

## RunPod Deployment Guide

### GPU Selection Guide

**IMPORTANT: Choose the right GPU to minimize costs!**

| Model | VRAM Needed | Cheapest GPU | Cost/Hour | Cost/Request* |
|-------|-------------|--------------|-----------|---------------|
| Budget (4B) | ~8GB | RTX 3090 24GB | $0.34 | ~$0.17 |
| Architect (32B) | ~20GB | RTX 4090 24GB | $0.69 | ~$0.35 |
| Code Writer (30B) | ~18GB | A40 48GB | $0.79 | ~$0.40 |
| Researcher (80B MoE) | ~40GB | A100 40GB | $1.14 | ~$0.57 |

*Average 30-60 sec per request with auto-scaling (`workersMin: 0`)

#### GPU Options by Price (Serverless):

**RTX 3090/4090** (~$0.34-0.69/hr)
- VRAM: 24GB
- âœ… Best for: 4B models, budget deployments
- âœ… Can run: Budget (4B), Architect (32B - tight fit)
- âŒ Too small for: 30B+ models comfortably

**A40** (~$0.79/hr)
- VRAM: 48GB
- âœ… Best for: 30-32B models (optimal balance)
- âœ… Can run: All models except very large batches
- ğŸ’¡ Recommended: Architect (32B), Code Writer (30B)

**A100 40GB** (~$1.14/hr)
- VRAM: 40GB
- âœ… Best for: 80B MoE models
- âœ… Can run: All your models
- ğŸ’¡ Recommended: Researcher (80B MoE)

**A100 80GB** (~$1.44/hr)
- VRAM: 80GB
- âš ï¸ Overkill for your models - avoid unless scaling >3 workers
- Only use if A100 40GB unavailable

**H100** (~$2.50-4.00/hr)
- âš ï¸ Much faster but 2-3x more expensive
- Only worth it if speed is absolutely critical

#### Cost Optimization Strategy:

**Deploy models on different GPUs:**
```
Budget (4B)      â†’ RTX 3090  ($0.34/hr)  Saves: $40/month vs A100
Architect (32B)  â†’ A40       ($0.79/hr)  Saves: $25/month vs A100
Code Writer (30B)â†’ A40       ($0.79/hr)  Saves: $25/month vs A100
Researcher (80B) â†’ A100 40GB ($1.14/hr)  Optimal for MoE
```

**Estimated monthly costs** (100 requests/month mixed):
- All on A100 80GB: ~$60/month
- Optimized GPUs: ~$25-35/month
- **Savings: $25-35/month (40-60% reduction)**

### Prerequisites

1. Create RunPod account at https://www.runpod.io
2. Add payment method
3. Get API key: Settings â†’ API Keys â†’ Create API Key
4. **Save your API key securely**

### Deployment Steps

#### Model 1: DeepSeek-R1 (Architect)

1. **Navigate to Serverless**
   - Click "Serverless" in left sidebar
   - Click "Quick Deploy"
   - Find "Serverless vLLM" â†’ Click "Start"

2. **Configure Endpoint**
   ```
   Endpoint Name: deepseek-r1-architecture
   vLLM Version: Latest
   ```

3. **Model Configuration**
   ```
   Model Name: huihui-ai/DeepSeek-R1-Distill-Qwen-32B-abliterated
   ```

4. **GPU Selection**
   ```
   GPU Type: A40 48GB (recommended, $0.79/hr)
   Alternative: RTX 4090 24GB ($0.69/hr, tighter fit)
   ```

5. **Scaling Settings**
   ```
   Min Workers: 0
   Max Workers: 3
   GPUs Per Worker: 1
   ```

6. **Environment Variables** (Advanced section)
   ```
   MODEL_NAME=huihui-ai/DeepSeek-R1-Distill-Qwen-32B-abliterated
   MAX_MODEL_LEN=32768
   ```

7. **Deploy** and **SAVE ENDPOINT ID**
   - You'll get an ID like: `abc123xyz456`
   - Your API URL: `https://api.runpod.ai/v2/abc123xyz456/openai/v1`

#### Model 2: Qwen3-Coder (Code Writer)

Repeat above steps with:

```
Endpoint Name: qwen3-coder-writer
Model Name: huihui-ai/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated
GPU Type: A40 48GB (recommended, $0.79/hr)
Environment Variables:
  MODEL_NAME=huihui-ai/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated
  MAX_MODEL_LEN=131072
```

**SAVE ENDPOINT ID #2**

#### Model 3: Qwen3-Next-80B (Researcher)

Repeat above steps with:

```
Endpoint Name: qwen3-next-research
Model Name: huihui-ai/Huihui-Qwen3-Next-80B-A3B-Thinking-Abliterated
GPU Type: A100 40GB (recommended, $1.14/hr - MoE only needs 40GB!)
Environment Variables:
  MODEL_NAME=huihui-ai/Huihui-Qwen3-Next-80B-A3B-Thinking-Abliterated
  MAX_MODEL_LEN=131072
```

**SAVE ENDPOINT ID #3**

#### Model 4: Qwen3-4B (Budget)

Repeat above steps with:

```
Endpoint Name: qwen3-4b-budget
Model Name: DavidAU/Qwen3-4B-Thinking-2507-Claude-4.5-Opus-High-Reasoning-Distill-Heretic-Abliterated
GPU Type: RTX 3090 24GB (cheapest, $0.34/hr) or RTX 4090 24GB ($0.69/hr)
Environment Variables:
  MODEL_NAME=DavidAU/Qwen3-4B-Thinking-2507-Claude-4.5-Opus-High-Reasoning-Distill-Heretic-Abliterated
  MAX_MODEL_LEN=131072
```

**SAVE ENDPOINT ID #4**

#### Verify Deployments

1. Go to Serverless dashboard
2. You should see 4 endpoints with Status: Active
3. Test each endpoint by clicking and checking logs

---

## Roo Code Configuration

### Installation

1. Open VS Code
2. Extensions (Ctrl/Cmd + Shift + X)
3. Search "Roo Code"
4. Install
5. Restart VS Code

### Profile Configuration

#### Profile 0: Claude Opus 4.5 (API)

1. Open Roo Code settings (Ctrl/Cmd + Shift + P â†’ "Roo Code: Open Settings")
2. Add Provider â†’ Select "Anthropic"
3. Configure:

```
Provider Name: Claude Opus
API Key: YOUR_ANTHROPIC_API_KEY (from console.anthropic.com)
Model: claude-opus-4.5-20251101
Display Name: ğŸŒŸ Claude Opus 4.5 (Max Quality)
Description: When you don't need abliteration and want the absolute best
Max Tokens: 200000
Temperature: 0.7
```

#### Profile 1: Architect (DeepSeek-R1)

1. Add Provider â†’ Select "OpenAI Compatible"
2. Configure:

```
Provider Name: Architect (DeepSeek-R1)
Base URL: https://api.runpod.ai/v2/<ENDPOINT_ID_1>/openai/v1
API Key: YOUR_RUNPOD_API_KEY
Model Name: huihui-ai/DeepSeek-R1-Distill-Qwen-32B-abliterated
Display Name: ğŸ—ï¸ Architect (DeepSeek-R1-32B)
Description: Architecture, system design, reverse engineering, debugging
Max Tokens: 32768
Temperature: 0.7
```

#### Profile 2: Code Writer (Qwen3-Coder)

1. Add Provider â†’ Select "OpenAI Compatible"
2. Configure:

```
Provider Name: Code Writer (Qwen3-Coder)
Base URL: https://api.runpod.ai/v2/<ENDPOINT_ID_2>/openai/v1
API Key: YOUR_RUNPOD_API_KEY
Model Name: huihui-ai/Huihui-Qwen3-Coder-30B-A3B-Instruct-abliterated
Display Name: ğŸ’» Code Writer (Qwen3-Coder-30B)
Description: Code generation, implementation, refactoring, scripts
Max Tokens: 131072
Temperature: 0.3
```

#### Profile 3: Researcher (Qwen3-Next-80B)

1. Add Provider â†’ Select "OpenAI Compatible"
2. Configure:

```
Provider Name: Researcher (Qwen3-Next-80B)
Base URL: https://api.runpod.ai/v2/<ENDPOINT_ID_3>/openai/v1
API Key: YOUR_RUNPOD_API_KEY
Model Name: huihui-ai/Huihui-Qwen3-Next-80B-A3B-Thinking-Abliterated
Display Name: ğŸ”¬ Researcher (Qwen3-Next-80B)
Description: Deep research, complex analysis, strategic planning
Max Tokens: 131072
Temperature: 0.7
```

#### Profile 4: Budget Assistant (Qwen3-4B)

1. Add Provider â†’ Select "OpenAI Compatible"
2. Configure:

```
Provider Name: Budget Assistant (Qwen3-4B)
Base URL: https://api.runpod.ai/v2/<ENDPOINT_ID_4>/openai/v1
API Key: YOUR_RUNPOD_API_KEY
Model Name: DavidAU/Qwen3-4B-Thinking-2507-Claude-4.5-Opus-High-Reasoning-Distill-Heretic-Abliterated
Display Name: âš¡ Budget Assistant (Qwen3-4B)
Description: Quick questions, simple tasks, drafts
Max Tokens: 131072
Temperature: 0.5
```

### Testing Your Setup

1. Open Roo Code chat
2. Click model selector dropdown
3. Should see all 5 profiles
4. Select "âš¡ Budget Assistant"
5. Test prompt: "What's the Python syntax for list comprehension?"
6. First request has ~2-5 sec cold start (normal)

### Adding MCP Servers (Internet Access)

1. Open terminal in VS Code
2. Install Context7:
   ```bash
   npx @context7/mcp-server
   ```
3. In Roo Code settings â†’ MCP Servers
4. Add:
   ```
   Name: Context7
   Command: npx
   Args: @context7/mcp-server
   ```
5. Restart Roo Code

**Now models can search the web!**

---

## Workflow Examples

### Example 1: Building a New Feature

**Task:** Implement real-time chat with WebSockets

**Step 1: Architecture Planning**
- **Model:** ğŸ—ï¸ Architect
- **Prompt:** "Design the architecture for a real-time chat feature with WebSockets, message persistence, and typing indicators."
- **Time:** 2 minutes
- **Cost:** $0.05
- **Output:** System design, database schema, API endpoints

**Step 2: Research WebSocket Libraries**
- **Model:** ğŸ”¬ Researcher
- **Prompt:** "Compare Socket.io vs native WebSocket vs ws library for Node.js. Consider ease of use, features, performance, and ecosystem."
- **Time:** 3 minutes
- **Cost:** $0.13
- **Output:** Comprehensive comparison

**Step 3: Implementation**
- **Model:** ğŸ’» Code Writer
- **Prompt:** "Implement the WebSocket server in Node.js based on this architecture [paste architecture from step 1]."
- **Time:** 10 minutes
- **Cost:** $0.24
- **Output:** Working code

**Step 4: Quick Questions**
- **Model:** âš¡ Budget
- **Prompt:** "How do I emit a WebSocket event in Socket.io?"
- **Time:** 30 seconds
- **Cost:** $0.003
- **Output:** Quick syntax answer

**Total:** 15.5 minutes, $0.42

---

### Example 2: Debugging Production Issue

**Task:** Intermittent 500 errors in production

**Step 1: Root Cause Analysis**
- **Model:** ğŸ—ï¸ Architect
- **Prompt:** "Here's the error log and stack trace. Trace the root cause [paste logs]."
- **Output:** Root cause identification

**Step 2: Implement Fix**
- **Model:** ğŸ’» Code Writer
- **Prompt:** "Write the fix for this race condition in the database transaction handling."
- **Output:** Fixed code

**Step 3: Add Tests**
- **Model:** ğŸ’» Code Writer
- **Prompt:** "Write integration tests that reproduce this race condition and verify the fix."
- **Output:** Test code

---

### Example 3: Research & Decision Making

**Task:** Choose session storage solution

**Step 1: Deep Research**
- **Model:** ğŸ”¬ Researcher
- **Prompt:** "Compare Redis vs Memcached for session storage in a high-traffic web app. Consider persistence, data structures, clustering, cost, and operational complexity."
- **Output:** Comprehensive analysis

**Step 2: Architecture**
- **Model:** ğŸ—ï¸ Architect
- **Prompt:** "Based on that research, design a session management system using Redis with fallback to database."
- **Output:** System architecture

**Step 3: Implementation**
- **Model:** ğŸ’» Code Writer
- **Prompt:** "Implement the Redis session store with the architecture above."
- **Output:** Code

---

### Example 4: Reverse Engineering

**Task:** Understand proprietary API

**Step 1: Reverse Engineer**
- **Model:** ğŸ—ï¸ Architect (ONLY)
- **Prompt:** "Analyze these API responses and reverse engineer the authentication scheme, endpoint structure, and data format [paste responses]."
- **Output:** API specification

**Step 2: Research Similar Patterns**
- **Model:** ğŸ”¬ Researcher
- **Prompt:** "Research common authentication schemes for REST APIs and identify security implications of this approach."
- **Output:** Security analysis

**Step 3: Build Client**
- **Model:** ğŸ’» Code Writer
- **Prompt:** "Based on this API spec, write a Python client library."
- **Output:** Working client

---

### Example 5: Pattern Analysis

**Task:** Identify user churn patterns

**Step 1: Pattern Analysis**
- **Model:** ğŸ”¬ Researcher
- **Prompt:** "Analyze these 10,000 user behavior logs and identify psychological patterns that correlate with user churn [provide data]."
- **Output:** Pattern report

**Step 2: Understand the Logic**
- **Model:** ğŸ—ï¸ Architect
- **Prompt:** "Explain the mathematical/psychological relationship between these patterns and churn probability."
- **Output:** Logical explanation

**Step 3: Build Detection Script**
- **Model:** ğŸ’» Code Writer
- **Prompt:** "Write a Python script that detects these churn patterns in real-time user data."
- **Output:** Detection script

---

## Quick Reference Cards

### Print-Friendly Quick Reference

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        ROO CODE MODEL SELECTION GUIDE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

NEED ABLITERATION?
  NO  â†’ ğŸŒŸ Claude Opus 4.5 (Best quality, $5-25/M tokens)
  YES â†’ Choose below â†“

TASK TYPES:

ğŸ—ï¸ ARCHITECT ($1.44/hr) - Understanding & Design
   â€¢ Why/how does this work?
   â€¢ Reverse engineering
   â€¢ System architecture
   â€¢ Debugging root causes
   â€¢ Algorithm analysis

ğŸ”¬ RESEARCHER ($2.50/hr) - Deep Analysis
   â€¢ Research & compare options
   â€¢ Pattern recognition
   â€¢ Psychological analysis
   â€¢ Complex planning
   â€¢ Strategic decisions

ğŸ’» CODE WRITER ($1.44/hr) - Implementation
   â€¢ Write ANY code
   â€¢ Scripts & automation
   â€¢ Refactoring
   â€¢ Tests
   â€¢ Features & fixes

âš¡ BUDGET ($0.40/hr) - Quick & Simple
   â€¢ Syntax questions
   â€¢ Simple explanations
   â€¢ Quick drafts
   â€¢ High-volume tasks

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Decision Matrix

| What You're Doing | Model to Use |
|-------------------|--------------|
| **Understanding WHY** something works | ğŸ—ï¸ Architect |
| **Tracing logic/algorithms backwards** | ğŸ—ï¸ Architect |
| **Decoding/decrypting/deobfuscating** | ğŸ—ï¸ Architect |
| **System architecture design** | ğŸ—ï¸ Architect |
| **Debugging complex issues** | ğŸ—ï¸ Architect |
| **Finding patterns in large datasets** | ğŸ”¬ Researcher |
| **Understanding psychological behavior** | ğŸ”¬ Researcher |
| **Researching similar systems/techniques** | ğŸ”¬ Researcher |
| **Strategic planning** | ğŸ”¬ Researcher |
| **Writing ANY code** | ğŸ’» Code Writer |
| **Building scripts/tools** | ğŸ’» Code Writer |
| **Implementing what you discovered** | ğŸ’» Code Writer |
| **Refactoring/optimizing code** | ğŸ’» Code Writer |
| **Quick syntax/simple questions** | âš¡ Budget |
| **Simple drafts** | âš¡ Budget |

---

## Cost Analysis

### Hourly Costs (RunPod Serverless)

| Model | GPU | Cost/Hour | Typical Task Duration | Cost/Task |
|-------|-----|-----------|----------------------|-----------|
| ğŸ—ï¸ Architect | A100 40GB | $1.44 | 5-10 min | $0.12-0.24 |
| ğŸ’» Code Writer | A100 40GB | $1.44 | 5-15 min | $0.12-0.36 |
| ğŸ”¬ Researcher | A100 80GB | $2.50 | 5-20 min | $0.21-0.83 |
| âš¡ Budget | A40 48GB | $0.40 | 1-5 min | $0.01-0.03 |

### Monthly Cost Estimates

**Light Usage (5 hours/month per model):**
- Architect: 5h Ã— $1.44 = $7.20
- Code Writer: 5h Ã— $1.44 = $7.20
- Researcher: 5h Ã— $2.50 = $12.50
- Budget: 5h Ã— $0.40 = $2.00
- **Total: ~$29/month**

**Moderate Usage (15 hours/month per model):**
- Architect: 15h Ã— $1.44 = $21.60
- Code Writer: 15h Ã— $1.44 = $21.60
- Researcher: 15h Ã— $2.50 = $37.50
- Budget: 15h Ã— $0.40 = $6.00
- **Total: ~$87/month**

**Heavy Usage (40 hours/month per model):**
- Architect: 40h Ã— $1.44 = $57.60
- Code Writer: 40h Ã— $1.44 = $57.60
- Researcher: 40h Ã— $2.50 = $100.00
- Budget: 40h Ã— $0.40 = $16.00
- **Total: ~$231/month**

### Cost Optimization Strategies

1. **Use Budget model for simple tasks** (saves 72% vs Architect)
2. **Serverless scales to $0** when not in use
3. **Use Claude Opus API** for non-abliterated tasks (might be cheaper for light usage)
4. **Share endpoints** - Architect can handle reverse engineering AND architecture
5. **Monitor usage** in RunPod dashboard

### Break-Even Analysis: Self-Hosted vs API

**Claude Opus 4.5 API:**
- $5 input / $25 output per million tokens
- 100M tokens = ~$500-2500 depending on input/output ratio

**Self-Hosted Abliterated:**
- $1.44-2.50/hour
- Break-even: ~200-350 hours of API usage per month
- For most users: Self-hosted is more expensive unless you're processing billions of tokens

**Recommendation:**
- Use API models (Claude, DeepSeek-R1-671B, Qwen3-Coder-480B) if you don't need abliteration
- Use self-hosted only if you specifically need abliteration

---

## Troubleshooting

### Common Issues

#### 1. Endpoint Returns 404

**Problem:** `https://api.runpod.ai/v2/<ID>/openai/v1` returns 404

**Solutions:**
- Check endpoint is deployed (RunPod dashboard â†’ Serverless)
- Verify endpoint ID is correct
- Check endpoint status is "Active"
- Wait 30 seconds for cold start

#### 2. Model Loads Slowly (Cold Start)

**Problem:** First request takes 30+ seconds

**Solutions:**
- Normal for first request after idle
- Increase "Min Workers" to 1 (keeps warm, costs more)
- Use Budget model for quick questions
- Subsequent requests will be fast (<2 seconds)

#### 3. Out of Memory Errors

**Problem:** Model fails to load with OOM error

**Solutions:**
- Increase GPU size (40GB â†’ 80GB)
- Check MAX_MODEL_LEN isn't too high
- Verify model size matches GPU (80B needs 80GB)

#### 4. Roo Code Can't Connect

**Problem:** "Failed to connect to endpoint"

**Solutions:**
- Verify RunPod API key is correct
- Check base URL format: `https://api.runpod.ai/v2/<ID>/openai/v1`
- Ensure endpoint is active
- Test with curl first

#### 5. Responses Are Poor Quality

**Problem:** Model gives bad answers

**Solutions:**
- Check you're using right model for task
- Verify model loaded correctly (check RunPod logs)
- Try adjusting temperature (lower = more focused)
- Consider if task is too complex for model size

---

## Advanced Tips

### Optimizing for Speed

1. **Keep endpoints warm**: Set Min Workers = 1 for frequently used models
2. **Use Budget model first**: Quick questions don't need big models
3. **Batch similar tasks**: Use same model for related work
4. **Parallel endpoints**: Deploy multiple instances for concurrent work

### Optimizing for Cost

1. **Scale to zero**: Set Min Workers = 0 (default)
2. **Right-size models**: Don't use Researcher for simple tasks
3. **Share endpoints**: One Architect endpoint for multiple use cases
4. **Monitor usage**: RunPod dashboard shows per-endpoint costs
5. **Use Claude API**: For non-abliterated tasks, might be cheaper

### Context Management

1. **32K limit on Architect**: Don't paste entire codebases
2. **256K on Coder**: Can handle large files
3. **Summarize first**: Use Budget to summarize, then Architect to analyze
4. **Chain models**: Researcher finds patterns â†’ Architect explains â†’ Coder implements

### Prompt Engineering

1. **Be specific**: "Explain X step-by-step" vs "Explain X"
2. **Provide context**: Include relevant code/data
3. **Ask for format**: "Explain as bullet points" or "Show as code"
4. **Iterate**: Start general, then drill down with follow-ups

---

## Resources

### Official Documentation

- **RunPod Docs:** https://docs.runpod.io/
- **Roo Code Docs:** https://docs.roocode.com/
- **Anthropic API:** https://docs.anthropic.com/

### Model Pages

- **DeepSeek-R1:** https://huggingface.co/deepseek-ai/DeepSeek-R1
- **Qwen3-Coder:** https://huggingface.co/Qwen/Qwen3-Coder-30B-A3B-Instruct
- **Qwen3:** https://qwenlm.github.io/blog/qwen3/

### Community

- **RunPod Discord:** https://discord.gg/runpod
- **Roo Code GitHub:** https://github.com/RooCodeInc/Roo-Code
- **r/LocalLLaMA:** https://reddit.com/r/LocalLLaMA

---

## Version History

- **v1.0** (2026-01-05): Initial guide
  - 5 model profiles
  - Complete RunPod deployment
  - Roo Code configuration
  - Decision trees and workflows

---

**END OF GUIDE**

*Save this document for reference. Update endpoint IDs after deployment.*
