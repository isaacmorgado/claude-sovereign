/**
 * SPLICE Backend Server
 *
 * Main entry point for the SPLICE backend API.
 * Orchestrates the audio analysis pipeline.
 *
 * Slices:
 * - Slice 4: Transcription (services/transcription.js)
 * - Slice 5: Take Detection (services/takeDetection.js)
 */

/* global setTimeout, setInterval */

require('dotenv').config();

const express = require('express');
const cors = require('cors');
const helmet = require('helmet');
const fs = require('fs');
const fsPromises = require('fs').promises;
const https = require('https');
const http = require('http');
const path = require('path');

// Async file existence check (non-blocking)
async function fileExists(filePath) {
  try {
    await fsPromises.access(filePath, fs.constants.R_OK);
    return true;
  } catch {
    return false;
  }
}

// Check if running in production (Railway injects RAILWAY_ENVIRONMENT)
const isProduction = process.env.NODE_ENV === 'production' || process.env.RAILWAY_ENVIRONMENT;

// Import slice services
const { transcribeAudio, transcribeWithWords, transcribeFull } = require('./services/transcription');
const { detectTakes } = require('./services/takeDetection');
const { detectSilences } = require('./services/silenceDetection');
const { detectAudioSilences, isFFprobeInstalled, getAudioDuration } = require('./services/ffprobeSilence');
const { detectSilencesRMS, sensitivityToParams, getWaveformData } = require('./services/rmsSilenceDetection');
const {
  detectProfanity,
  getProfanityList,
  getSupportedLanguages,
  getAvailableBleepSounds,
  parseWordList,
  generateBleepsForSegments,
  cleanupBleepFiles
} = require('./services/profanityDetection');
const {
  detectStutters,
  detectAllRepetitions
} = require('./services/repetitionDetection');
const {
  analyzeMultitrack,
  autoBalanceMultitrack,
  advancedBalanceMultitrack
} = require('./services/multitrackAnalysis');
const {
  toSRT,
  toVTT,
  toPlainText,
  toJSON,
  exportToFile,
  getSupportedFormats
} = require('./services/captionExporter');
const { processXMLFile } = require('./services/xmlProcessor');
const { isolateVocals, isReplicateConfigured } = require('./services/vocalIsolation');
const { generateCutList, generateTakesCutList, validateCutList, alignToFrame, alignToFrameFloor, alignToFrameCeil } = require('./services/cutListGenerator');
const { generateZoomPoints, addZoomsToCutList, ZOOM_PRESETS, ZOOM_FREQUENCIES } = require('./services/zoomGenerator');
const { detectChapters, detectChaptersFallback, formatYouTubeTimestamps } = require('./services/chapterDetection');

// Usage tracking and billing
const usageTracking = require('./services/usageTracking');
// Rate limiter for usage-based endpoints
const { requireCredits } = require('./middleware/rateLimiter');
// JWT authentication
const { generateToken, generateRefreshToken, verifyToken, authenticateToken, maskSensitiveData } = require('./middleware/auth');
// Referral system
const referralService = require('./services/referralService');
// License key system
const licenseService = require('./services/licenseService');

// Maximum file size for audio processing (500MB)
const MAX_FILE_SIZE_BYTES = 500 * 1024 * 1024;

/**
 * Validate file size to prevent OOM crashes
 * @param {string} filePath - Path to file
 * @returns {Promise<{valid: boolean, size?: number, error?: string}>}
 */
async function validateFileSize(filePath) {
  try {
    const stats = await require('fs').promises.stat(filePath);
    if (stats.size > MAX_FILE_SIZE_BYTES) {
      return {
        valid: false,
        size: stats.size,
        error: `File too large (${(stats.size / 1024 / 1024).toFixed(1)}MB). Maximum allowed: ${MAX_FILE_SIZE_BYTES / 1024 / 1024}MB`
      };
    }
    return { valid: true, size: stats.size };
  } catch (err) {
    return { valid: false, error: `Cannot access file: ${err.message}` };
  }
}

// =============================================================================
// PERF-FIX: Static Response Cache
// Cache static endpoint responses at startup to avoid repeated computation
// =============================================================================

const crypto = require('crypto');

// Generate ETag from content
function generateETag(content) {
  return `"${crypto.createHash('md5').update(JSON.stringify(content)).digest('hex')}"`;
}

// Static response cache - populated at startup
const STATIC_RESPONSE_CACHE = {
  profanityLanguages: null,
  profanityBleeps: null,
  exportFormats: null
};

// Initialize cache at startup (called after server starts)
function initializeStaticCache() {
  // Cache profanity languages
  const languages = getSupportedLanguages();
  STATIC_RESPONSE_CACHE.profanityLanguages = {
    body: { success: true, languages },
    etag: generateETag({ languages })
  };

  // Cache profanity bleeps
  const sounds = getAvailableBleepSounds();
  STATIC_RESPONSE_CACHE.profanityBleeps = {
    body: { success: true, sounds },
    etag: generateETag({ sounds })
  };

  // Cache export formats
  const formats = getSupportedFormats();
  STATIC_RESPONSE_CACHE.exportFormats = {
    body: { success: true, formats },
    etag: generateETag({ formats })
  };

  console.log('[SPLICE] Static response cache initialized');
}

// Helper to send cached response with ETag
function sendCachedResponse(req, res, cacheKey) {
  const cached = STATIC_RESPONSE_CACHE[cacheKey];
  if (!cached) {
    return res.status(500).json({ error: 'Cache not initialized' });
  }

  // Check If-None-Match header for conditional GET
  const clientETag = req.headers['if-none-match'];
  if (clientETag === cached.etag) {
    return res.status(304).end(); // Not Modified
  }

  // Send cached response with ETag and cache headers
  res.set('ETag', cached.etag);
  res.set('Cache-Control', 'public, max-age=86400'); // Cache for 24 hours
  res.json(cached.body);
}

// Stripe for webhooks
const Stripe = require('stripe');
const stripe = new Stripe(process.env.STRIPE_SECRET_KEY);

// =============================================================================
// Server Configuration
// =============================================================================

const app = express();
const PORT = process.env.PORT || 3847;

// HTTPS certificates (generated by mkcert) - only for local development
let httpsOptions = null;
if (!isProduction) {
  const keyPath = path.join(__dirname, 'localhost+1-key.pem');
  const certPath = path.join(__dirname, 'localhost+1.pem');
  if (fs.existsSync(keyPath) && fs.existsSync(certPath)) {
    httpsOptions = {
      key: fs.readFileSync(keyPath),
      cert: fs.readFileSync(certPath)
    };
  }
}

// =============================================================================
// Security Configuration
// =============================================================================

// CORS whitelist - restrict origins in production
const CORS_WHITELIST = [
  'http://localhost:3000',
  'http://localhost:3847',
  'https://localhost:3847',
  'http://127.0.0.1:3000',
  'http://127.0.0.1:3847',
  'https://127.0.0.1:3847',
  'https://splice.app',
  'https://www.splice.app',
  'https://splice-api-production.up.railway.app',
  // Adobe CEP/UXP panels run from file:// or bolt://
  'file://',
  'bolt://'
];

const corsOptions = {
  origin: function (origin, callback) {
    // Allow requests with no origin (like mobile apps, Postman, or Adobe plugins)
    if (!origin) {
      return callback(null, true);
    }
    // Check if origin is in whitelist
    if (CORS_WHITELIST.some(allowed => origin.startsWith(allowed) || origin === allowed)) {
      return callback(null, true);
    }
    // In development, allow all origins with warning
    if (!isProduction) {
      console.warn(`[CORS] Non-whitelisted origin in dev: ${origin}`);
      return callback(null, true);
    }
    // In production, reject non-whitelisted origins
    console.error(`[CORS] Blocked request from: ${origin}`);
    return callback(new Error('Not allowed by CORS'));
  },
  credentials: true,
  methods: ['GET', 'POST', 'PUT', 'DELETE', 'OPTIONS'],
  allowedHeaders: ['Content-Type', 'Authorization', 'x-stripe-customer-id', 'stripe-signature']
};

app.use(cors(corsOptions));

// Security headers via helmet
app.use(helmet({
  contentSecurityPolicy: {
    directives: {
      defaultSrc: ["'self'"],
      scriptSrc: ["'self'"],
      styleSrc: ["'self'", "'unsafe-inline'"],
      imgSrc: ["'self'", 'data:', 'https:'],
      connectSrc: ["'self'", 'https://api.stripe.com', 'https://api.openai.com', 'https://api.replicate.com'],
      fontSrc: ["'self'"],
      objectSrc: ["'none'"],
      mediaSrc: ["'self'"],
      frameSrc: ["'none'"]
    }
  },
  hsts: {
    maxAge: 31536000,
    includeSubDomains: true,
    preload: true
  },
  referrerPolicy: { policy: 'strict-origin-when-cross-origin' },
  noSniff: true,
  xssFilter: true,
  hidePoweredBy: true
}));

// Helper to determine tier from price ID with logging
function getTierFromPriceId(priceId) {
  if (priceId === process.env.STRIPE_PRICE_STARTER) return 'starter';
  if (priceId === process.env.STRIPE_PRICE_PRO) return 'pro';
  if (priceId === process.env.STRIPE_PRICE_TEAM) return 'team';

  // Log unknown price ID for debugging
  console.warn(`[SPLICE] Unknown price ID: ${priceId} - defaulting to starter tier`);
  return 'starter';
}

// Stripe webhook needs raw body - must be before express.json()
app.post('/webhooks/stripe', express.raw({ type: 'application/json' }), async (req, res) => {
  const sig = req.headers['stripe-signature'];
  const webhookSecret = process.env.STRIPE_WEBHOOK_SECRET;

  let event;

  try {
    if (webhookSecret) {
      event = stripe.webhooks.constructEvent(req.body, sig, webhookSecret);
    } else if (isProduction) {
      // SECURITY: Reject unsigned webhooks in production
      console.error('[SPLICE] CRITICAL: STRIPE_WEBHOOK_SECRET not set in production');
      return res.status(500).json({ error: 'Webhook configuration error: secret not configured' });
    } else {
      // For local development testing only
      // req.body is a Buffer from express.raw(), convert to string for JSON.parse
      const bodyString = typeof req.body === 'string' ? req.body : req.body.toString('utf8');
      event = JSON.parse(bodyString);
      console.warn('[SPLICE] Warning: Processing webhook without signature verification (dev only)');
    }
  } catch (err) {
    console.error('[SPLICE] Webhook signature verification failed:', err.message);
    return res.status(400).json({ error: 'Webhook signature verification failed' });
  }

  console.log(`[SPLICE] Webhook received: ${event.type} (${event.id})`);

  // Idempotency check - skip if already processed
  if (await usageTracking.isEventProcessed(event.id)) {
    console.log(`[SPLICE] Event ${event.id} already processed, skipping`);
    return res.json({ received: true, skipped: true });
  }

  try {
    switch (event.type) {
      case 'customer.subscription.created':
      case 'customer.subscription.updated': {
        const subscription = event.data.object;
        const customerId = subscription.customer;

        // Validate customerId
        if (!customerId) {
          console.error('[SPLICE] Missing customer ID in subscription event');
          return res.status(400).json({ error: 'Missing customer ID' });
        }

        // Get tier from price ID
        const priceId = subscription.items?.data?.[0]?.price?.id;
        const tier = getTierFromPriceId(priceId);

        // Update user tier and reset hours
        await usageTracking.updateTier(customerId, tier);
        console.log(`[SPLICE] Updated customer ${customerId} to tier: ${tier}`);

        // Generate license key for new subscriptions with retry and delivery
        if (event.type === 'customer.subscription.created') {
          let licenseResult = null;
          let retryCount = 0;
          const maxRetries = 3;

          // Retry mechanism for license key generation
          while (retryCount < maxRetries) {
            licenseResult = await licenseService.generateLicenseKey(customerId);
            if (licenseResult.success) {
              break;
            }
            retryCount++;
            console.warn(`[SPLICE] License key generation attempt ${retryCount}/${maxRetries} failed: ${licenseResult.error}`);
            // Wait before retry (exponential backoff)
            if (retryCount < maxRetries) {
              await new Promise(resolve => setTimeout(resolve, 1000 * retryCount));
            }
          }

          if (licenseResult && licenseResult.success) {
            // SECURITY: Mask license key in logs
            console.log(`[SPLICE] Generated license key for ${maskSensitiveData(customerId)}: ${maskSensitiveData(licenseResult.key)}`);

            // Store license key in Stripe subscription metadata as backup
            try {
              await stripe.subscriptions.update(subscription.id, {
                metadata: {
                  license_key: licenseResult.key,
                  license_generated_at: new Date().toISOString()
                }
              });
              console.log(`[SPLICE] Stored license key in Stripe metadata for subscription ${subscription.id}`);
            } catch (metaErr) {
              console.error(`[SPLICE] Failed to store license key in Stripe metadata:`, metaErr.message);
            }

            // Get customer email and send license key
            try {
              const customer = await stripe.customers.retrieve(customerId);
              if (customer.email) {
                // SECURITY: Mask sensitive data in logs
                console.log(`[SPLICE] License key ready for delivery to ${maskSensitiveData(customer.email)}: ${maskSensitiveData(licenseResult.key)}`);
                // TODO: Integrate with email service (SendGrid, SES, etc.)
                // await sendLicenseKeyEmail(customer.email, licenseResult.key, tier);

                // Store email in database for reference
                await usageTracking.updateTier(customerId, tier, customer.email);
              } else {
                console.warn(`[SPLICE] No email found for customer ${customerId}`);
              }
            } catch (emailErr) {
              console.error(`[SPLICE] Error getting customer email:`, emailErr.message);
            }
          } else {
            // CRITICAL: License generation failed - return 500 to trigger Stripe retry
            const errorMsg = `Failed to generate license key after ${maxRetries} attempts: ${licenseResult?.error || 'Unknown error'}`;
            console.error(`[SPLICE] ${errorMsg}`);
            return res.status(500).json({ error: errorMsg });
          }
        }
        break;
      }

      case 'customer.subscription.deleted': {
        const subscription = event.data.object;
        const customerId = subscription.customer;

        // Validate customerId
        if (!customerId) {
          console.error('[SPLICE] Missing customer ID in subscription.deleted event');
          return res.status(400).json({ error: 'Missing customer ID' });
        }

        // Downgrade to cancelled (0 hours)
        await usageTracking.updateTier(customerId, 'cancelled');
        console.log(`[SPLICE] Subscription cancelled for customer ${customerId}`);
        break;
      }

      case 'invoice.payment_succeeded': {
        const invoice = event.data.object;
        const customerId = invoice.customer;
        const subscriptionId = invoice.subscription;

        // Validate customerId
        if (!customerId) {
          console.error('[SPLICE] Missing customer ID in invoice event');
          return res.status(400).json({ error: 'Missing customer ID' });
        }

        // Reset hours on successful payment (new billing period)
        if (subscriptionId) {
          const subscription = await stripe.subscriptions.retrieve(subscriptionId);
          const priceId = subscription.items?.data?.[0]?.price?.id;
          const tier = getTierFromPriceId(priceId);

          await usageTracking.resetHours(customerId, tier);
          console.log(`[SPLICE] Reset hours for customer ${customerId} (tier: ${tier})`);
        }
        break;
      }

      default:
        console.log(`[SPLICE] Unhandled event type: ${event.type}`);
    }

    // Record event as processed (idempotency)
    await usageTracking.recordWebhookEvent(event.id, event.type);

    res.json({ received: true });
  } catch (err) {
    console.error('[SPLICE] Webhook handler error:', err);
    res.status(500).json({ error: err.message });
  }
});

app.use(express.json());

// =============================================================================
// Routes
// =============================================================================

/**
 * GET / - API information
 */
app.get('/', (req, res) => {
  res.json({
    service: 'splice-backend',
    version: '0.3.0',
    endpoints: {
      'GET /': 'This info',
      'GET /health': 'Health check',
      'GET /ffprobe-check': 'Check if FFprobe is installed',
      'GET /replicate-check': 'Check if Replicate API is configured',
      'POST /analyze': 'Analyze WAV file { wavPath }',
      'POST /silences': 'Detect silences via Whisper gaps { wavPath, threshold: 0.5 }',
      'POST /silences-audio': 'Detect silences via FFprobe { wavPath, threshold: -30, minDuration: 0.5, padding: 0.1 }',
      'POST /silences-rms': 'Detect silences via RMS analysis { wavPath, threshold: -30, minSilenceLength: 0.5, paddingStart: 0.1, paddingEnd: 0.05, autoThreshold: false, sensitivity: 50 }',
      'POST /profanity': 'Detect profanity in transcript { wavPath, language: "en", customBlocklist: [], customAllowlist: [] }',
      'GET /profanity/languages': 'Get supported languages for profanity detection',
      'GET /profanity/bleeps': 'Get available bleep sounds',
      'POST /repetitions': 'Detect phrase repetitions and stutters { wavPath, phraseSize: 5, tolerance: 0.7, useOpenAI: false }',
      'POST /fillers': 'Detect filler words (um, uh, like, etc.) { wavPath, customFillers: [] }',
      'POST /stutters': 'Detect single-word stutters only { wavPath, minRepeats: 2 }',
      'POST /export/captions': 'Export transcript to caption format { wavPath, format: srt|vtt|txt|json, outputPath? }',
      'GET /export/formats': 'Get supported caption export formats',
      'POST /multitrack': 'Analyze multiple audio tracks for multicam { audioPaths: [], speakerNames: [], videoTrackMapping: {} }',
      'POST /multitrack/auto-balance': 'Auto-balance speaker screentime { audioPaths: [], speakerNames: [] }',
      'POST /multitrack/advanced-balance': 'Advanced GA-optimized balancing { audioPaths: [], maxConsecutiveSeconds: 30, momentumFactor: 0.7 }',
      'POST /process-xml': 'Process FCP XML { xmlPath, silences, removeGaps: true }',
      'POST /cut-list': 'Generate JSON cut list for DOM building (v3.5) { sourceName, sourcePath, duration, silences, takes?, settings? }',
      'POST /cut-list/takes': 'Generate cut list keeping only takes { sourceName, sourcePath, duration, takes, settings? }',
      'POST /zoom': 'Generate zoom points from transcript { transcript, settings: { frequency, preset, placement } }',
      'GET /zoom/presets': 'Get available zoom presets and frequencies',
      'POST /chapters': 'Detect chapters in transcript using AI { transcript, settings: { maxChapters, minChapterLength } }',
      'POST /chapters/fallback': 'Detect chapters without AI (gap-based) { transcript, settings }',
      'POST /isolate-vocals': 'Isolate vocals from audio { audioPath }',
      'POST /batch/silences': 'Batch process multiple files for silence detection { files: [], options: {} }',
      'GET /batch/status/:jobId': 'Get batch job status',
      'GET /batch/results/:jobId': 'Get full batch job results',
      'GET /batch/jobs': 'List all batch jobs',
      'DELETE /batch/:jobId': 'Delete a batch job',
      'GET /credits': 'Get user credit balance (requires x-stripe-customer-id header)',
      'GET /usage-history': 'Get usage history (requires x-stripe-customer-id header)',
      'POST /webhooks/stripe': 'Stripe webhook endpoint',
      'GET /referral/code': 'Get or create referral code for user',
      'POST /referral/validate': 'Validate a referral code',
      'POST /referral/apply': 'Apply referral code at signup',
      'GET /referral/stats': 'Get referral statistics for user',
      'POST /license/activate': 'Activate license key { key: "SPLICE-XXXX-XXXX-XXXX" }',
      'GET /license/key': 'Get license key for customer (requires x-stripe-customer-id)',
      'POST /license/resend': 'Resend license key to customer email { customerId? }'
    }
  });
});

/**
 * GET /health - Health check
 */
app.get('/health', (req, res) => {
  res.json({ status: 'ok', service: 'splice-backend' });
});

/**
 * POST /analyze - Main analysis endpoint
 *
 * Pipeline:
 * 1. Validate input (wavPath)
 * 2. Slice 4: Transcribe audio with Whisper
 * 3. Slice 5: Detect takes with GPT-4o-mini
 * 4. Return combined results
 */
app.post('/analyze', requireCredits({ endpoint: 'analyze' }), async (req, res) => {
  const { wavPath } = req.body;

  // Validate input
  if (!wavPath) {
    return res.status(400).json({ error: 'wavPath is required' });
  }

  if (!(await fileExists(wavPath))) {
    return res.status(404).json({ error: `File not found: ${wavPath}` });
  }

  console.log(`[SPLICE] Analyzing: ${wavPath}`);

  try {
    // Slice 4 - GPT-4o-mini transcription
    const transcript = await transcribeAudio(wavPath);

    // Slice 5 - GPT-4o-mini take detection
    const takes = await detectTakes(transcript);

    // Deduct usage based on audio duration
    const audioDuration = transcript.duration || 0;
    let balance = null;
    if (audioDuration > 0 && req.deductUsage) {
      balance = await req.deductUsage(audioDuration);
    }

    res.json({
      success: true,
      wavPath,
      transcript,
      takes,
      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
    });
  } catch (err) {
    console.error('[SPLICE] Error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /transcribe/word-level - Get frame-aligned word-level timestamps
 *
 * Returns word-level timestamps with optional frame alignment for precise editing.
 * Uses the unified transcription cache (same API call as /analyze).
 *
 * Body:
 * - wavPath: Path to audio file
 * - frameRate: Optional frame rate for alignment (23.976, 24, 29.97, 30, 60)
 *
 * Returns:
 * - words: Array of {word, start, end, startAligned?, endAligned?}
 * - text: Full transcript text
 * - duration: Audio duration in seconds
 */
app.post('/transcribe/word-level', requireCredits({ endpoint: 'transcribe-word-level' }), async (req, res) => {
  const { wavPath, frameRate = 0 } = req.body;

  if (!wavPath) {
    return res.status(400).json({ error: 'wavPath is required' });
  }

  if (!(await fileExists(wavPath))) {
    return res.status(404).json({ error: `File not found: ${wavPath}` });
  }

  console.log(`[SPLICE] Word-level transcription: ${wavPath} (frameRate: ${frameRate || 'none'})`);

  try {
    // Use unified transcription (gets both segments and words in one API call)
    const full = await transcribeFull(wavPath);

    // Apply frame alignment if requested
    let words = full.words || [];
    const hasFrameAlignment = frameRate > 0;

    if (hasFrameAlignment) {
      words = words.map(w => ({
        word: w.word,
        start: w.start,
        end: w.end,
        // Add frame-aligned versions
        startAligned: parseFloat(alignToFrameFloor(w.start, frameRate).toFixed(6)),
        endAligned: parseFloat(alignToFrameCeil(w.end, frameRate).toFixed(6))
      }));
      console.log(`[SPLICE] Applied ${frameRate}fps frame alignment to ${words.length} words`);
    }

    // Deduct usage based on audio duration
    const audioDuration = full.duration || 0;
    let balance = null;
    if (audioDuration > 0 && req.deductUsage) {
      balance = await req.deductUsage(audioDuration);
    }

    res.json({
      success: true,
      wavPath,
      text: full.text,
      words,
      wordCount: words.length,
      duration: full.duration,
      language: full.language,
      frameAligned: hasFrameAlignment,
      frameRate: hasFrameAlignment ? frameRate : null,
      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
    });
  } catch (err) {
    console.error('[SPLICE] Word-level transcription error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /silences - Detect silent gaps in audio
 *
 * Pipeline:
 * 1. Transcribe audio with Whisper (cached)
 * 2. Analyze gaps between segments
 * 3. Return silence regions
 */
app.post('/silences', requireCredits({ endpoint: 'silences' }), async (req, res) => {
  const { wavPath, threshold = 0.5 } = req.body;

  if (!wavPath) {
    return res.status(400).json({ error: 'wavPath is required' });
  }

  if (!(await fileExists(wavPath))) {
    return res.status(404).json({ error: `File not found: ${wavPath}` });
  }

  console.log(`[SPLICE] Detecting silences: ${wavPath} (threshold: ${threshold}s)`);

  try {
    const transcript = await transcribeAudio(wavPath);
    const silences = detectSilences(transcript.segments, threshold);

    // Deduct usage based on audio duration
    const audioDuration = transcript.duration || 0;
    let balance = null;
    if (audioDuration > 0 && req.deductUsage) {
      balance = await req.deductUsage(audioDuration);
    }

    res.json({
      success: true,
      wavPath,
      threshold,
      silences,
      count: silences.length,
      totalSilenceDuration: silences.reduce((sum, s) => sum + s.duration, 0).toFixed(2),
      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
    });
  } catch (err) {
    console.error('[SPLICE] Silence detection error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /silences-audio - Detect silences using FFprobe audio analysis
 *
 * Uses actual audio levels (dB threshold) instead of transcript gaps.
 * More accurate for detecting silence vs background noise.
 */
app.post('/silences-audio', requireCredits({ endpoint: 'silences-audio' }), async (req, res) => {
  const {
    wavPath,
    threshold = -30,
    minDuration = 0.5,
    padding = 0.1
  } = req.body;

  if (!wavPath) {
    return res.status(400).json({ error: 'wavPath is required' });
  }

  if (!(await fileExists(wavPath))) {
    return res.status(404).json({ error: `File not found: ${wavPath}` });
  }

  // Check FFprobe availability
  const ffprobeAvailable = await isFFprobeInstalled();
  if (!ffprobeAvailable) {
    return res.status(500).json({
      error: 'FFprobe not installed. Run: brew install ffmpeg'
    });
  }

  console.log(`[SPLICE] FFprobe silence detection: ${wavPath} (threshold: ${threshold}dB, min: ${minDuration}s)`);

  try {
    const silences = await detectAudioSilences(wavPath, {
      threshold,
      minDuration,
      padding
    });

    const totalDuration = silences.reduce((sum, s) => sum + s.duration, 0);

    // Deduct usage based on audio duration
    let balance = null;
    try {
      const audioDuration = await getAudioDuration(wavPath);
      if (audioDuration > 0 && req.deductUsage) {
        balance = await req.deductUsage(audioDuration);
      }
    } catch (durErr) {
      console.warn('[SPLICE] Could not get audio duration for billing:', durErr.message);
    }

    res.json({
      success: true,
      wavPath,
      threshold,
      minDuration,
      padding,
      silences,
      count: silences.length,
      totalSilenceDuration: totalDuration.toFixed(2),
      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
    });
  } catch (err) {
    console.error('[SPLICE] FFprobe silence detection error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /silences-rms - Detect silences using RMS audio analysis
 *
 * Advanced silence detection with:
 * - RMS (Root Mean Square) audio level analysis
 * - Auto-threshold detection from audio histogram
 * - Configurable padding (before/after cuts)
 * - Sensitivity slider mapping (0-100)
 *
 * Options:
 * - threshold: dBFS threshold (-60 to -20, default: -30)
 * - minSilenceLength: Minimum silence duration in seconds (default: 0.5)
 * - seekStep: Analysis window step in seconds (default: 0.05)
 * - paddingStart: Buffer before silence in seconds (default: 0.1)
 * - paddingEnd: Buffer after silence in seconds (default: 0.05)
 * - autoThreshold: Auto-detect optimal threshold (default: false)
 * - sensitivity: UI sensitivity 0-100 (overrides other params if provided)
 */
app.post('/silences-rms', requireCredits({ endpoint: 'silences-rms' }), async (req, res) => {
  const { wavPath, sensitivity, ...manualOptions } = req.body;

  if (!wavPath) {
    return res.status(400).json({ error: 'wavPath is required' });
  }

  if (!(await fileExists(wavPath))) {
    return res.status(404).json({ error: `File not found: ${wavPath}` });
  }

  // Validate file size to prevent OOM
  const sizeCheck = await validateFileSize(wavPath);
  if (!sizeCheck.valid) {
    return res.status(413).json({ error: sizeCheck.error });
  }

  // Check FFprobe availability (needed for audio extraction)
  const ffprobeAvailable = await isFFprobeInstalled();
  if (!ffprobeAvailable) {
    return res.status(500).json({
      error: 'FFprobe not installed. Run: brew install ffmpeg'
    });
  }

  // Build options - use sensitivity if provided, otherwise use manual options
  let options = {};
  if (typeof sensitivity === 'number') {
    options = sensitivityToParams(sensitivity);
    console.log(`[SPLICE] RMS detection with sensitivity ${sensitivity}`);
  } else {
    options = {
      threshold: manualOptions.threshold ?? -30,
      minSilenceLength: manualOptions.minSilenceLength ?? 0.5,
      seekStep: manualOptions.seekStep ?? 0.05,
      paddingStart: manualOptions.paddingStart ?? 0.1,
      paddingEnd: manualOptions.paddingEnd ?? 0.05,
      autoThreshold: manualOptions.autoThreshold ?? false,
      mergeDistance: manualOptions.mergeDistance ?? 0.2
    };
  }

  console.log(`[SPLICE] RMS silence detection: ${wavPath}`);

  try {
    const result = await detectSilencesRMS(wavPath, options);

    // Deduct usage based on audio duration
    const audioDuration = result.metadata?.audioDuration || 0;
    let balance = null;
    if (audioDuration > 0 && req.deductUsage) {
      balance = await req.deductUsage(audioDuration);
    }

    res.json({
      success: true,
      wavPath,
      ...result,
      count: result.silences.length,
      totalSilenceDuration: result.metadata.totalSilenceDuration.toFixed(2),
      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
    });
  } catch (err) {
    console.error('[SPLICE] RMS silence detection error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /waveform - Get waveform data for visualization
 *
 * Extracts RMS waveform data from audio file for canvas visualization.
 * Returns normalized amplitude values (0-1) for drawing waveform display.
 *
 * Options:
 * - wavPath: Path to audio file (required)
 * - targetPoints: Number of data points to return (default: 400)
 * - windowMs: Window size in milliseconds for RMS calculation (default: 50)
 *
 * Response:
 * - waveform: Array of normalized RMS values (0-1)
 * - duration: Audio duration in seconds
 * - pointCount: Number of points in waveform array
 * - sampleRate: Audio sample rate
 */
app.post('/waveform', requireCredits({ endpoint: 'waveform' }), async (req, res) => {
  const { wavPath, targetPoints = 400, windowMs = 50 } = req.body;

  if (!wavPath) {
    return res.status(400).json({ error: 'wavPath is required' });
  }

  if (!(await fileExists(wavPath))) {
    return res.status(404).json({ error: `File not found: ${wavPath}` });
  }

  // Validate file size to prevent OOM
  const sizeCheck = await validateFileSize(wavPath);
  if (!sizeCheck.valid) {
    return res.status(413).json({ error: sizeCheck.error });
  }

  console.log(`[SPLICE] Waveform extraction: ${wavPath} (${targetPoints} points)`);

  try {
    const result = await getWaveformData(wavPath, { targetPoints, windowMs });

    res.json({
      success: true,
      wavPath,
      ...result
    });
  } catch (err) {
    console.error('[SPLICE] Waveform extraction error:', err);
    res.status(500).json({ error: err.message });
  }
});

// =============================================================================
// Profanity Detection Routes
// =============================================================================

/**
 * POST /profanity - Detect profanity in audio/transcript
 *
 * Transcribes audio (if needed) and detects profanity words.
 * Returns word-level and segment-level results for muting/bleeping.
 *
 * Options:
 * - wavPath: Path to audio file (required)
 * - transcript: Pre-existing transcript (optional, skips transcription)
 * - language: Language code (en, es, fr, de) - default: en
 * - customBlocklist: Array or comma-separated string of additional words to censor
 * - customAllowlist: Array or comma-separated string of words to allow
 * - frameRate: Frame rate for boundary alignment (default: 30)
 */
app.post('/profanity', requireCredits({ endpoint: 'profanity' }), async (req, res) => {
  const {
    wavPath,
    transcript: providedTranscript,
    language = 'en',
    customBlocklist = [],
    customAllowlist = [],
    frameRate = 30
  } = req.body;

  if (!wavPath && !providedTranscript) {
    return res.status(400).json({ error: 'wavPath or transcript is required' });
  }

  if (wavPath && !(await fileExists(wavPath))) {
    return res.status(404).json({ error: `File not found: ${wavPath}` });
  }

  console.log(`[SPLICE] Profanity detection: ${wavPath || 'provided transcript'} (language: ${language})`);

  try {
    // Get or create transcript with word-level timestamps
    let transcript = providedTranscript;
    if (!transcript && wavPath) {
      // Use transcribeWithWords for word-level timestamps required by profanity detection
      transcript = await transcribeWithWords(wavPath);
    }

    // Validate transcript has words
    if (!transcript || !transcript.words || transcript.words.length === 0) {
      return res.status(400).json({
        error: 'Transcript must contain word-level timing data',
        hint: 'Ensure transcription returns words array with start/end times'
      });
    }

    // Parse custom lists
    const blocklist = parseWordList(customBlocklist);
    const allowlist = parseWordList(customAllowlist);

    // Detect profanity
    const result = detectProfanity(transcript, {
      language,
      customBlocklist: blocklist,
      customAllowlist: allowlist,
      frameRate
    });

    // Deduct usage based on audio duration
    const audioDuration = transcript.duration || 0;
    let balance = null;
    if (audioDuration > 0 && req.deductUsage) {
      balance = await req.deductUsage(audioDuration);
    }

    res.json({
      success: true,
      wavPath,
      ...result,
      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
    });
  } catch (err) {
    console.error('[SPLICE] Profanity detection error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * GET /profanity/languages - Get supported languages
 * PERF-FIX: Uses cached response with ETag for conditional GET
 */
app.get('/profanity/languages', (req, res) => {
  sendCachedResponse(req, res, 'profanityLanguages');
});

/**
 * GET /profanity/bleeps - Get available bleep sounds
 * PERF-FIX: Uses cached response with ETag for conditional GET
 */
app.get('/profanity/bleeps', (req, res) => {
  sendCachedResponse(req, res, 'profanityBleeps');
});

/**
 * POST /profanity/generate-bleeps - Generate bleep audio files for profanity segments
 *
 * Creates WAV bleep files for each profanity segment that can be inserted into the timeline.
 *
 * Body:
 * - segments: Array of {start, end} profanity segments (required)
 * - bleepType: Type of bleep sound ('standard', 'tv', 'radio', 'duck', 'mute') (default: 'standard')
 * - volume: Volume level 0-1 (default: 0.5)
 *
 * Returns:
 * - bleeps: Array of generated bleep file info with paths
 */
app.post('/profanity/generate-bleeps', requireCredits({ endpoint: 'profanity-bleeps' }), async (req, res) => {
  const { segments, bleepType = 'standard', volume = 0.5 } = req.body;

  if (!segments || !Array.isArray(segments) || segments.length === 0) {
    return res.status(400).json({ error: 'segments array is required and must not be empty' });
  }

  // Validate segments have start/end
  for (let i = 0; i < segments.length; i++) {
    if (typeof segments[i].start !== 'number' || typeof segments[i].end !== 'number') {
      return res.status(400).json({ error: `Segment ${i} must have numeric start and end properties` });
    }
  }

  console.log(`[SPLICE] Generating ${segments.length} bleep audio files (type: ${bleepType})`);

  try {
    const bleeps = await generateBleepsForSegments(segments, {
      bleepType,
      volume,
      outputDir: '/tmp'
    });

    // Calculate total duration for usage tracking
    const totalDuration = segments.reduce((sum, seg) => sum + (seg.end - seg.start), 0);
    let balance = null;
    if (totalDuration > 0 && req.deductUsage) {
      balance = await req.deductUsage(totalDuration);
    }

    res.json({
      success: true,
      bleepCount: bleeps.length,
      bleepType,
      bleeps,
      totalDuration,
      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
    });
  } catch (err) {
    console.error('[SPLICE] Error generating bleeps:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * GET /profanity/list/:language - Get default profanity list for a language
 */
app.get('/profanity/list/:language', (req, res) => {
  const { language } = req.params;
  const list = getProfanityList(language);

  res.json({
    success: true,
    language,
    wordCount: list.length,
    // Return first 50 words as sample (full list is large)
    sample: list.slice(0, 50),
    note: 'Full list available but truncated for response size'
  });
});

// =============================================================================
// Repetition/Stutter Detection Routes
// =============================================================================

/**
 * POST /repetitions - Detect phrase repetitions and stutters
 *
 * Analyzes transcript for repeated phrases and stutters.
 * Returns segments that can be removed to clean up the edit.
 *
 * Options:
 * - wavPath: Path to audio file (required unless transcript provided)
 * - transcript: Pre-existing transcript (optional)
 * - phraseSize: Words per comparison window (default: 5)
 * - tolerance: Similarity threshold 0-1 (default: 0.7)
 * - searchRadius: Words to search ahead (default: 100)
 * - useOpenAI: Use OpenAI for boundary refinement (default: false)
 * - includeStutters: Also detect single-word stutters (default: true)
 */
app.post('/repetitions', requireCredits({ endpoint: 'repetitions' }), async (req, res) => {
  const {
    wavPath,
    transcript: providedTranscript,
    phraseSize = 5,
    tolerance = 0.7,
    searchRadius = 100,
    useOpenAI = false,
    includeStutters = true
  } = req.body;

  if (!wavPath && !providedTranscript) {
    return res.status(400).json({ error: 'wavPath or transcript is required' });
  }

  if (wavPath && !(await fileExists(wavPath))) {
    return res.status(404).json({ error: `File not found: ${wavPath}` });
  }

  console.log(`[SPLICE] Repetition detection: ${wavPath || 'provided transcript'}`);

  try {
    // Get or create transcript with word-level timestamps
    let transcript = providedTranscript;
    if (!transcript && wavPath) {
      // Use transcribeWithWords for word-level timestamps required by repetition detection
      transcript = await transcribeWithWords(wavPath);
    }

    // Validate transcript has words
    if (!transcript || !transcript.words || transcript.words.length === 0) {
      return res.status(400).json({
        error: 'Transcript must contain word-level timing data'
      });
    }

    // Detect all repetitions (phrases + stutters)
    const result = await detectAllRepetitions(transcript, {
      phraseSize,
      tolerance,
      searchRadius,
      useOpenAI
    });

    // Optionally filter out stutters
    if (!includeStutters) {
      result.stutters = [];
      result.removalSegments = result.removalSegments.filter(s => s.type !== 'stutter');
    }

    // Deduct usage based on audio duration
    const audioDuration = transcript.duration || 0;
    let balance = null;
    if (audioDuration > 0 && req.deductUsage) {
      balance = await req.deductUsage(audioDuration);
    }

    res.json({
      success: true,
      wavPath,
      ...result,
      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
    });
  } catch (err) {
    console.error('[SPLICE] Repetition detection error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /fillers - Detect filler words (um, uh, like, etc.)
 *
 * Transcribes audio and identifies filler words with timestamps.
 * Returns segments that can be cut or reviewed for removal.
 * Supports frame alignment for precise video editing.
 *
 * Options:
 * - wavPath: Path to audio file (required unless transcript provided)
 * - transcript: Pre-existing transcript with word-level timing (optional)
 * - customFillers: Additional filler words to detect (optional)
 * - frameRate: Frame rate for alignment (0 = no alignment, 24/30/60 etc.)
 * - paddingMs: Padding in ms around filler words for cleaner cuts (default 50)
 */
app.post('/fillers', requireCredits({ endpoint: 'fillers' }), async (req, res) => {
  const {
    wavPath,
    transcript: providedTranscript,
    customFillers = [],
    frameRate = 0, // Optional: align timestamps to frames
    paddingMs = 50 // Padding around filler words for cleaner cuts
  } = req.body;

  if (!wavPath && !providedTranscript) {
    return res.status(400).json({ error: 'wavPath or transcript is required' });
  }

  if (wavPath && !(await fileExists(wavPath))) {
    return res.status(404).json({ error: `File not found: ${wavPath}` });
  }

  console.log(`[SPLICE] Filler word detection: ${wavPath || 'provided transcript'}`);

  try {
    // Get or create transcript with word-level timestamps
    let transcript = providedTranscript;
    if (!transcript && wavPath) {
      transcript = await transcribeWithWords(wavPath);
    }

    // Validate transcript has words
    if (!transcript || !transcript.words || transcript.words.length === 0) {
      return res.status(400).json({
        error: 'Transcript must contain word-level timing data'
      });
    }

    // Default filler words (common in English speech)
    const defaultFillers = [
      'um', 'uh', 'ah', 'er', 'eh',           // Hesitation sounds
      'like', 'so', 'well', 'right',           // Discourse markers
      'you know', 'i mean', 'basically',       // Filler phrases
      'actually', 'literally', 'honestly',     // Overused qualifiers
      'kind of', 'sort of', 'you see'          // Hedging phrases
    ];

    // Combine default + custom fillers (lowercase for matching)
    const fillerSet = new Set([
      ...defaultFillers,
      ...customFillers.map(f => f.toLowerCase().trim())
    ]);

    // Detect filler words
    const fillers = [];
    const words = transcript.words;

    for (let i = 0; i < words.length; i++) {
      const word = words[i];
      const normalizedWord = word.word.toLowerCase().replace(/[.,!?;:'"]/g, '').trim();

      // Check single-word fillers
      if (fillerSet.has(normalizedWord)) {
        fillers.push({
          word: word.word,
          normalizedWord,
          start: word.start,
          end: word.end,
          duration: word.end - word.start,
          index: i,
          type: 'filler'
        });
        continue;
      }

      // Check two-word phrases (e.g., "you know", "kind of")
      if (i < words.length - 1) {
        const nextWord = words[i + 1];
        const twoWordPhrase = `${normalizedWord} ${nextWord.word.toLowerCase().replace(/[.,!?;:'"]/g, '').trim()}`;
        if (fillerSet.has(twoWordPhrase)) {
          fillers.push({
            word: `${word.word} ${nextWord.word}`,
            normalizedWord: twoWordPhrase,
            start: word.start,
            end: nextWord.end,
            duration: nextWord.end - word.start,
            index: i,
            type: 'filler_phrase'
          });
          // Skip next word since it's part of this phrase
          i++;
        }
      }
    }

    // Apply frame alignment if requested
    const hasFrameAlignment = frameRate > 0;
    const paddingSec = paddingMs / 1000;

    // Enhance fillers with aligned timestamps and padding
    const enhancedFillers = fillers.map(f => {
      // Add padding for cleaner cuts
      const paddedStart = Math.max(0, f.start - paddingSec);
      const paddedEnd = f.end + paddingSec;

      // Apply frame alignment if requested
      let startAligned = paddedStart;
      let endAligned = paddedEnd;
      if (hasFrameAlignment) {
        startAligned = alignToFrameFloor(paddedStart, frameRate);
        endAligned = alignToFrameCeil(paddedEnd, frameRate);
      }

      return {
        ...f,
        paddedStart,
        paddedEnd,
        startAligned: parseFloat(startAligned.toFixed(4)),
        endAligned: parseFloat(endAligned.toFixed(4)),
        durationAligned: parseFloat((endAligned - startAligned).toFixed(4))
      };
    });

    // Calculate total filler time
    const totalFillerDuration = fillers.reduce((sum, f) => sum + f.duration, 0);
    const audioDuration = transcript.duration || (words.length > 0 ? words[words.length - 1].end : 0);
    const fillerPercentage = audioDuration > 0 ? (totalFillerDuration / audioDuration) * 100 : 0;

    // Deduct usage based on audio duration
    let balance = null;
    if (audioDuration > 0 && req.deductUsage) {
      balance = await req.deductUsage(audioDuration);
    }

    res.json({
      success: true,
      wavPath,
      fillers: enhancedFillers,
      metadata: {
        totalWords: words.length,
        fillerCount: enhancedFillers.length,
        totalFillerDuration: parseFloat(totalFillerDuration.toFixed(3)),
        audioDuration: parseFloat(audioDuration.toFixed(3)),
        fillerPercentage: parseFloat(fillerPercentage.toFixed(2)),
        fillersPerMinute: audioDuration > 0 ? parseFloat((enhancedFillers.length / (audioDuration / 60)).toFixed(2)) : 0,
        frameRate: hasFrameAlignment ? frameRate : null,
        frameAligned: hasFrameAlignment,
        paddingMs
      },
      removalSegments: enhancedFillers.map(f => ({
        start: f.startAligned,
        end: f.endAligned,
        duration: f.durationAligned,
        reason: `Filler: "${f.word}"`,
        type: f.type
      })),
      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
    });
  } catch (err) {
    console.error('[SPLICE] Filler detection error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /stutters - Detect single-word stutters only
 *
 * Focused detection for word-level stutters (e.g., "I I I think").
 * Faster than full repetition detection.
 */
app.post('/stutters', requireCredits({ endpoint: 'stutters' }), async (req, res) => {
  const {
    wavPath,
    transcript: providedTranscript,
    options = {},
    // Support both top-level and nested options for flexibility
    minRepeats = options.minRepeats ?? 2,
    maxGapMs = options.maxGapMs ?? 500,
    ignoreFillers = options.ignoreFillers ?? true,
    minWordLength = options.minWordLength ?? 1
  } = req.body;

  if (!wavPath && !providedTranscript) {
    return res.status(400).json({ error: 'wavPath or transcript is required' });
  }

  if (wavPath && !(await fileExists(wavPath))) {
    return res.status(404).json({ error: `File not found: ${wavPath}` });
  }

  console.log(`[SPLICE] Stutter detection: ${wavPath || 'provided transcript'}`);

  try {
    // Get or create transcript with word-level timestamps
    let transcript = providedTranscript;
    if (!transcript && wavPath) {
      // Use transcribeWithWords for word-level timestamps required by stutter detection
      transcript = await transcribeWithWords(wavPath);
    }

    // Validate transcript exists and has words array
    if (!transcript || !transcript.words) {
      return res.status(400).json({
        error: 'Transcript must contain word-level timing data'
      });
    }

    // Empty transcript returns empty result (not an error)
    if (transcript.words.length === 0) {
      return res.json({
        success: true,
        stutters: [],
        metadata: { type: 'stutters', totalWords: 0, stutterCount: 0, totalRepeatedWords: 0 }
      });
    }

    // Detect stutters only
    const result = detectStutters(transcript, {
      minRepeats,
      maxGapMs,
      ignoreFillers,
      minWordLength
    });

    // Deduct usage based on audio duration
    const audioDuration = transcript.duration || 0;
    let balance = null;
    if (audioDuration > 0 && req.deductUsage) {
      balance = await req.deductUsage(audioDuration);
    }

    res.json({
      success: true,
      wavPath,
      ...result,
      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
    });
  } catch (err) {
    console.error('[SPLICE] Stutter detection error:', err);
    res.status(500).json({ error: err.message });
  }
});

// =============================================================================
// Caption Export Routes
// =============================================================================

/**
 * POST /export/captions - Export transcript to caption format (SRT, VTT, etc.)
 *
 * Converts a transcript to the specified caption format.
 * Can optionally save to file.
 *
 * Options:
 * - wavPath: Path to audio file (to transcribe first)
 * - transcript: Pre-existing transcript with word-level timing
 * - format: Export format (srt, vtt, txt, json) - default: srt
 * - outputPath: Optional file path to save to
 * - maxWordsPerCaption: Max words per caption (default: 8)
 * - maxDuration: Max duration per caption in seconds (default: 5)
 */
app.post('/export/captions', requireCredits({ endpoint: 'export-captions' }), async (req, res) => {
  const {
    wavPath,
    transcript: providedTranscript,
    format = 'srt',
    outputPath = null,
    maxWordsPerCaption = 8,
    maxDuration = 5
  } = req.body;

  if (!wavPath && !providedTranscript) {
    return res.status(400).json({ error: 'wavPath or transcript is required' });
  }

  if (wavPath && !(await fileExists(wavPath))) {
    return res.status(404).json({ error: `File not found: ${wavPath}` });
  }

  console.log(`[SPLICE] Caption export: ${wavPath || 'provided transcript'} -> ${format}`);

  try {
    // Get or create transcript with word-level timestamps
    let transcript = providedTranscript;
    if (!transcript && wavPath) {
      transcript = await transcribeWithWords(wavPath);
    }

    const exportOptions = { maxWordsPerCaption, maxDuration };

    // Generate caption content based on format
    let content;
    let mimeType;

    switch (format.toLowerCase()) {
      case 'srt':
        content = toSRT(transcript, exportOptions);
        mimeType = 'application/x-subrip';
        break;
      case 'vtt':
      case 'webvtt':
        content = toVTT(transcript, exportOptions);
        mimeType = 'text/vtt';
        break;
      case 'txt':
      case 'text':
        content = toPlainText(transcript, { ...exportOptions, includeTimestamps: true });
        mimeType = 'text/plain';
        break;
      case 'json':
        content = toJSON(transcript);
        mimeType = 'application/json';
        break;
      default:
        return res.status(400).json({
          error: `Unsupported format: ${format}`,
          supportedFormats: getSupportedFormats()
        });
    }

    // Save to file if outputPath provided
    let savedPath = null;
    if (outputPath) {
      const result = await exportToFile(transcript, outputPath, format, exportOptions);
      savedPath = result.path;
      console.log(`[SPLICE] Saved captions to: ${savedPath}`);
    }

    // Deduct usage based on audio duration
    const audioDuration = transcript.duration || 0;
    let balance = null;
    if (audioDuration > 0 && req.deductUsage) {
      balance = await req.deductUsage(audioDuration);
    }

    res.json({
      success: true,
      format,
      content,
      mimeType,
      savedPath,
      wordCount: transcript.words?.length || 0,
      duration: transcript.duration || 0,
      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
    });
  } catch (err) {
    console.error('[SPLICE] Caption export error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * GET /export/formats - Get supported export formats
 * PERF-FIX: Uses cached response with ETag for conditional GET
 */
app.get('/export/formats', (req, res) => {
  sendCachedResponse(req, res, 'exportFormats');
});

// =============================================================================
// Multitrack/Multicam Analysis Routes
// =============================================================================

/**
 * POST /multitrack - Analyze multiple audio tracks for multicam editing
 *
 * Analyzes audio levels across multiple tracks to determine optimal
 * video angle selection based on who is speaking.
 *
 * Options:
 * - audioPaths: Array of paths to audio files (one per speaker) - required
 * - speakerNames: Array of speaker names (optional)
 * - videoTrackMapping: Object mapping speaker index to video track { 0: 0, 1: 1 }
 * - minShotDuration: Minimum seconds before next cut (default: 2.0)
 * - switchingFrequency: How often to allow cuts 0-100 (default: 50)
 * - wideShotEnabled: Enable wide shot detection (default: true)
 * - wideShotPercentage: Target % of wide shots (default: 20)
 * - wideShotTracks: Video track indices for wide shots
 * - cutawayEnabled: Enable cutaway insertion (default: false)
 * - cutawayTracks: Video track indices for cutaways
 * - speakerBoosts: Per-speaker dB adjustments { "Speaker 1": 5 }
 */
app.post('/multitrack', requireCredits({ endpoint: 'multitrack' }), async (req, res) => {
  const {
    audioPaths,
    speakerNames,
    videoTrackMapping = {},
    minShotDuration = 2.0,
    switchingFrequency = 50,
    wideShotEnabled = true,
    wideShotPercentage = 20,
    wideShotTracks = [],
    cutawayEnabled = false,
    cutawayTracks = [],
    speakerBoosts = {},
    frameRate = 30
  } = req.body;

  // Validate audioPaths
  if (!audioPaths || !Array.isArray(audioPaths) || audioPaths.length === 0) {
    return res.status(400).json({ error: 'audioPaths array is required (at least 1 path)' });
  }

  // Validate all files exist
  for (const audioPath of audioPaths) {
    if (!fs.existsSync(audioPath)) {
      return res.status(404).json({ error: `File not found: ${audioPath}` });
    }
  }

  // Check FFprobe availability
  const ffprobeAvailable = await isFFprobeInstalled();
  if (!ffprobeAvailable) {
    return res.status(500).json({
      error: 'FFprobe not installed. Run: brew install ffmpeg'
    });
  }

  console.log(`[SPLICE] Multitrack analysis: ${audioPaths.length} track(s)`);

  try {
    const result = await analyzeMultitrack(audioPaths, {
      speakerNames: speakerNames || audioPaths.map((_, i) => `Speaker ${i + 1}`),
      videoTrackMapping,
      minShotDuration,
      switchingFrequency,
      wideShotEnabled,
      wideShotPercentage,
      wideShotTracks,
      cutawayEnabled,
      cutawayTracks,
      speakerBoosts,
      frameRate
    });

    // Deduct usage based on total duration (use longest track)
    const audioDuration = result.metadata?.totalDuration || 0;
    let balance = null;
    if (audioDuration > 0 && req.deductUsage) {
      balance = await req.deductUsage(audioDuration);
    }

    res.json({
      success: true,
      ...result,
      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
    });
  } catch (err) {
    console.error('[SPLICE] Multitrack analysis error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /multitrack/auto-balance - Auto-balance speaker screentime
 *
 * Automatically adjusts speaker boosts to achieve equal screentime distribution.
 * Runs multiple iterations to find optimal parameters.
 */
app.post('/multitrack/auto-balance', requireCredits({ endpoint: 'multitrack-auto-balance' }), async (req, res) => {
  const {
    audioPaths,
    speakerNames,
    videoTrackMapping = {},
    minShotDuration = 2.0,
    switchingFrequency = 50,
    wideShotEnabled = false, // Disable wide shots for balance calc
    frameRate = 30
  } = req.body;

  // Validate audioPaths
  if (!audioPaths || !Array.isArray(audioPaths) || audioPaths.length < 2) {
    return res.status(400).json({ error: 'audioPaths array requires at least 2 tracks for balancing' });
  }

  // Validate all files exist
  for (const audioPath of audioPaths) {
    if (!fs.existsSync(audioPath)) {
      return res.status(404).json({ error: `File not found: ${audioPath}` });
    }
  }

  // Check FFprobe availability
  const ffprobeAvailable = await isFFprobeInstalled();
  if (!ffprobeAvailable) {
    return res.status(500).json({
      error: 'FFprobe not installed. Run: brew install ffmpeg'
    });
  }

  console.log(`[SPLICE] Auto-balancing multitrack: ${audioPaths.length} track(s)`);

  try {
    const result = await autoBalanceMultitrack(audioPaths, {
      speakerNames: speakerNames || audioPaths.map((_, i) => `Speaker ${i + 1}`),
      videoTrackMapping,
      minShotDuration,
      switchingFrequency,
      wideShotEnabled,
      frameRate
    });

    // Deduct usage based on total duration
    const audioDuration = result.metadata?.totalDuration || 0;
    let balance = null;
    if (audioDuration > 0 && req.deductUsage) {
      balance = await req.deductUsage(audioDuration);
    }

    res.json({
      success: true,
      ...result,
      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
    });
  } catch (err) {
    console.error('[SPLICE] Auto-balance error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /multitrack/advanced-balance - Advanced GA-optimized balancing
 *
 * Uses genetic algorithm optimization with constraints:
 * - maxConsecutiveSeconds: Prevent single speaker dominating too long
 * - momentumFactor: Reduce rapid switching between speakers
 * - targetDistribution: Custom target percentages per speaker
 */
app.post('/multitrack/advanced-balance', requireCredits({ endpoint: 'multitrack-advanced' }), async (req, res) => {
  const {
    audioPaths,
    speakerNames,
    videoTrackMapping = {},
    minShotDuration = 2.0,
    switchingFrequency = 50,
    frameRate = 30,
    // Advanced options
    maxConsecutiveSeconds = 30,
    momentumFactor = 0.7,
    populationSize = 20,
    generations = 10,
    targetDistribution = null
  } = req.body;

  // Validate audioPaths
  if (!audioPaths || !Array.isArray(audioPaths) || audioPaths.length < 2) {
    return res.status(400).json({ error: 'audioPaths array requires at least 2 tracks for balancing' });
  }

  // Validate all files exist
  for (const audioPath of audioPaths) {
    if (!fs.existsSync(audioPath)) {
      return res.status(404).json({ error: `File not found: ${audioPath}` });
    }
  }

  // Validate constraints
  if (maxConsecutiveSeconds < 5 || maxConsecutiveSeconds > 120) {
    return res.status(400).json({ error: 'maxConsecutiveSeconds must be between 5 and 120' });
  }
  if (momentumFactor < 0 || momentumFactor > 1) {
    return res.status(400).json({ error: 'momentumFactor must be between 0 and 1' });
  }

  // Check FFprobe availability
  const ffprobeAvailable = await isFFprobeInstalled();
  if (!ffprobeAvailable) {
    return res.status(500).json({
      error: 'FFprobe not installed. Run: brew install ffmpeg'
    });
  }

  console.log(`[SPLICE] Advanced balancing multitrack: ${audioPaths.length} track(s)`);
  console.log(`  - Max consecutive: ${maxConsecutiveSeconds}s, Momentum: ${momentumFactor}`);

  try {
    const result = await advancedBalanceMultitrack(audioPaths, {
      speakerNames: speakerNames || audioPaths.map((_, i) => `Speaker ${i + 1}`),
      videoTrackMapping,
      minShotDuration,
      switchingFrequency,
      frameRate,
      maxConsecutiveSeconds,
      momentumFactor,
      populationSize,
      generations,
      targetDistribution
    });

    // Deduct usage based on total duration
    const audioDuration = result.metadata?.totalDuration || 0;
    let balance = null;
    if (audioDuration > 0 && req.deductUsage) {
      balance = await req.deductUsage(audioDuration);
    }

    res.json({
      success: true,
      ...result,
      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
    });
  } catch (err) {
    console.error('[SPLICE] Advanced balance error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /process-xml - Process FCP XML to split clips at silences
 *
 * Takes an FCP XML file and silence timestamps, splits clips
 * at silence boundaries, and optionally removes gaps.
 */
app.post('/process-xml', requireCredits({ endpoint: 'process-xml' }), async (req, res) => {
  const {
    xmlPath,
    silences,
    removeGaps = true,
    outputPath = null
  } = req.body;

  if (!xmlPath) {
    return res.status(400).json({ error: 'xmlPath is required' });
  }

  if (!silences || !Array.isArray(silences)) {
    return res.status(400).json({ error: 'silences array is required' });
  }

  if (!fs.existsSync(xmlPath)) {
    return res.status(404).json({ error: `XML file not found: ${xmlPath}` });
  }

  console.log(`[SPLICE] Processing XML: ${xmlPath} with ${silences.length} silence(s)`);

  try {
    const result = await processXMLFile(xmlPath, silences, {
      outputPath,
      removeGaps
    });

    res.json({
      success: true,
      inputPath: xmlPath,
      outputPath: result.outputPath,
      stats: result.stats
    });
  } catch (err) {
    console.error('[SPLICE] XML processing error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /cut-list - Generate a JSON cut list for direct DOM building (v3.5)
 *
 * Takes silences and optionally takes, returns a cut list that the
 * plugin can use to build sequences directly via UXP APIs.
 *
 * Body:
 * - sourceName: Name of the source clip
 * - sourcePath: Full path to the source file
 * - duration: Total duration in seconds
 * - silences: Array of silence segments [{start, end, duration}]
 * - takes: (optional) Array of detected takes
 * - settings: (optional) Generation settings
 *
 * Requires authentication via x-stripe-customer-id header
 */
app.post('/cut-list', requireCredits({ endpoint: 'cut-list' }), async (req, res) => {
  const {
    sourceName,
    sourcePath,
    duration,
    silences,
    takes = [],
    settings = {}
  } = req.body;

  // Validate required fields
  if (!sourceName && !sourcePath) {
    return res.status(400).json({ error: 'sourceName or sourcePath is required' });
  }

  if (typeof duration !== 'number' || duration <= 0) {
    return res.status(400).json({ error: 'duration must be a positive number' });
  }

  if (!silences || !Array.isArray(silences)) {
    return res.status(400).json({ error: 'silences array is required' });
  }

  console.log(`[SPLICE] Generating cut list for ${sourceName || sourcePath} (${silences.length} silences)`);

  try {
    const cutList = generateCutList({
      sourceName: sourceName || path.basename(sourcePath),
      sourcePath,
      duration,
      silences,
      takes,
      settings
    });

    // Validate the generated cut list
    const validation = validateCutList(cutList);
    if (!validation.valid) {
      return res.status(500).json({
        error: 'Generated cut list is invalid',
        validationErrors: validation.errors
      });
    }

    res.json({
      success: true,
      cutList
    });
  } catch (err) {
    console.error('[SPLICE] Cut list generation error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /cut-list/takes - Generate a cut list that keeps only takes
 *
 * Alternative endpoint for "keep best takes only" workflow.
 *
 * Requires authentication via x-stripe-customer-id header
 */
app.post('/cut-list/takes', requireCredits({ endpoint: 'cut-list-takes' }), async (req, res) => {
  const {
    sourceName,
    sourcePath,
    duration,
    takes,
    settings = {}
  } = req.body;

  // Validate required fields
  if (!sourceName && !sourcePath) {
    return res.status(400).json({ error: 'sourceName or sourcePath is required' });
  }

  if (typeof duration !== 'number' || duration <= 0) {
    return res.status(400).json({ error: 'duration must be a positive number' });
  }

  if (!takes || !Array.isArray(takes) || takes.length === 0) {
    return res.status(400).json({ error: 'takes array is required and must not be empty' });
  }

  console.log(`[SPLICE] Generating takes cut list for ${sourceName || sourcePath} (${takes.length} takes)`);

  try {
    const cutList = generateTakesCutList({
      sourceName: sourceName || path.basename(sourcePath),
      sourcePath,
      duration,
      takes,
      settings
    });

    res.json({
      success: true,
      cutList
    });
  } catch (err) {
    console.error('[SPLICE] Takes cut list generation error:', err);
    res.status(500).json({ error: err.message });
  }
});

// =============================================================================
// Auto Zoom & Chapter Detection Routes (Phase 3)
// =============================================================================

/**
 * POST /zoom - Generate zoom points from transcript
 *
 * Analyzes transcript to find emphasis points and generates zoom data.
 *
 * Body:
 * - transcript: Transcript object with words/segments
 * - settings: {
 *     frequency: 'low'|'medium'|'high',
 *     preset: 'subtle'|'medium'|'dramatic',
 *     placement: 'sentence_start'|'keywords'|'random'|'speaker_change'
 *   }
 */
app.post('/zoom', requireCredits({ endpoint: 'zoom' }), async (req, res) => {
  const {
    transcript,
    wavPath,
    settings = {}
  } = req.body;

  // Get transcript from wavPath if not provided directly
  let transcriptData = transcript;
  if (!transcriptData && wavPath) {
    if (!(await fileExists(wavPath))) {
      return res.status(404).json({ error: `File not found: ${wavPath}` });
    }
    try {
      transcriptData = await transcribeWithWords(wavPath);
    } catch (err) {
      return res.status(500).json({ error: `Transcription failed: ${err.message}` });
    }
  }

  if (!transcriptData) {
    return res.status(400).json({ error: 'transcript or wavPath is required' });
  }

  console.log(`[SPLICE] Generating zoom points (${settings.frequency || 'medium'}/${settings.preset || 'medium'})`);

  try {
    const zoomPoints = generateZoomPoints(transcriptData, settings);

    // Deduct usage based on audio duration
    const audioDuration = transcriptData.duration || 0;
    let balance = null;
    if (audioDuration > 0 && req.deductUsage) {
      balance = await req.deductUsage(audioDuration);
    }

    res.json({
      success: true,
      zoomPoints,
      count: zoomPoints.length,
      settings: {
        frequency: settings.frequency || 'medium',
        preset: settings.preset || 'medium',
        placement: settings.placement || 'sentence_start'
      },
      presets: ZOOM_PRESETS,
      frequencies: ZOOM_FREQUENCIES,
      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
    });
  } catch (err) {
    console.error('[SPLICE] Zoom generation error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * GET /zoom/presets - Get available zoom presets and frequencies
 */
app.get('/zoom/presets', (req, res) => {
  res.json({
    success: true,
    presets: ZOOM_PRESETS,
    frequencies: ZOOM_FREQUENCIES,
    placements: ['sentence_start', 'keywords', 'random', 'speaker_change']
  });
});

/**
 * POST /chapters - Detect chapters in transcript using AI
 *
 * Analyzes transcript to identify natural topic/chapter boundaries.
 * Returns chapter data with YouTube timestamps and timeline markers.
 *
 * Body:
 * - transcript: Transcript object with text/segments
 * - wavPath: Optional path to audio file (will transcribe if no transcript)
 * - settings: {
 *     maxChapters: number (default 10),
 *     minChapterLength: number in seconds (default 60),
 *     titleStyle: 'standard' | 'youtube' | 'shorts' (default 'standard')
 *   }
 */
app.post('/chapters', requireCredits({ endpoint: 'chapters' }), async (req, res) => {
  const {
    transcript,
    wavPath,
    settings = {}
  } = req.body;

  // Get transcript from wavPath if not provided directly
  let transcriptData = transcript;
  if (!transcriptData && wavPath) {
    if (!(await fileExists(wavPath))) {
      return res.status(404).json({ error: `File not found: ${wavPath}` });
    }
    try {
      transcriptData = await transcribeAudio(wavPath);
    } catch (err) {
      return res.status(500).json({ error: `Transcription failed: ${err.message}` });
    }
  }

  if (!transcriptData) {
    return res.status(400).json({ error: 'transcript or wavPath is required' });
  }

  console.log(`[SPLICE] Detecting chapters (max ${settings.maxChapters || 10}, style: ${settings.titleStyle || 'standard'})`);

  try {
    const result = await detectChapters(transcriptData, settings);

    // Deduct usage (5 seconds per detection)
    const usageSeconds = 5;
    let balance = null;
    if (req.deductUsage) {
      balance = await req.deductUsage(usageSeconds);
    }

    res.json({
      success: true,
      ...result,
      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
    });
  } catch (err) {
    console.error('[SPLICE] Chapter detection error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /chapters/fallback - Detect chapters without AI (gap-based)
 *
 * Uses silence gaps to identify potential chapter boundaries.
 * Faster but less accurate than AI-based detection.
 */
app.post('/chapters/fallback', requireCredits({ endpoint: 'chapters' }), async (req, res) => {
  const { transcript, settings = {} } = req.body;

  if (!transcript) {
    return res.status(400).json({ error: 'transcript is required' });
  }

  try {
    const result = detectChaptersFallback(transcript, settings);

    res.json({
      success: true,
      ...result
    });
  } catch (err) {
    console.error('[SPLICE] Chapter fallback error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /chapters/dividers - Generate chapter divider data for timeline insertion
 *
 * Takes chapter data and generates divider clip information with styling,
 * colors, animation, and timing for inserting visual chapter separators.
 */
app.post('/chapters/dividers', requireCredits({ endpoint: 'chapters' }), async (req, res) => {
  const { chapters, settings = {} } = req.body;

  if (!chapters || !Array.isArray(chapters) || chapters.length === 0) {
    return res.status(400).json({ error: 'chapters array is required' });
  }

  // Validate chapter objects
  for (let i = 0; i < chapters.length; i++) {
    const ch = chapters[i];
    if (typeof ch.startTime !== 'number') {
      return res.status(400).json({
        error: `Invalid chapter at index ${i}: startTime must be a number`
      });
    }
    if (!ch.title || typeof ch.title !== 'string') {
      return res.status(400).json({
        error: `Invalid chapter at index ${i}: title is required`
      });
    }
  }

  try {
    const { generateChapterDividers } = require('./services/chapterDetection');
    const result = generateChapterDividers(chapters, settings);

    // Deduct usage
    if (req.deductUsage) {
      await req.deductUsage(result.metadata.count * 0.1); // 0.1 credits per divider
    }

    res.json({
      success: true,
      ...result
    });
  } catch (err) {
    console.error('[SPLICE] Chapter dividers error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * GET /chapters/dividers/presets - Get available divider styles and presets
 */
app.get('/chapters/dividers/presets', (req, res) => {
  const { getDividerPresets } = require('./services/chapterDetection');
  res.json(getDividerPresets());
});

// ============================================================================
// YOUTUBE CONTENT GENERATION ENDPOINTS
// ============================================================================

/**
 * POST /youtube/description - Generate YouTube video description
 *
 * Creates SEO-optimized description with summary, key points,
 * timestamps, and hashtags from transcript.
 */
app.post('/youtube/description', requireCredits({ endpoint: 'youtube' }), async (req, res) => {
  const { transcript, options = {} } = req.body;

  if (!transcript) {
    return res.status(400).json({ error: 'transcript is required' });
  }

  try {
    const { generateDescription } = require('./services/youtubeGenerator');
    const result = await generateDescription(transcript, options);

    if (!result.success) {
      return res.status(400).json({ error: result.error });
    }

    // Deduct usage based on description length
    if (req.deductUsage) {
      await req.deductUsage(0.5); // 0.5 credits per description
    }

    res.json(result);
  } catch (err) {
    console.error('[SPLICE] YouTube description error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /youtube/title - Generate YouTube video titles
 *
 * Creates multiple title options with different styles.
 */
app.post('/youtube/title', requireCredits({ endpoint: 'youtube' }), async (req, res) => {
  const { transcript, options = {} } = req.body;

  if (!transcript) {
    return res.status(400).json({ error: 'transcript is required' });
  }

  try {
    const { generateTitle } = require('./services/youtubeGenerator');
    const result = await generateTitle(transcript, options);

    if (!result.success) {
      return res.status(400).json({ error: result.error });
    }

    // Deduct usage
    if (req.deductUsage) {
      await req.deductUsage(0.25); // 0.25 credits per title generation
    }

    res.json(result);
  } catch (err) {
    console.error('[SPLICE] YouTube title error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /youtube/shorts - Generate Shorts/TikTok metadata
 *
 * Creates title, caption, and hashtags for short-form content.
 */
app.post('/youtube/shorts', requireCredits({ endpoint: 'youtube' }), async (req, res) => {
  const { transcript, options = {} } = req.body;

  if (!transcript) {
    return res.status(400).json({ error: 'transcript is required' });
  }

  try {
    const { generateShortsMetadata } = require('./services/youtubeGenerator');
    const result = await generateShortsMetadata(transcript, options);

    if (!result.success) {
      return res.status(400).json({ error: result.error });
    }

    // Deduct usage
    if (req.deductUsage) {
      await req.deductUsage(0.25); // 0.25 credits per shorts metadata
    }

    res.json(result);
  } catch (err) {
    console.error('[SPLICE] YouTube shorts error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * GET /youtube/options - Get available generation options
 */
app.get('/youtube/options', (req, res) => {
  const { getGeneratorOptions } = require('./services/youtubeGenerator');
  res.json(getGeneratorOptions());
});

// ============================================================================
// ANIMATED CAPTIONS ENDPOINTS
// ============================================================================

/**
 * POST /captions/animate - Generate animated captions from transcript
 *
 * Creates word-by-word animated captions with template styling.
 */
app.post('/captions/animate', requireCredits({ endpoint: 'captions' }), async (req, res) => {
  const { transcript, template = 'mrbeast', settings = {} } = req.body;

  if (!transcript) {
    return res.status(400).json({ error: 'transcript is required' });
  }

  try {
    const { generateAnimatedCaptions } = require('./services/animatedCaptions');
    const result = await generateAnimatedCaptions(transcript, template, settings);

    if (!result.success) {
      return res.status(400).json({ error: result.error });
    }

    // Deduct usage
    if (req.deductUsage) {
      await req.deductUsage(0.5); // 0.5 credits per caption generation
    }

    res.json(result);
  } catch (err) {
    console.error('[SPLICE] Animated captions error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * GET /captions/templates - Get available caption templates
 */
app.get('/captions/templates', (req, res) => {
  const { getTemplates } = require('./services/animatedCaptions');
  res.json(getTemplates());
});

/**
 * GET /captions/template/:id - Get specific template details
 */
app.get('/captions/template/:id', (req, res) => {
  const { getTemplateById } = require('./services/animatedCaptions');
  const template = getTemplateById(req.params.id);

  if (!template) {
    return res.status(404).json({ error: `Template '${req.params.id}' not found` });
  }

  res.json(template);
});

/**
 * POST /captions/detect-keywords - Detect keywords for highlighting
 */
app.post('/captions/detect-keywords', requireCredits({ endpoint: 'captions' }), async (req, res) => {
  const { transcript, options = {} } = req.body;

  if (!transcript) {
    return res.status(400).json({ error: 'transcript is required' });
  }

  try {
    const { detectKeywords } = require('./services/animatedCaptions');
    const keywords = await detectKeywords(transcript, options);

    // Deduct usage
    if (req.deductUsage) {
      await req.deductUsage(0.25); // 0.25 credits
    }

    res.json({ success: true, keywords });
  } catch (err) {
    console.error('[SPLICE] Keyword detection error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /captions/insert-emojis - Insert emojis into transcript
 */
app.post('/captions/insert-emojis', requireCredits({ endpoint: 'captions' }), async (req, res) => {
  const { transcript, options = {} } = req.body;

  if (!transcript) {
    return res.status(400).json({ error: 'transcript is required' });
  }

  try {
    const { insertEmojis } = require('./services/animatedCaptions');
    const result = await insertEmojis(transcript, options);

    if (!result.success) {
      return res.status(400).json({ error: result.error });
    }

    // Deduct usage
    if (req.deductUsage) {
      await req.deductUsage(0.25); // 0.25 credits
    }

    res.json(result);
  } catch (err) {
    console.error('[SPLICE] Emoji insertion error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /captions/apply-template - Apply template to existing caption data
 */
app.post('/captions/apply-template', requireCredits({ endpoint: 'captions' }), (req, res) => {
  const { captionData, templateId } = req.body;

  if (!captionData || !templateId) {
    return res.status(400).json({ error: 'captionData and templateId are required' });
  }

  const { applyTemplate } = require('./services/animatedCaptions');
  const result = applyTemplate(captionData, templateId);

  if (!result.success) {
    return res.status(400).json(result);
  }

  res.json(result);
});

/**
 * POST /captions/export/mogrt - Generate MOGRT-compatible data
 */
app.post('/captions/export/mogrt', requireCredits({ endpoint: 'captions' }), async (req, res) => {
  const { captions, settings = {} } = req.body;

  if (!captions || !Array.isArray(captions)) {
    return res.status(400).json({ error: 'captions array is required' });
  }

  try {
    const { generateMOGRTData } = require('./services/animatedCaptions');
    const result = generateMOGRTData(captions, settings);

    // Deduct usage
    if (req.deductUsage) {
      await req.deductUsage(0.25); // 0.25 credits
    }

    res.json(result);
  } catch (err) {
    console.error('[SPLICE] MOGRT export error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /captions/export/burned - Export captions for burning into video
 */
app.post('/captions/export/burned', requireCredits({ endpoint: 'captions' }), async (req, res) => {
  const { videoPath, captions, outputPath } = req.body;

  if (!captions || !Array.isArray(captions)) {
    return res.status(400).json({ error: 'captions array is required' });
  }

  try {
    const { exportBurnedInCaptions } = require('./services/animatedCaptions');
    const result = await exportBurnedInCaptions(videoPath, captions, outputPath);

    // Deduct usage
    if (req.deductUsage) {
      await req.deductUsage(0.5); // 0.5 credits
    }

    res.json(result);
  } catch (err) {
    console.error('[SPLICE] Burned captions export error:', err);
    res.status(500).json({ error: err.message });
  }
});

// ============================================================================
// TEXT-BASED EDITING ENDPOINTS
// ============================================================================

/**
 * POST /text-edit/prepare - Create editable transcript structure
 *
 * Converts transcript to editable format with unique word IDs.
 */
app.post('/text-edit/prepare', requireCredits({ endpoint: 'text-edit' }), async (req, res) => {
  const { transcript } = req.body;

  if (!transcript) {
    return res.status(400).json({ error: 'transcript is required' });
  }

  try {
    const { generateEditableTranscript } = require('./services/textBasedEditing');
    const result = generateEditableTranscript(transcript);

    if (!result.success) {
      return res.status(400).json({ error: result.error });
    }

    // Deduct usage
    if (req.deductUsage) {
      await req.deductUsage(0.25); // 0.25 credits
    }

    res.json(result);
  } catch (err) {
    console.error('[SPLICE] Text-edit prepare error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /text-edit/apply - Apply text edits and get operations
 *
 * Compares original and edited text, returns edit operations.
 */
app.post('/text-edit/apply', requireCredits({ endpoint: 'text-edit' }), async (req, res) => {
  const { transcript, editedText } = req.body;

  if (!transcript) {
    return res.status(400).json({ error: 'transcript is required' });
  }

  if (typeof editedText !== 'string') {
    return res.status(400).json({ error: 'editedText is required' });
  }

  try {
    const { applyTextEdits } = require('./services/textBasedEditing');
    const result = applyTextEdits(transcript, editedText);

    if (!result.success) {
      return res.status(400).json({ error: result.error });
    }

    // Deduct usage
    if (req.deductUsage) {
      await req.deductUsage(0.5); // 0.5 credits
    }

    res.json(result);
  } catch (err) {
    console.error('[SPLICE] Text-edit apply error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /text-edit/search - Search transcript with timestamps
 */
app.post('/text-edit/search', requireCredits({ endpoint: 'text-edit' }), async (req, res) => {
  const { transcript, searchText } = req.body;

  if (!transcript) {
    return res.status(400).json({ error: 'transcript is required' });
  }

  if (!searchText) {
    return res.status(400).json({ error: 'searchText is required' });
  }

  try {
    const { searchTranscript } = require('./services/textBasedEditing');
    const result = searchTranscript(transcript, searchText);

    if (!result.success) {
      return res.status(400).json({ error: result.error });
    }

    // Deduct usage
    if (req.deductUsage) {
      await req.deductUsage(0.1); // 0.1 credits
    }

    res.json(result);
  } catch (err) {
    console.error('[SPLICE] Text-edit search error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /text-edit/replace - Search and replace (generates cut operations)
 */
app.post('/text-edit/replace', requireCredits({ endpoint: 'text-edit' }), async (req, res) => {
  const { transcript, searchText, replaceText = '' } = req.body;

  if (!transcript) {
    return res.status(400).json({ error: 'transcript is required' });
  }

  if (!searchText) {
    return res.status(400).json({ error: 'searchText is required' });
  }

  try {
    const { searchAndReplace } = require('./services/textBasedEditing');
    const result = searchAndReplace(transcript, searchText, replaceText);

    if (!result.success) {
      return res.status(400).json({ error: result.error });
    }

    // Deduct usage
    if (req.deductUsage) {
      await req.deductUsage(0.25); // 0.25 credits
    }

    res.json(result);
  } catch (err) {
    console.error('[SPLICE] Text-edit replace error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /text-edit/preview - Preview edits without applying
 */
app.post('/text-edit/preview', requireCredits({ endpoint: 'text-edit' }), async (req, res) => {
  const { transcript, editedText } = req.body;

  if (!transcript) {
    return res.status(400).json({ error: 'transcript is required' });
  }

  if (typeof editedText !== 'string') {
    return res.status(400).json({ error: 'editedText is required' });
  }

  try {
    const { previewEdits } = require('./services/textBasedEditing');
    const result = previewEdits(transcript, editedText);

    if (!result.success) {
      return res.status(400).json({ error: result.error });
    }

    // Deduct usage (small amount for preview)
    if (req.deductUsage) {
      await req.deductUsage(0.1); // 0.1 credits
    }

    res.json(result);
  } catch (err) {
    console.error('[SPLICE] Text-edit preview error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /text-edit/cut-list - Generate cut list from edit operations
 */
app.post('/text-edit/cut-list', requireCredits({ endpoint: 'text-edit' }), async (req, res) => {
  const { operations, sourceInfo = {} } = req.body;

  if (!operations || !Array.isArray(operations)) {
    return res.status(400).json({ error: 'operations array is required' });
  }

  try {
    const { generateEditCutList } = require('./services/textBasedEditing');
    const result = generateEditCutList(operations, sourceInfo);

    if (!result.success) {
      return res.status(400).json({ error: result.error });
    }

    // Deduct usage
    if (req.deductUsage) {
      await req.deductUsage(0.25); // 0.25 credits
    }

    res.json(result);
  } catch (err) {
    console.error('[SPLICE] Text-edit cut-list error:', err);
    res.status(500).json({ error: err.message });
  }
});

// ============================================================================
// SOCIAL REFRAME ENDPOINTS
// ============================================================================

/**
 * POST /reframe/analyze - Analyze video for reframe with face tracking
 */
app.post('/reframe/analyze', requireCredits({ endpoint: 'reframe' }), async (req, res) => {
  const { videoPath, options = {} } = req.body;

  if (!videoPath) {
    return res.status(400).json({ error: 'videoPath is required' });
  }

  try {
    const { analyzeForReframe } = require('./services/socialReframe');
    const result = await analyzeForReframe(videoPath, options);

    if (!result.success) {
      return res.status(400).json({ error: result.error });
    }

    // Deduct usage
    if (req.deductUsage) {
      await req.deductUsage(1.0); // 1 credit for analysis
    }

    res.json(result);
  } catch (err) {
    console.error('[SPLICE] Reframe analyze error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /reframe/calculate - Calculate crop positions for aspect ratio
 */
app.post('/reframe/calculate', requireCredits({ endpoint: 'reframe' }), async (req, res) => {
  const { tracking, targetAspect } = req.body;

  if (!tracking) {
    return res.status(400).json({ error: 'tracking data is required' });
  }

  if (!targetAspect) {
    return res.status(400).json({ error: 'targetAspect is required' });
  }

  try {
    const { calculateReframeCrops } = require('./services/socialReframe');
    const result = calculateReframeCrops(tracking, targetAspect);

    // Deduct usage
    if (req.deductUsage) {
      await req.deductUsage(0.25); // 0.25 credits
    }

    res.json({ success: true, crops: result });
  } catch (err) {
    console.error('[SPLICE] Reframe calculate error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /reframe/motion-path - Generate smooth motion path
 */
app.post('/reframe/motion-path', requireCredits({ endpoint: 'reframe' }), async (req, res) => {
  const { crops, duration, frameRate } = req.body;

  if (!crops || !Array.isArray(crops)) {
    return res.status(400).json({ error: 'crops array is required' });
  }

  if (!duration || !frameRate) {
    return res.status(400).json({ error: 'duration and frameRate are required' });
  }

  try {
    const { generateMotionPath } = require('./services/socialReframe');
    const result = generateMotionPath(crops, duration, frameRate);

    if (!result.success) {
      return res.status(400).json({ error: result.error });
    }

    // Deduct usage
    if (req.deductUsage) {
      await req.deductUsage(0.25); // 0.25 credits
    }

    res.json(result);
  } catch (err) {
    console.error('[SPLICE] Reframe motion-path error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /reframe/export - Batch export all formats
 */
app.post('/reframe/export', requireCredits({ endpoint: 'reframe' }), async (req, res) => {
  const { videoPath, formats = ['portrait', 'square'], settings = {} } = req.body;

  if (!videoPath) {
    return res.status(400).json({ error: 'videoPath is required' });
  }

  try {
    const { batchExportFormats } = require('./services/socialReframe');
    const result = await batchExportFormats(videoPath, formats, settings);

    if (!result.success) {
      return res.status(400).json({ error: result.error });
    }

    // Deduct usage per format
    if (req.deductUsage) {
      await req.deductUsage(0.5 * formats.length);
    }

    res.json(result);
  } catch (err) {
    console.error('[SPLICE] Reframe export error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * GET /reframe/platforms - Get available platforms and aspect ratios
 */
app.get('/reframe/platforms', (req, res) => {
  const { getPlatformPresets } = require('./services/socialReframe');
  res.json(getPlatformPresets());
});

/**
 * GET /reframe/safe-zones/:platform - Get safe zones for platform
 */
app.get('/reframe/safe-zones/:platform', (req, res) => {
  const { getSafeZones } = require('./services/socialReframe');
  const result = getSafeZones(req.params.platform);

  if (!result.success) {
    return res.status(404).json(result);
  }

  res.json(result);
});

/**
 * POST /faces/detect - Detect faces in video
 */
app.post('/faces/detect', requireCredits({ endpoint: 'reframe' }), async (req, res) => {
  const { videoPath, options = {} } = req.body;

  if (!videoPath) {
    return res.status(400).json({ error: 'videoPath is required' });
  }

  try {
    const { detectFaces } = require('./services/faceDetection');
    const result = await detectFaces(videoPath, options);

    if (!result.success) {
      return res.status(400).json({ error: result.error });
    }

    // Deduct usage
    if (req.deductUsage) {
      await req.deductUsage(0.5); // 0.5 credits
    }

    res.json(result);
  } catch (err) {
    console.error('[SPLICE] Face detect error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /faces/track - Track faces throughout video
 */
app.post('/faces/track', requireCredits({ endpoint: 'reframe' }), async (req, res) => {
  const { videoPath, options = {} } = req.body;

  if (!videoPath) {
    return res.status(400).json({ error: 'videoPath is required' });
  }

  try {
    const { trackFaces } = require('./services/faceDetection');
    const result = await trackFaces(videoPath, options);

    if (!result.success) {
      return res.status(400).json({ error: result.error });
    }

    // Deduct usage
    if (req.deductUsage) {
      await req.deductUsage(1.0); // 1 credit for tracking
    }

    res.json(result);
  } catch (err) {
    console.error('[SPLICE] Face track error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /faces/identify-speaker - Identify primary speaker
 */
app.post('/faces/identify-speaker', requireCredits({ endpoint: 'reframe' }), (req, res) => {
  const { faces, audioAnalysis = null } = req.body;

  if (!faces || !Array.isArray(faces)) {
    return res.status(400).json({ error: 'faces array is required' });
  }

  try {
    const { identifySpeaker } = require('./services/faceDetection');
    const result = identifySpeaker(faces, audioAnalysis);
    res.json(result);
  } catch (err) {
    console.error('[SPLICE] Identify speaker error:', err);
    res.status(500).json({ error: err.message });
  }
});

// ============================================================================
// SYSTEM ENDPOINTS
// ============================================================================

/**
 * GET /ffprobe-check - Check if FFprobe is installed
 */
app.get('/ffprobe-check', async (req, res) => {
  const installed = await isFFprobeInstalled();
  res.json({
    installed,
    message: installed
      ? 'FFprobe is available'
      : 'FFprobe not found. Install with: brew install ffmpeg'
  });
});

/**
 * GET /replicate-check - Check if Replicate API is configured
 */
app.get('/replicate-check', async (req, res) => {
  const configured = isReplicateConfigured();
  res.json({
    configured,
    message: configured
      ? 'Replicate API is configured'
      : 'REPLICATE_API_TOKEN not set. Add to .env file.'
  });
});

/**
 * POST /isolate-vocals - Isolate vocals from audio using Demucs
 *
 * Uses Replicate's Demucs model to separate vocals from background audio.
 * Cost: ~$0.015/min of audio
 *
 * Tier access:
 * - Starter: No access (upgrade required)
 * - Pro: 2 hours included, then $0.08/min overage
 * - Team: 5 hours included, then $0.08/min overage
 */
app.post('/isolate-vocals', requireCredits({ endpoint: 'isolate-vocals' }), async (req, res) => {
  const { audioPath, stem = 'vocals', outputDir = null } = req.body;
  const stripeCustomerId = req.headers['x-stripe-customer-id'];

  if (!audioPath) {
    return res.status(400).json({ error: 'audioPath is required' });
  }

  if (!fs.existsSync(audioPath)) {
    return res.status(404).json({ error: `File not found: ${audioPath}` });
  }

  // Check Replicate configuration
  if (!isReplicateConfigured()) {
    return res.status(500).json({
      error: 'Replicate API not configured. Set REPLICATE_API_TOKEN in .env'
    });
  }

  // Get audio duration for billing
  let audioDurationSeconds = 0;
  try {
    audioDurationSeconds = await getAudioDuration(audioPath);
  } catch (err) {
    console.warn('[SPLICE] Could not get audio duration:', err.message);
  }

  const audioDurationMinutes = audioDurationSeconds / 60;

  // Check isolation access if customer ID provided
  if (stripeCustomerId) {
    const accessCheck = await usageTracking.checkIsolationAccess(stripeCustomerId, audioDurationMinutes);

    if (!accessCheck.allowed) {
      return res.status(403).json({
        error: accessCheck.message,
        reason: accessCheck.reason,
        upgradeRequired: accessCheck.reason === 'upgrade_required'
      });
    }

    console.log(`[SPLICE] Isolation access: ${accessCheck.message}`);
  }

  console.log(`[SPLICE] Isolating vocals: ${audioPath} (${audioDurationMinutes.toFixed(1)} min)`);

  try {
    const result = await isolateVocals(audioPath, {
      stem,
      outputDir: outputDir || undefined
    });

    // Deduct isolation usage if customer ID provided
    let usageInfo = null;
    if (stripeCustomerId) {
      usageInfo = await usageTracking.deductIsolationUsage(
        stripeCustomerId,
        audioDurationSeconds,
        'isolate-vocals'
      );
      console.log(`[SPLICE] Isolation usage deducted: ${audioDurationMinutes.toFixed(1)} min`);
      if (usageInfo.isolationUsed?.overageCost > 0) {
        console.log(`[SPLICE] Overage cost: $${usageInfo.isolationUsed.overageCost.toFixed(2)}`);
      }
    }

    res.json({
      success: true,
      inputPath: audioPath,
      outputPath: result.outputPath,
      stem: result.stem,
      processingTime: result.processingTime,
      availableStems: result.allStems,
      audioDurationMinutes,
      usage: usageInfo ? {
        isolationHoursRemaining: usageInfo.isolationHoursRemaining,
        overageCost: usageInfo.isolationUsed?.overageCost || 0
      } : null
    });
  } catch (err) {
    console.error('[SPLICE] Vocal isolation error:', err);
    res.status(500).json({ error: err.message });
  }
});

// =============================================================================
// Batch Processing Routes
// =============================================================================

// In-memory job queue for batch processing
const batchJobs = new Map();

// Batch job limits to prevent memory leak
const MAX_BATCH_JOBS = 10000;
const BATCH_JOB_MAX_AGE_MS = 24 * 60 * 60 * 1000; // 24 hours

/**
 * Generate a unique job ID
 */
function generateJobId() {
  return `batch_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
}

/**
 * Clean up old batch jobs to prevent memory leak
 * Removes jobs older than 24 hours
 */
function cleanupOldBatchJobs() {
  const now = Date.now();
  let removedCount = 0;

  for (const [jobId, job] of batchJobs.entries()) {
    const createdAt = new Date(job.createdAt).getTime();
    if (now - createdAt > BATCH_JOB_MAX_AGE_MS) {
      batchJobs.delete(jobId);
      removedCount++;
    }
  }

  if (removedCount > 0) {
    console.log(`[SPLICE] Cleaned up ${removedCount} old batch job(s)`);
  }
}

/**
 * Enforce max job limit by removing oldest completed jobs
 */
function enforceJobLimit() {
  if (batchJobs.size < MAX_BATCH_JOBS) return;

  // Get completed jobs sorted by creation date (oldest first)
  const completedJobs = Array.from(batchJobs.entries())
    .filter(([_, job]) => job.status !== 'processing')
    .sort((a, b) => new Date(a[1].createdAt) - new Date(b[1].createdAt));

  // Remove oldest completed jobs until under limit
  const toRemove = batchJobs.size - MAX_BATCH_JOBS + 1;
  for (let i = 0; i < Math.min(toRemove, completedJobs.length); i++) {
    batchJobs.delete(completedJobs[i][0]);
  }

  console.log(`[SPLICE] Enforced job limit, removed ${Math.min(toRemove, completedJobs.length)} job(s)`);
}

// Run cleanup every hour
setInterval(cleanupOldBatchJobs, 60 * 60 * 1000);

/**
 * POST /batch/silences - Process multiple files for silence detection
 *
 * Creates a batch job that processes multiple audio files.
 * Returns a job ID for tracking progress.
 *
 * Body:
 * - files: Array of file paths to process
 * - options: Detection options (sensitivity, threshold, etc.)
 */
app.post('/batch/silences', requireCredits({ endpoint: 'batch-silences' }), async (req, res) => {
  const { files, options = {} } = req.body;

  if (!files || !Array.isArray(files) || files.length === 0) {
    return res.status(400).json({ error: 'files array is required' });
  }

  // Validate all files exist
  const missingFiles = files.filter(f => !fs.existsSync(f));
  if (missingFiles.length > 0) {
    return res.status(404).json({
      error: 'Some files not found',
      missingFiles
    });
  }

  // Enforce job limit before creating new job
  enforceJobLimit();

  const jobId = generateJobId();

  // Initialize job with customer ID for usage tracking
  const job = {
    id: jobId,
    type: 'silences',
    status: 'processing',
    createdAt: new Date().toISOString(),
    stripeCustomerId: req.stripeCustomerId,  // Store for usage deduction
    files: files.map(f => ({
      path: f,
      status: 'pending',
      result: null,
      error: null
    })),
    options,
    progress: {
      total: files.length,
      completed: 0,
      failed: 0,
      percentage: 0
    },
    results: [],
    errors: [],
    totalUsageDeducted: 0  // Track total seconds deducted
  };

  batchJobs.set(jobId, job);
  console.log(`[SPLICE] Batch job ${jobId} created with ${files.length} files`);

  // Start processing in background
  processBatchJob(jobId);

  res.json({
    success: true,
    jobId,
    message: `Batch job created with ${files.length} files`,
    statusUrl: `/batch/status/${jobId}`
  });
});

/**
 * Process a batch job (runs in background)
 */
async function processBatchJob(jobId) {
  const job = batchJobs.get(jobId);
  if (!job) return;

  const { sensitivity, ...manualOptions } = job.options;

  // Build detection options
  let detectionOptions = {};
  if (typeof sensitivity === 'number') {
    detectionOptions = sensitivityToParams(sensitivity);
  } else {
    detectionOptions = {
      threshold: manualOptions.threshold ?? -30,
      minSilenceLength: manualOptions.minSilenceLength ?? 0.5,
      paddingStart: manualOptions.paddingStart ?? 0.1,
      paddingEnd: manualOptions.paddingEnd ?? 0.05,
      autoThreshold: manualOptions.autoThreshold ?? false
    };
  }

  // Process files with controlled parallelism (3 concurrent for disk I/O efficiency)
  const CONCURRENCY_LIMIT = 3;
  const chunks = [];
  for (let i = 0; i < job.files.length; i += CONCURRENCY_LIMIT) {
    chunks.push(job.files.slice(i, i + CONCURRENCY_LIMIT));
  }

  for (const chunk of chunks) {
    // Mark chunk files as processing
    chunk.forEach(f => f.status = 'processing');

    // Process chunk in parallel
    const chunkResults = await Promise.all(
      chunk.map(async (fileEntry, chunkIndex) => {
        try {
          const result = await detectSilencesRMS(fileEntry.path, detectionOptions);

          fileEntry.status = 'completed';
          fileEntry.result = {
            silences: result.silences,
            count: result.silences.length,
            totalSilenceDuration: result.metadata.totalSilenceDuration,
            audioDuration: result.metadata.audioDuration
          };

          job.results.push({
            file: fileEntry.path,
            ...fileEntry.result
          });

          // Deduct usage for this file
          const audioDuration = result.metadata?.audioDuration || 0;
          if (audioDuration > 0 && job.stripeCustomerId) {
            try {
              await usageTracking.deductUsage(job.stripeCustomerId, audioDuration, 'batch-silences');
              job.totalUsageDeducted += audioDuration;
            } catch (usageErr) {
              console.warn(`[SPLICE] Batch ${jobId}: Usage deduction failed:`, usageErr.message);
            }
          }

          job.progress.completed++;
          return { success: true, fileEntry };
        } catch (err) {
          fileEntry.status = 'failed';
          fileEntry.error = err.message;

          job.errors.push({
            file: fileEntry.path,
            error: err.message
          });

          job.progress.failed++;
          console.error(`[SPLICE] Batch ${jobId}: ${fileEntry.path} failed:`, err.message);
          return { success: false, fileEntry, error: err };
        }
      })
    );

    // Update progress after each chunk
    job.progress.percentage = Math.round(
      ((job.progress.completed + job.progress.failed) / job.progress.total) * 100
    );
    console.log(`[SPLICE] Batch ${jobId}: ${job.progress.completed + job.progress.failed}/${job.files.length} processed`);
  }

  // Mark job as complete
  job.status = job.progress.failed === job.progress.total ? 'failed' :
               job.progress.failed > 0 ? 'completed_with_errors' : 'completed';
  job.completedAt = new Date().toISOString();

  console.log(`[SPLICE] Batch job ${jobId} ${job.status}`);
}

/**
 * GET /batch/status/:jobId - Get batch job status and results
 * Requires x-stripe-customer-id header matching job owner
 */
app.get('/batch/status/:jobId', (req, res) => {
  const { jobId } = req.params;
  const stripeCustomerId = req.headers['x-stripe-customer-id'];
  const job = batchJobs.get(jobId);

  if (!job) {
    return res.status(404).json({ error: 'Job not found' });
  }

  // Verify customer ownership
  if (job.stripeCustomerId && job.stripeCustomerId !== stripeCustomerId) {
    return res.status(403).json({ error: 'Access denied: Job belongs to another user' });
  }

  res.json({
    success: true,
    job: {
      id: job.id,
      type: job.type,
      status: job.status,
      createdAt: job.createdAt,
      completedAt: job.completedAt,
      progress: job.progress,
      files: job.files.map(f => ({
        path: f.path,
        status: f.status,
        silenceCount: f.result?.count,
        error: f.error
      }))
    }
  });
});

/**
 * GET /batch/results/:jobId - Get full results for a completed batch job
 * Requires x-stripe-customer-id header matching job owner
 */
app.get('/batch/results/:jobId', (req, res) => {
  const { jobId } = req.params;
  const stripeCustomerId = req.headers['x-stripe-customer-id'];
  const job = batchJobs.get(jobId);

  if (!job) {
    return res.status(404).json({ error: 'Job not found' });
  }

  // Verify customer ownership
  if (job.stripeCustomerId && job.stripeCustomerId !== stripeCustomerId) {
    return res.status(403).json({ error: 'Access denied: Job belongs to another user' });
  }

  if (job.status === 'processing') {
    return res.status(202).json({
      success: false,
      message: 'Job still processing',
      progress: job.progress
    });
  }

  res.json({
    success: true,
    jobId: job.id,
    status: job.status,
    progress: job.progress,
    results: job.results,
    errors: job.errors,
    summary: {
      totalFiles: job.progress.total,
      successful: job.progress.completed,
      failed: job.progress.failed,
      totalSilences: job.results.reduce((sum, r) => sum + (r.count || 0), 0),
      totalSilenceDuration: job.results.reduce((sum, r) => sum + (r.totalSilenceDuration || 0), 0)
    }
  });
});

/**
 * DELETE /batch/:jobId - Cancel or delete a batch job
 * Requires x-stripe-customer-id header matching job owner
 */
app.delete('/batch/:jobId', (req, res) => {
  const { jobId } = req.params;
  const stripeCustomerId = req.headers['x-stripe-customer-id'];
  const job = batchJobs.get(jobId);

  if (!job) {
    return res.status(404).json({ error: 'Job not found' });
  }

  // Verify customer ownership
  if (job.stripeCustomerId && job.stripeCustomerId !== stripeCustomerId) {
    return res.status(403).json({ error: 'Access denied: Job belongs to another user' });
  }

  // Note: This doesn't actually cancel in-progress processing
  // but prevents the job from being queried
  batchJobs.delete(jobId);

  res.json({
    success: true,
    message: `Job ${jobId} deleted`
  });
});

/**
 * GET /batch/jobs - List batch jobs for authenticated user
 * Requires x-stripe-customer-id header to filter jobs by owner
 */
app.get('/batch/jobs', (req, res) => {
  const stripeCustomerId = req.headers['x-stripe-customer-id'];

  // Filter jobs by customer ownership (only show user's own jobs)
  const jobs = Array.from(batchJobs.values())
    .filter(job => !job.stripeCustomerId || job.stripeCustomerId === stripeCustomerId)
    .map(job => ({
      id: job.id,
      type: job.type,
      status: job.status,
      createdAt: job.createdAt,
      completedAt: job.completedAt,
      progress: job.progress
    }));

  // Sort by creation date (newest first)
  jobs.sort((a, b) => new Date(b.createdAt) - new Date(a.createdAt));

  res.json({
    success: true,
    count: jobs.length,
    jobs
  });
});

// =============================================================================
// Authentication Routes
// =============================================================================

/**
 * POST /auth/login - Authenticate with license key and get JWT token
 *
 * SECURITY: This is the primary authentication endpoint.
 * Validates license key and returns a JWT token for API access.
 */
app.post('/auth/login', async (req, res) => {
  const { licenseKey } = req.body;

  if (!licenseKey) {
    return res.status(400).json({
      error: 'License key required',
      message: 'Please provide your license key to log in'
    });
  }

  try {
    // Validate and activate the license key
    const licenseResult = await licenseService.activateLicense(licenseKey);

    if (!licenseResult.success) {
      console.log(`[Auth] Failed login attempt with key: ${maskSensitiveData(licenseKey)}`);
      return res.status(401).json({
        error: 'Invalid license key',
        message: licenseResult.error || 'The license key is invalid or expired'
      });
    }

    // Get user's tier and balance
    const balance = await usageTracking.getBalance(licenseResult.customerId);

    // Generate JWT tokens
    const tokenResult = generateToken(licenseResult.customerId, {
      tier: balance.tier,
      email: licenseResult.email
    });
    const refreshResult = generateRefreshToken(licenseResult.customerId);

    console.log(`[Auth] Successful login for ${maskSensitiveData(licenseResult.customerId)}`);

    res.json({
      success: true,
      token: tokenResult.token,
      tokenType: tokenResult.tokenType,
      expiresIn: tokenResult.expiresIn,
      refreshToken: refreshResult.refreshToken,
      customerId: licenseResult.customerId,
      tier: balance.tier,
      hoursRemaining: balance.hoursRemaining
    });
  } catch (err) {
    console.error('[Auth] Login error:', err.message);
    res.status(500).json({ error: 'Authentication failed. Please try again.' });
  }
});

/**
 * POST /auth/refresh - Refresh an expired JWT token
 *
 * Uses a refresh token to get a new access token
 */
app.post('/auth/refresh', async (req, res) => {
  const { refreshToken } = req.body;

  if (!refreshToken) {
    return res.status(400).json({
      error: 'Refresh token required'
    });
  }

  try {
    const decoded = verifyToken(refreshToken);

    if (!decoded || decoded.type !== 'refresh') {
      return res.status(401).json({
        error: 'Invalid refresh token',
        message: 'Please log in again'
      });
    }

    // Get current user info
    const balance = await usageTracking.getBalance(decoded.sub);

    // Generate new access token
    const tokenResult = generateToken(decoded.sub, {
      tier: balance.tier
    });

    console.log(`[Auth] Token refreshed for ${maskSensitiveData(decoded.sub)}`);

    res.json({
      success: true,
      token: tokenResult.token,
      tokenType: tokenResult.tokenType,
      expiresIn: tokenResult.expiresIn
    });
  } catch (err) {
    console.error('[Auth] Token refresh error:', err.message);
    res.status(401).json({
      error: 'Failed to refresh token',
      message: 'Please log in again'
    });
  }
});

/**
 * POST /auth/logout - Invalidate tokens (client-side)
 *
 * Note: JWT tokens are stateless, so this is primarily for logging
 * and future token blacklisting if needed.
 */
app.post('/auth/logout', authenticateToken, (req, res) => {
  console.log(`[Auth] Logout for ${maskSensitiveData(req.stripeCustomerId)}`);

  // TODO: If implementing token blacklisting, add token to blacklist here

  res.json({
    success: true,
    message: 'Logged out successfully'
  });
});

// =============================================================================
// Billing & Credits Routes
// =============================================================================

/**
 * GET /credits - Get user's credit balance
 *
 * Supports both JWT (Authorization: Bearer) and legacy x-stripe-customer-id header
 */
app.get('/credits', async (req, res) => {
  // Support both JWT and legacy auth
  let stripeCustomerId = null;

  // Try JWT first
  const authHeader = req.headers['authorization'];
  if (authHeader && authHeader.startsWith('Bearer ')) {
    const token = authHeader.slice(7);
    const decoded = verifyToken(token);
    if (decoded && decoded.sub) {
      stripeCustomerId = decoded.sub;
    }
  }

  // Fallback to legacy header
  if (!stripeCustomerId) {
    stripeCustomerId = req.headers['x-stripe-customer-id'];
  }

  if (!stripeCustomerId) {
    return res.status(401).json({
      error: 'Authentication required',
      message: 'Please provide a valid Bearer token or log in again'
    });
  }

  try {
    const balance = await usageTracking.getBalance(stripeCustomerId);
    res.json({
      success: true,
      ...balance
    });
  } catch (err) {
    console.error('[SPLICE] Credits error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * GET /usage-history - Get user's usage history
 */
app.get('/usage-history', async (req, res) => {
  // Support both JWT and legacy auth
  let stripeCustomerId = null;

  const authHeader = req.headers['authorization'];
  if (authHeader && authHeader.startsWith('Bearer ')) {
    const token = authHeader.slice(7);
    const decoded = verifyToken(token);
    if (decoded && decoded.sub) {
      stripeCustomerId = decoded.sub;
    }
  }

  if (!stripeCustomerId) {
    stripeCustomerId = req.headers['x-stripe-customer-id'];
  }

  if (!stripeCustomerId) {
    return res.status(401).json({
      error: 'Authentication required',
      message: 'Please provide a valid Bearer token or log in again'
    });
  }

  try {
    const history = await usageTracking.getUsageHistory(stripeCustomerId);
    res.json({
      success: true,
      history
    });
  } catch (err) {
    console.error('[SPLICE] Usage history error:', err);
    res.status(500).json({ error: err.message });
  }
});

// =============================================================================
// Referral System Endpoints
// =============================================================================

/**
 * GET /referral/code - Get or create referral code for user
 *
 * Requires x-stripe-customer-id header
 */
app.get('/referral/code', async (req, res) => {
  const stripeCustomerId = req.headers['x-stripe-customer-id'];

  if (!stripeCustomerId) {
    return res.status(401).json({
      error: 'Authentication required',
      message: 'Missing x-stripe-customer-id header'
    });
  }

  try {
    const codeInfo = await referralService.getOrCreateCode(stripeCustomerId);
    res.json({
      success: true,
      ...codeInfo
    });
  } catch (err) {
    console.error('[SPLICE] Referral code error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /referral/validate - Validate a referral code
 *
 * Body: { code: string, customerId?: string }
 */
app.post('/referral/validate', async (req, res) => {
  const { code, customerId } = req.body;

  if (!code) {
    return res.status(400).json({
      error: 'Missing code',
      message: 'Referral code is required'
    });
  }

  try {
    const result = await referralService.validateCode(code, customerId);
    res.json({
      success: true,
      ...result
    });
  } catch (err) {
    console.error('[SPLICE] Referral validate error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /referral/apply - Apply referral code at signup
 *
 * Body: { code: string, customerId: string }
 */
app.post('/referral/apply', async (req, res) => {
  const { code, customerId } = req.body;

  if (!code || !customerId) {
    return res.status(400).json({
      error: 'Missing required fields',
      message: 'Both code and customerId are required'
    });
  }

  try {
    const result = await referralService.applyCode(code, customerId, stripe);
    res.json({
      success: true,
      ...result
    });
  } catch (err) {
    console.error('[SPLICE] Referral apply error:', err);
    // Return user-friendly errors for validation failures
    if (err.message.includes('Cannot use your own') ||
        err.message.includes('already used') ||
        err.message.includes('not found') ||
        err.message.includes('no longer active')) {
      return res.status(400).json({ error: err.message });
    }
    res.status(500).json({ error: err.message });
  }
});

/**
 * GET /referral/stats - Get referral statistics for user
 *
 * Requires x-stripe-customer-id header
 */
app.get('/referral/stats', async (req, res) => {
  const stripeCustomerId = req.headers['x-stripe-customer-id'];

  if (!stripeCustomerId) {
    return res.status(401).json({
      error: 'Authentication required',
      message: 'Missing x-stripe-customer-id header'
    });
  }

  try {
    const stats = await referralService.getStats(stripeCustomerId);
    res.json({
      success: true,
      ...stats
    });
  } catch (err) {
    console.error('[SPLICE] Referral stats error:', err);
    res.status(500).json({ error: err.message });
  }
});

// =============================================================================
// License Key Endpoints
// =============================================================================

/**
 * POST /license/activate - Activate a license key
 *
 * Body: { key: "SPLICE-XXXX-XXXX-XXXX" }
 * Returns: { success, customerId, tier, hoursRemaining }
 */
app.post('/license/activate', async (req, res) => {
  const { key } = req.body;

  if (!key) {
    return res.status(400).json({
      error: 'Missing license key',
      message: 'License key is required'
    });
  }

  // Validate format
  if (!licenseService.isValidKeyFormat(key)) {
    return res.status(400).json({
      error: 'Invalid license key format',
      message: 'License key should be in format: SPLICE-XXXX-XXXX-XXXX'
    });
  }

  try {
    // Activate the key
    const result = await licenseService.activateLicenseKey(key);

    if (!result.success) {
      return res.status(400).json({
        success: false,
        error: result.error
      });
    }

    // Get the customer's balance and tier info
    const balance = await usageTracking.getBalance(result.customerId);

    res.json({
      success: true,
      customerId: result.customerId,
      tier: balance.tier,
      tierName: balance.tierName,
      hoursRemaining: balance.hoursRemaining,
      hoursTotal: balance.hoursTotal
    });
  } catch (err) {
    console.error('[SPLICE] License activation error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * GET /license/key - Get license key for a customer (for display/resend)
 *
 * Requires x-stripe-customer-id header
 */
app.get('/license/key', async (req, res) => {
  const stripeCustomerId = req.headers['x-stripe-customer-id'];

  if (!stripeCustomerId) {
    return res.status(401).json({
      error: 'Authentication required',
      message: 'Missing x-stripe-customer-id header'
    });
  }

  try {
    const result = await licenseService.getLicenseByCustomerId(stripeCustomerId);

    if (!result.success) {
      return res.status(404).json({
        success: false,
        error: result.error
      });
    }

    res.json({
      success: true,
      key: result.key,
      activated: result.activated,
      createdAt: result.createdAt
    });
  } catch (err) {
    console.error('[SPLICE] License lookup error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /license/resend - Resend license key to customer email
 *
 * For support cases where customer didn't receive their license key.
 * Requires x-stripe-customer-id header or customerId in body (for support).
 */
app.post('/license/resend', async (req, res) => {
  // Allow customerId from header or body (for support staff)
  const stripeCustomerId = req.headers['x-stripe-customer-id'] || req.body.customerId;

  if (!stripeCustomerId) {
    return res.status(401).json({
      error: 'Authentication required',
      message: 'Missing customer ID'
    });
  }

  try {
    // Get existing license key
    const licenseResult = await licenseService.getLicenseByCustomerId(stripeCustomerId);

    if (!licenseResult.success) {
      // No license exists - try to generate one
      console.log(`[SPLICE] No license found for ${stripeCustomerId}, generating new one`);
      const newLicense = await licenseService.generateLicenseKey(stripeCustomerId);

      if (!newLicense.success) {
        return res.status(500).json({
          success: false,
          error: 'Failed to generate license key',
          details: newLicense.error
        });
      }

      licenseResult.key = newLicense.key;
      licenseResult.success = true;
    }

    // Get customer email from Stripe
    let customerEmail = null;
    try {
      const customer = await stripe.customers.retrieve(stripeCustomerId);
      customerEmail = customer.email;
    } catch (stripeErr) {
      console.error(`[SPLICE] Failed to get customer email:`, stripeErr.message);
    }

    if (!customerEmail) {
      return res.status(400).json({
        success: false,
        error: 'No email address found for customer',
        key: licenseResult.key, // Still return key for manual delivery
        manualDeliveryRequired: true
      });
    }

    // SECURITY: Mask sensitive data in logs
    console.log(`[SPLICE] License key resend requested for ${maskSensitiveData(customerEmail)}: ${maskSensitiveData(licenseResult.key)}`);
    // TODO: Integrate with email service
    // await sendLicenseKeyEmail(customerEmail, licenseResult.key);

    res.json({
      success: true,
      message: `License key will be sent to ${customerEmail}`,
      email: customerEmail,
      key: licenseResult.key, // Include key for immediate display
      activated: licenseResult.activated
    });
  } catch (err) {
    console.error('[SPLICE] License resend error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /license/lookup - Look up license key by email address
 *
 * SECURITY: Does NOT return the license key in the response.
 * Instead, sends the key via email to the verified email address.
 * This prevents attackers from obtaining keys by guessing email addresses.
 */
app.post('/license/lookup', async (req, res) => {
  const { email } = req.body;

  if (!email) {
    return res.status(400).json({
      error: 'Email address required'
    });
  }

  // Validate email format
  const emailRegex = /^[^\s@]+@[^\s@]+\.[^\s@]+$/;
  if (!emailRegex.test(email)) {
    return res.status(400).json({
      error: 'Invalid email format'
    });
  }

  try {
    // Look up customer by email in Stripe
    const customers = await stripe.customers.list({
      email: email.toLowerCase(),
      limit: 1
    });

    if (customers.data.length === 0) {
      // SECURITY: Don't reveal if email exists in our system
      // Always return same success message to prevent enumeration
      console.log(`[SPLICE] License lookup attempt for unknown email: ${maskSensitiveData(email)}`);
      return res.json({
        success: true,
        message: 'If an account exists with this email, the license key will be sent shortly.',
        emailSent: true
      });
    }

    const customer = customers.data[0];

    // Get license key for this customer
    let licenseResult = await licenseService.getLicenseByCustomerId(customer.id);

    if (!licenseResult.success) {
      // Check if they have an active subscription before generating key
      const subscriptions = await stripe.subscriptions.list({
        customer: customer.id,
        status: 'active',
        limit: 1
      });

      if (subscriptions.data.length === 0) {
        // SECURITY: Same message to prevent enumeration
        console.log(`[SPLICE] License lookup - no active subscription for: ${maskSensitiveData(email)}`);
        return res.json({
          success: true,
          message: 'If an account exists with this email, the license key will be sent shortly.',
          emailSent: true
        });
      }

      // Generate a new license key for active subscriber without one
      const newLicense = await licenseService.generateLicenseKey(customer.id);
      if (!newLicense.success) {
        console.error(`[SPLICE] Failed to generate license key for ${maskSensitiveData(customer.id)}`);
        return res.status(500).json({
          success: false,
          error: 'Failed to process request. Please try again later.'
        });
      }
      licenseResult = newLicense;
    }

    // SECURITY: Log the lookup (masked) and send via email
    console.log(`[SPLICE] License key lookup for ${maskSensitiveData(email)} - sending via email`);

    // TODO: Integrate with email service (SendGrid, SES, etc.)
    // await sendLicenseKeyEmail(email, licenseResult.key);

    // SECURITY: Never return the key in the response
    // Always send via email to the verified address
    res.json({
      success: true,
      message: 'Your license key has been sent to your email address. Please check your inbox (and spam folder).',
      emailSent: true,
      // Hint at activation status without revealing the key
      hint: licenseResult.activated
        ? 'Note: Your license is already activated on a device.'
        : null
    });
  } catch (err) {
    console.error('[SPLICE] License lookup error:', err.message);
    res.status(500).json({ error: 'Failed to process request. Please try again later.' });
  }
});

// =============================================================================
// AI Music Generation Endpoints (Phase 8 - AI Music Feature)
// =============================================================================

// Import music services (lazy load to prevent startup failures if deps missing)
let musicQueue, songIdentification, musicGeneration, r2Storage, musicAlignment, musicTimeline;
try {
  musicQueue = require('./services/musicQueue');
  songIdentification = require('./services/songIdentification');
  musicGeneration = require('./services/musicGeneration');
  r2Storage = require('./services/r2Storage');
  musicAlignment = require('./services/musicAlignment');
  musicTimeline = require('./services/musicTimeline');
} catch (err) {
  console.warn('[SPLICE] Music services not available:', err.message);
}

// POST /music/identify - Identify song from YouTube URL
app.post('/music/identify', requireCredits, async (req, res) => {
  const { youtubeUrl } = req.body;

  if (!youtubeUrl) {
    return res.status(400).json({ error: 'youtubeUrl is required' });
  }

  if (!songIdentification) {
    return res.status(503).json({ error: 'Song identification service not available' });
  }

  try {
    // Validate URL
    const validation = songIdentification.validateYouTubeUrl(youtubeUrl);
    if (!validation.valid) {
      return res.status(400).json({ error: validation.error });
    }

    // Check dependencies
    const deps = await songIdentification.checkDependencies();
    if (!deps.ytdlp) {
      return res.status(503).json({ error: 'yt-dlp is not installed on server' });
    }
    if (!deps.ffmpeg) {
      return res.status(503).json({ error: 'FFmpeg is not installed on server' });
    }

    // Check ACRCloud credentials
    if (!songIdentification.hasACRCloudCredentials()) {
      return res.status(503).json({ error: 'ACRCloud credentials not configured' });
    }

    // Identify song
    const result = await songIdentification.identifyFromYouTube(youtubeUrl);

    res.json(result);

  } catch (err) {
    console.error('[SPLICE] Song identification error:', err.message);
    res.status(500).json({ error: err.message || 'Song identification failed' });
  }
});

// POST /music/generate - Start music generation job
app.post('/music/generate', requireCredits, async (req, res) => {
  const { youtubeUrl, prompt, duration, mood, instruments, referenceSong } = req.body;
  const customerId = req.stripeCustomerId;

  if (!customerId) {
    return res.status(401).json({ error: 'Authentication required' });
  }

  if (!musicQueue) {
    return res.status(503).json({ error: 'Music generation service not available' });
  }

  try {
    // Validate options if musicGeneration is available
    if (musicGeneration) {
      const validation = musicGeneration.validateOptions({ duration, mood, instruments });
      if (!validation.valid) {
        return res.status(400).json({ error: validation.errors.join(', ') });
      }
    }

    // Add job to queue
    const result = await musicQueue.addMusicJob({
      customerId,
      youtubeUrl,
      prompt,
      duration: duration || 60,
      mood: mood || 'neutral',
      instruments: instruments || [],
      referenceSong
    });

    res.json({
      success: true,
      jobId: result.jobId,
      status: result.status,
      estimatedTime: result.estimatedTime,
      statusUrl: `/music/status/${result.jobId}`
    });

  } catch (err) {
    console.error('[SPLICE] Music generation error:', err.message);
    res.status(500).json({ error: err.message || 'Failed to start music generation' });
  }
});

// POST /music/generate-variations - Generate 3 song variations for user selection
app.post('/music/generate-variations', requireCredits, async (req, res) => {
  const { prompt, duration, mood, instruments, referenceSong } = req.body;
  const customerId = req.stripeCustomerId;

  if (!customerId) {
    return res.status(401).json({ error: 'Authentication required' });
  }

  if (!musicQueue) {
    return res.status(503).json({ error: 'Music generation service not available' });
  }

  try {
    // Validate options if musicGeneration is available
    if (musicGeneration) {
      const validation = musicGeneration.validateOptions({ duration, mood, instruments });
      if (!validation.valid) {
        return res.status(400).json({ error: validation.errors.join(', ') });
      }
    }

    // Check for variations credits (2.5 credits = 3 music credits equivalent)
    const usageTracking = require('./services/usageTracking');
    const hasCredits = await usageTracking.checkVariationsCredits(customerId);
    if (!hasCredits.canGenerate) {
      return res.status(402).json({
        error: 'Insufficient credits for variations',
        creditsRequired: 2.5,
        creditsAvailable: hasCredits.creditsAvailable
      });
    }

    // Add variations job to queue
    const result = await musicQueue.addVariationsJob({
      customerId,
      prompt,
      duration: duration || 60,
      mood: mood || 'neutral',
      instruments: instruments || [],
      referenceSong
    });

    res.json({
      success: true,
      jobId: result.jobId,
      status: result.status,
      isVariations: true,
      estimatedTime: result.estimatedTime,
      statusUrl: `/music/variations/status/${result.jobId}`
    });

  } catch (err) {
    console.error('[SPLICE] Music variations error:', err.message);
    res.status(500).json({ error: err.message || 'Failed to start variations generation' });
  }
});

// POST /music/generate-scene-aware - Generate music with transcript analysis
app.post('/music/generate-scene-aware', requireCredits, async (req, res) => {
  const { segments, prompt, duration, mood, instruments, referenceSong } = req.body;
  const customerId = req.stripeCustomerId;

  if (!customerId) {
    return res.status(401).json({ error: 'Authentication required' });
  }

  if (!musicQueue) {
    return res.status(503).json({ error: 'Music generation service not available' });
  }

  // Validate segments
  if (!segments || !Array.isArray(segments) || segments.length === 0) {
    return res.status(400).json({ error: 'Transcript segments are required' });
  }

  try {
    // Validate scene-aware options
    if (musicGeneration) {
      const validation = musicGeneration.validateSceneAwareOptions(segments, { duration, mood, instruments });
      if (!validation.valid) {
        return res.status(400).json({ error: validation.errors.join(', ') });
      }
    }

    // Check for scene-aware credits (1.5 credits)
    const hasCredits = await usageTracking.checkSceneAwareCredits(customerId);
    if (!hasCredits.canGenerate) {
      return res.status(402).json({
        error: 'Insufficient credits for scene-aware music',
        creditsRequired: 1.5,
        creditsAvailable: hasCredits.creditsAvailable
      });
    }

    // Add scene-aware job to queue with scene analysis flag
    const result = await musicQueue.addMusicJob({
      customerId,
      prompt,
      duration: duration || 60,
      mood: mood || 'neutral',
      instruments: instruments || [],
      referenceSong,
      isSceneAware: true,
      segments
    });

    res.json({
      success: true,
      jobId: result.jobId,
      status: result.status,
      isSceneAware: true,
      estimatedTime: result.estimatedTime,
      statusUrl: `/music/status/${result.jobId}`
    });

  } catch (err) {
    console.error('[SPLICE] Scene-aware music error:', err.message);
    res.status(500).json({ error: err.message || 'Failed to start scene-aware music generation' });
  }
});

// GET /music/variations/status/:jobId - Get variations job status with detailed progress
app.get('/music/variations/status/:jobId', requireCredits, async (req, res) => {
  const { jobId } = req.params;
  const customerId = req.stripeCustomerId;

  if (!musicQueue) {
    return res.status(503).json({ error: 'Music generation service not available' });
  }

  try {
    const status = await musicQueue.getVariationsJobStatus(jobId);

    if (!status) {
      return res.status(404).json({ error: 'Job not found' });
    }

    // Verify ownership
    if (status.data.customerId !== customerId) {
      return res.status(403).json({ error: 'Not authorized to access this job' });
    }

    res.json(status);

  } catch (err) {
    console.error('[SPLICE] Variations status error:', err.message);
    res.status(500).json({ error: err.message || 'Failed to get job status' });
  }
});

// POST /music/variations/:jobId/select - Select a variation to finalize
app.post('/music/variations/:jobId/select', requireCredits, async (req, res) => {
  const { jobId } = req.params;
  const { variationIndex } = req.body;
  const customerId = req.stripeCustomerId;

  if (!musicQueue) {
    return res.status(503).json({ error: 'Music generation service not available' });
  }

  if (variationIndex === undefined || variationIndex === null) {
    return res.status(400).json({ error: 'variationIndex is required' });
  }

  const index = parseInt(variationIndex);
  if (isNaN(index) || index < 0 || index > 2) {
    return res.status(400).json({ error: 'variationIndex must be 0, 1, or 2' });
  }

  try {
    // Select the variation
    const result = await musicQueue.selectVariation(jobId, index, customerId);

    // Deduct variations credits (2.5 credits)
    const usageTracking = require('./services/usageTracking');
    await usageTracking.deductVariationsCredit(customerId);

    res.json({
      success: true,
      ...result
    });

  } catch (err) {
    console.error('[SPLICE] Variation selection error:', err.message);
    res.status(500).json({ error: err.message || 'Failed to select variation' });
  }
});

// GET /music/status/:jobId - Get job status
app.get('/music/status/:jobId', requireCredits, async (req, res) => {
  const { jobId } = req.params;
  const customerId = req.stripeCustomerId;

  if (!musicQueue) {
    return res.status(503).json({ error: 'Music generation service not available' });
  }

  try {
    const status = await musicQueue.getJobStatus(jobId);

    if (!status) {
      return res.status(404).json({ error: 'Job not found' });
    }

    // Verify ownership
    if (status.data.customerId !== customerId) {
      return res.status(403).json({ error: 'Access denied' });
    }

    res.json(status);

  } catch (err) {
    console.error('[SPLICE] Job status error:', err.message);
    res.status(500).json({ error: err.message || 'Failed to get job status' });
  }
});

// GET /music/library - Get user's music library
app.get('/music/library', requireCredits, async (req, res) => {
  const customerId = req.stripeCustomerId;

  if (!customerId) {
    return res.status(401).json({ error: 'Authentication required' });
  }

  if (!musicQueue) {
    return res.status(503).json({ error: 'Music generation service not available' });
  }

  try {
    const jobs = await musicQueue.getCustomerJobs(customerId, {
      limit: parseInt(req.query.limit) || 50,
      offset: parseInt(req.query.offset) || 0
    });

    // Filter to only completed jobs for library
    const library = jobs.filter(j => j.status === 'completed');

    res.json(library);

  } catch (err) {
    console.error('[SPLICE] Music library error:', err.message);
    res.status(500).json({ error: err.message || 'Failed to load music library' });
  }
});

// GET /music/:jobId - Get music with signed download URL
app.get('/music/:jobId', requireCredits, async (req, res) => {
  const { jobId } = req.params;
  const customerId = req.stripeCustomerId;

  if (!musicQueue || !r2Storage) {
    return res.status(503).json({ error: 'Music service not available' });
  }

  try {
    const status = await musicQueue.getJobStatus(jobId);

    if (!status) {
      return res.status(404).json({ error: 'Music not found' });
    }

    // Verify ownership
    if (status.data.customerId !== customerId) {
      return res.status(403).json({ error: 'Access denied' });
    }

    if (status.status !== 'completed') {
      return res.status(400).json({ error: 'Music generation not complete' });
    }

    // Generate signed download URLs
    const masterKey = r2Storage.generateStorageKey(customerId, jobId, 'master.wav');
    const previewKey = r2Storage.generateStorageKey(customerId, jobId, 'preview.mp3');

    const [downloadUrl, previewUrl] = await Promise.all([
      r2Storage.getSignedDownloadUrl(masterKey, 3600), // 1 hour
      r2Storage.getSignedDownloadUrl(previewKey, 3600).catch(() => null)
    ]);

    res.json({
      success: true,
      music: {
        jobId,
        title: status.data.musicResult?.title || 'Generated Music',
        duration: status.data.duration,
        mood: status.data.mood,
        downloadUrl,
        previewUrl,
        createdAt: status.createdAt,
        completedAt: status.completedAt
      }
    });

  } catch (err) {
    console.error('[SPLICE] Get music error:', err.message);
    res.status(500).json({ error: err.message || 'Failed to get music' });
  }
});

// DELETE /music/:jobId - Delete music from library
app.delete('/music/:jobId', requireCredits, async (req, res) => {
  const { jobId } = req.params;
  const customerId = req.stripeCustomerId;

  if (!musicQueue || !r2Storage) {
    return res.status(503).json({ error: 'Music service not available' });
  }

  try {
    const status = await musicQueue.getJobStatus(jobId);

    if (!status) {
      return res.status(404).json({ error: 'Music not found' });
    }

    // Verify ownership
    if (status.data.customerId !== customerId) {
      return res.status(403).json({ error: 'Access denied' });
    }

    // Delete from R2
    await r2Storage.deleteJobFiles(customerId, jobId);

    // Note: Job record stays in Redis for history
    // Could optionally call musicQueue.cancelJob if we want to remove it

    res.json({ success: true, message: 'Music deleted' });

  } catch (err) {
    console.error('[SPLICE] Delete music error:', err.message);
    res.status(500).json({ error: err.message || 'Failed to delete music' });
  }
});

// GET /music/credits - Get music credits balance
app.get('/music/credits', requireCredits, async (req, res) => {
  const customerId = req.stripeCustomerId;

  if (!customerId) {
    return res.status(401).json({ error: 'Authentication required' });
  }

  try {
    // Get credits from database using usageTracking
    const credits = await usageTracking.getMusicCredits(customerId);

    res.json(credits);

  } catch (err) {
    console.error('[SPLICE] Music credits error:', err.message);
    res.status(500).json({ error: err.message || 'Failed to get credits' });
  }
});

// GET /music/moods - Get available mood presets
app.get('/music/moods', (req, res) => {
  if (!musicGeneration) {
    return res.status(503).json({ error: 'Music service not available' });
  }

  res.json(musicGeneration.getAvailableMoods());
});

// GET /music/instruments - Get available instrument presets
app.get('/music/instruments', (req, res) => {
  if (!musicGeneration) {
    return res.status(503).json({ error: 'Music service not available' });
  }

  res.json(musicGeneration.getAvailableInstruments());
});

// GET /music/queue-stats - Get queue statistics (admin only)
app.get('/music/queue-stats', requireCredits, async (req, res) => {
  if (!musicQueue) {
    return res.status(503).json({ error: 'Music service not available' });
  }

  try {
    const stats = await musicQueue.getQueueStats();
    res.json(stats);
  } catch (err) {
    console.error('[SPLICE] Queue stats error:', err.message);
    res.status(500).json({ error: err.message || 'Failed to get queue stats' });
  }
});

// POST /music/align - Align music to video duration with beat-matching
app.post('/music/align', requireCredits, async (req, res) => {
  const { jobId, targetDuration, fadeDuration, beatAlign = true, searchWindow } = req.body;
  const customerId = req.customerId;

  if (!jobId) {
    return res.status(400).json({ error: 'jobId is required' });
  }

  if (!targetDuration || typeof targetDuration !== 'number') {
    return res.status(400).json({ error: 'targetDuration (number in seconds) is required' });
  }

  if (!musicAlignment || !musicQueue || !r2Storage) {
    return res.status(503).json({ error: 'Music alignment service not available' });
  }

  try {
    // Validate options
    const validation = musicAlignment.validateAlignmentOptions({
      targetDuration,
      fadeDuration,
      searchWindow
    });
    if (!validation.valid) {
      return res.status(400).json({ error: validation.errors.join(', ') });
    }

    // Get job and verify ownership
    const job = await musicQueue.getJobStatus(jobId);
    if (!job) {
      return res.status(404).json({ error: 'Job not found' });
    }
    if (job.customerId !== customerId) {
      return res.status(403).json({ error: 'Access denied' });
    }
    if (job.status !== 'completed') {
      return res.status(400).json({ error: 'Job must be completed before alignment' });
    }

    // Download the master audio from R2
    const masterKey = r2Storage.generateStorageKey(customerId, jobId, 'master.wav');
    const audioBuffer = await r2Storage.downloadFile(masterKey);

    // Perform alignment with beat detection
    const result = await musicAlignment.trimToLength(audioBuffer, targetDuration, {
      fadeDuration: fadeDuration || musicAlignment.DEFAULT_FADE_DURATION,
      beatAlign,
      searchWindow: searchWindow || musicAlignment.BEAT_SEARCH_WINDOW
    });

    // Generate aligned file key
    const alignedKey = r2Storage.generateStorageKey(customerId, jobId, `aligned_${Math.round(targetDuration)}s.wav`);

    // Upload aligned audio to R2
    await r2Storage.uploadBuffer(alignedKey, result.buffer, 'audio/wav');

    // Get signed URL for download
    const downloadUrl = await r2Storage.getSignedDownloadUrl(alignedKey, 3600);

    res.json({
      success: true,
      jobId,
      targetDuration,
      actualDuration: result.cutTime,
      wasAligned: result.wasAligned,
      beatCount: result.beats.length,
      downloadUrl,
      alignedKey
    });

  } catch (err) {
    console.error('[SPLICE] Music align error:', err.message);
    res.status(500).json({ error: err.message || 'Failed to align music' });
  }
});

// POST /music/analyze-beats - Analyze beats in audio without trimming
app.post('/music/analyze-beats', requireCredits, async (req, res) => {
  const { jobId } = req.body;
  const customerId = req.customerId;

  if (!jobId) {
    return res.status(400).json({ error: 'jobId is required' });
  }

  if (!musicAlignment || !musicQueue || !r2Storage) {
    return res.status(503).json({ error: 'Music alignment service not available' });
  }

  try {
    // Get job and verify ownership
    const job = await musicQueue.getJobStatus(jobId);
    if (!job) {
      return res.status(404).json({ error: 'Job not found' });
    }
    if (job.customerId !== customerId) {
      return res.status(403).json({ error: 'Access denied' });
    }
    if (job.status !== 'completed') {
      return res.status(400).json({ error: 'Job must be completed before analysis' });
    }

    // Download the master audio from R2
    const masterKey = r2Storage.generateStorageKey(customerId, jobId, 'master.wav');
    const audioBuffer = await r2Storage.downloadFile(masterKey);

    // Analyze beats
    const analysis = await musicAlignment.analyzeBeats(audioBuffer);

    res.json({
      success: true,
      jobId,
      duration: analysis.duration,
      beatCount: analysis.beatCount,
      bpm: analysis.bpm,
      beats: analysis.beats
    });

  } catch (err) {
    console.error('[SPLICE] Beat analysis error:', err.message);
    res.status(500).json({ error: err.message || 'Failed to analyze beats' });
  }
});

// GET /music/alignment-options - Get alignment configuration options
app.get('/music/alignment-options', (req, res) => {
  if (!musicAlignment) {
    return res.status(503).json({ error: 'Music alignment service not available' });
  }

  res.json({
    fadeDuration: {
      default: musicAlignment.DEFAULT_FADE_DURATION,
      min: musicAlignment.MIN_FADE_DURATION,
      max: musicAlignment.MAX_FADE_DURATION
    },
    searchWindow: {
      default: musicAlignment.BEAT_SEARCH_WINDOW,
      min: 0.5,
      max: 10
    },
    minAudioDuration: musicAlignment.MIN_AUDIO_DURATION
  });
});

// =============================================================================
// Start Server
// =============================================================================

// Initialize database and start server
async function startServer() {
  try {
    await usageTracking.initDatabase();
    await referralService.initReferralTables();
    await licenseService.initLicenseTables();
    console.log('[SPLICE] Database initialized');

    // PERF-FIX: Initialize static response cache at startup
    initializeStaticCache();

    if (isProduction || !httpsOptions) {
      // Production: Railway provides TLS termination, use HTTP
      http.createServer(app).listen(PORT, () => {
        console.log(`[SPLICE] Backend running at http://0.0.0.0:${PORT} (production)`);
      });
    } else {
      // Development: Use HTTPS with local certificates
      https.createServer(httpsOptions, app).listen(PORT, () => {
        console.log(`[SPLICE] Backend running at https://127.0.0.1:${PORT} (development)`);
        console.log(`[SPLICE] POST /analyze with { "wavPath": "/path/to/audio.wav" }`);
      });
    }
  } catch (err) {
    console.error('[SPLICE] Failed to start server:', err);
    process.exit(1);
  }
}

startServer();
