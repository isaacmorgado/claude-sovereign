/**
 * MediaPipe Face Mesh Detection Utility
 * Maps MediaPipe's 468 landmarks to our custom facial landmarks
 */

// MediaPipe landmark indices for front profile
// Reference: https://github.com/google/mediapipe/blob/master/mediapipe/modules/face_geometry/data/canonical_face_model_uv_visualization.png
export const MEDIAPIPE_FRONT_MAPPING: Record<string, number | number[]> = {
  // Head
  trichion: 10, // Top of forehead (approximate - MediaPipe doesn't have exact hairline)

  // Left Eye
  left_pupila: 468, // Left iris center (if available) or use 159
  left_canthus_medialis: 133, // Inner corner left eye
  left_canthus_lateralis: 33, // Outer corner left eye
  left_palpebra_superior: 159, // Upper eyelid center
  left_palpebra_inferior: 145, // Lower eyelid center
  left_sulcus_palpebralis_lateralis: 130, // Lateral eyelid crease
  left_pretarsal_skin_crease: 247, // Upper eyelid crease

  // Right Eye
  right_pupila: 473, // Right iris center (if available) or use 386
  right_canthus_medialis: 362, // Inner corner right eye
  right_canthus_lateralis: 263, // Outer corner right eye
  right_palpebra_superior: 386, // Upper eyelid center
  right_palpebra_inferior: 374, // Lower eyelid center
  right_sulcus_palpebralis_lateralis: 359, // Lateral eyelid crease
  right_pretarsal_skin_crease: 467, // Upper eyelid crease

  // Left Brow
  left_supercilium_medialis: 107, // Inner brow
  left_supercilium_medial_corner: 66, // Brow inner corner
  left_supercilium_superior: 105, // Brow arch top
  left_supercilium_apex: 70, // Brow peak
  left_supercilium_lateralis: 46, // Brow tail

  // Right Brow
  right_supercilium_medialis: 336, // Inner brow
  right_supercilium_medial_corner: 296, // Brow inner corner
  right_supercilium_superior: 334, // Brow arch top
  right_supercilium_apex: 300, // Brow peak
  right_supercilium_lateralis: 276, // Brow tail

  // Nose
  nasal_base: 6, // Bridge of nose
  left_dorsum_nasi: 198, // Left nose bridge
  right_dorsum_nasi: 420, // Right nose bridge
  left_ala_nasi: 129, // Left nostril
  right_ala_nasi: 358, // Right nostril
  subnasale: 2, // Base of nose

  // Mouth
  labrale_superius: 0, // Upper lip center
  cupids_bow: 13, // Cupid's bow center
  mouth_middle: 14, // Mouth center
  labrale_inferius: 17, // Lower lip center
  left_cheilion: 61, // Left mouth corner
  right_cheilion: 291, // Right mouth corner

  // Jaw
  left_gonion_superior: 116, // Left jaw upper
  right_gonion_superior: 345, // Right jaw upper
  left_gonion_inferior: 172, // Left jaw lower
  right_gonion_inferior: 397, // Right jaw lower

  // Chin
  left_mentum_lateralis: 135, // Left chin
  right_mentum_lateralis: 364, // Right chin
  menton: 152, // Chin bottom

  // Cheeks
  left_zygion: 234, // Left cheekbone
  right_zygion: 454, // Right cheekbone
  left_temporal: 127, // Left temple
  right_temporal: 356, // Right temple

  // Ears (approximate - MediaPipe doesn't track ears well)
  left_auricular_lateral: 234, // Use cheekbone as proxy
  right_auricular_lateral: 454, // Use cheekbone as proxy

  // Neck (not tracked by MediaPipe - use chin as reference)
  left_cervical_lateralis: 172,
  right_cervical_lateralis: 397,
};

// MediaPipe landmark indices for side profile
// Note: MediaPipe works best with frontal faces, side profile detection is less reliable
export const MEDIAPIPE_SIDE_MAPPING: Record<string, number | number[]> = {
  // These mappings work when face is slightly turned
  vertex: 10,
  external_occipital_region: 10, // Not visible in side
  trichion_profile: 10,
  frontalis: 151,
  glabella: 9,
  corneal_apex: 468, // Iris
  lateral_eyelid: 33,
  lower_eyelid_profile: 145,
  zygoma_lateralis: 234,
  nasion: 6,
  rhinion: 4,
  supratip: 4,
  pronasale: 1,
  infratip: 2,
  columella: 2,
  subnasale_profile: 2,
  subalare: 129,
  labrale_superius_profile: 0,
  labrale_inferius_profile: 17,
  cheilion_profile: 61,
  sublabiale: 18,
  orbitale: 145,
  gonion_superior_profile: 116,
  gonion_inferior_profile: 172,
  pogonion: 152,
  menton_profile: 152,
  porion: 127, // Temple area
  tragus: 127,
  intertragic_notch: 127,
  cervical_point: 152,
  neckpoint: 152,
};

export interface DetectedLandmarks {
  landmarks: Array<{ id: string; x: number; y: number }>;
  confidence: number;
  faceBox: { x: number; y: number; width: number; height: number };
}

/**
 * Detect facial landmarks using MediaPipe Face Mesh
 */
export async function detectFaceLandmarks(
  imageElement: HTMLImageElement | HTMLVideoElement | HTMLCanvasElement,
  mode: 'front' | 'side'
): Promise<DetectedLandmarks | null> {
  // Dynamic import to avoid SSR issues
  const { FaceMesh } = await import('@mediapipe/face_mesh');

  return new Promise((resolve) => {
    const faceMesh = new FaceMesh({
      locateFile: (file) => {
        return `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`;
      },
    });

    faceMesh.setOptions({
      maxNumFaces: 1,
      refineLandmarks: true, // Enables iris tracking
      minDetectionConfidence: 0.5,
      minTrackingConfidence: 0.5,
    });

    faceMesh.onResults((results) => {
      if (!results.multiFaceLandmarks || results.multiFaceLandmarks.length === 0) {
        resolve(null);
        return;
      }

      const mpLandmarks = results.multiFaceLandmarks[0];
      const mapping = mode === 'front' ? MEDIAPIPE_FRONT_MAPPING : MEDIAPIPE_SIDE_MAPPING;

      // Calculate face bounding box
      let minX = 1, minY = 1, maxX = 0, maxY = 0;
      mpLandmarks.forEach((lm) => {
        minX = Math.min(minX, lm.x);
        minY = Math.min(minY, lm.y);
        maxX = Math.max(maxX, lm.x);
        maxY = Math.max(maxY, lm.y);
      });

      // Map MediaPipe landmarks to our landmarks
      const landmarks = Object.entries(mapping).map(([id, mpIndex]) => {
        const idx = Array.isArray(mpIndex) ? mpIndex[0] : mpIndex;
        const lm = mpLandmarks[idx];
        return {
          id,
          x: lm?.x ?? 0.5,
          y: lm?.y ?? 0.5,
        };
      });

      resolve({
        landmarks,
        confidence: 0.9, // MediaPipe doesn't provide per-detection confidence
        faceBox: {
          x: minX,
          y: minY,
          width: maxX - minX,
          height: maxY - minY,
        },
      });

      faceMesh.close();
    });

    // Send image to MediaPipe
    faceMesh.send({ image: imageElement });
  });
}

/**
 * Get the region to zoom into for a specific landmark
 */
export function getLandmarkZoomRegion(
  landmarkId: string,
  mode: 'front' | 'side'
): { centerX: number; centerY: number; zoomLevel: number } {
  // Define zoom regions for different landmark groups
  const regions: Record<string, { centerX: number; centerY: number; zoomLevel: number }> = {
    // Eyes - zoom in close
    left_pupila: { centerX: 0.35, centerY: 0.35, zoomLevel: 3 },
    left_canthus_medialis: { centerX: 0.4, centerY: 0.35, zoomLevel: 3 },
    left_canthus_lateralis: { centerX: 0.3, centerY: 0.35, zoomLevel: 3 },
    right_pupila: { centerX: 0.65, centerY: 0.35, zoomLevel: 3 },
    right_canthus_medialis: { centerX: 0.6, centerY: 0.35, zoomLevel: 3 },
    right_canthus_lateralis: { centerX: 0.7, centerY: 0.35, zoomLevel: 3 },

    // Brows
    left_supercilium_apex: { centerX: 0.35, centerY: 0.28, zoomLevel: 2.5 },
    right_supercilium_apex: { centerX: 0.65, centerY: 0.28, zoomLevel: 2.5 },

    // Nose
    nasal_base: { centerX: 0.5, centerY: 0.4, zoomLevel: 2 },
    subnasale: { centerX: 0.5, centerY: 0.55, zoomLevel: 2.5 },

    // Mouth
    labrale_superius: { centerX: 0.5, centerY: 0.6, zoomLevel: 2.5 },
    mouth_middle: { centerX: 0.5, centerY: 0.65, zoomLevel: 2 },

    // Chin
    menton: { centerX: 0.5, centerY: 0.85, zoomLevel: 2 },

    // Default for other landmarks
    default: { centerX: 0.5, centerY: 0.5, zoomLevel: 1.5 },
  };

  return regions[landmarkId] || regions.default;
}

/**
 * Load image and run detection
 */
export async function detectFromImageUrl(
  imageUrl: string,
  mode: 'front' | 'side'
): Promise<DetectedLandmarks | null> {
  return new Promise((resolve, reject) => {
    const img = new Image();
    img.crossOrigin = 'anonymous';
    img.onload = async () => {
      try {
        const result = await detectFaceLandmarks(img, mode);
        resolve(result);
      } catch (error) {
        reject(error);
      }
    };
    img.onerror = () => reject(new Error('Failed to load image'));
    img.src = imageUrl;
  });
}
