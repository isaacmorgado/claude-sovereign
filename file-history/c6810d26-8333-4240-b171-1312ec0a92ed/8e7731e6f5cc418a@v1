/**
 * Slice 4: Groq Whisper Transcription Service
 *
 * Handles audio transcription using Groq's Whisper API.
 * Returns timestamped segments for take detection.
 * Includes caching to avoid repeated API calls.
 */

const fs = require('fs');
const Groq = require('groq-sdk');

// Initialize Groq client
const groq = new Groq({ apiKey: process.env.GROQ_API_KEY });

// In-memory cache: { wavPath: { mtime, result } }
const transcriptCache = new Map();

/**
 * Transcribe audio file using Groq Whisper (with caching)
 * @param {string} wavPath - Path to the WAV file
 * @returns {Promise<{text: string, segments: Array, language: string, duration: number}>}
 */
async function transcribeAudio(wavPath) {
  // Check cache based on file modification time
  const stats = fs.statSync(wavPath);
  const mtime = stats.mtimeMs;

  const cached = transcriptCache.get(wavPath);
  if (cached && cached.mtime === mtime) {
    console.log('[SPLICE] Using cached transcription (file unchanged)');
    return cached.result;
  }

  console.log('[SPLICE] Starting Groq Whisper transcription...');

  const transcription = await groq.audio.transcriptions.create({
    file: fs.createReadStream(wavPath),
    model: 'whisper-large-v3',
    response_format: 'verbose_json',
    language: 'en',
  });

  console.log(`[SPLICE] Transcription complete: ${transcription.text.slice(0, 100)}...`);

  const result = {
    text: transcription.text,
    segments: transcription.segments || [],
    language: transcription.language,
    duration: transcription.duration
  };

  // Cache the result
  transcriptCache.set(wavPath, { mtime, result });
  console.log('[SPLICE] Transcription cached');

  return result;
}

module.exports = { transcribeAudio };
