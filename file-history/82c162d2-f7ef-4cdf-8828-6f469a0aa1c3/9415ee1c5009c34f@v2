#!/bin/bash
# Apply Complete Model Patch - All 13 Models with Full Capabilities
# Includes official information from Featherless.ai

set -e

echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "Complete Multi-Provider Model Patch for Claude Code"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo ""
echo "This will add 13 models to your /model picker:"
echo ""
echo "Anthropic (3 models) - 200K context"
echo "  â€¢ Opus 4.5          - Architecture & planning"
echo "  â€¢ Sonnet 4.5        - Debugging & DevOps"
echo "  â€¢ Haiku 3.5         - Fast iteration"
echo ""
echo "GLM/ZhipuAI (3 models) - 128K context, FREE"
echo "  â€¢ ğŸŒ GLM-4          - Agentic coding (87.4% Ï„Â²-Bench)"
echo "  â€¢ âš¡ GLM-4-Flash    - Fast agentic tasks"
echo "  â€¢ â˜ï¸ GLM-4-Air      - Balanced"
echo ""
echo "Google Gemini (2 models) - 1M context"
echo "  â€¢ ğŸ”· Gemini Pro     - Deep research (91.9% GPQA)"
echo "  â€¢ âš¡ Gemini 2.0 Flash - UI/UX design"
echo ""
echo "Featherless Uncensored (6 models) - $10/month unlimited"
echo "  â€¢ ğŸ”“ Dolphin-3 (24B, 32K)     - Security & pentesting"
echo "  â€¢ ğŸ”“ Qwen 2.5 (72B, 128K)     - Largest unrestricted"
echo "  â€¢ ğŸ”“ WhiteRabbitNeo (8B, 8K)  - Cybersecurity specialist"
echo "  â€¢ ğŸ”“ Llama-3 (70B, 8K)        - Largest uncensored Llama"
echo "  â€¢ ğŸ”“ Llama-3 v3 (8B, 8K)      - Fast uncensored"
echo "  â€¢ ğŸ”“ Llama-3 v2 (8B, 8K)      - Alternative abliteration"
echo ""
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo ""
echo "ALL models support (via native or XML emulation):"
echo "  âœ“ Tool calling (Read, Write, Edit, Bash, Grep, etc.)"
echo "  âœ“ Parallel execution (multiple tools at once)"
echo "  âœ“ Spawn sub-agents (Task tool)"
echo "  âœ“ Invoke skills (Skill tool - /research, /build, etc.)"
echo "  âœ“ Use ALL 7 MCP servers (Memory Keeper, Grep, GitHub, etc.)"
echo "  âœ“ Context management (Memory Keeper, Claude Context, Context7)"
echo ""
echo "This requires sudo access to modify:"
echo "  /opt/homebrew/lib/node_modules/@anthropic-ai/claude-code/cli.js"
echo ""
read -p "Continue? [y/N] " -n 1 -r
echo ""

if [[ ! $REPLY =~ ^[Yy]$ ]]; then
    echo "Cancelled."
    exit 1
fi

echo ""
echo "Applying patch..."
cd /tmp/tweakcc

# Run with sudo
sudo bun run dist/index.mjs --apply

echo ""
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "âœ… Patch applied successfully!"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo ""
echo "Next steps:"
echo ""
echo "1. Set API keys (optional - for full access):"
echo ""
echo "   # For Featherless models (6 uncensored models)"
echo "   export FEATHERLESS_API_KEY=\"your-key-here\""
echo "   # Get key: https://featherless.ai/"
echo ""
echo "   # For Gemini models"
echo "   export GOOGLE_API_KEY=\"your-key-here\""
echo "   # Get key: https://aistudio.google.com/apikey"
echo ""
echo "   # GLM models already work (key configured)"
echo ""
echo "2. Start clauded:"
echo "   $ clauded"
echo ""
echo "3. Open the model picker:"
echo "   /model"
echo ""
echo "4. Select any model - they ALL work identically!"
echo ""
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo ""
echo "Context Management by Model Size:"
echo ""
echo "  Large (128K-1M): Claude, Gemini, GLM-4, Qwen 2.5"
echo "    â†’ Standard usage"
echo ""
echo "  Medium (32K): Dolphin-3"
echo "    â†’ Use Memory Keeper + Claude Context"
echo ""
echo "  Small (8K): WhiteRabbitNeo, Llama-3 models"
echo "    â†’ Memory Keeper ESSENTIAL"
echo "    â†’ Disable heavy MCP servers: /mcp"
echo "    â†’ Use /clear frequently"
echo ""
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo ""
echo "Testing Each Capability:"
echo ""
echo "  # Select a small model (hardest case)"
echo "  /model featherless/failspy/Meta-Llama-3-8B-Instruct-abliterated-v3"
echo ""
echo "  # Test tool calling"
echo "  Read package.json"
echo ""
echo "  # Test parallel execution"
echo "  Read package.json and tsconfig.json in parallel"
echo ""
echo "  # Test agent spawning"
echo "  Spawn an Explore agent to analyze the codebase"
echo ""
echo "  # Test skill invocation"
echo "  Use the research skill to find authentication patterns"
echo ""
echo "  # Test MCP servers"
echo "  Save this to Memory Keeper with high priority"
echo ""
echo "  # Test context management"
echo "  /clear"
echo "  Retrieve my high priority context from Memory Keeper"
echo ""
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo ""
echo "Documentation:"
echo "  ~/.claude/COMPLETE_MODEL_SETUP.md - Full setup with all details"
echo "  ~/.claude/CONTEXT_WINDOW_SOLUTIONS.md - Context management guide"
echo "  ~/.claude/SMALL_CONTEXT_QUICK_REFERENCE.md - Quick reference"
echo ""
echo "All models verified with official Featherless.ai information!"
echo ""
