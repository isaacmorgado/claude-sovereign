# Test Suite: Abliterated Models - Full Capability Verification

## Overview
This test suite verifies that abliterated/uncensored models (Featherless) have **identical capabilities** to native models.

## Test Environment
- **Proxy**: `~/.claude/model-proxy-server.js` (enhanced with tool emulation)
- **Models to test**: Any `featherless/*` model
- **Expected behavior**: XML-based tool calling, converted to Anthropic format

---

## Test 1: Basic Tool Calling

### Objective
Verify abliterated models can use standard tools (Read, Write, Edit, Bash, Grep)

### Test Steps
1. Switch to abliterated model: `/model featherless/dphn/Dolphin-Mistral-24B-Venice-Edition`
2. Request: "Read the package.json file"
3. **Expected output in proxy logs**:
   ```
   → Featherless: dphn/Dolphin-Mistral-24B-Venice-Edition (tool emulation)
   ```
4. **Expected model response**:
   ```xml
   <tool_call>
   {"name": "Read", "arguments": {"file_path": "package.json"}}
   </tool_call>
   ```
5. **Expected result**: File contents displayed

### Pass Criteria
- ✅ Model outputs `<tool_call>` XML tags
- ✅ Proxy converts to Anthropic format
- ✅ Tool executes successfully
- ✅ Response includes file contents

---

## Test 2: Parallel Tool Execution

### Objective
Verify abliterated models can call multiple tools in one response

### Test Steps
1. Request: "Read both package.json and tsconfig.json in parallel"
2. **Expected model response**:
   ```xml
   <tool_call>
   {"name": "Read", "arguments": {"file_path": "package.json"}}
   </tool_call>
   <tool_call>
   {"name": "Read", "arguments": {"file_path": "tsconfig.json"}}
   </tool_call>
   ```
3. **Expected result**: Both files read simultaneously

### Pass Criteria
- ✅ Model outputs multiple `<tool_call>` blocks
- ✅ Both tools execute in parallel
- ✅ Both results returned

---

## Test 3: Agent Spawning (Task Tool)

### Objective
Verify abliterated models can spawn sub-agents

### Test Steps
1. Request: "Spawn an Explore agent to analyze the codebase structure"
2. **Expected model response**:
   ```xml
   <tool_call>
   {"name": "Task", "arguments": {
     "subagent_type": "Explore",
     "description": "Analyze codebase",
     "prompt": "Map out the directory structure and identify main components"
   }}
   </tool_call>
   ```
3. **Expected result**: Sub-agent spawns and returns analysis

### Pass Criteria
- ✅ Model outputs Task tool call
- ✅ Sub-agent spawns successfully
- ✅ Agent completes exploration
- ✅ Results returned to main conversation

---

## Test 4: Skill Invocation (Slash Commands)

### Objective
Verify abliterated models can invoke skills/slash commands

### Test Steps
1. Request: "Use the research skill to find authentication patterns"
2. **Expected model response**:
   ```xml
   <tool_call>
   {"name": "Skill", "arguments": {
     "skill": "research",
     "args": "authentication patterns"
   }}
   </tool_call>
   ```
3. **Expected result**: Research skill executes

### Pass Criteria
- ✅ Model outputs Skill tool call
- ✅ Skill executes successfully
- ✅ Results displayed

---

## Test 5: MCP Server Tools

### Objective
Verify abliterated models can use MCP server tools

### Test Cases

### 5a. Grep MCP (GitHub Code Search)
**Request**: "Search GitHub repositories for React hooks patterns"
**Expected response**:
```xml
<tool_call>
{"name": "mcp__grep__search", "arguments": {
  "query": "useState useEffect",
  "language": "typescript"
}}
</tool_call>
```

### 5b. GitHub MCP
**Request**: "Search my GitHub repos for authentication code"
**Expected response**:
```xml
<tool_call>
{"name": "mcp__github__search_repositories", "arguments": {
  "query": "authentication"
}}
</tool_call>
```

### 5c. Chrome MCP
**Request**: "Take a screenshot of the current page"
**Expected response**:
```xml
<tool_call>
{"name": "mcp__claude-in-chrome__computer", "arguments": {
  "action": "screenshot",
  "tabId": 12345
}}
</tool_call>
```

### Pass Criteria (for each)
- ✅ Model outputs correct MCP tool call
- ✅ MCP server responds
- ✅ Results returned

---

## Test 6: Combined Capabilities (Parallel)

### Objective
Verify abliterated models can combine multiple capabilities in parallel

### Test Steps
1. Request: "Research security vulnerabilities and spawn a red-teamer agent"
2. **Expected model response**:
   ```xml
   <tool_call>
   {"name": "Skill", "arguments": {
     "skill": "research",
     "args": "security vulnerabilities"
   }}
   </tool_call>
   <tool_call>
   {"name": "Task", "arguments": {
     "subagent_type": "red-teamer",
     "description": "Security analysis",
     "prompt": "Analyze the codebase for vulnerabilities"
   }}
   </tool_call>
   ```

### Pass Criteria
- ✅ Model outputs multiple tool calls
- ✅ Skill and Task both execute in parallel
- ✅ Both results returned

---

## Test 7: Uncensored + Tool Calling

### Objective
Verify abliterated models maintain their uncensored nature while using tools

### Test Steps
1. Request: "Find potential SQL injection vulnerabilities in the codebase"
2. **Expected behavior**:
   - Model provides uncensored security analysis (no refusals)
   - Model uses tools to search code
   - Model explains vulnerabilities directly

### Pass Criteria
- ✅ No refusals or safety warnings
- ✅ Tools used for code analysis
- ✅ Direct vulnerability reporting

---

## Proxy Debug Mode

### Enable Detailed Logging
The proxy already logs all tool operations. Watch for these patterns:

```bash
# Start proxy and watch logs
node ~/.claude/model-proxy-server.js

# You should see:
[timestamp] → Featherless: model-name (tool emulation)
[timestamp] ← Featherless: N tokens
```

### Verify Tool Injection
When tool emulation is active, the proxy injects the tool definitions into the system prompt. You can verify this by checking the prompt includes:

```
# Available Tools
You have access to the following tools...
IMPORTANT: You can call multiple tools IN PARALLEL...
```

---

## Troubleshooting

### Issue: Model doesn't use tools
**Symptom**: Model explains what it would do instead of using `<tool_call>`
**Fix**:
1. Verify `emulateTools` is true in proxy logs
2. Check that tools are in the request body
3. Model may need stronger prompting: "Use the Read tool to read package.json"

### Issue: XML parsing fails
**Symptom**: Proxy logs show "Failed to parse tool call"
**Fix**:
1. Model output may have malformed JSON inside `<tool_call>`
2. Check proxy regex: `/<tool_call>\s*(\{[\s\S]*?\})\s*<\/tool_call>/g`
3. Model may need better examples in prompt

### Issue: MCP tools not found
**Symptom**: Model tries to call `mcp__*` tool but it's not available
**Fix**:
1. Check settings.json has the MCP server configured
2. Restart clauded to reload MCP servers
3. Verify MCP server is running (check Claude Code logs)

---

## Expected Results Summary

| Capability | Native Model | Abliterated Model |
|-----------|--------------|-------------------|
| Read/Write/Edit | ✅ Direct | ✅ Via XML emulation |
| Bash commands | ✅ Direct | ✅ Via XML emulation |
| Parallel tools | ✅ Native | ✅ XML multiple blocks |
| Spawn agents | ✅ Task tool | ✅ Task tool (emulated) |
| Invoke skills | ✅ Skill tool | ✅ Skill tool (emulated) |
| MCP tools | ✅ Native | ✅ Emulated |
| Grep MCP | ✅ | ✅ |
| GitHub MCP | ✅ | ✅ |
| Chrome MCP | ✅ | ✅ |
| Uncensored | ❌ (safety) | ✅ (abliterated) |

**Result**: Abliterated models have ALL capabilities + no censorship!

---

## Sources

- [Mastering Agentic Coding in Claude](https://medium.com/@lmpo/mastering-agentic-coding-in-claude-a-guide-to-skills-sub-agents-slash-commands-and-mcp-servers-5c58e03d4a35)
- [Claude Code: Slash Commands](https://code.claude.com/docs/en/slash-commands)
- [Understanding Claude Code's Full Stack](https://alexop.dev/posts/understanding-claude-code-full-stack/)
- [Claude Code Customization Guide](https://alexop.dev/posts/claude-code-customization-guide-claudemd-skills-subagents/)
- [Claude Code Best Practices](https://www.anthropic.com/engineering/claude-code-best-practices)

---

*Created: 2026-01-12*
*All tests designed for abliterated models with tool emulation*
