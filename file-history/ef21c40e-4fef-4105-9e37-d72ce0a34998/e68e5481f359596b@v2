# SPLICE Implementation Plan - Phases 2, 3, 4
## Caption Styling, Auto Zoom, Workflow Automation & Polish

**Date**: 2026-01-12
**Objective**: Implement advanced caption styling, auto zoom with face detection, workflow automation, and polish
**Total Timeline**: 6 weeks (30 business days)
**Skipped**: Phase 1 (B-roll Stock Search)

---

## Overview

| Phase | Features | Duration | Cost |
|-------|----------|----------|------|
| **Phase 2** | Caption Styling (15 pickers + 6 animations) | 5-7 days | $0 |
| **Phase 3** | Auto Zoom (face detection) + Workflow Automation | 13-17 days | $0 |
| **Phase 4** | Polish, Testing, Documentation | 5-7 days | $0 |
| **Total** | All Features | **23-31 days** | **$0** |

---

## Phase 2: Advanced Caption Styling System
**Duration**: 5-7 days (1 week)
**Team**: 1-2 developers

### Deliverables

#### 1. 15 Color Picker System (2 days)
**Integration**: Pickr library (https://github.com/Simonwep/pickr)

**Implementation**:

```javascript
// splice-plugin/js/captionStyling.js
import Pickr from '@simonwep/pickr';

class CaptionStylingSystem {
  constructor() {
    this.pickers = {};
    this.initializeAllPickers();
  }

  initializeAllPickers() {
    const pickrConfig = {
      theme: 'nano',
      default: '#FFFFFF',
      swatches: [
        '#FF0000', '#00FF00', '#0000FF',
        '#FFFF00', '#FF00FF', '#00FFFF',
        '#000000', '#FFFFFF'
      ],
      components: {
        preview: true,
        opacity: true,
        hue: true,
        interaction: {
          hex: true,
          rgba: true,
          input: true,
          save: true
        }
      }
    };

    // 1. Font Color (Solid)
    this.pickers.fontColor = Pickr.create({
      el: '#font-color-picker',
      default: '#FFFFFF',
      ...pickrConfig
    }).on('save', (color) => {
      this.updateStyle('font.color', color.toHEXA().toString());
    });

    // 2-3. Font Gradient Colors
    this.pickers.fontGradient1 = Pickr.create({
      el: '#font-gradient1-picker',
      default: '#FF0000',
      ...pickrConfig
    }).on('save', (color) => {
      this.updateStyle('font.gradient.color1', color.toHEXA().toString());
      this.recalculateGradient('font');
    });

    this.pickers.fontGradient2 = Pickr.create({
      el: '#font-gradient2-picker',
      default: '#0000FF',
      ...pickrConfig
    }).on('save', (color) => {
      this.updateStyle('font.gradient.color2', color.toHEXA().toString());
      this.recalculateGradient('font');
    });

    // 4. Outline Color
    this.pickers.outlineColor = Pickr.create({
      el: '#outline-color-picker',
      default: '#000000',
      ...pickrConfig
    }).on('save', (color) => {
      this.updateStyle('outline.color', color.toHEXA().toString());
    });

    // 5. Box Color (Solid)
    this.pickers.boxColor = Pickr.create({
      el: '#box-color-picker',
      default: '#000000AA',
      ...pickrConfig
    }).on('save', (color) => {
      this.updateStyle('box.color', color.toHEXA().toString());
    });

    // 6-7. Box Gradient Colors
    this.pickers.boxGradient1 = Pickr.create({
      el: '#box-gradient1-picker',
      default: '#FF0000',
      ...pickrConfig
    }).on('save', (color) => {
      this.updateStyle('box.gradient.color1', color.toHEXA().toString());
      this.recalculateGradient('box');
    });

    this.pickers.boxGradient2 = Pickr.create({
      el: '#box-gradient2-picker',
      default: '#FFFF00',
      ...pickrConfig
    }).on('save', (color) => {
      this.updateStyle('box.gradient.color2', color.toHEXA().toString());
      this.recalculateGradient('box');
    });

    // 8. Shadow Color
    this.pickers.shadowColor = Pickr.create({
      el: '#shadow-color-picker',
      default: '#00000080',
      ...pickrConfig
    }).on('save', (color) => {
      this.updateStyle('shadow.color', color.toHEXA().toString());
    });

    // 9. Animation: Highlight Color
    this.pickers.animHighlight = Pickr.create({
      el: '#anim-highlight-picker',
      default: '#FFFF00',
      ...pickrConfig
    }).on('save', (color) => {
      this.updateStyle('animation.highlight.color', color.toHEXA().toString());
    });

    // 10. Animation: Glow Color
    this.pickers.animGlow = Pickr.create({
      el: '#anim-glow-picker',
      default: '#FF0000',
      ...pickrConfig
    }).on('save', (color) => {
      this.updateStyle('animation.glow.color', color.toHEXA().toString());
    });

    // 11. Animation: Highlight Stroke Color
    this.pickers.animHighlightStroke = Pickr.create({
      el: '#anim-highlight-stroke-picker',
      default: '#000000',
      ...pickrConfig
    }).on('save', (color) => {
      this.updateStyle('animation.highlight.strokeColor', color.toHEXA().toString());
    });

    // 12. Animation: Underline Color
    this.pickers.animUnderline = Pickr.create({
      el: '#anim-underline-picker',
      default: '#00FF00',
      ...pickrConfig
    }).on('save', (color) => {
      this.updateStyle('animation.underline.color', color.toHEXA().toString());
    });

    // 13. Animation: Box Color
    this.pickers.animBox = Pickr.create({
      el: '#anim-box-picker',
      default: '#0000FFAA',
      ...pickrConfig
    }).on('save', (color) => {
      this.updateStyle('animation.box.color', color.toHEXA().toString());
    });

    // 14. Animation: Reveal Outline Color
    this.pickers.animRevealOutline = Pickr.create({
      el: '#anim-reveal-outline-picker',
      default: '#FFFFFF',
      ...pickrConfig
    }).on('save', (color) => {
      this.updateStyle('animation.reveal.outlineColor', color.toHEXA().toString());
    });

    // 15. Chapter Font Color
    this.pickers.chapterFont = Pickr.create({
      el: '#chapter-font-picker',
      default: '#FFFFFF',
      ...pickrConfig
    }).on('save', (color) => {
      this.updateStyle('chapter.fontColor', color.toHEXA().toString());
    });
  }

  updateStyle(path, value) {
    // Update internal style object
    const keys = path.split('.');
    let obj = this.currentStyle;
    for (let i = 0; i < keys.length - 1; i++) {
      obj[keys[i]] = obj[keys[i]] || {};
      obj = obj[keys[i]];
    }
    obj[keys[keys.length - 1]] = value;

    // Trigger preview update
    this.updatePreview();
  }
}
```

**UI Layout** (`splice-plugin/caption-styling-ui.html`):
```html
<div class="caption-styling-panel">
  <!-- Font Styling -->
  <section class="styling-section">
    <h3>Font</h3>
    <div class="color-row">
      <label>Solid Color</label>
      <div id="font-color-picker"></div>
    </div>
    <div class="gradient-row">
      <label>Gradient</label>
      <div class="gradient-controls">
        <div id="font-gradient1-picker"></div>
        <div id="font-gradient2-picker"></div>
        <input type="range" id="font-gradient-angle" min="0" max="360" value="0" />
        <span id="font-gradient-angle-value">0°</span>
      </div>
    </div>
  </section>

  <!-- Outline Styling -->
  <section class="styling-section">
    <h3>Outline</h3>
    <div class="color-row">
      <label>Color</label>
      <div id="outline-color-picker"></div>
    </div>
    <div class="slider-row">
      <label>Width</label>
      <input type="range" id="outline-width" min="0" max="10" step="0.5" value="2" />
    </div>
  </section>

  <!-- Box Styling -->
  <section class="styling-section">
    <h3>Box Background</h3>
    <div class="color-row">
      <label>Solid Color</label>
      <div id="box-color-picker"></div>
    </div>
    <div class="gradient-row">
      <label>Gradient</label>
      <div class="gradient-controls">
        <div id="box-gradient1-picker"></div>
        <div id="box-gradient2-picker"></div>
        <input type="range" id="box-gradient-angle" min="0" max="360" value="90" />
        <span id="box-gradient-angle-value">90°</span>
      </div>
    </div>
  </section>

  <!-- Shadow Styling -->
  <section class="styling-section">
    <h3>Shadow</h3>
    <div class="color-row">
      <label>Color</label>
      <div id="shadow-color-picker"></div>
    </div>
    <div class="slider-row">
      <label>Blur</label>
      <input type="range" id="shadow-blur" min="0" max="20" step="1" value="5" />
    </div>
  </section>

  <!-- Animation Colors -->
  <section class="styling-section">
    <h3>Animation Colors</h3>
    <div class="color-row">
      <label>Highlight</label>
      <div id="anim-highlight-picker"></div>
    </div>
    <div class="color-row">
      <label>Glow</label>
      <div id="anim-glow-picker"></div>
    </div>
    <div class="color-row">
      <label>Underline</label>
      <div id="anim-underline-picker"></div>
    </div>
    <div class="color-row">
      <label>Box</label>
      <div id="anim-box-picker"></div>
    </div>
    <div class="color-row">
      <label>Reveal Outline</label>
      <div id="anim-reveal-outline-picker"></div>
    </div>
  </section>

  <!-- Chapter Styling -->
  <section class="styling-section">
    <h3>Chapter Markers</h3>
    <div class="color-row">
      <label>Font Color</label>
      <div id="chapter-font-picker"></div>
    </div>
  </section>
</div>
```

---

#### 2. Gradient System (1 day)

**Algorithm**:
```javascript
// splice-plugin/js/gradientCalculator.js
class GradientCalculator {
  /**
   * Calculate gradient coordinates from angle
   * @param {number} angle - Gradient angle in degrees (0-360)
   * @returns {Object} - Start/end coordinates as percentages
   */
  static calculateGradientCoordinates(angle) {
    // Normalize angle to 0-360
    angle = ((angle % 360) + 360) % 360;

    // Convert to radians
    const radians = (angle * Math.PI) / 180;

    // Calculate start point (opposite direction)
    const x1 = 50 + Math.cos(radians + Math.PI) * 50;
    const y1 = 50 + Math.sin(radians + Math.PI) * 50;

    // Calculate end point
    const x2 = 50 + Math.cos(radians) * 50;
    const y2 = 50 + Math.sin(radians) * 50;

    return {
      x1: Math.round(x1 * 100) / 100,
      y1: Math.round(y1 * 100) / 100,
      x2: Math.round(x2 * 100) / 100,
      y2: Math.round(y2 * 100) / 100
    };
  }

  /**
   * Generate CSS linear gradient
   */
  static toCss(color1, color2, angle) {
    return `linear-gradient(${angle}deg, ${color1}, ${color2})`;
  }

  /**
   * Generate SVG gradient for preview
   */
  static toSvg(color1, color2, angle, id = 'grad') {
    const coords = this.calculateGradientCoordinates(angle);
    return `
      <linearGradient id="${id}" x1="${coords.x1}%" y1="${coords.y1}%" x2="${coords.x2}%" y2="${coords.y2}%">
        <stop offset="0%" style="stop-color:${color1}" />
        <stop offset="100%" style="stop-color:${color2}" />
      </linearGradient>
    `;
  }

  /**
   * Generate Premiere Pro graphic layer gradient
   */
  static toPremiereXml(color1, color2, angle) {
    const coords = this.calculateGradientCoordinates(angle);
    return {
      fillType: 'gradient',
      gradientType: 'linear',
      startPoint: { x: coords.x1, y: coords.y1 },
      endPoint: { x: coords.x2, y: coords.y2 },
      colorStops: [
        { offset: 0, color: this.hexToRgb(color1) },
        { offset: 1, color: this.hexToRgb(color2) }
      ]
    };
  }

  static hexToRgb(hex) {
    const result = /^#?([a-f\d]{2})([a-f\d]{2})([a-f\d]{2})([a-f\d]{2})?$/i.exec(hex);
    return result ? {
      r: parseInt(result[1], 16),
      g: parseInt(result[2], 16),
      b: parseInt(result[3], 16),
      a: result[4] ? parseInt(result[4], 16) / 255 : 1
    } : null;
  }
}
```

---

#### 3. 6 Animation Types (2-3 days)

**Base Animation Class**:
```javascript
// splice-plugin/js/animations/BaseAnimation.js
class BaseAnimation {
  constructor(word, settings) {
    this.word = word; // { text, start, end, duration }
    this.settings = settings;
    this.keyframes = [];
  }

  /**
   * Generate keyframes for the animation
   * @returns {Array} Array of keyframe objects
   */
  generate() {
    throw new Error('generate() must be implemented by subclass');
  }

  /**
   * Easing function (ease-in-out by default)
   */
  ease(t, type = 'ease-in-out') {
    switch (type) {
      case 'linear':
        return t;
      case 'ease-in':
        return t * t;
      case 'ease-out':
        return t * (2 - t);
      case 'ease-in-out':
        return t < 0.5 ? 2 * t * t : -1 + (4 - 2 * t) * t;
      case 'cubic':
        return t < 0.5 ? 4 * t * t * t : (t - 1) * (2 * t - 2) * (2 * t - 2) + 1;
      case 'elastic':
        return Math.sin(-13 * (Math.PI / 2) * (t + 1)) * Math.pow(2, -10 * t) + 1;
      default:
        return t;
    }
  }

  /**
   * Apply animation to Premiere Pro clip
   */
  async applyToPremiere(clip) {
    throw new Error('applyToPremiere() must be implemented by subclass');
  }
}
```

**Animation 1: Wiggle (Fourier Series)**:
```javascript
// splice-plugin/js/animations/WiggleAnimation.js
class WiggleAnimation extends BaseAnimation {
  generate() {
    const {
      intensity = 1.0,
      frequency = 12, // Hz
      duration = 0.3  // seconds
    } = this.settings;

    // Fourier coefficients (10 harmonics)
    const coefficients = [0.5, 0.3, 0.15, 0.08, 0.05, 0.03, 0.02, 0.01, 0.01, 0.01];
    const amplitude = 5 * intensity; // pixels
    const fps = 30;
    const frameCount = Math.ceil(duration * fps);

    this.keyframes = [];

    for (let frame = 0; frame <= frameCount; frame++) {
      const t = frame / fps;
      let x = 0, y = 0;

      // Sum sine waves (Fourier series)
      for (let i = 0; i < coefficients.length; i++) {
        const coef = coefficients[i];
        const freq = frequency * (i + 1);
        x += coef * Math.sin(2 * Math.PI * freq * t) * amplitude;
        y += coef * Math.cos(2 * Math.PI * freq * t) * amplitude;
      }

      this.keyframes.push({
        time: this.word.start + t,
        position: { x, y },
        rotation: x * 0.1 // Slight rotation based on x displacement
      });
    }

    return this.keyframes;
  }

  async applyToPremiere(clip) {
    const component = await clip.getMotionComponent();

    for (const keyframe of this.keyframes) {
      await component.addKeyframe(keyframe.time, {
        position: {
          x: clip.position.x + keyframe.position.x,
          y: clip.position.y + keyframe.position.y
        },
        rotation: keyframe.rotation
      });
    }
  }
}
```

**Animation 2: Highlight (Color Fade + Scale)**:
```javascript
class HighlightAnimation extends BaseAnimation {
  generate() {
    const {
      color = '#FFFF00',
      duration = 0.5
    } = this.settings;

    this.keyframes = [
      { time: 0.0, bgColor: 'transparent', bgOpacity: 0, scale: 1.0 },
      { time: 0.1, bgColor: color, bgOpacity: 1, scale: 1.1 },
      { time: 0.4, bgColor: color, bgOpacity: 1, scale: 1.1 },
      { time: 0.5, bgColor: 'transparent', bgOpacity: 0, scale: 1.0 }
    ];

    return this.keyframes.map(kf => ({
      ...kf,
      time: this.word.start + kf.time
    }));
  }

  async applyToPremiere(clip) {
    // Create background shape layer
    const bgLayer = await clip.createShapeLayer('highlight-bg');

    for (const keyframe of this.keyframes) {
      await bgLayer.addKeyframe(keyframe.time, {
        fillColor: keyframe.bgColor,
        opacity: keyframe.bgOpacity * 100
      });

      await clip.getMotionComponent().addKeyframe(keyframe.time, {
        scale: keyframe.scale * 100
      });
    }
  }
}
```

**Animation 3: Glow (Multi-layer Shadow)**:
```javascript
class GlowAnimation extends BaseAnimation {
  generate() {
    const {
      color = '#FF0000',
      layers = 5,
      maxBlur = 20,
      duration = 0.5
    } = this.settings;

    const fps = 30;
    const frameCount = Math.ceil(duration * fps);
    this.keyframes = [];

    for (let frame = 0; frame <= frameCount; frame++) {
      const t = frame / frameCount;
      const intensity = Math.sin(t * Math.PI); // 0 → 1 → 0
      const blur = maxBlur * intensity;

      const shadows = [];
      for (let layer = 1; layer <= layers; layer++) {
        shadows.push({
          x: 0,
          y: 0,
          blur: blur * layer / layers,
          color: color
        });
      }

      this.keyframes.push({
        time: this.word.start + t * duration,
        shadows
      });
    }

    return this.keyframes;
  }

  async applyToPremiere(clip) {
    const textComponent = await clip.getTextComponent();

    for (const keyframe of this.keyframes) {
      // Premiere Pro supports multiple drop shadows
      await textComponent.addKeyframe(keyframe.time, {
        shadows: keyframe.shadows
      });
    }
  }
}
```

**Animation 4: Underline (Center Outward)**:
```javascript
class UnderlineAnimation extends BaseAnimation {
  generate() {
    const {
      color = '#00FF00',
      thickness = 3,
      duration = 0.15
    } = this.settings;

    const wordWidth = this.measureTextWidth(this.word.text);

    this.keyframes = [
      {
        time: 0.0,
        width: 0,
        left: wordWidth / 2,
        thickness,
        color
      },
      {
        time: duration,
        width: wordWidth,
        left: 0,
        thickness,
        color
      }
    ];

    return this.keyframes.map(kf => ({
      ...kf,
      time: this.word.start + kf.time
    }));
  }

  measureTextWidth(text) {
    // Estimate width based on font size and character count
    const avgCharWidth = this.settings.fontSize * 0.6;
    return text.length * avgCharWidth;
  }

  async applyToPremiere(clip) {
    const underlineLayer = await clip.createShapeLayer('underline');

    for (const keyframe of this.keyframes) {
      await underlineLayer.addKeyframe(keyframe.time, {
        width: keyframe.width,
        height: keyframe.thickness,
        position: { x: keyframe.left, y: clip.height + 5 }, // Below text
        fillColor: keyframe.color
      });
    }
  }
}
```

**Animation 5: Box (Scale + Opacity Fade)**:
```javascript
class BoxAnimation extends BaseAnimation {
  generate() {
    const {
      color = '#000000AA',
      padding = 10,
      duration = 0.2
    } = this.settings;

    this.keyframes = [
      { time: 0.0, scale: 0.8, opacity: 0 },
      { time: duration, scale: 1.0, opacity: 1 }
    ];

    return this.keyframes.map(kf => ({
      ...kf,
      time: this.word.start + kf.time,
      color,
      padding
    }));
  }

  async applyToPremiere(clip) {
    const boxLayer = await clip.createShapeLayer('box-bg');

    for (const keyframe of this.keyframes) {
      await boxLayer.addKeyframe(keyframe.time, {
        scale: keyframe.scale * 100,
        opacity: keyframe.opacity * 100,
        fillColor: keyframe.color,
        padding: keyframe.padding
      });
    }
  }
}
```

**Animation 6: Reveal (Clipping Mask)**:
```javascript
class RevealAnimation extends BaseAnimation {
  generate() {
    const {
      direction = 'left-to-right', // or 'right-to-left', 'top-to-bottom', 'bottom-to-top'
      duration = 0.3
    } = this.settings;

    this.keyframes = [];

    const fps = 30;
    const frameCount = Math.ceil(duration * fps);

    for (let frame = 0; frame <= frameCount; frame++) {
      const t = frame / frameCount;
      const eased = this.ease(t, 'ease-out');

      let clipPath;
      switch (direction) {
        case 'left-to-right':
          clipPath = `inset(0 ${100 - eased * 100}% 0 0)`;
          break;
        case 'right-to-left':
          clipPath = `inset(0 0 0 ${100 - eased * 100}%)`;
          break;
        case 'top-to-bottom':
          clipPath = `inset(0 0 ${100 - eased * 100}% 0)`;
          break;
        case 'bottom-to-top':
          clipPath = `inset(${100 - eased * 100}% 0 0 0)`;
          break;
      }

      this.keyframes.push({
        time: this.word.start + t * duration,
        clipPath,
        reveal: eased
      });
    }

    return this.keyframes;
  }

  async applyToPremiere(clip) {
    // Create mask layer
    const maskLayer = await clip.createMask('reveal-mask');

    for (const keyframe of this.keyframes) {
      const maskWidth = this.settings.direction.includes('left') || this.settings.direction.includes('right')
        ? clip.width * keyframe.reveal
        : clip.width;

      const maskHeight = this.settings.direction.includes('top') || this.settings.direction.includes('bottom')
        ? clip.height * keyframe.reveal
        : clip.height;

      let maskX = 0, maskY = 0;

      if (this.settings.direction === 'right-to-left') {
        maskX = clip.width - maskWidth;
      } else if (this.settings.direction === 'bottom-to-top') {
        maskY = clip.height - maskHeight;
      }

      await maskLayer.addKeyframe(keyframe.time, {
        width: maskWidth,
        height: maskHeight,
        position: { x: maskX, y: maskY }
      });
    }
  }
}
```

---

### Phase 2 Testing (0.5 days)
- Test all 15 color pickers
- Verify gradient calculations at 0°, 45°, 90°, 180°, 270°
- Test all 6 animations on sample captions
- Performance testing with 100+ caption words

---

## Phase 3: Auto Zoom + Workflow Automation
**Duration**: 13-17 days (2.5-3.5 weeks)

### Part A: Auto Zoom with Face Detection (7-10 days)

#### 1. Face Detection Integration (3-4 days)

**Library**: face-api.js (https://github.com/justadudewhohacks/face-api.js)

```bash
npm install face-api.js canvas
```

**Implementation**:
```javascript
// splice-backend/services/faceDetection.js
const faceapi = require('face-api.js');
const canvas = require('canvas');
const { Canvas, Image, ImageData } = canvas;

// Polyfill for Node.js environment
faceapi.env.monkeyPatch({ Canvas, Image, ImageData });

class FaceDetectionService {
  constructor() {
    this.modelsLoaded = false;
  }

  async initialize() {
    if (this.modelsLoaded) return;

    // Load models (only need to do this once)
    const modelPath = './models';
    await faceapi.nets.ssdMobilenetv1.loadFromDisk(modelPath);
    await faceapi.nets.mtcnn.loadFromDisk(modelPath);
    await faceapi.nets.faceLandmark68Net.loadFromDisk(modelPath);

    this.modelsLoaded = true;
  }

  /**
   * Detect faces in an image
   * @param {string} imagePath - Path to image file
   * @returns {Promise<Object|null>} Face center coordinates or null
   */
  async detectFace(imagePath) {
    await this.initialize();

    // Load image
    const img = await canvas.loadImage(imagePath);

    // Try fast detection first (SSD MobileNet v1)
    let detections = await faceapi
      .detectAllFaces(img, new faceapi.SsdMobilenetv1Options({ minConfidence: 0.5 }))
      .withFaceLandmarks();

    // Fallback to accurate detection if none found (MTCNN)
    if (detections.length === 0) {
      detections = await faceapi
        .detectAllFaces(img, new faceapi.MtcnnOptions({ minFaceSize: 50 }))
        .withFaceLandmarks();
    }

    // No faces found
    if (detections.length === 0) {
      return null;
    }

    // Return largest face (main subject)
    const largestFace = detections.sort((a, b) => {
      const aArea = a.detection.box.width * a.detection.box.height;
      const bArea = b.detection.box.width * b.detection.box.height;
      return bArea - aArea;
    })[0];

    const box = largestFace.detection.box;

    // Calculate center as percentage of frame
    const centerX = (box.x + box.width / 2) / img.width * 100;
    const centerY = (box.y + box.height / 2) / img.height * 100;

    // Clamp to safe region (account for zoom scale)
    const zoomScale = 1.5; // 150% zoom
    const safeMargin = (100 - 100 / zoomScale) / 2; // 16.67% margin

    return {
      x: Math.max(safeMargin, Math.min(100 - safeMargin, centerX)),
      y: Math.max(safeMargin, Math.min(100 - safeMargin, centerY)),
      confidence: largestFace.detection.score,
      box: {
        x: box.x / img.width * 100,
        y: box.y / img.height * 100,
        width: box.width / img.width * 100,
        height: box.height / img.height * 100
      }
    };
  }

  /**
   * Extract frames from video at specific times
   * @param {string} videoPath - Path to video file
   * @param {Array<number>} times - Array of timestamps in seconds
   * @returns {Promise<Array<string>>} Array of frame image paths
   */
  async extractFrames(videoPath, times) {
    const ffmpeg = require('fluent-ffmpeg');
    const fs = require('fs').promises;
    const path = require('path');
    const os = require('os');

    const tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'frames-'));
    const framePaths = [];

    for (let i = 0; i < times.length; i++) {
      const time = times[i];
      const outputPath = path.join(tempDir, `frame-${i}.png`);

      await new Promise((resolve, reject) => {
        ffmpeg(videoPath)
          .seekInput(time)
          .frames(1)
          .output(outputPath)
          .on('end', resolve)
          .on('error', reject)
          .run();
      });

      framePaths.push(outputPath);
    }

    return framePaths;
  }

  /**
   * Detect faces at multiple timestamps in video
   * @param {string} videoPath - Path to video file
   * @param {Array<number>} times - Array of timestamps in seconds
   * @returns {Promise<Array<Object>>} Array of face detection results
   */
  async detectFacesInVideo(videoPath, times) {
    // Extract frames
    const framePaths = await this.extractFrames(videoPath, times);

    // Detect faces in each frame
    const results = [];
    for (let i = 0; i < framePaths.length; i++) {
      const face = await this.detectFace(framePaths[i]);
      results.push({
        time: times[i],
        face: face,
        framePath: framePaths[i]
      });
    }

    return results;
  }
}

module.exports = new FaceDetectionService();
```

**API Route**:
```javascript
// splice-backend/routes/zoom.js
const express = require('express');
const router = express.Router();
const faceDetection = require('../services/faceDetection');
const { authenticateToken } = require('../middleware/auth');

router.post('/detect-faces', authenticateToken, async (req, res) => {
  try {
    const { videoPath, times } = req.body;

    if (!videoPath || !times || !Array.isArray(times)) {
      return res.status(400).json({ error: 'videoPath and times array required' });
    }

    const results = await faceDetection.detectFacesInVideo(videoPath, times);

    res.json({
      success: true,
      detections: results
    });
  } catch (error) {
    console.error('Face detection error:', error);
    res.status(500).json({ error: 'Face detection failed' });
  }
});

module.exports = router;
```

---

#### 2. Transcript Synchronization (2-3 days)

```javascript
// splice-plugin/js/autoZoom.js
class AutoZoomTranscriptSync {
  /**
   * Find optimal zoom placements based on transcript
   * @param {Array} words - Transcript words with timestamps
   * @param {string} frequency - 'low', 'medium', 'high'
   * @returns {Array} Array of zoom times
   */
  static findZoomPlacements(words, frequency = 'medium') {
    const intervals = {
      low: 15,    // Every 15 seconds
      medium: 8,  // Every 8 seconds
      high: 4     // Every 4 seconds
    };

    const interval = intervals[frequency];
    const zoomTimes = [];
    let lastZoomTime = 0;

    // Find key moments in transcript
    for (let i = 0; i < words.length; i++) {
      const word = words[i];

      // Check if enough time has passed since last zoom
      if (word.start - lastZoomTime < interval) {
        continue;
      }

      // Identify key moments
      const isQuestion = word.word.endsWith('?');
      const isEmphasis = word.word === word.word.toUpperCase() && word.word.length > 2;

      // Check for pause after word (scene change)
      const nextWord = words[i + 1];
      const isPause = nextWord && (nextWord.start - word.end > 0.5);

      // Check for comma/period (natural break)
      const isBreak = word.word.endsWith(',') || word.word.endsWith('.');

      if (isQuestion || isEmphasis || isPause || isBreak) {
        zoomTimes.push(word.start);
        lastZoomTime = word.start;
      }
    }

    // Quantize to frame boundaries (30fps)
    return zoomTimes.map(time => Math.round(time * 30) / 30);
  }

  /**
   * Generate zoom keyframes with face centering
   * @param {number} startTime - Zoom start time
   * @param {number} duration - Zoom duration
   * @param {Object} faceCenter - Face center coordinates {x, y}
   * @param {number} scale - Zoom scale (1.5 = 150%)
   * @returns {Array} Array of keyframes
   */
  static generateKeyframes(startTime, duration, faceCenter, scale = 1.5) {
    const fps = 30;
    const frameCount = Math.ceil(duration * fps);
    const keyframes = [];

    for (let frame = 0; frame <= frameCount; frame++) {
      const progress = frame / frameCount;

      // Asymmetric easing (power2)
      const eased = this.asymmetricEase(progress);

      // Interpolate scale (1.0 → scale)
      const currentScale = 1 + (scale - 1) * eased;

      // Interpolate position (center → face center)
      let posX = 50, posY = 50; // Default center

      if (faceCenter) {
        posX = 50 + (faceCenter.x - 50) * eased;
        posY = 50 + (faceCenter.y - 50) * eased;
      }

      keyframes.push({
        time: startTime + frame / fps,
        scale: currentScale,
        position: { x: posX, y: posY },
        frame: Math.round((startTime + frame / fps) * fps)
      });
    }

    return keyframes;
  }

  /**
   * Asymmetric easing function (separate in/out curves)
   * @param {number} t - Progress (0 to 1)
   * @param {number} power - Easing power (2 = smooth, 3 = snappy)
   * @returns {number} Eased value
   */
  static asymmetricEase(t, power = 2) {
    if (t < 0.5) {
      // Ease-in (first half): slow start
      return Math.pow(t * 2, power) / 2;
    } else {
      // Ease-out (second half): slow end
      return 1 - Math.pow((1 - t) * 2, power) / 2;
    }
  }
}
```

---

#### 3. Premiere Pro Integration (2-3 days)

```javascript
// splice-plugin/js/autoZoom.js (continued)
async function applyAutoZoom(options) {
  const {
    transcriptWords,
    frequency = 'medium',
    scale = 1.5,
    duration = 2.0,
    enableFaceDetection = true
  } = options;

  // 1. Find zoom placements from transcript
  const zoomTimes = AutoZoomTranscriptSync.findZoomPlacements(transcriptWords, frequency);

  console.log(`Found ${zoomTimes.length} zoom placements`);

  // 2. Get active sequence
  const sequence = await getActiveSequence();
  if (!sequence) {
    throw new Error('No active sequence');
  }

  // 3. Get video clip
  const videoClip = sequence.videoTracks[0].clips[0];
  if (!videoClip) {
    throw new Error('No video clip found');
  }

  // 4. Face detection (if enabled)
  let faceDetections = [];
  if (enableFaceDetection) {
    try {
      const videoPath = await exportVideoForAnalysis(videoClip);

      const response = await fetch(`${backendUrl}/zoom/detect-faces`, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${accessToken}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          videoPath,
          times: zoomTimes
        })
      });

      const data = await response.json();
      faceDetections = data.detections;

      console.log(`Detected faces in ${faceDetections.filter(d => d.face).length} frames`);
    } catch (error) {
      console.error('Face detection failed, using center position:', error);
    }
  }

  // 5. Apply zoom keyframes to clip
  const motionComponent = await videoClip.getMotionComponent();

  for (let i = 0; i < zoomTimes.length; i++) {
    const startTime = zoomTimes[i];
    const faceCenter = faceDetections[i]?.face || { x: 50, y: 50 };

    const keyframes = AutoZoomTranscriptSync.generateKeyframes(
      startTime,
      duration,
      faceCenter,
      scale
    );

    // Apply keyframes
    for (const kf of keyframes) {
      await motionComponent.addKeyframe(kf.time, {
        scale: kf.scale * 100,
        position: {
          x: (kf.position.x - 50) * 2, // Convert percentage to offset
          y: (kf.position.y - 50) * 2
        }
      });
    }

    updateProgress(i + 1, zoomTimes.length);
  }

  console.log(`Applied ${zoomTimes.length} zoom animations`);
}
```

---

### Part B: Workflow Automation (6-7 days)

#### 1. Database Schema (0.5 days)

```sql
-- splice-backend/migrations/add_workflows.sql
CREATE TABLE workflows (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id VARCHAR(255) NOT NULL,
  name VARCHAR(255) NOT NULL,
  description TEXT,
  scope VARCHAR(50) DEFAULT 'entire_sequence', -- 'entire_sequence' | 'selected_clips' | 'active_clip'
  steps JSONB NOT NULL, -- Array of step objects
  created_at TIMESTAMP DEFAULT NOW(),
  updated_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_workflows_user ON workflows(user_id);

CREATE TABLE workflow_executions (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  workflow_id UUID REFERENCES workflows(id) ON DELETE CASCADE,
  user_id VARCHAR(255) NOT NULL,
  sequence_id VARCHAR(255),
  status VARCHAR(50) DEFAULT 'running', -- 'running' | 'completed' | 'failed' | 'cancelled'
  results JSONB, -- Array of step results
  started_at TIMESTAMP DEFAULT NOW(),
  completed_at TIMESTAMP
);

CREATE INDEX idx_executions_workflow ON workflow_executions(workflow_id);
CREATE INDEX idx_executions_user ON workflow_executions(user_id);
CREATE INDEX idx_executions_status ON workflow_executions(status);
```

---

#### 2. Backend API (2-3 days)

```javascript
// splice-backend/routes/workflows.js
const express = require('express');
const router = express.Router();
const { authenticateToken } = require('../middleware/auth');
const db = require('../db');

// Create workflow
router.post('/', authenticateToken, async (req, res) => {
  try {
    const { name, description, scope, steps } = req.body;
    const userId = req.stripeCustomerId;

    if (!name || !steps || !Array.isArray(steps)) {
      return res.status(400).json({ error: 'name and steps array required' });
    }

    const result = await db.query(
      `INSERT INTO workflows (user_id, name, description, scope, steps)
       VALUES ($1, $2, $3, $4, $5)
       RETURNING *`,
      [userId, name, description, scope || 'entire_sequence', JSON.stringify(steps)]
    );

    res.json({
      success: true,
      workflow: result.rows[0]
    });
  } catch (error) {
    console.error('Create workflow error:', error);
    res.status(500).json({ error: 'Failed to create workflow' });
  }
});

// List workflows
router.get('/', authenticateToken, async (req, res) => {
  try {
    const userId = req.stripeCustomerId;

    const result = await db.query(
      `SELECT * FROM workflows WHERE user_id = $1 ORDER BY updated_at DESC`,
      [userId]
    );

    res.json({
      success: true,
      workflows: result.rows
    });
  } catch (error) {
    console.error('List workflows error:', error);
    res.status(500).json({ error: 'Failed to list workflows' });
  }
});

// Get workflow by ID
router.get('/:id', authenticateToken, async (req, res) => {
  try {
    const { id } = req.params;
    const userId = req.stripeCustomerId;

    const result = await db.query(
      `SELECT * FROM workflows WHERE id = $1 AND user_id = $2`,
      [id, userId]
    );

    if (result.rows.length === 0) {
      return res.status(404).json({ error: 'Workflow not found' });
    }

    res.json({
      success: true,
      workflow: result.rows[0]
    });
  } catch (error) {
    console.error('Get workflow error:', error);
    res.status(500).json({ error: 'Failed to get workflow' });
  }
});

// Update workflow
router.put('/:id', authenticateToken, async (req, res) => {
  try {
    const { id } = req.params;
    const { name, description, scope, steps } = req.body;
    const userId = req.stripeCustomerId;

    const result = await db.query(
      `UPDATE workflows
       SET name = COALESCE($1, name),
           description = COALESCE($2, description),
           scope = COALESCE($3, scope),
           steps = COALESCE($4, steps),
           updated_at = NOW()
       WHERE id = $5 AND user_id = $6
       RETURNING *`,
      [name, description, scope, steps ? JSON.stringify(steps) : null, id, userId]
    );

    if (result.rows.length === 0) {
      return res.status(404).json({ error: 'Workflow not found' });
    }

    res.json({
      success: true,
      workflow: result.rows[0]
    });
  } catch (error) {
    console.error('Update workflow error:', error);
    res.status(500).json({ error: 'Failed to update workflow' });
  }
});

// Delete workflow
router.delete('/:id', authenticateToken, async (req, res) => {
  try {
    const { id } = req.params;
    const userId = req.stripeCustomerId;

    const result = await db.query(
      `DELETE FROM workflows WHERE id = $1 AND user_id = $2 RETURNING id`,
      [id, userId]
    );

    if (result.rows.length === 0) {
      return res.status(404).json({ error: 'Workflow not found' });
    }

    res.json({ success: true });
  } catch (error) {
    console.error('Delete workflow error:', error);
    res.status(500).json({ error: 'Failed to delete workflow' });
  }
});

// Execute workflow
router.post('/:id/execute', authenticateToken, async (req, res) => {
  try {
    const { id } = req.params;
    const { sequenceId } = req.body;
    const userId = req.stripeCustomerId;

    // Get workflow
    const workflowResult = await db.query(
      `SELECT * FROM workflows WHERE id = $1 AND user_id = $2`,
      [id, userId]
    );

    if (workflowResult.rows.length === 0) {
      return res.status(404).json({ error: 'Workflow not found' });
    }

    const workflow = workflowResult.rows[0];

    // Create execution record
    const executionResult = await db.query(
      `INSERT INTO workflow_executions (workflow_id, user_id, sequence_id, status)
       VALUES ($1, $2, $3, 'running')
       RETURNING *`,
      [id, userId, sequenceId]
    );

    const execution = executionResult.rows[0];

    // Return immediately - execution happens asynchronously
    res.json({
      success: true,
      executionId: execution.id,
      status: 'running'
    });

    // Execute workflow in background (non-blocking)
    executeWorkflowAsync(workflow, execution.id, userId, sequenceId)
      .catch(error => {
        console.error('Workflow execution error:', error);
      });

  } catch (error) {
    console.error('Execute workflow error:', error);
    res.status(500).json({ error: 'Failed to execute workflow' });
  }
});

// Get execution status
router.get('/executions/:executionId', authenticateToken, async (req, res) => {
  try {
    const { executionId } = req.params;
    const userId = req.stripeCustomerId;

    const result = await db.query(
      `SELECT * FROM workflow_executions WHERE id = $1 AND user_id = $2`,
      [executionId, userId]
    );

    if (result.rows.length === 0) {
      return res.status(404).json({ error: 'Execution not found' });
    }

    res.json({
      success: true,
      execution: result.rows[0]
    });
  } catch (error) {
    console.error('Get execution error:', error);
    res.status(500).json({ error: 'Failed to get execution' });
  }
});

module.exports = router;
```

**Workflow Execution Engine**:
```javascript
// splice-backend/services/workflowExecutor.js
const db = require('../db');

async function executeWorkflowAsync(workflow, executionId, userId, sequenceId) {
  const results = [];

  try {
    // Sort steps by order
    const steps = workflow.steps.sort((a, b) => (a.order || 0) - (b.order || 0));

    for (const step of steps) {
      if (!step.enabled) {
        results.push({ step: step.type, status: 'skipped' });
        continue;
      }

      try {
        // Execute step based on type
        let result;
        switch (step.type) {
          case 'silenceCutting':
            result = await executeSilenceCutting(userId, sequenceId, step.settings);
            break;
          case 'zooms':
            result = await executeZooms(userId, sequenceId, step.settings);
            break;
          case 'captions':
            result = await executeCaptions(userId, sequenceId, step.settings);
            break;
          case 'music':
            result = await executeMusic(userId, sequenceId, step.settings);
            break;
          case 'chapters':
            result = await executeChapters(userId, sequenceId, step.settings);
            break;
          default:
            throw new Error(`Unknown step type: ${step.type}`);
        }

        results.push({ step: step.type, status: 'success', result });

        // Update progress
        await db.query(
          `UPDATE workflow_executions SET results = $1 WHERE id = $2`,
          [JSON.stringify(results), executionId]
        );

      } catch (error) {
        // Non-blocking error - log and continue
        console.error(`Step ${step.type} failed:`, error);
        results.push({ step: step.type, status: 'failed', error: error.message });

        // Continue to next step (don't stop pipeline)
      }
    }

    // Mark execution complete
    await db.query(
      `UPDATE workflow_executions
       SET status = 'completed', results = $1, completed_at = NOW()
       WHERE id = $2`,
      [JSON.stringify(results), executionId]
    );

  } catch (error) {
    console.error('Workflow execution fatal error:', error);

    await db.query(
      `UPDATE workflow_executions
       SET status = 'failed', results = $1, completed_at = NOW()
       WHERE id = $2`,
      [JSON.stringify({ error: error.message }), executionId]
    );
  }
}

// Step execution functions
async function executeSilenceCutting(userId, sequenceId, settings) {
  // Call existing silence cutting endpoint
  const response = await fetch(`http://localhost:3847/silence/cut`, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ userId, sequenceId, ...settings })
  });

  if (!response.ok) {
    throw new Error('Silence cutting failed');
  }

  return await response.json();
}

async function executeZooms(userId, sequenceId, settings) {
  // Call zoom endpoint
  const response = await fetch(`http://localhost:3847/zoom/apply`, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ userId, sequenceId, ...settings })
  });

  if (!response.ok) {
    throw new Error('Zoom application failed');
  }

  return await response.json();
}

// ... (similar functions for captions, music, chapters)

module.exports = { executeWorkflowAsync };
```

---

#### 3. Plugin UI (3-4 days)

**Workflow Builder UI** (`splice-plugin/workflow-builder.html`):
```html
<div class="workflow-builder">
  <div class="workflow-header">
    <input type="text" id="workflow-name" placeholder="Workflow Name" />
    <button id="save-workflow">Save</button>
    <button id="load-workflow">Load</button>
  </div>

  <div class="workflow-steps">
    <h3>Steps</h3>
    <div id="steps-container">
      <!-- Steps will be added here dynamically -->
    </div>

    <div class="add-step">
      <select id="step-type">
        <option value="">-- Add Step --</option>
        <option value="silenceCutting">Silence Cutting</option>
        <option value="zooms">Auto Zoom</option>
        <option value="captions">Captions</option>
        <option value="music">Music</option>
        <option value="chapters">Chapters</option>
      </select>
      <button id="add-step-btn">Add</button>
    </div>
  </div>

  <div class="workflow-actions">
    <button id="execute-workflow" class="primary">Execute Workflow</button>
  </div>
</div>

<template id="step-template">
  <div class="workflow-step" data-step-id="">
    <div class="step-header">
      <span class="step-number"></span>
      <span class="step-type"></span>
      <input type="checkbox" class="step-enabled" checked />
      <button class="step-settings">⚙️</button>
      <button class="step-remove">❌</button>
    </div>
    <div class="step-settings-panel" style="display: none;">
      <!-- Settings will be populated based on step type -->
    </div>
  </div>
</template>
```

**Workflow Builder JS**:
```javascript
// splice-plugin/js/workflowBuilder.js
class WorkflowBuilder {
  constructor() {
    this.steps = [];
    this.workflowId = null;
    this.initializeEventListeners();
  }

  initializeEventListeners() {
    document.getElementById('add-step-btn').addEventListener('click', () => {
      const stepType = document.getElementById('step-type').value;
      if (stepType) {
        this.addStep(stepType);
      }
    });

    document.getElementById('save-workflow').addEventListener('click', () => {
      this.saveWorkflow();
    });

    document.getElementById('load-workflow').addEventListener('click', () => {
      this.loadWorkflowDialog();
    });

    document.getElementById('execute-workflow').addEventListener('click', () => {
      this.executeWorkflow();
    });
  }

  addStep(type) {
    const step = {
      id: generateId(),
      type,
      enabled: true,
      order: this.steps.length,
      settings: this.getDefaultSettings(type)
    };

    this.steps.push(step);
    this.renderSteps();
  }

  getDefaultSettings(type) {
    const defaults = {
      silenceCutting: {
        tightness: 65,
        algorithm: 'rms',
        minSilenceLength: 0.5
      },
      zooms: {
        frequency: 'medium',
        scale: 1.5,
        faceDetection: true
      },
      captions: {
        language: 'en',
        template: 'mrbeast'
      },
      music: {
        mood: 'energetic',
        duration: 120
      },
      chapters: {
        maxChapters: 10
      }
    };

    return defaults[type] || {};
  }

  renderSteps() {
    const container = document.getElementById('steps-container');
    container.innerHTML = '';

    this.steps.forEach((step, index) => {
      const template = document.getElementById('step-template');
      const stepEl = template.content.cloneNode(true);

      stepEl.querySelector('.workflow-step').dataset.stepId = step.id;
      stepEl.querySelector('.step-number').textContent = index + 1;
      stepEl.querySelector('.step-type').textContent = step.type;
      stepEl.querySelector('.step-enabled').checked = step.enabled;

      // Event listeners
      stepEl.querySelector('.step-enabled').addEventListener('change', (e) => {
        step.enabled = e.target.checked;
      });

      stepEl.querySelector('.step-settings').addEventListener('click', () => {
        this.showStepSettings(step);
      });

      stepEl.querySelector('.step-remove').addEventListener('click', () => {
        this.removeStep(step.id);
      });

      container.appendChild(stepEl);
    });
  }

  showStepSettings(step) {
    // Show modal with settings for this step type
    const modal = document.createElement('div');
    modal.className = 'modal';
    modal.innerHTML = `
      <div class="modal-content">
        <h3>${step.type} Settings</h3>
        <div id="settings-form"></div>
        <button id="save-settings">Save</button>
        <button id="cancel-settings">Cancel</button>
      </div>
    `;

    // Populate settings form based on step type
    const form = modal.querySelector('#settings-form');
    for (const [key, value] of Object.entries(step.settings)) {
      form.innerHTML += `
        <div class="form-field">
          <label>${key}</label>
          <input type="text" name="${key}" value="${value}" />
        </div>
      `;
    }

    document.body.appendChild(modal);

    modal.querySelector('#save-settings').addEventListener('click', () => {
      // Save settings
      const inputs = form.querySelectorAll('input');
      inputs.forEach(input => {
        step.settings[input.name] = input.value;
      });
      modal.remove();
    });

    modal.querySelector('#cancel-settings').addEventListener('click', () => {
      modal.remove();
    });
  }

  removeStep(stepId) {
    this.steps = this.steps.filter(s => s.id !== stepId);
    this.renderSteps();
  }

  async saveWorkflow() {
    const name = document.getElementById('workflow-name').value;
    if (!name) {
      alert('Please enter a workflow name');
      return;
    }

    try {
      const response = await fetch(`${backendUrl}/workflows`, {
        method: this.workflowId ? 'PUT' : 'POST',
        headers: {
          'Authorization': `Bearer ${accessToken}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          name,
          steps: this.steps
        })
      });

      const data = await response.json();

      if (data.success) {
        this.workflowId = data.workflow.id;
        alert('Workflow saved!');
      } else {
        alert('Failed to save workflow');
      }
    } catch (error) {
      console.error('Save workflow error:', error);
      alert('Error saving workflow');
    }
  }

  async loadWorkflowDialog() {
    // Fetch user's workflows
    const response = await fetch(`${backendUrl}/workflows`, {
      headers: {
        'Authorization': `Bearer ${accessToken}`
      }
    });

    const data = await response.json();

    if (!data.success || data.workflows.length === 0) {
      alert('No saved workflows found');
      return;
    }

    // Show selection dialog
    const modal = document.createElement('div');
    modal.className = 'modal';
    modal.innerHTML = `
      <div class="modal-content">
        <h3>Load Workflow</h3>
        <select id="workflow-select">
          ${data.workflows.map(w => `<option value="${w.id}">${w.name}</option>`).join('')}
        </select>
        <button id="load-btn">Load</button>
        <button id="cancel-btn">Cancel</button>
      </div>
    `;

    document.body.appendChild(modal);

    modal.querySelector('#load-btn').addEventListener('click', async () => {
      const workflowId = modal.querySelector('#workflow-select').value;
      await this.loadWorkflow(workflowId);
      modal.remove();
    });

    modal.querySelector('#cancel-btn').addEventListener('click', () => {
      modal.remove();
    });
  }

  async loadWorkflow(workflowId) {
    const response = await fetch(`${backendUrl}/workflows/${workflowId}`, {
      headers: {
        'Authorization': `Bearer ${accessToken}`
      }
    });

    const data = await response.json();

    if (data.success) {
      this.workflowId = data.workflow.id;
      document.getElementById('workflow-name').value = data.workflow.name;
      this.steps = data.workflow.steps;
      this.renderSteps();
    }
  }

  async executeWorkflow() {
    if (this.steps.length === 0) {
      alert('No steps to execute');
      return;
    }

    if (!this.workflowId) {
      alert('Please save workflow first');
      return;
    }

    // Get active sequence ID
    const sequence = await getActiveSequence();
    if (!sequence) {
      alert('No active sequence');
      return;
    }

    try {
      const response = await fetch(`${backendUrl}/workflows/${this.workflowId}/execute`, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${accessToken}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          sequenceId: sequence.id
        })
      });

      const data = await response.json();

      if (data.success) {
        alert(`Workflow started! Execution ID: ${data.executionId}`);

        // Poll for completion
        this.pollExecutionStatus(data.executionId);
      } else {
        alert('Failed to start workflow');
      }
    } catch (error) {
      console.error('Execute workflow error:', error);
      alert('Error executing workflow');
    }
  }

  async pollExecutionStatus(executionId) {
    const interval = setInterval(async () => {
      try {
        const response = await fetch(`${backendUrl}/workflows/executions/${executionId}`, {
          headers: {
            'Authorization': `Bearer ${accessToken}`
          }
        });

        const data = await response.json();

        if (data.success) {
          const execution = data.execution;

          if (execution.status === 'completed') {
            clearInterval(interval);
            alert('Workflow completed!');
            console.log('Results:', execution.results);
          } else if (execution.status === 'failed') {
            clearInterval(interval);
            alert('Workflow failed. Check console for details.');
            console.error('Workflow error:', execution.results);
          }
        }
      } catch (error) {
        console.error('Poll error:', error);
      }
    }, 2000); // Poll every 2 seconds
  }
}

// Initialize
const workflowBuilder = new WorkflowBuilder();
```

---

## Phase 4: Polish, Testing & Documentation
**Duration**: 5-7 days (1 week)

### 1. Performance Optimization (2 days)
- Profile color picker rendering
- Optimize animation keyframe generation
- Cache face detection models
- Batch database queries
- Add loading indicators for long operations

### 2. Testing (2-3 days)
- Unit tests for all animation algorithms
- Integration tests for workflow execution
- End-to-end tests with Premiere Pro
- Performance tests with 100+ captions
- Load tests for workflow system

### 3. Documentation (1-2 days)
- User guide for caption styling
- Tutorial video for auto zoom
- Workflow automation examples
- API documentation
- Troubleshooting guide

---

## Summary

### Total Timeline: 23-31 Days (5-6 Weeks)

| Phase | Deliverables | Days |
|-------|-------------|------|
| **Phase 2** | 15 color pickers + 6 animations + gradients | 5-7 |
| **Phase 3A** | Face detection + transcript sync + asymmetric easing | 7-10 |
| **Phase 3B** | Workflow database + API + UI + execution engine | 6-7 |
| **Phase 4** | Performance + testing + documentation | 5-7 |
| **Total** | **All Features** | **23-31** |

### Cost: $0/month
- No additional API costs
- All features use existing infrastructure
- Face detection runs locally (face-api.js)
- Workflow automation uses existing endpoints

### Team: 1-2 Developers
- 1 developer: 6 weeks
- 2 developers: 4 weeks (parallelized)

---

## Success Metrics

### Phase 2 Success:
- ✅ All 15 color pickers functional
- ✅ Gradients render correctly at all angles
- ✅ All 6 animations work smoothly (60fps)
- ✅ Export to Premiere Pro preserves styling

### Phase 3A Success:
- ✅ Face detection accuracy >85%
- ✅ Transcript sync places zooms at natural breaks
- ✅ Asymmetric easing feels professional
- ✅ Processing time <5s per zoom placement

### Phase 3B Success:
- ✅ Workflows save/load reliably
- ✅ Execution completes without crashes
- ✅ Non-blocking errors don't stop pipeline
- ✅ Progress tracking updates in real-time

### Phase 4 Success:
- ✅ All tests passing (unit + integration + E2E)
- ✅ Documentation complete with examples
- ✅ Performance targets met (<2s caption render)
- ✅ Zero critical bugs

---

**Document Version**: 1.0
**Last Updated**: 2026-01-12
**Timeline**: 5-6 weeks with 1-2 developers
**Cost**: $0/month additional
**Next Steps**: Begin Phase 2 (Caption Styling System)
