---
description: Autonomous feature builder - reads architecture, builds, tests, loops
argument-hint: "[feature-name] [--from architecture.md]"
allowed-tools: ["Bash", "Read", "Write", "Edit", "Glob", "Grep", "Task", "mcp__grep__searchGitHub", "WebSearch"]
---

# Autonomous Build Command

> **Prompting Principles** (keep prompts token-effective):
> - Short, focused prompts > long essays. Agent is smart.
> - Reference docs, don't dump them. Summarize what's needed.
> - Work in focused sets. One feature family per session.
> - Describe what you see, not file paths. Let agent navigate.

Build features autonomously by:
1. Reading architecture documents (summarized, not dumped)
2. **Searching for working code examples** (grep MCP)
3. Implementing incrementally (focused, small steps)
4. **Logging all fix attempts** to debug-log.md
5. **Researching errors online** when stuck
6. Validating after each step
7. **Auto-continuing** until complete or blocked

## Usage

```
/build                           # Continue from buildguide.md next section
/build auth-system               # Build specific feature
/build --from docs/architecture.md   # Use specific architecture doc
```

## Instructions

Parse arguments: $ARGUMENTS

### Step 0: Initialize Debug Log

Ensure `.claude/docs/debug-log.md` exists:

```bash
mkdir -p .claude/docs
if [[ ! -f .claude/docs/debug-log.md ]]; then
    # Create from template or initialize
    cat > .claude/docs/debug-log.md << 'EOF'
# Debug Log

> Last Updated: [DATE]

## Active Issues

## Session: [TODAY]

---

## Resolved Issues

## Patterns Discovered

## Research Cache
EOF
fi
```

Add session header for today if not exists.

### Step 1: Load Architecture Context

**Find and read architecture documents in this order:**

1. If `--from <file>` specified, read that file
2. Otherwise check these locations:
   - `buildguide.md` (preferred - has implementation plan)
   - `ARCHITECTURE.md`
   - `docs/architecture.md`
   - `.claude/docs/architecture.md`
   - `CLAUDE.md` (fallback)

Extract from architecture:
- **Tech stack** (language, framework, tools)
- **Project structure** (directories, patterns)
- **Quality commands** (lint, typecheck, test commands)
- **Current section** to implement (from buildguide.md checklist)

### Step 2: Determine Build Target

**If feature name provided:**
- Find matching section in buildguide.md
- Read its Implementation Approach

**If no feature name:**
- Find first unchecked `- [ ]` section in buildguide.md
- That's the build target

**Extract from section:**
- What to build (Overview)
- How it fits (Architecture Fit)
- Implementation steps (Implementation Approach)
- Files to create/modify

### Step 3: Research Before Building ⭐ NEW

**Before implementing, search for working examples:**

Use `mcp__grep__searchGitHub` to find real-world code:

```
For each key component to implement:

1. Search for the pattern:
   - query: "[library/framework] [feature]"
   - language: [project language]

2. Search for similar implementations:
   - query: "[feature name] implementation"
   - language: [project language]

3. Search in test files for usage examples:
   - query: "[feature]"
   - path: "*test*" or "*spec*"
```

**Log research to debug-log.md:**

```markdown
### Research: [feature name]
**Time**: [timestamp]
**Searches performed**:
1. [query 1] → [X results]
2. [query 2] → [X results]

**Useful patterns found**:
- [Pattern 1 from repo/file]
- [Pattern 2 from repo/file]

**Implementation approach based on research**:
[Summary of best practices discovered]
```

### Step 4: Create Build Plan

Write a `.claude/current-build.local.md` state file:

```markdown
---
feature: [feature name]
phase: implementing
started: [timestamp]
iteration: 1
fix_attempts: 0
research_done: true
---

## Build Target
[What we're building]

## Research Insights
[Key patterns from Step 3]

## Implementation Steps
1. [ ] Step 1
2. [ ] Step 2
...

## Quality Gates
- [ ] Lint passes
- [ ] Types check
- [ ] Tests pass
- [ ] No regressions

## Files to Modify
- [file list from architecture]
```

### Step 5: Implement Incrementally

For each implementation step:

1. **Announce** what you're implementing
2. **Reference** research insights from Step 3
3. **Implement** the code changes following discovered patterns
4. **Auto-quality check** runs via PostToolUse hook (lint, types)
5. **If errors**: Go to Step 6 (Error Resolution)
6. **Mark step complete** in current-build.local.md
7. **Continue** to next step

### Step 6: Error Resolution with Research ⭐ NEW

**When an error occurs:**

**6a. Log the error to debug-log.md:**
```markdown
### Issue: [Error type]
**Time**: [timestamp]
**Error Message**:
```
[exact error]
```
**Context**: [file, function, what was being done]
```

**6b. Search GitHub for similar errors:**
```
Use mcp__grep__searchGitHub:
- query: "[key part of error message]"
- language: [project language]
```

**6c. If GitHub search insufficient (< 3 results), search web:**
```
Use WebSearch:
- query: "[error message]" [framework] fix solution
```

**6d. Log research results:**
```markdown
**Research Results**:
- GitHub: [X] similar cases found
- Web: [sources checked]

**Potential solutions**:
1. [Solution 1] - from [source]
2. [Solution 2] - from [source]
```

**6e. Try fixes in order, logging each attempt:**
```markdown
#### Attempt [N]: [description]
**Time**: [timestamp]
**Approach**: [what's being tried]
**Based on**: [source of this solution]
**Result**: ❌ Failed / ✅ Success
```

**6f. After 3 failed attempts:**
- Do deeper web search with different terms
- Search for the specific library + error combination
- Check if it's a known issue in GitHub Issues

**6g. After 5 failed attempts:**
- Log all attempts to debug-log.md
- Note: "STUCK - needs human review"
- Continue to next step or feature (don't block entire build)

### Step 7: After Implementation Complete

Run full validation:

```bash
# Detect and run quality commands based on project type
if [[ -f package.json ]]; then
    npm run lint 2>&1 || true
    npm run typecheck 2>&1 || npx tsc --noEmit 2>&1 || true
    npm test 2>&1 || true
elif [[ -f pyproject.toml ]] || [[ -f requirements.txt ]]; then
    ruff check . 2>&1 || pylint **/*.py 2>&1 || true
    mypy . 2>&1 || true
    pytest 2>&1 || true
elif [[ -f go.mod ]]; then
    go vet ./... 2>&1 || true
    staticcheck ./... 2>&1 || true
    go test ./... 2>&1 || true
elif [[ -f Cargo.toml ]]; then
    cargo clippy 2>&1 || true
    cargo test 2>&1 || true
fi
```

### Step 8: Handle Validation Failures

**If any quality gate fails:**

1. Parse error output
2. Group errors by type (lint, type, test)
3. **For each error group, research solutions first:**

```
Use mcp__grep__searchGitHub to find how others solved similar issues
Log findings to debug-log.md
```

4. Spawn parallel fix agents WITH research context:

```
Use the Task tool to spawn 3 agents in parallel:

Agent 1 (if lint errors):
- Research: Search for "[lint rule]" fix examples
- Fix all lint errors using discovered patterns
- Log each fix attempt to debug-log.md
- Re-run lint to verify

Agent 2 (if type errors):
- Research: Search for the type error pattern
- Fix all type errors
- Log each fix attempt to debug-log.md
- Re-run typecheck to verify

Agent 3 (if test failures):
- Research: Search for similar test failure patterns
- Analyze root cause
- Fix code or update tests
- Log each fix attempt to debug-log.md
- Re-run tests to verify
```

5. After agents complete, run validation again
6. Loop until all gates pass (max 3 iterations)
7. **If still failing after 3 iterations:**
   - Log to debug-log.md as unresolved
   - Continue to next feature (don't block)
   - Mark in buildguide.md with ⚠️

### Step 9: Mark Complete and Continue

When all quality gates pass:

1. **Update current-build.local.md**:
   - Set `phase: complete`
   - Check all quality gates
   - Note total fix_attempts

2. **Update buildguide.md**:
   - Mark section complete: `- [ ]` → `- [x]`

3. **Update debug-log.md**:
   - Move resolved issues to "Resolved Issues" section
   - Add to "Patterns Discovered" if new patterns found
   - Cache useful code examples in "Research Cache"

4. **Run /checkpoint**:
   - Saves state to CLAUDE.md
   - Generates continuation prompt
   - Advances to next section

5. **Check context usage**:
   - If < 40%: Continue to next section automatically
   - If >= 40%: Let auto-continue hook handle compaction

6. **Loop**:
   - Find next unchecked section
   - Go back to Step 2
   - Continue until all sections complete or user says "stop"

### Step 10: Completion

When all sections in buildguide.md are checked:

```
✅ Build Complete!

All sections implemented:
- [x] Section 1
- [x] Section 2
...

Quality verified:
- Lint: ✅
- Types: ✅
- Tests: ✅

Debug Log Summary:
- Total issues encountered: [N]
- Issues resolved: [N]
- Patterns discovered: [N]

See .claude/docs/debug-log.md for full history.

Run /checkpoint to save final state.
```

## Stopping the Build

Say "stop", "pause", or "hold" to pause autonomous building.
The current state is saved in `.claude/current-build.local.md`.

Resume with `/build` - it will continue from where it stopped.

## Integration

This command integrates with:
- `/collect` - Gathers architecture into buildguide.md
- `/checkpoint` - Saves state after each feature
- `/research` - Deep-dive into specific patterns or errors
- `/log-fix` - Quick fix logging
- Auto-continue hook - Handles context compaction
- PostToolUse hook - Auto-lints after every edit
- **mcp__grep__searchGitHub** - Finds working code examples
- **WebSearch** - Researches error solutions online
