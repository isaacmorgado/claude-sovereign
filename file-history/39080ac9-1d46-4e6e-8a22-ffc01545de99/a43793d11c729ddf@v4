---
description: Autonomous feature builder - reads architecture, builds, tests, loops
argument-hint: "[feature-name] [--from architecture.md]"
allowed-tools: ["Bash", "Read", "Write", "Edit", "Glob", "Grep", "Task", "mcp__grep__searchGitHub", "WebSearch"]
---

# Autonomous Build Command

> **Prompting Principles** (keep prompts token-effective):
> - Short, focused prompts > long essays. Agent is smart.
> - Reference docs, don't dump them. Summarize what's needed.
> - Work in focused sets. One feature family per session.
> - Describe what you see, not file paths. Let agent navigate.

Build features autonomously by:
1. Reading architecture documents (summarized, not dumped)
2. **Searching for working code examples** (grep MCP)
3. Implementing incrementally (focused, small steps)
4. **Logging all fix attempts** to debug-log.md
5. **Researching errors online** when stuck
6. Validating after each step
7. **Auto-continuing** until complete or blocked

## Usage

```
/build                           # Continue from buildguide.md next section
/build auth-system               # Build specific feature
/build --from docs/architecture.md   # Use specific architecture doc
```

## Instructions

Parse arguments: $ARGUMENTS

### Step 0: Initialize Debug Log

Ensure `.claude/docs/debug-log.md` exists:

```bash
mkdir -p .claude/docs
if [[ ! -f .claude/docs/debug-log.md ]]; then
    # Create from template or initialize
    cat > .claude/docs/debug-log.md << 'EOF'
# Debug Log

> Last Updated: [DATE]

## Active Issues

## Session: [TODAY]

---

## Resolved Issues

## Patterns Discovered

## Research Cache
EOF
fi
```

Add session header for today if not exists.

### Step 1: Load Architecture Context

**Find and read architecture documents in this order:**

1. If `--from <file>` specified, read that file
2. Otherwise check these locations:
   - `buildguide.md` (preferred - has implementation plan)
   - `ARCHITECTURE.md`
   - `docs/architecture.md`
   - `.claude/docs/architecture.md`
   - `CLAUDE.md` (fallback)

Extract from architecture:
- **Tech stack** (language, framework, tools)
- **Project structure** (directories, patterns)
- **Quality commands** (lint, typecheck, test commands)
- **Current section** to implement (from buildguide.md checklist)

### Step 2: Determine Build Target

**If feature name provided:**
- Find matching section in buildguide.md
- Read its Implementation Approach

**If no feature name:**
- Find first unchecked `- [ ]` section in buildguide.md
- That's the build target

**Extract from section:**
- What to build (Overview)
- How it fits (Architecture Fit)
- Implementation steps (Implementation Approach)
- Files to create/modify

### Step 3: Research Before Building ⭐ NEW

**Before implementing, search for working examples:**

Use `mcp__grep__searchGitHub` to find real-world code:

```
For each key component to implement:

1. Search for the pattern:
   - query: "[library/framework] [feature]"
   - language: [project language]

2. Search for similar implementations:
   - query: "[feature name] implementation"
   - language: [project language]

3. Search in test files for usage examples:
   - query: "[feature]"
   - path: "*test*" or "*spec*"
```

**Log research to debug-log.md:**

```markdown
### Research: [feature name]
**Time**: [timestamp]
**Searches performed**:
1. [query 1] → [X results]
2. [query 2] → [X results]

**Useful patterns found**:
- [Pattern 1 from repo/file]
- [Pattern 2 from repo/file]

**Implementation approach based on research**:
[Summary of best practices discovered]
```

### Step 4: Create Build Plan

Write a `.claude/current-build.local.md` state file:

```markdown
---
feature: [feature name]
phase: implementing
started: [timestamp]
iteration: 1
fix_attempts: 0
research_done: true
---

## Build Target
[What we're building]

## Research Insights
[Key patterns from Step 3]

## Implementation Steps
1. [ ] Step 1
2. [ ] Step 2
...

## Quality Gates
- [ ] Lint passes
- [ ] Types check
- [ ] Tests pass
- [ ] No regressions

## Files to Modify
- [file list from architecture]
```

### Step 5: Implement Incrementally

For each implementation step:

1. **Announce** what you're implementing
2. **Reference** research insights from Step 3
3. **Implement** the code changes following discovered patterns
4. **Auto-quality check** runs via PostToolUse hook (lint, types)
5. **If errors**: Go to Step 6 (Error Resolution)
6. **Mark step complete** in current-build.local.md
7. **Continue** to next step

### Step 6: Smart Error Resolution ⭐ ENHANCED

**Error Classification System** (from Discord.js, neo4j, midday-ai patterns):

| Classification | Retry? | Action |
|---------------|--------|--------|
| TRANSIENT | Yes | Network/timeout - retry with backoff |
| RATE_LIMIT | Yes | Wait longer, then retry |
| CLIENT_ERROR | No | Fix code (syntax, type, validation) |
| BUILD_ERROR | No | Fix code (lint, compile errors) |
| DATABASE_ERROR | Maybe | Check connection, retry once |
| UNKNOWN | Once | Retry once, then investigate |

**6a. Classify the error first:**
```
Look at error message and classify:
- TRANSIENT: timeout, network, 502/503/504
- RATE_LIMIT: 429, "too many requests"
- CLIENT_ERROR: syntax error, type error, 400/401/403
- BUILD_ERROR: "cannot find", lint error, compile failed
- DATABASE_ERROR: connection, postgres, deadlock
```

**6b. If TRANSIENT/RATE_LIMIT - auto retry with backoff:**
```
Retry up to 3 times with exponential backoff:
- Attempt 1: wait 1s
- Attempt 2: wait 2s
- Attempt 3: wait 4s
- RATE_LIMIT: multiply delays by 5
```

**6c. If CLIENT_ERROR/BUILD_ERROR - research and fix:**
```
1. Extract key error pattern (not full message)
2. Search GitHub: mcp__grep__searchGitHub
   - query: "[error code or pattern]"
   - language: [project language]
3. If < 3 results, search web:
   - WebSearch: "[error] [framework] fix"
```

**6d. Log to debug-log.md with classification:**
```markdown
### Issue: [CLASSIFICATION] - [brief description]
**Time**: [timestamp]
**Classification**: [CLIENT_ERROR|BUILD_ERROR|etc]
**Retryable**: [true/false]
**Error**: `[core error message]`
**File**: [file:line if available]
**Research**: [X GitHub results, Y web sources]
**Solution**: [what fixed it or "STUCK"]
```

**6e. Try fixes based on research:**
```
For each potential fix (max 3):
1. Apply fix
2. Run validation
3. If pass → log success, continue
4. If fail → log attempt, try next
```

**6f. After 3 failed fixes:**
- Search web with different terms
- Check GitHub Issues for the library
- Look for version-specific issues

**6g. After 5 failed fixes:**
- Mark as "STUCK - [classification]" in debug-log.md
- **DO NOT BLOCK** - continue to next task
- Agent will revisit stuck issues at end of build

### Step 7: After Implementation Complete

Run full validation:

```bash
# Detect and run quality commands based on project type
if [[ -f package.json ]]; then
    npm run lint 2>&1 || true
    npm run typecheck 2>&1 || npx tsc --noEmit 2>&1 || true
    npm test 2>&1 || true
elif [[ -f pyproject.toml ]] || [[ -f requirements.txt ]]; then
    ruff check . 2>&1 || pylint **/*.py 2>&1 || true
    mypy . 2>&1 || true
    pytest 2>&1 || true
elif [[ -f go.mod ]]; then
    go vet ./... 2>&1 || true
    staticcheck ./... 2>&1 || true
    go test ./... 2>&1 || true
elif [[ -f Cargo.toml ]]; then
    cargo clippy 2>&1 || true
    cargo test 2>&1 || true
fi
```

### Step 8: Handle Validation Failures

**If any quality gate fails:**

1. Parse error output
2. Group errors by type (lint, type, test)
3. **For each error group, research solutions first:**

```
Use mcp__grep__searchGitHub to find how others solved similar issues
Log findings to debug-log.md
```

4. Spawn parallel fix agents WITH research context:

```
Use the Task tool to spawn 3 agents in parallel:

Agent 1 (if lint errors):
- Research: Search for "[lint rule]" fix examples
- Fix all lint errors using discovered patterns
- Log each fix attempt to debug-log.md
- Re-run lint to verify

Agent 2 (if type errors):
- Research: Search for the type error pattern
- Fix all type errors
- Log each fix attempt to debug-log.md
- Re-run typecheck to verify

Agent 3 (if test failures):
- Research: Search for similar test failure patterns
- Analyze root cause
- Fix code or update tests
- Log each fix attempt to debug-log.md
- Re-run tests to verify
```

5. After agents complete, run validation again
6. Loop until all gates pass (max 3 iterations)
7. **If still failing after 3 iterations:**
   - Log to debug-log.md as unresolved
   - Continue to next feature (don't block)
   - Mark in buildguide.md with ⚠️

### Step 9: Mark Complete and Continue

When all quality gates pass:

1. **Update current-build.local.md**:
   - Set `phase: complete`
   - Check all quality gates
   - Note total fix_attempts

2. **Update buildguide.md**:
   - Mark section complete: `- [ ]` → `- [x]`

3. **Update debug-log.md**:
   - Move resolved issues to "Resolved Issues" section
   - Add to "Patterns Discovered" if new patterns found
   - Cache useful code examples in "Research Cache"

4. **Run /checkpoint**:
   - Saves state to CLAUDE.md
   - Generates continuation prompt
   - Advances to next section

5. **Check context usage**:
   - If < 40%: Continue to next section automatically
   - If >= 40%: Let auto-continue hook handle compaction

6. **Loop**:
   - Find next unchecked section
   - Go back to Step 2
   - Continue until all sections complete or user says "stop"

### Step 9.5: Revisit Stuck Issues ⭐ NEW

Before completion, revisit any STUCK issues:

```bash
# Check for stuck issues
STUCK_COUNT=$(grep -c "STUCK" .claude/docs/debug-log.md 2>/dev/null || echo "0")
```

**If stuck issues exist:**

1. **Re-attempt with fresh context:**
   - Read the stuck issue from debug-log.md
   - Search GitHub with different query terms
   - Search web for latest solutions (2024/2025)

2. **Try alternative approaches:**
   - If library issue: check for alternative library
   - If type error: try type assertion or any cast (temporary)
   - If test failure: check if test itself is wrong

3. **For each stuck issue, either:**
   - ✅ Fix it and mark resolved
   - ⚠️ Document workaround and continue
   - ❌ Mark as "REQUIRES_HUMAN" with detailed context

4. **Update debug-log.md:**
```markdown
### Revisited: [Issue]
**Original Classification**: [X]
**Second Attempt Result**: [FIXED|WORKAROUND|REQUIRES_HUMAN]
**Resolution**: [what was done]
```

### Step 10: Completion

When all sections in buildguide.md are checked:

```
✅ Build Complete!

All sections implemented:
- [x] Section 1
- [x] Section 2
...

Quality verified:
- Lint: ✅
- Types: ✅
- Tests: ✅

Debug Log Summary:
- Total issues encountered: [N]
- Issues resolved: [N]
- Stuck issues revisited: [N]
- Still requiring human: [N]
- Patterns discovered: [N]

See .claude/docs/debug-log.md for full history.

Run /checkpoint to save final state.
```

## Stopping the Build

Say "stop", "pause", or "hold" to pause autonomous building.
The current state is saved in `.claude/current-build.local.md`.

Resume with `/build` - it will continue from where it stopped.

## Integration

This command integrates with:
- `/collect` - Gathers architecture into buildguide.md
- `/checkpoint` - Saves state after each feature
- `/research` - Deep-dive into specific patterns or errors
- `/log-fix` - Quick fix logging
- Auto-continue hook - Handles context compaction
- PostToolUse hook - Auto-lints after every edit
- **mcp__grep__searchGitHub** - Finds working code examples
- **WebSearch** - Researches error solutions online
