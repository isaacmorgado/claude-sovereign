/**
 * SPLICE Backend Server
 *
 * Main entry point for the SPLICE backend API.
 * Orchestrates the audio analysis pipeline.
 *
 * Slices:
 * - Slice 4: Transcription (services/transcription.js)
 * - Slice 5: Take Detection (services/takeDetection.js)
 */

/* global setTimeout, setInterval */

require('dotenv').config();

const express = require('express');
const cors = require('cors');
const fs = require('fs');
const fsPromises = require('fs').promises;
const https = require('https');
const http = require('http');
const path = require('path');

// Async file existence check (non-blocking)
async function fileExists(filePath) {
  try {
    await fsPromises.access(filePath, fs.constants.R_OK);
    return true;
  } catch {
    return false;
  }
}

// Check if running in production (Railway injects RAILWAY_ENVIRONMENT)
const isProduction = process.env.NODE_ENV === 'production' || process.env.RAILWAY_ENVIRONMENT;

// Import slice services
const { transcribeAudio, transcribeWithWords } = require('./services/transcription');
const { detectTakes } = require('./services/takeDetection');
const { detectSilences } = require('./services/silenceDetection');
const { detectAudioSilences, isFFprobeInstalled, getAudioDuration } = require('./services/ffprobeSilence');
const { detectSilencesRMS, sensitivityToParams } = require('./services/rmsSilenceDetection');
const {
  detectProfanity,
  getProfanityList,
  getSupportedLanguages,
  getAvailableBleepSounds,
  parseWordList
} = require('./services/profanityDetection');
const {
  detectStutters,
  detectAllRepetitions
} = require('./services/repetitionDetection');
const {
  analyzeMultitrack,
  autoBalanceMultitrack
} = require('./services/multitrackAnalysis');
const {
  toSRT,
  toVTT,
  toPlainText,
  toJSON,
  exportToFile,
  getSupportedFormats
} = require('./services/captionExporter');
const { processXMLFile } = require('./services/xmlProcessor');
const { isolateVocals, isReplicateConfigured } = require('./services/vocalIsolation');
const { generateCutList, generateTakesCutList, validateCutList } = require('./services/cutListGenerator');

// Usage tracking and billing
const usageTracking = require('./services/usageTracking');
// Rate limiter for usage-based endpoints
const { requireCredits } = require('./middleware/rateLimiter');
// Referral system
const referralService = require('./services/referralService');
// License key system
const licenseService = require('./services/licenseService');

// Maximum file size for audio processing (500MB)
const MAX_FILE_SIZE_BYTES = 500 * 1024 * 1024;

/**
 * Validate file size to prevent OOM crashes
 * @param {string} filePath - Path to file
 * @returns {Promise<{valid: boolean, size?: number, error?: string}>}
 */
async function validateFileSize(filePath) {
  try {
    const stats = await require('fs').promises.stat(filePath);
    if (stats.size > MAX_FILE_SIZE_BYTES) {
      return {
        valid: false,
        size: stats.size,
        error: `File too large (${(stats.size / 1024 / 1024).toFixed(1)}MB). Maximum allowed: ${MAX_FILE_SIZE_BYTES / 1024 / 1024}MB`
      };
    }
    return { valid: true, size: stats.size };
  } catch (err) {
    return { valid: false, error: `Cannot access file: ${err.message}` };
  }
}

// Stripe for webhooks
const Stripe = require('stripe');
const stripe = new Stripe(process.env.STRIPE_SECRET_KEY);

// =============================================================================
// Server Configuration
// =============================================================================

const app = express();
const PORT = process.env.PORT || 3847;

// HTTPS certificates (generated by mkcert) - only for local development
let httpsOptions = null;
if (!isProduction) {
  const keyPath = path.join(__dirname, 'localhost+1-key.pem');
  const certPath = path.join(__dirname, 'localhost+1.pem');
  if (fs.existsSync(keyPath) && fs.existsSync(certPath)) {
    httpsOptions = {
      key: fs.readFileSync(keyPath),
      cert: fs.readFileSync(certPath)
    };
  }
}

app.use(cors());

// Helper to determine tier from price ID with logging
function getTierFromPriceId(priceId) {
  if (priceId === process.env.STRIPE_PRICE_STARTER) return 'starter';
  if (priceId === process.env.STRIPE_PRICE_PRO) return 'pro';
  if (priceId === process.env.STRIPE_PRICE_TEAM) return 'team';

  // Log unknown price ID for debugging
  console.warn(`[SPLICE] Unknown price ID: ${priceId} - defaulting to starter tier`);
  return 'starter';
}

// Stripe webhook needs raw body - must be before express.json()
app.post('/webhooks/stripe', express.raw({ type: 'application/json' }), async (req, res) => {
  const sig = req.headers['stripe-signature'];
  const webhookSecret = process.env.STRIPE_WEBHOOK_SECRET;

  let event;

  try {
    if (webhookSecret) {
      event = stripe.webhooks.constructEvent(req.body, sig, webhookSecret);
    } else if (isProduction) {
      // SECURITY: Reject unsigned webhooks in production
      console.error('[SPLICE] CRITICAL: STRIPE_WEBHOOK_SECRET not set in production');
      return res.status(500).json({ error: 'Webhook configuration error: secret not configured' });
    } else {
      // For local development testing only
      // req.body is a Buffer from express.raw(), convert to string for JSON.parse
      const bodyString = typeof req.body === 'string' ? req.body : req.body.toString('utf8');
      event = JSON.parse(bodyString);
      console.warn('[SPLICE] Warning: Processing webhook without signature verification (dev only)');
    }
  } catch (err) {
    console.error('[SPLICE] Webhook signature verification failed:', err.message);
    return res.status(400).json({ error: 'Webhook signature verification failed' });
  }

  console.log(`[SPLICE] Webhook received: ${event.type} (${event.id})`);

  // Idempotency check - skip if already processed
  if (await usageTracking.isEventProcessed(event.id)) {
    console.log(`[SPLICE] Event ${event.id} already processed, skipping`);
    return res.json({ received: true, skipped: true });
  }

  try {
    switch (event.type) {
      case 'customer.subscription.created':
      case 'customer.subscription.updated': {
        const subscription = event.data.object;
        const customerId = subscription.customer;

        // Validate customerId
        if (!customerId) {
          console.error('[SPLICE] Missing customer ID in subscription event');
          return res.status(400).json({ error: 'Missing customer ID' });
        }

        // Get tier from price ID
        const priceId = subscription.items?.data?.[0]?.price?.id;
        const tier = getTierFromPriceId(priceId);

        // Update user tier and reset hours
        await usageTracking.updateTier(customerId, tier);
        console.log(`[SPLICE] Updated customer ${customerId} to tier: ${tier}`);

        // Generate license key for new subscriptions with retry and delivery
        if (event.type === 'customer.subscription.created') {
          let licenseResult = null;
          let retryCount = 0;
          const maxRetries = 3;

          // Retry mechanism for license key generation
          while (retryCount < maxRetries) {
            licenseResult = await licenseService.generateLicenseKey(customerId);
            if (licenseResult.success) {
              break;
            }
            retryCount++;
            console.warn(`[SPLICE] License key generation attempt ${retryCount}/${maxRetries} failed: ${licenseResult.error}`);
            // Wait before retry (exponential backoff)
            if (retryCount < maxRetries) {
              await new Promise(resolve => setTimeout(resolve, 1000 * retryCount));
            }
          }

          if (licenseResult && licenseResult.success) {
            console.log(`[SPLICE] Generated license key for ${customerId}: ${licenseResult.key}`);

            // Store license key in Stripe subscription metadata as backup
            try {
              await stripe.subscriptions.update(subscription.id, {
                metadata: {
                  license_key: licenseResult.key,
                  license_generated_at: new Date().toISOString()
                }
              });
              console.log(`[SPLICE] Stored license key in Stripe metadata for subscription ${subscription.id}`);
            } catch (metaErr) {
              console.error(`[SPLICE] Failed to store license key in Stripe metadata:`, metaErr.message);
            }

            // Get customer email and send license key
            try {
              const customer = await stripe.customers.retrieve(customerId);
              if (customer.email) {
                // Log email delivery (placeholder for actual email service)
                console.log(`[SPLICE] License key ready for delivery to ${customer.email}: ${licenseResult.key}`);
                // TODO: Integrate with email service (SendGrid, SES, etc.)
                // await sendLicenseKeyEmail(customer.email, licenseResult.key, tier);

                // Store email in database for reference
                await usageTracking.updateTier(customerId, tier, customer.email);
              } else {
                console.warn(`[SPLICE] No email found for customer ${customerId}`);
              }
            } catch (emailErr) {
              console.error(`[SPLICE] Error getting customer email:`, emailErr.message);
            }
          } else {
            console.error(`[SPLICE] Failed to generate license key after ${maxRetries} attempts: ${licenseResult?.error || 'Unknown error'}`);
          }
        }
        break;
      }

      case 'customer.subscription.deleted': {
        const subscription = event.data.object;
        const customerId = subscription.customer;

        // Validate customerId
        if (!customerId) {
          console.error('[SPLICE] Missing customer ID in subscription.deleted event');
          return res.status(400).json({ error: 'Missing customer ID' });
        }

        // Downgrade to cancelled (0 hours)
        await usageTracking.updateTier(customerId, 'cancelled');
        console.log(`[SPLICE] Subscription cancelled for customer ${customerId}`);
        break;
      }

      case 'invoice.payment_succeeded': {
        const invoice = event.data.object;
        const customerId = invoice.customer;
        const subscriptionId = invoice.subscription;

        // Validate customerId
        if (!customerId) {
          console.error('[SPLICE] Missing customer ID in invoice event');
          return res.status(400).json({ error: 'Missing customer ID' });
        }

        // Reset hours on successful payment (new billing period)
        if (subscriptionId) {
          const subscription = await stripe.subscriptions.retrieve(subscriptionId);
          const priceId = subscription.items?.data?.[0]?.price?.id;
          const tier = getTierFromPriceId(priceId);

          await usageTracking.resetHours(customerId, tier);
          console.log(`[SPLICE] Reset hours for customer ${customerId} (tier: ${tier})`);
        }
        break;
      }

      default:
        console.log(`[SPLICE] Unhandled event type: ${event.type}`);
    }

    // Record event as processed (idempotency)
    await usageTracking.recordWebhookEvent(event.id, event.type);

    res.json({ received: true });
  } catch (err) {
    console.error('[SPLICE] Webhook handler error:', err);
    res.status(500).json({ error: err.message });
  }
});

app.use(express.json());

// =============================================================================
// Routes
// =============================================================================

/**
 * GET / - API information
 */
app.get('/', (req, res) => {
  res.json({
    service: 'splice-backend',
    version: '0.3.0',
    endpoints: {
      'GET /': 'This info',
      'GET /health': 'Health check',
      'GET /ffprobe-check': 'Check if FFprobe is installed',
      'GET /replicate-check': 'Check if Replicate API is configured',
      'POST /analyze': 'Analyze WAV file { wavPath }',
      'POST /silences': 'Detect silences via Whisper gaps { wavPath, threshold: 0.5 }',
      'POST /silences-audio': 'Detect silences via FFprobe { wavPath, threshold: -30, minDuration: 0.5, padding: 0.1 }',
      'POST /silences-rms': 'Detect silences via RMS analysis { wavPath, threshold: -30, minSilenceLength: 0.5, paddingStart: 0.1, paddingEnd: 0.05, autoThreshold: false, sensitivity: 50 }',
      'POST /profanity': 'Detect profanity in transcript { wavPath, language: "en", customBlocklist: [], customAllowlist: [] }',
      'GET /profanity/languages': 'Get supported languages for profanity detection',
      'GET /profanity/bleeps': 'Get available bleep sounds',
      'POST /repetitions': 'Detect phrase repetitions and stutters { wavPath, phraseSize: 5, tolerance: 0.7, useOpenAI: false }',
      'POST /fillers': 'Detect filler words (um, uh, like, etc.) { wavPath, customFillers: [] }',
      'POST /stutters': 'Detect single-word stutters only { wavPath, minRepeats: 2 }',
      'POST /export/captions': 'Export transcript to caption format { wavPath, format: srt|vtt|txt|json, outputPath? }',
      'GET /export/formats': 'Get supported caption export formats',
      'POST /multitrack': 'Analyze multiple audio tracks for multicam { audioPaths: [], speakerNames: [], videoTrackMapping: {} }',
      'POST /multitrack/auto-balance': 'Auto-balance speaker screentime { audioPaths: [], speakerNames: [] }',
      'POST /process-xml': 'Process FCP XML { xmlPath, silences, removeGaps: true }',
      'POST /cut-list': 'Generate JSON cut list for DOM building (v3.5) { sourceName, sourcePath, duration, silences, takes?, settings? }',
      'POST /cut-list/takes': 'Generate cut list keeping only takes { sourceName, sourcePath, duration, takes, settings? }',
      'POST /isolate-vocals': 'Isolate vocals from audio { audioPath }',
      'POST /batch/silences': 'Batch process multiple files for silence detection { files: [], options: {} }',
      'GET /batch/status/:jobId': 'Get batch job status',
      'GET /batch/results/:jobId': 'Get full batch job results',
      'GET /batch/jobs': 'List all batch jobs',
      'DELETE /batch/:jobId': 'Delete a batch job',
      'GET /credits': 'Get user credit balance (requires x-stripe-customer-id header)',
      'GET /usage-history': 'Get usage history (requires x-stripe-customer-id header)',
      'POST /webhooks/stripe': 'Stripe webhook endpoint',
      'GET /referral/code': 'Get or create referral code for user',
      'POST /referral/validate': 'Validate a referral code',
      'POST /referral/apply': 'Apply referral code at signup',
      'GET /referral/stats': 'Get referral statistics for user',
      'POST /license/activate': 'Activate license key { key: "SPLICE-XXXX-XXXX-XXXX" }',
      'GET /license/key': 'Get license key for customer (requires x-stripe-customer-id)',
      'POST /license/resend': 'Resend license key to customer email { customerId? }'
    }
  });
});

/**
 * GET /health - Health check
 */
app.get('/health', (req, res) => {
  res.json({ status: 'ok', service: 'splice-backend' });
});

/**
 * POST /analyze - Main analysis endpoint
 *
 * Pipeline:
 * 1. Validate input (wavPath)
 * 2. Slice 4: Transcribe audio with Whisper
 * 3. Slice 5: Detect takes with GPT-4o-mini
 * 4. Return combined results
 */
app.post('/analyze', requireCredits({ endpoint: 'analyze' }), async (req, res) => {
  const { wavPath } = req.body;

  // Validate input
  if (!wavPath) {
    return res.status(400).json({ error: 'wavPath is required' });
  }

  if (!(await fileExists(wavPath))) {
    return res.status(404).json({ error: `File not found: ${wavPath}` });
  }

  console.log(`[SPLICE] Analyzing: ${wavPath}`);

  try {
    // Slice 4 - GPT-4o-mini transcription
    const transcript = await transcribeAudio(wavPath);

    // Slice 5 - GPT-4o-mini take detection
    const takes = await detectTakes(transcript);

    // Deduct usage based on audio duration
    const audioDuration = transcript.duration || 0;
    let balance = null;
    if (audioDuration > 0 && req.deductUsage) {
      balance = await req.deductUsage(audioDuration);
    }

    res.json({
      success: true,
      wavPath,
      transcript,
      takes,
      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
    });
  } catch (err) {
    console.error('[SPLICE] Error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /silences - Detect silent gaps in audio
 *
 * Pipeline:
 * 1. Transcribe audio with Whisper (cached)
 * 2. Analyze gaps between segments
 * 3. Return silence regions
 */
app.post('/silences', requireCredits({ endpoint: 'silences' }), async (req, res) => {
  const { wavPath, threshold = 0.5 } = req.body;

  if (!wavPath) {
    return res.status(400).json({ error: 'wavPath is required' });
  }

  if (!(await fileExists(wavPath))) {
    return res.status(404).json({ error: `File not found: ${wavPath}` });
  }

  console.log(`[SPLICE] Detecting silences: ${wavPath} (threshold: ${threshold}s)`);

  try {
    const transcript = await transcribeAudio(wavPath);
    const silences = detectSilences(transcript.segments, threshold);

    // Deduct usage based on audio duration
    const audioDuration = transcript.duration || 0;
    let balance = null;
    if (audioDuration > 0 && req.deductUsage) {
      balance = await req.deductUsage(audioDuration);
    }

    res.json({
      success: true,
      wavPath,
      threshold,
      silences,
      count: silences.length,
      totalSilenceDuration: silences.reduce((sum, s) => sum + s.duration, 0).toFixed(2),
      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
    });
  } catch (err) {
    console.error('[SPLICE] Silence detection error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /silences-audio - Detect silences using FFprobe audio analysis
 *
 * Uses actual audio levels (dB threshold) instead of transcript gaps.
 * More accurate for detecting silence vs background noise.
 */
app.post('/silences-audio', requireCredits({ endpoint: 'silences-audio' }), async (req, res) => {
  const {
    wavPath,
    threshold = -30,
    minDuration = 0.5,
    padding = 0.1
  } = req.body;

  if (!wavPath) {
    return res.status(400).json({ error: 'wavPath is required' });
  }

  if (!(await fileExists(wavPath))) {
    return res.status(404).json({ error: `File not found: ${wavPath}` });
  }

  // Check FFprobe availability
  const ffprobeAvailable = await isFFprobeInstalled();
  if (!ffprobeAvailable) {
    return res.status(500).json({
      error: 'FFprobe not installed. Run: brew install ffmpeg'
    });
  }

  console.log(`[SPLICE] FFprobe silence detection: ${wavPath} (threshold: ${threshold}dB, min: ${minDuration}s)`);

  try {
    const silences = await detectAudioSilences(wavPath, {
      threshold,
      minDuration,
      padding
    });

    const totalDuration = silences.reduce((sum, s) => sum + s.duration, 0);

    // Deduct usage based on audio duration
    let balance = null;
    try {
      const audioDuration = await getAudioDuration(wavPath);
      if (audioDuration > 0 && req.deductUsage) {
        balance = await req.deductUsage(audioDuration);
      }
    } catch (durErr) {
      console.warn('[SPLICE] Could not get audio duration for billing:', durErr.message);
    }

    res.json({
      success: true,
      wavPath,
      threshold,
      minDuration,
      padding,
      silences,
      count: silences.length,
      totalSilenceDuration: totalDuration.toFixed(2),
      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
    });
  } catch (err) {
    console.error('[SPLICE] FFprobe silence detection error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /silences-rms - Detect silences using RMS audio analysis
 *
 * Advanced silence detection with:
 * - RMS (Root Mean Square) audio level analysis
 * - Auto-threshold detection from audio histogram
 * - Configurable padding (before/after cuts)
 * - Sensitivity slider mapping (0-100)
 *
 * Options:
 * - threshold: dBFS threshold (-60 to -20, default: -30)
 * - minSilenceLength: Minimum silence duration in seconds (default: 0.5)
 * - seekStep: Analysis window step in seconds (default: 0.05)
 * - paddingStart: Buffer before silence in seconds (default: 0.1)
 * - paddingEnd: Buffer after silence in seconds (default: 0.05)
 * - autoThreshold: Auto-detect optimal threshold (default: false)
 * - sensitivity: UI sensitivity 0-100 (overrides other params if provided)
 */
app.post('/silences-rms', requireCredits({ endpoint: 'silences-rms' }), async (req, res) => {
  const { wavPath, sensitivity, ...manualOptions } = req.body;

  if (!wavPath) {
    return res.status(400).json({ error: 'wavPath is required' });
  }

  if (!(await fileExists(wavPath))) {
    return res.status(404).json({ error: `File not found: ${wavPath}` });
  }

  // Validate file size to prevent OOM
  const sizeCheck = await validateFileSize(wavPath);
  if (!sizeCheck.valid) {
    return res.status(413).json({ error: sizeCheck.error });
  }

  // Check FFprobe availability (needed for audio extraction)
  const ffprobeAvailable = await isFFprobeInstalled();
  if (!ffprobeAvailable) {
    return res.status(500).json({
      error: 'FFprobe not installed. Run: brew install ffmpeg'
    });
  }

  // Build options - use sensitivity if provided, otherwise use manual options
  let options = {};
  if (typeof sensitivity === 'number') {
    options = sensitivityToParams(sensitivity);
    console.log(`[SPLICE] RMS detection with sensitivity ${sensitivity}`);
  } else {
    options = {
      threshold: manualOptions.threshold ?? -30,
      minSilenceLength: manualOptions.minSilenceLength ?? 0.5,
      seekStep: manualOptions.seekStep ?? 0.05,
      paddingStart: manualOptions.paddingStart ?? 0.1,
      paddingEnd: manualOptions.paddingEnd ?? 0.05,
      autoThreshold: manualOptions.autoThreshold ?? false,
      mergeDistance: manualOptions.mergeDistance ?? 0.2
    };
  }

  console.log(`[SPLICE] RMS silence detection: ${wavPath}`);

  try {
    const result = await detectSilencesRMS(wavPath, options);

    // Deduct usage based on audio duration
    const audioDuration = result.metadata?.audioDuration || 0;
    let balance = null;
    if (audioDuration > 0 && req.deductUsage) {
      balance = await req.deductUsage(audioDuration);
    }

    res.json({
      success: true,
      wavPath,
      ...result,
      count: result.silences.length,
      totalSilenceDuration: result.metadata.totalSilenceDuration.toFixed(2),
      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
    });
  } catch (err) {
    console.error('[SPLICE] RMS silence detection error:', err);
    res.status(500).json({ error: err.message });
  }
});

// =============================================================================
// Profanity Detection Routes
// =============================================================================

/**
 * POST /profanity - Detect profanity in audio/transcript
 *
 * Transcribes audio (if needed) and detects profanity words.
 * Returns word-level and segment-level results for muting/bleeping.
 *
 * Options:
 * - wavPath: Path to audio file (required)
 * - transcript: Pre-existing transcript (optional, skips transcription)
 * - language: Language code (en, es, fr, de) - default: en
 * - customBlocklist: Array or comma-separated string of additional words to censor
 * - customAllowlist: Array or comma-separated string of words to allow
 * - frameRate: Frame rate for boundary alignment (default: 30)
 */
app.post('/profanity', requireCredits({ endpoint: 'profanity' }), async (req, res) => {
  const {
    wavPath,
    transcript: providedTranscript,
    language = 'en',
    customBlocklist = [],
    customAllowlist = [],
    frameRate = 30
  } = req.body;

  if (!wavPath && !providedTranscript) {
    return res.status(400).json({ error: 'wavPath or transcript is required' });
  }

  if (wavPath && !(await fileExists(wavPath))) {
    return res.status(404).json({ error: `File not found: ${wavPath}` });
  }

  console.log(`[SPLICE] Profanity detection: ${wavPath || 'provided transcript'} (language: ${language})`);

  try {
    // Get or create transcript with word-level timestamps
    let transcript = providedTranscript;
    if (!transcript && wavPath) {
      // Use transcribeWithWords for word-level timestamps required by profanity detection
      transcript = await transcribeWithWords(wavPath);
    }

    // Validate transcript has words
    if (!transcript || !transcript.words || transcript.words.length === 0) {
      return res.status(400).json({
        error: 'Transcript must contain word-level timing data',
        hint: 'Ensure transcription returns words array with start/end times'
      });
    }

    // Parse custom lists
    const blocklist = parseWordList(customBlocklist);
    const allowlist = parseWordList(customAllowlist);

    // Detect profanity
    const result = detectProfanity(transcript, {
      language,
      customBlocklist: blocklist,
      customAllowlist: allowlist,
      frameRate
    });

    // Deduct usage based on audio duration
    const audioDuration = transcript.duration || 0;
    let balance = null;
    if (audioDuration > 0 && req.deductUsage) {
      balance = await req.deductUsage(audioDuration);
    }

    res.json({
      success: true,
      wavPath,
      ...result,
      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
    });
  } catch (err) {
    console.error('[SPLICE] Profanity detection error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * GET /profanity/languages - Get supported languages
 */
app.get('/profanity/languages', (req, res) => {
  res.json({
    success: true,
    languages: getSupportedLanguages()
  });
});

/**
 * GET /profanity/bleeps - Get available bleep sounds
 */
app.get('/profanity/bleeps', (req, res) => {
  res.json({
    success: true,
    sounds: getAvailableBleepSounds()
  });
});

/**
 * GET /profanity/list/:language - Get default profanity list for a language
 */
app.get('/profanity/list/:language', (req, res) => {
  const { language } = req.params;
  const list = getProfanityList(language);

  res.json({
    success: true,
    language,
    wordCount: list.length,
    // Return first 50 words as sample (full list is large)
    sample: list.slice(0, 50),
    note: 'Full list available but truncated for response size'
  });
});

// =============================================================================
// Repetition/Stutter Detection Routes
// =============================================================================

/**
 * POST /repetitions - Detect phrase repetitions and stutters
 *
 * Analyzes transcript for repeated phrases and stutters.
 * Returns segments that can be removed to clean up the edit.
 *
 * Options:
 * - wavPath: Path to audio file (required unless transcript provided)
 * - transcript: Pre-existing transcript (optional)
 * - phraseSize: Words per comparison window (default: 5)
 * - tolerance: Similarity threshold 0-1 (default: 0.7)
 * - searchRadius: Words to search ahead (default: 100)
 * - useOpenAI: Use OpenAI for boundary refinement (default: false)
 * - includeStutters: Also detect single-word stutters (default: true)
 */
app.post('/repetitions', requireCredits({ endpoint: 'repetitions' }), async (req, res) => {
  const {
    wavPath,
    transcript: providedTranscript,
    phraseSize = 5,
    tolerance = 0.7,
    searchRadius = 100,
    useOpenAI = false,
    includeStutters = true
  } = req.body;

  if (!wavPath && !providedTranscript) {
    return res.status(400).json({ error: 'wavPath or transcript is required' });
  }

  if (wavPath && !(await fileExists(wavPath))) {
    return res.status(404).json({ error: `File not found: ${wavPath}` });
  }

  console.log(`[SPLICE] Repetition detection: ${wavPath || 'provided transcript'}`);

  try {
    // Get or create transcript with word-level timestamps
    let transcript = providedTranscript;
    if (!transcript && wavPath) {
      // Use transcribeWithWords for word-level timestamps required by repetition detection
      transcript = await transcribeWithWords(wavPath);
    }

    // Validate transcript has words
    if (!transcript || !transcript.words || transcript.words.length === 0) {
      return res.status(400).json({
        error: 'Transcript must contain word-level timing data'
      });
    }

    // Detect all repetitions (phrases + stutters)
    const result = await detectAllRepetitions(transcript, {
      phraseSize,
      tolerance,
      searchRadius,
      useOpenAI
    });

    // Optionally filter out stutters
    if (!includeStutters) {
      result.stutters = [];
      result.removalSegments = result.removalSegments.filter(s => s.type !== 'stutter');
    }

    // Deduct usage based on audio duration
    const audioDuration = transcript.duration || 0;
    let balance = null;
    if (audioDuration > 0 && req.deductUsage) {
      balance = await req.deductUsage(audioDuration);
    }

    res.json({
      success: true,
      wavPath,
      ...result,
      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
    });
  } catch (err) {
    console.error('[SPLICE] Repetition detection error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /fillers - Detect filler words (um, uh, like, etc.)
 *
 * Transcribes audio and identifies filler words with timestamps.
 * Returns segments that can be cut or reviewed for removal.
 *
 * Options:
 * - wavPath: Path to audio file (required unless transcript provided)
 * - transcript: Pre-existing transcript with word-level timing (optional)
 * - customFillers: Additional filler words to detect (optional)
 */
app.post('/fillers', requireCredits({ endpoint: 'fillers' }), async (req, res) => {
  const {
    wavPath,
    transcript: providedTranscript,
    customFillers = []
  } = req.body;

  if (!wavPath && !providedTranscript) {
    return res.status(400).json({ error: 'wavPath or transcript is required' });
  }

  if (wavPath && !(await fileExists(wavPath))) {
    return res.status(404).json({ error: `File not found: ${wavPath}` });
  }

  console.log(`[SPLICE] Filler word detection: ${wavPath || 'provided transcript'}`);

  try {
    // Get or create transcript with word-level timestamps
    let transcript = providedTranscript;
    if (!transcript && wavPath) {
      transcript = await transcribeWithWords(wavPath);
    }

    // Validate transcript has words
    if (!transcript || !transcript.words || transcript.words.length === 0) {
      return res.status(400).json({
        error: 'Transcript must contain word-level timing data'
      });
    }

    // Default filler words (common in English speech)
    const defaultFillers = [
      'um', 'uh', 'ah', 'er', 'eh',           // Hesitation sounds
      'like', 'so', 'well', 'right',           // Discourse markers
      'you know', 'i mean', 'basically',       // Filler phrases
      'actually', 'literally', 'honestly',     // Overused qualifiers
      'kind of', 'sort of', 'you see'          // Hedging phrases
    ];

    // Combine default + custom fillers (lowercase for matching)
    const fillerSet = new Set([
      ...defaultFillers,
      ...customFillers.map(f => f.toLowerCase().trim())
    ]);

    // Detect filler words
    const fillers = [];
    const words = transcript.words;

    for (let i = 0; i < words.length; i++) {
      const word = words[i];
      const normalizedWord = word.word.toLowerCase().replace(/[.,!?;:'"]/g, '').trim();

      // Check single-word fillers
      if (fillerSet.has(normalizedWord)) {
        fillers.push({
          word: word.word,
          normalizedWord,
          start: word.start,
          end: word.end,
          duration: word.end - word.start,
          index: i,
          type: 'filler'
        });
        continue;
      }

      // Check two-word phrases (e.g., "you know", "kind of")
      if (i < words.length - 1) {
        const nextWord = words[i + 1];
        const twoWordPhrase = `${normalizedWord} ${nextWord.word.toLowerCase().replace(/[.,!?;:'"]/g, '').trim()}`;
        if (fillerSet.has(twoWordPhrase)) {
          fillers.push({
            word: `${word.word} ${nextWord.word}`,
            normalizedWord: twoWordPhrase,
            start: word.start,
            end: nextWord.end,
            duration: nextWord.end - word.start,
            index: i,
            type: 'filler_phrase'
          });
          // Skip next word since it's part of this phrase
          i++;
        }
      }
    }

    // Calculate total filler time
    const totalFillerDuration = fillers.reduce((sum, f) => sum + f.duration, 0);
    const audioDuration = transcript.duration || (words.length > 0 ? words[words.length - 1].end : 0);
    const fillerPercentage = audioDuration > 0 ? (totalFillerDuration / audioDuration) * 100 : 0;

    // Deduct usage based on audio duration
    let balance = null;
    if (audioDuration > 0 && req.deductUsage) {
      balance = await req.deductUsage(audioDuration);
    }

    res.json({
      success: true,
      wavPath,
      fillers,
      metadata: {
        totalWords: words.length,
        fillerCount: fillers.length,
        totalFillerDuration: parseFloat(totalFillerDuration.toFixed(3)),
        audioDuration: parseFloat(audioDuration.toFixed(3)),
        fillerPercentage: parseFloat(fillerPercentage.toFixed(2)),
        fillersPerMinute: audioDuration > 0 ? parseFloat((fillers.length / (audioDuration / 60)).toFixed(2)) : 0
      },
      removalSegments: fillers.map(f => ({
        start: f.start,
        end: f.end,
        duration: f.duration,
        reason: `Filler: "${f.word}"`,
        type: f.type
      })),
      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
    });
  } catch (err) {
    console.error('[SPLICE] Filler detection error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /stutters - Detect single-word stutters only
 *
 * Focused detection for word-level stutters (e.g., "I I I think").
 * Faster than full repetition detection.
 */
app.post('/stutters', requireCredits({ endpoint: 'stutters' }), async (req, res) => {
  const {
    wavPath,
    transcript: providedTranscript,
    options = {},
    // Support both top-level and nested options for flexibility
    minRepeats = options.minRepeats ?? 2,
    maxGapMs = options.maxGapMs ?? 500,
    ignoreFillers = options.ignoreFillers ?? true,
    minWordLength = options.minWordLength ?? 1
  } = req.body;

  if (!wavPath && !providedTranscript) {
    return res.status(400).json({ error: 'wavPath or transcript is required' });
  }

  if (wavPath && !(await fileExists(wavPath))) {
    return res.status(404).json({ error: `File not found: ${wavPath}` });
  }

  console.log(`[SPLICE] Stutter detection: ${wavPath || 'provided transcript'}`);

  try {
    // Get or create transcript with word-level timestamps
    let transcript = providedTranscript;
    if (!transcript && wavPath) {
      // Use transcribeWithWords for word-level timestamps required by stutter detection
      transcript = await transcribeWithWords(wavPath);
    }

    // Validate transcript exists and has words array
    if (!transcript || !transcript.words) {
      return res.status(400).json({
        error: 'Transcript must contain word-level timing data'
      });
    }

    // Empty transcript returns empty result (not an error)
    if (transcript.words.length === 0) {
      return res.json({
        success: true,
        stutters: [],
        metadata: { type: 'stutters', totalWords: 0, stutterCount: 0, totalRepeatedWords: 0 }
      });
    }

    // Detect stutters only
    const result = detectStutters(transcript, {
      minRepeats,
      maxGapMs,
      ignoreFillers,
      minWordLength
    });

    // Deduct usage based on audio duration
    const audioDuration = transcript.duration || 0;
    let balance = null;
    if (audioDuration > 0 && req.deductUsage) {
      balance = await req.deductUsage(audioDuration);
    }

    res.json({
      success: true,
      wavPath,
      ...result,
      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
    });
  } catch (err) {
    console.error('[SPLICE] Stutter detection error:', err);
    res.status(500).json({ error: err.message });
  }
});

// =============================================================================
// Caption Export Routes
// =============================================================================

/**
 * POST /export/captions - Export transcript to caption format (SRT, VTT, etc.)
 *
 * Converts a transcript to the specified caption format.
 * Can optionally save to file.
 *
 * Options:
 * - wavPath: Path to audio file (to transcribe first)
 * - transcript: Pre-existing transcript with word-level timing
 * - format: Export format (srt, vtt, txt, json) - default: srt
 * - outputPath: Optional file path to save to
 * - maxWordsPerCaption: Max words per caption (default: 8)
 * - maxDuration: Max duration per caption in seconds (default: 5)
 */
app.post('/export/captions', requireCredits({ endpoint: 'export-captions' }), async (req, res) => {
  const {
    wavPath,
    transcript: providedTranscript,
    format = 'srt',
    outputPath = null,
    maxWordsPerCaption = 8,
    maxDuration = 5
  } = req.body;

  if (!wavPath && !providedTranscript) {
    return res.status(400).json({ error: 'wavPath or transcript is required' });
  }

  if (wavPath && !(await fileExists(wavPath))) {
    return res.status(404).json({ error: `File not found: ${wavPath}` });
  }

  console.log(`[SPLICE] Caption export: ${wavPath || 'provided transcript'} -> ${format}`);

  try {
    // Get or create transcript with word-level timestamps
    let transcript = providedTranscript;
    if (!transcript && wavPath) {
      transcript = await transcribeWithWords(wavPath);
    }

    const exportOptions = { maxWordsPerCaption, maxDuration };

    // Generate caption content based on format
    let content;
    let mimeType;

    switch (format.toLowerCase()) {
      case 'srt':
        content = toSRT(transcript, exportOptions);
        mimeType = 'application/x-subrip';
        break;
      case 'vtt':
      case 'webvtt':
        content = toVTT(transcript, exportOptions);
        mimeType = 'text/vtt';
        break;
      case 'txt':
      case 'text':
        content = toPlainText(transcript, { ...exportOptions, includeTimestamps: true });
        mimeType = 'text/plain';
        break;
      case 'json':
        content = toJSON(transcript);
        mimeType = 'application/json';
        break;
      default:
        return res.status(400).json({
          error: `Unsupported format: ${format}`,
          supportedFormats: getSupportedFormats()
        });
    }

    // Save to file if outputPath provided
    let savedPath = null;
    if (outputPath) {
      const result = await exportToFile(transcript, outputPath, format, exportOptions);
      savedPath = result.path;
      console.log(`[SPLICE] Saved captions to: ${savedPath}`);
    }

    // Deduct usage based on audio duration
    const audioDuration = transcript.duration || 0;
    let balance = null;
    if (audioDuration > 0 && req.deductUsage) {
      balance = await req.deductUsage(audioDuration);
    }

    res.json({
      success: true,
      format,
      content,
      mimeType,
      savedPath,
      wordCount: transcript.words?.length || 0,
      duration: transcript.duration || 0,
      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
    });
  } catch (err) {
    console.error('[SPLICE] Caption export error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * GET /export/formats - Get supported export formats
 */
app.get('/export/formats', (req, res) => {
  res.json({
    success: true,
    formats: getSupportedFormats()
  });
});

// =============================================================================
// Multitrack/Multicam Analysis Routes
// =============================================================================

/**
 * POST /multitrack - Analyze multiple audio tracks for multicam editing
 *
 * Analyzes audio levels across multiple tracks to determine optimal
 * video angle selection based on who is speaking.
 *
 * Options:
 * - audioPaths: Array of paths to audio files (one per speaker) - required
 * - speakerNames: Array of speaker names (optional)
 * - videoTrackMapping: Object mapping speaker index to video track { 0: 0, 1: 1 }
 * - minShotDuration: Minimum seconds before next cut (default: 2.0)
 * - switchingFrequency: How often to allow cuts 0-100 (default: 50)
 * - wideShotEnabled: Enable wide shot detection (default: true)
 * - wideShotPercentage: Target % of wide shots (default: 20)
 * - wideShotTracks: Video track indices for wide shots
 * - cutawayEnabled: Enable cutaway insertion (default: false)
 * - cutawayTracks: Video track indices for cutaways
 * - speakerBoosts: Per-speaker dB adjustments { "Speaker 1": 5 }
 */
app.post('/multitrack', requireCredits({ endpoint: 'multitrack' }), async (req, res) => {
  const {
    audioPaths,
    speakerNames,
    videoTrackMapping = {},
    minShotDuration = 2.0,
    switchingFrequency = 50,
    wideShotEnabled = true,
    wideShotPercentage = 20,
    wideShotTracks = [],
    cutawayEnabled = false,
    cutawayTracks = [],
    speakerBoosts = {},
    frameRate = 30
  } = req.body;

  // Validate audioPaths
  if (!audioPaths || !Array.isArray(audioPaths) || audioPaths.length === 0) {
    return res.status(400).json({ error: 'audioPaths array is required (at least 1 path)' });
  }

  // Validate all files exist
  for (const audioPath of audioPaths) {
    if (!fs.existsSync(audioPath)) {
      return res.status(404).json({ error: `File not found: ${audioPath}` });
    }
  }

  // Check FFprobe availability
  const ffprobeAvailable = await isFFprobeInstalled();
  if (!ffprobeAvailable) {
    return res.status(500).json({
      error: 'FFprobe not installed. Run: brew install ffmpeg'
    });
  }

  console.log(`[SPLICE] Multitrack analysis: ${audioPaths.length} track(s)`);

  try {
    const result = await analyzeMultitrack(audioPaths, {
      speakerNames: speakerNames || audioPaths.map((_, i) => `Speaker ${i + 1}`),
      videoTrackMapping,
      minShotDuration,
      switchingFrequency,
      wideShotEnabled,
      wideShotPercentage,
      wideShotTracks,
      cutawayEnabled,
      cutawayTracks,
      speakerBoosts,
      frameRate
    });

    // Deduct usage based on total duration (use longest track)
    const audioDuration = result.metadata?.totalDuration || 0;
    let balance = null;
    if (audioDuration > 0 && req.deductUsage) {
      balance = await req.deductUsage(audioDuration);
    }

    res.json({
      success: true,
      ...result,
      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
    });
  } catch (err) {
    console.error('[SPLICE] Multitrack analysis error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /multitrack/auto-balance - Auto-balance speaker screentime
 *
 * Automatically adjusts speaker boosts to achieve equal screentime distribution.
 * Runs multiple iterations to find optimal parameters.
 */
app.post('/multitrack/auto-balance', requireCredits({ endpoint: 'multitrack-auto-balance' }), async (req, res) => {
  const {
    audioPaths,
    speakerNames,
    videoTrackMapping = {},
    minShotDuration = 2.0,
    switchingFrequency = 50,
    wideShotEnabled = false, // Disable wide shots for balance calc
    frameRate = 30
  } = req.body;

  // Validate audioPaths
  if (!audioPaths || !Array.isArray(audioPaths) || audioPaths.length < 2) {
    return res.status(400).json({ error: 'audioPaths array requires at least 2 tracks for balancing' });
  }

  // Validate all files exist
  for (const audioPath of audioPaths) {
    if (!fs.existsSync(audioPath)) {
      return res.status(404).json({ error: `File not found: ${audioPath}` });
    }
  }

  // Check FFprobe availability
  const ffprobeAvailable = await isFFprobeInstalled();
  if (!ffprobeAvailable) {
    return res.status(500).json({
      error: 'FFprobe not installed. Run: brew install ffmpeg'
    });
  }

  console.log(`[SPLICE] Auto-balancing multitrack: ${audioPaths.length} track(s)`);

  try {
    const result = await autoBalanceMultitrack(audioPaths, {
      speakerNames: speakerNames || audioPaths.map((_, i) => `Speaker ${i + 1}`),
      videoTrackMapping,
      minShotDuration,
      switchingFrequency,
      wideShotEnabled,
      frameRate
    });

    // Deduct usage based on total duration
    const audioDuration = result.metadata?.totalDuration || 0;
    let balance = null;
    if (audioDuration > 0 && req.deductUsage) {
      balance = await req.deductUsage(audioDuration);
    }

    res.json({
      success: true,
      ...result,
      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
    });
  } catch (err) {
    console.error('[SPLICE] Auto-balance error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /process-xml - Process FCP XML to split clips at silences
 *
 * Takes an FCP XML file and silence timestamps, splits clips
 * at silence boundaries, and optionally removes gaps.
 */
app.post('/process-xml', async (req, res) => {
  const {
    xmlPath,
    silences,
    removeGaps = true,
    outputPath = null
  } = req.body;

  if (!xmlPath) {
    return res.status(400).json({ error: 'xmlPath is required' });
  }

  if (!silences || !Array.isArray(silences)) {
    return res.status(400).json({ error: 'silences array is required' });
  }

  if (!fs.existsSync(xmlPath)) {
    return res.status(404).json({ error: `XML file not found: ${xmlPath}` });
  }

  console.log(`[SPLICE] Processing XML: ${xmlPath} with ${silences.length} silence(s)`);

  try {
    const result = await processXMLFile(xmlPath, silences, {
      outputPath,
      removeGaps
    });

    res.json({
      success: true,
      inputPath: xmlPath,
      outputPath: result.outputPath,
      stats: result.stats
    });
  } catch (err) {
    console.error('[SPLICE] XML processing error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /cut-list - Generate a JSON cut list for direct DOM building (v3.5)
 *
 * Takes silences and optionally takes, returns a cut list that the
 * plugin can use to build sequences directly via UXP APIs.
 *
 * Body:
 * - sourceName: Name of the source clip
 * - sourcePath: Full path to the source file
 * - duration: Total duration in seconds
 * - silences: Array of silence segments [{start, end, duration}]
 * - takes: (optional) Array of detected takes
 * - settings: (optional) Generation settings
 *
 * Requires authentication via x-stripe-customer-id header
 */
app.post('/cut-list', requireCredits({ endpoint: 'cut-list' }), async (req, res) => {
  const {
    sourceName,
    sourcePath,
    duration,
    silences,
    takes = [],
    settings = {}
  } = req.body;

  // Validate required fields
  if (!sourceName && !sourcePath) {
    return res.status(400).json({ error: 'sourceName or sourcePath is required' });
  }

  if (typeof duration !== 'number' || duration <= 0) {
    return res.status(400).json({ error: 'duration must be a positive number' });
  }

  if (!silences || !Array.isArray(silences)) {
    return res.status(400).json({ error: 'silences array is required' });
  }

  console.log(`[SPLICE] Generating cut list for ${sourceName || sourcePath} (${silences.length} silences)`);

  try {
    const cutList = generateCutList({
      sourceName: sourceName || path.basename(sourcePath),
      sourcePath,
      duration,
      silences,
      takes,
      settings
    });

    // Validate the generated cut list
    const validation = validateCutList(cutList);
    if (!validation.valid) {
      return res.status(500).json({
        error: 'Generated cut list is invalid',
        validationErrors: validation.errors
      });
    }

    res.json({
      success: true,
      cutList
    });
  } catch (err) {
    console.error('[SPLICE] Cut list generation error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /cut-list/takes - Generate a cut list that keeps only takes
 *
 * Alternative endpoint for "keep best takes only" workflow.
 *
 * Requires authentication via x-stripe-customer-id header
 */
app.post('/cut-list/takes', requireCredits({ endpoint: 'cut-list-takes' }), async (req, res) => {
  const {
    sourceName,
    sourcePath,
    duration,
    takes,
    settings = {}
  } = req.body;

  // Validate required fields
  if (!sourceName && !sourcePath) {
    return res.status(400).json({ error: 'sourceName or sourcePath is required' });
  }

  if (typeof duration !== 'number' || duration <= 0) {
    return res.status(400).json({ error: 'duration must be a positive number' });
  }

  if (!takes || !Array.isArray(takes) || takes.length === 0) {
    return res.status(400).json({ error: 'takes array is required and must not be empty' });
  }

  console.log(`[SPLICE] Generating takes cut list for ${sourceName || sourcePath} (${takes.length} takes)`);

  try {
    const cutList = generateTakesCutList({
      sourceName: sourceName || path.basename(sourcePath),
      sourcePath,
      duration,
      takes,
      settings
    });

    res.json({
      success: true,
      cutList
    });
  } catch (err) {
    console.error('[SPLICE] Takes cut list generation error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * GET /ffprobe-check - Check if FFprobe is installed
 */
app.get('/ffprobe-check', async (req, res) => {
  const installed = await isFFprobeInstalled();
  res.json({
    installed,
    message: installed
      ? 'FFprobe is available'
      : 'FFprobe not found. Install with: brew install ffmpeg'
  });
});

/**
 * GET /replicate-check - Check if Replicate API is configured
 */
app.get('/replicate-check', async (req, res) => {
  const configured = isReplicateConfigured();
  res.json({
    configured,
    message: configured
      ? 'Replicate API is configured'
      : 'REPLICATE_API_TOKEN not set. Add to .env file.'
  });
});

/**
 * POST /isolate-vocals - Isolate vocals from audio using Demucs
 *
 * Uses Replicate's Demucs model to separate vocals from background audio.
 * Cost: ~$0.015/min of audio
 *
 * Tier access:
 * - Starter: No access (upgrade required)
 * - Pro: 2 hours included, then $0.08/min overage
 * - Team: 5 hours included, then $0.08/min overage
 */
app.post('/isolate-vocals', requireCredits({ endpoint: 'isolate-vocals' }), async (req, res) => {
  const { audioPath, stem = 'vocals', outputDir = null } = req.body;
  const stripeCustomerId = req.headers['x-stripe-customer-id'];

  if (!audioPath) {
    return res.status(400).json({ error: 'audioPath is required' });
  }

  if (!fs.existsSync(audioPath)) {
    return res.status(404).json({ error: `File not found: ${audioPath}` });
  }

  // Check Replicate configuration
  if (!isReplicateConfigured()) {
    return res.status(500).json({
      error: 'Replicate API not configured. Set REPLICATE_API_TOKEN in .env'
    });
  }

  // Get audio duration for billing
  let audioDurationSeconds = 0;
  try {
    audioDurationSeconds = await getAudioDuration(audioPath);
  } catch (err) {
    console.warn('[SPLICE] Could not get audio duration:', err.message);
  }

  const audioDurationMinutes = audioDurationSeconds / 60;

  // Check isolation access if customer ID provided
  if (stripeCustomerId) {
    const accessCheck = await usageTracking.checkIsolationAccess(stripeCustomerId, audioDurationMinutes);

    if (!accessCheck.allowed) {
      return res.status(403).json({
        error: accessCheck.message,
        reason: accessCheck.reason,
        upgradeRequired: accessCheck.reason === 'upgrade_required'
      });
    }

    console.log(`[SPLICE] Isolation access: ${accessCheck.message}`);
  }

  console.log(`[SPLICE] Isolating vocals: ${audioPath} (${audioDurationMinutes.toFixed(1)} min)`);

  try {
    const result = await isolateVocals(audioPath, {
      stem,
      outputDir: outputDir || undefined
    });

    // Deduct isolation usage if customer ID provided
    let usageInfo = null;
    if (stripeCustomerId) {
      usageInfo = await usageTracking.deductIsolationUsage(
        stripeCustomerId,
        audioDurationSeconds,
        'isolate-vocals'
      );
      console.log(`[SPLICE] Isolation usage deducted: ${audioDurationMinutes.toFixed(1)} min`);
      if (usageInfo.isolationUsed?.overageCost > 0) {
        console.log(`[SPLICE] Overage cost: $${usageInfo.isolationUsed.overageCost.toFixed(2)}`);
      }
    }

    res.json({
      success: true,
      inputPath: audioPath,
      outputPath: result.outputPath,
      stem: result.stem,
      processingTime: result.processingTime,
      availableStems: result.allStems,
      audioDurationMinutes,
      usage: usageInfo ? {
        isolationHoursRemaining: usageInfo.isolationHoursRemaining,
        overageCost: usageInfo.isolationUsed?.overageCost || 0
      } : null
    });
  } catch (err) {
    console.error('[SPLICE] Vocal isolation error:', err);
    res.status(500).json({ error: err.message });
  }
});

// =============================================================================
// Batch Processing Routes
// =============================================================================

// In-memory job queue for batch processing
const batchJobs = new Map();

// Batch job limits to prevent memory leak
const MAX_BATCH_JOBS = 10000;
const BATCH_JOB_MAX_AGE_MS = 24 * 60 * 60 * 1000; // 24 hours

/**
 * Generate a unique job ID
 */
function generateJobId() {
  return `batch_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
}

/**
 * Clean up old batch jobs to prevent memory leak
 * Removes jobs older than 24 hours
 */
function cleanupOldBatchJobs() {
  const now = Date.now();
  let removedCount = 0;

  for (const [jobId, job] of batchJobs.entries()) {
    const createdAt = new Date(job.createdAt).getTime();
    if (now - createdAt > BATCH_JOB_MAX_AGE_MS) {
      batchJobs.delete(jobId);
      removedCount++;
    }
  }

  if (removedCount > 0) {
    console.log(`[SPLICE] Cleaned up ${removedCount} old batch job(s)`);
  }
}

/**
 * Enforce max job limit by removing oldest completed jobs
 */
function enforceJobLimit() {
  if (batchJobs.size < MAX_BATCH_JOBS) return;

  // Get completed jobs sorted by creation date (oldest first)
  const completedJobs = Array.from(batchJobs.entries())
    .filter(([_, job]) => job.status !== 'processing')
    .sort((a, b) => new Date(a[1].createdAt) - new Date(b[1].createdAt));

  // Remove oldest completed jobs until under limit
  const toRemove = batchJobs.size - MAX_BATCH_JOBS + 1;
  for (let i = 0; i < Math.min(toRemove, completedJobs.length); i++) {
    batchJobs.delete(completedJobs[i][0]);
  }

  console.log(`[SPLICE] Enforced job limit, removed ${Math.min(toRemove, completedJobs.length)} job(s)`);
}

// Run cleanup every hour
setInterval(cleanupOldBatchJobs, 60 * 60 * 1000);

/**
 * POST /batch/silences - Process multiple files for silence detection
 *
 * Creates a batch job that processes multiple audio files.
 * Returns a job ID for tracking progress.
 *
 * Body:
 * - files: Array of file paths to process
 * - options: Detection options (sensitivity, threshold, etc.)
 */
app.post('/batch/silences', requireCredits({ endpoint: 'batch-silences' }), async (req, res) => {
  const { files, options = {} } = req.body;

  if (!files || !Array.isArray(files) || files.length === 0) {
    return res.status(400).json({ error: 'files array is required' });
  }

  // Validate all files exist
  const missingFiles = files.filter(f => !fs.existsSync(f));
  if (missingFiles.length > 0) {
    return res.status(404).json({
      error: 'Some files not found',
      missingFiles
    });
  }

  // Enforce job limit before creating new job
  enforceJobLimit();

  const jobId = generateJobId();

  // Initialize job with customer ID for usage tracking
  const job = {
    id: jobId,
    type: 'silences',
    status: 'processing',
    createdAt: new Date().toISOString(),
    stripeCustomerId: req.stripeCustomerId,  // Store for usage deduction
    files: files.map(f => ({
      path: f,
      status: 'pending',
      result: null,
      error: null
    })),
    options,
    progress: {
      total: files.length,
      completed: 0,
      failed: 0,
      percentage: 0
    },
    results: [],
    errors: [],
    totalUsageDeducted: 0  // Track total seconds deducted
  };

  batchJobs.set(jobId, job);
  console.log(`[SPLICE] Batch job ${jobId} created with ${files.length} files`);

  // Start processing in background
  processBatchJob(jobId);

  res.json({
    success: true,
    jobId,
    message: `Batch job created with ${files.length} files`,
    statusUrl: `/batch/status/${jobId}`
  });
});

/**
 * Process a batch job (runs in background)
 */
async function processBatchJob(jobId) {
  const job = batchJobs.get(jobId);
  if (!job) return;

  const { sensitivity, ...manualOptions } = job.options;

  // Build detection options
  let detectionOptions = {};
  if (typeof sensitivity === 'number') {
    detectionOptions = sensitivityToParams(sensitivity);
  } else {
    detectionOptions = {
      threshold: manualOptions.threshold ?? -30,
      minSilenceLength: manualOptions.minSilenceLength ?? 0.5,
      paddingStart: manualOptions.paddingStart ?? 0.1,
      paddingEnd: manualOptions.paddingEnd ?? 0.05,
      autoThreshold: manualOptions.autoThreshold ?? false
    };
  }

  // Process files sequentially to avoid overwhelming the system
  for (let i = 0; i < job.files.length; i++) {
    const fileEntry = job.files[i];
    fileEntry.status = 'processing';

    try {
      const result = await detectSilencesRMS(fileEntry.path, detectionOptions);

      fileEntry.status = 'completed';
      fileEntry.result = {
        silences: result.silences,
        count: result.silences.length,
        totalSilenceDuration: result.metadata.totalSilenceDuration,
        audioDuration: result.metadata.audioDuration
      };

      job.results.push({
        file: fileEntry.path,
        ...fileEntry.result
      });

      // Deduct usage for this file
      const audioDuration = result.metadata?.audioDuration || 0;
      if (audioDuration > 0 && job.stripeCustomerId) {
        try {
          await usageTracking.deductUsage(job.stripeCustomerId, audioDuration, 'batch-silences');
          job.totalUsageDeducted += audioDuration;
        } catch (usageErr) {
          console.warn(`[SPLICE] Batch ${jobId}: Usage deduction failed:`, usageErr.message);
        }
      }

      job.progress.completed++;
      console.log(`[SPLICE] Batch ${jobId}: ${i + 1}/${job.files.length} completed`);
    } catch (err) {
      fileEntry.status = 'failed';
      fileEntry.error = err.message;

      job.errors.push({
        file: fileEntry.path,
        error: err.message
      });

      job.progress.failed++;
      console.error(`[SPLICE] Batch ${jobId}: ${fileEntry.path} failed:`, err.message);
    }

    // Update progress
    job.progress.percentage = Math.round(
      ((job.progress.completed + job.progress.failed) / job.progress.total) * 100
    );
  }

  // Mark job as complete
  job.status = job.progress.failed === job.progress.total ? 'failed' :
               job.progress.failed > 0 ? 'completed_with_errors' : 'completed';
  job.completedAt = new Date().toISOString();

  console.log(`[SPLICE] Batch job ${jobId} ${job.status}`);
}

/**
 * GET /batch/status/:jobId - Get batch job status and results
 * Requires x-stripe-customer-id header matching job owner
 */
app.get('/batch/status/:jobId', (req, res) => {
  const { jobId } = req.params;
  const stripeCustomerId = req.headers['x-stripe-customer-id'];
  const job = batchJobs.get(jobId);

  if (!job) {
    return res.status(404).json({ error: 'Job not found' });
  }

  // Verify customer ownership
  if (job.stripeCustomerId && job.stripeCustomerId !== stripeCustomerId) {
    return res.status(403).json({ error: 'Access denied: Job belongs to another user' });
  }

  res.json({
    success: true,
    job: {
      id: job.id,
      type: job.type,
      status: job.status,
      createdAt: job.createdAt,
      completedAt: job.completedAt,
      progress: job.progress,
      files: job.files.map(f => ({
        path: f.path,
        status: f.status,
        silenceCount: f.result?.count,
        error: f.error
      }))
    }
  });
});

/**
 * GET /batch/results/:jobId - Get full results for a completed batch job
 * Requires x-stripe-customer-id header matching job owner
 */
app.get('/batch/results/:jobId', (req, res) => {
  const { jobId } = req.params;
  const stripeCustomerId = req.headers['x-stripe-customer-id'];
  const job = batchJobs.get(jobId);

  if (!job) {
    return res.status(404).json({ error: 'Job not found' });
  }

  // Verify customer ownership
  if (job.stripeCustomerId && job.stripeCustomerId !== stripeCustomerId) {
    return res.status(403).json({ error: 'Access denied: Job belongs to another user' });
  }

  if (job.status === 'processing') {
    return res.status(202).json({
      success: false,
      message: 'Job still processing',
      progress: job.progress
    });
  }

  res.json({
    success: true,
    jobId: job.id,
    status: job.status,
    progress: job.progress,
    results: job.results,
    errors: job.errors,
    summary: {
      totalFiles: job.progress.total,
      successful: job.progress.completed,
      failed: job.progress.failed,
      totalSilences: job.results.reduce((sum, r) => sum + (r.count || 0), 0),
      totalSilenceDuration: job.results.reduce((sum, r) => sum + (r.totalSilenceDuration || 0), 0)
    }
  });
});

/**
 * DELETE /batch/:jobId - Cancel or delete a batch job
 * Requires x-stripe-customer-id header matching job owner
 */
app.delete('/batch/:jobId', (req, res) => {
  const { jobId } = req.params;
  const stripeCustomerId = req.headers['x-stripe-customer-id'];
  const job = batchJobs.get(jobId);

  if (!job) {
    return res.status(404).json({ error: 'Job not found' });
  }

  // Verify customer ownership
  if (job.stripeCustomerId && job.stripeCustomerId !== stripeCustomerId) {
    return res.status(403).json({ error: 'Access denied: Job belongs to another user' });
  }

  // Note: This doesn't actually cancel in-progress processing
  // but prevents the job from being queried
  batchJobs.delete(jobId);

  res.json({
    success: true,
    message: `Job ${jobId} deleted`
  });
});

/**
 * GET /batch/jobs - List batch jobs for authenticated user
 * Requires x-stripe-customer-id header to filter jobs by owner
 */
app.get('/batch/jobs', (req, res) => {
  const stripeCustomerId = req.headers['x-stripe-customer-id'];

  // Filter jobs by customer ownership (only show user's own jobs)
  const jobs = Array.from(batchJobs.values())
    .filter(job => !job.stripeCustomerId || job.stripeCustomerId === stripeCustomerId)
    .map(job => ({
      id: job.id,
      type: job.type,
      status: job.status,
      createdAt: job.createdAt,
      completedAt: job.completedAt,
      progress: job.progress
    }));

  // Sort by creation date (newest first)
  jobs.sort((a, b) => new Date(b.createdAt) - new Date(a.createdAt));

  res.json({
    success: true,
    count: jobs.length,
    jobs
  });
});

// =============================================================================
// Billing & Credits Routes
// =============================================================================

/**
 * GET /credits - Get user's credit balance
 *
 * Requires x-stripe-customer-id header
 */
app.get('/credits', async (req, res) => {
  const stripeCustomerId = req.headers['x-stripe-customer-id'];

  if (!stripeCustomerId) {
    return res.status(401).json({
      error: 'Authentication required',
      message: 'Missing x-stripe-customer-id header'
    });
  }

  try {
    const balance = await usageTracking.getBalance(stripeCustomerId);
    res.json({
      success: true,
      ...balance
    });
  } catch (err) {
    console.error('[SPLICE] Credits error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * GET /usage-history - Get user's usage history
 */
app.get('/usage-history', async (req, res) => {
  const stripeCustomerId = req.headers['x-stripe-customer-id'];

  if (!stripeCustomerId) {
    return res.status(401).json({
      error: 'Authentication required',
      message: 'Missing x-stripe-customer-id header'
    });
  }

  try {
    const history = await usageTracking.getUsageHistory(stripeCustomerId);
    res.json({
      success: true,
      history
    });
  } catch (err) {
    console.error('[SPLICE] Usage history error:', err);
    res.status(500).json({ error: err.message });
  }
});

// =============================================================================
// Referral System Endpoints
// =============================================================================

/**
 * GET /referral/code - Get or create referral code for user
 *
 * Requires x-stripe-customer-id header
 */
app.get('/referral/code', async (req, res) => {
  const stripeCustomerId = req.headers['x-stripe-customer-id'];

  if (!stripeCustomerId) {
    return res.status(401).json({
      error: 'Authentication required',
      message: 'Missing x-stripe-customer-id header'
    });
  }

  try {
    const codeInfo = await referralService.getOrCreateCode(stripeCustomerId);
    res.json({
      success: true,
      ...codeInfo
    });
  } catch (err) {
    console.error('[SPLICE] Referral code error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /referral/validate - Validate a referral code
 *
 * Body: { code: string, customerId?: string }
 */
app.post('/referral/validate', async (req, res) => {
  const { code, customerId } = req.body;

  if (!code) {
    return res.status(400).json({
      error: 'Missing code',
      message: 'Referral code is required'
    });
  }

  try {
    const result = await referralService.validateCode(code, customerId);
    res.json({
      success: true,
      ...result
    });
  } catch (err) {
    console.error('[SPLICE] Referral validate error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /referral/apply - Apply referral code at signup
 *
 * Body: { code: string, customerId: string }
 */
app.post('/referral/apply', async (req, res) => {
  const { code, customerId } = req.body;

  if (!code || !customerId) {
    return res.status(400).json({
      error: 'Missing required fields',
      message: 'Both code and customerId are required'
    });
  }

  try {
    const result = await referralService.applyCode(code, customerId, stripe);
    res.json({
      success: true,
      ...result
    });
  } catch (err) {
    console.error('[SPLICE] Referral apply error:', err);
    // Return user-friendly errors for validation failures
    if (err.message.includes('Cannot use your own') ||
        err.message.includes('already used') ||
        err.message.includes('not found') ||
        err.message.includes('no longer active')) {
      return res.status(400).json({ error: err.message });
    }
    res.status(500).json({ error: err.message });
  }
});

/**
 * GET /referral/stats - Get referral statistics for user
 *
 * Requires x-stripe-customer-id header
 */
app.get('/referral/stats', async (req, res) => {
  const stripeCustomerId = req.headers['x-stripe-customer-id'];

  if (!stripeCustomerId) {
    return res.status(401).json({
      error: 'Authentication required',
      message: 'Missing x-stripe-customer-id header'
    });
  }

  try {
    const stats = await referralService.getStats(stripeCustomerId);
    res.json({
      success: true,
      ...stats
    });
  } catch (err) {
    console.error('[SPLICE] Referral stats error:', err);
    res.status(500).json({ error: err.message });
  }
});

// =============================================================================
// License Key Endpoints
// =============================================================================

/**
 * POST /license/activate - Activate a license key
 *
 * Body: { key: "SPLICE-XXXX-XXXX-XXXX" }
 * Returns: { success, customerId, tier, hoursRemaining }
 */
app.post('/license/activate', async (req, res) => {
  const { key } = req.body;

  if (!key) {
    return res.status(400).json({
      error: 'Missing license key',
      message: 'License key is required'
    });
  }

  // Validate format
  if (!licenseService.isValidKeyFormat(key)) {
    return res.status(400).json({
      error: 'Invalid license key format',
      message: 'License key should be in format: SPLICE-XXXX-XXXX-XXXX'
    });
  }

  try {
    // Activate the key
    const result = await licenseService.activateLicenseKey(key);

    if (!result.success) {
      return res.status(400).json({
        success: false,
        error: result.error
      });
    }

    // Get the customer's balance and tier info
    const balance = await usageTracking.getBalance(result.customerId);

    res.json({
      success: true,
      customerId: result.customerId,
      tier: balance.tier,
      tierName: balance.tierName,
      hoursRemaining: balance.hoursRemaining,
      hoursTotal: balance.hoursTotal
    });
  } catch (err) {
    console.error('[SPLICE] License activation error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * GET /license/key - Get license key for a customer (for display/resend)
 *
 * Requires x-stripe-customer-id header
 */
app.get('/license/key', async (req, res) => {
  const stripeCustomerId = req.headers['x-stripe-customer-id'];

  if (!stripeCustomerId) {
    return res.status(401).json({
      error: 'Authentication required',
      message: 'Missing x-stripe-customer-id header'
    });
  }

  try {
    const result = await licenseService.getLicenseByCustomerId(stripeCustomerId);

    if (!result.success) {
      return res.status(404).json({
        success: false,
        error: result.error
      });
    }

    res.json({
      success: true,
      key: result.key,
      activated: result.activated,
      createdAt: result.createdAt
    });
  } catch (err) {
    console.error('[SPLICE] License lookup error:', err);
    res.status(500).json({ error: err.message });
  }
});

/**
 * POST /license/resend - Resend license key to customer email
 *
 * For support cases where customer didn't receive their license key.
 * Requires x-stripe-customer-id header or customerId in body (for support).
 */
app.post('/license/resend', async (req, res) => {
  // Allow customerId from header or body (for support staff)
  const stripeCustomerId = req.headers['x-stripe-customer-id'] || req.body.customerId;

  if (!stripeCustomerId) {
    return res.status(401).json({
      error: 'Authentication required',
      message: 'Missing customer ID'
    });
  }

  try {
    // Get existing license key
    const licenseResult = await licenseService.getLicenseByCustomerId(stripeCustomerId);

    if (!licenseResult.success) {
      // No license exists - try to generate one
      console.log(`[SPLICE] No license found for ${stripeCustomerId}, generating new one`);
      const newLicense = await licenseService.generateLicenseKey(stripeCustomerId);

      if (!newLicense.success) {
        return res.status(500).json({
          success: false,
          error: 'Failed to generate license key',
          details: newLicense.error
        });
      }

      licenseResult.key = newLicense.key;
      licenseResult.success = true;
    }

    // Get customer email from Stripe
    let customerEmail = null;
    try {
      const customer = await stripe.customers.retrieve(stripeCustomerId);
      customerEmail = customer.email;
    } catch (stripeErr) {
      console.error(`[SPLICE] Failed to get customer email:`, stripeErr.message);
    }

    if (!customerEmail) {
      return res.status(400).json({
        success: false,
        error: 'No email address found for customer',
        key: licenseResult.key, // Still return key for manual delivery
        manualDeliveryRequired: true
      });
    }

    // Log the resend request (placeholder for actual email service)
    console.log(`[SPLICE] License key resend requested for ${customerEmail}: ${licenseResult.key}`);
    // TODO: Integrate with email service
    // await sendLicenseKeyEmail(customerEmail, licenseResult.key);

    res.json({
      success: true,
      message: `License key will be sent to ${customerEmail}`,
      email: customerEmail,
      key: licenseResult.key, // Include key for immediate display
      activated: licenseResult.activated
    });
  } catch (err) {
    console.error('[SPLICE] License resend error:', err);
    res.status(500).json({ error: err.message });
  }
});

// =============================================================================
// Start Server
// =============================================================================

// Initialize database and start server
async function startServer() {
  try {
    await usageTracking.initDatabase();
    await referralService.initReferralTables();
    await licenseService.initLicenseTables();
    console.log('[SPLICE] Database initialized');

    if (isProduction || !httpsOptions) {
      // Production: Railway provides TLS termination, use HTTP
      http.createServer(app).listen(PORT, () => {
        console.log(`[SPLICE] Backend running at http://0.0.0.0:${PORT} (production)`);
      });
    } else {
      // Development: Use HTTPS with local certificates
      https.createServer(httpsOptions, app).listen(PORT, () => {
        console.log(`[SPLICE] Backend running at https://127.0.0.1:${PORT} (development)`);
        console.log(`[SPLICE] POST /analyze with { "wavPath": "/path/to/audio.wav" }`);
      });
    }
  } catch (err) {
    console.error('[SPLICE] Failed to start server:', err);
    process.exit(1);
  }
}

startServer();
