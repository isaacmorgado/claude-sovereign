/**
 * Slice 4: Groq Whisper Transcription Service
 *
 * Handles audio transcription using Groq's Whisper API.
 * Returns timestamped segments for take detection.
 */

const fs = require('fs');
const Groq = require('groq-sdk');

// Initialize Groq client
const groq = new Groq({ apiKey: process.env.GROQ_API_KEY });

/**
 * Transcribe audio file using Groq Whisper
 * @param {string} wavPath - Path to the WAV file
 * @returns {Promise<{text: string, segments: Array, language: string, duration: number}>}
 */
async function transcribeAudio(wavPath) {
  console.log('[SPLICE] Starting Groq Whisper transcription...');

  const transcription = await groq.audio.transcriptions.create({
    file: fs.createReadStream(wavPath),
    model: 'whisper-large-v3',
    response_format: 'verbose_json',
    language: 'en',
  });

  console.log(`[SPLICE] Transcription complete: ${transcription.text.slice(0, 100)}...`);

  return {
    text: transcription.text,
    segments: transcription.segments || [],
    language: transcription.language,
    duration: transcription.duration
  };
}

module.exports = { transcribeAudio };
