require('dotenv').config();

const express = require('express');
const cors = require('cors');
const fs = require('fs');
const https = require('https');
const path = require('path');
const Groq = require('groq-sdk');
const OpenAI = require('openai');

const app = express();
const PORT = process.env.PORT || 3847;

// HTTPS certificates (generated by mkcert)
const httpsOptions = {
  key: fs.readFileSync(path.join(__dirname, 'localhost+1-key.pem')),
  cert: fs.readFileSync(path.join(__dirname, 'localhost+1.pem'))
};

// Initialize clients
const groq = new Groq({ apiKey: process.env.GROQ_API_KEY });
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

app.use(cors());
app.use(express.json());

// Root
app.get('/', (req, res) => {
  res.json({
    service: 'splice-backend',
    endpoints: {
      'GET /': 'This info',
      'GET /health': 'Health check',
      'POST /analyze': 'Analyze WAV file { wavPath: "/path/to/audio.wav" }'
    }
  });
});

// Health check
app.get('/health', (req, res) => {
  res.json({ status: 'ok', service: 'splice-backend' });
});

// POST /analyze - Receive WAV path, transcribe with Groq Whisper
app.post('/analyze', async (req, res) => {
  const { wavPath } = req.body;

  if (!wavPath) {
    return res.status(400).json({ error: 'wavPath is required' });
  }

  // Verify file exists
  if (!fs.existsSync(wavPath)) {
    return res.status(404).json({ error: `File not found: ${wavPath}` });
  }

  console.log(`[SPLICE] Analyzing: ${wavPath}`);

  try {
    // Slice 4 - Groq Whisper transcription
    const transcript = await transcribeAudio(wavPath);

    // Slice 5 - GPT-4o-mini take detection
    const takes = await detectTakes(transcript);

    res.json({
      success: true,
      wavPath,
      transcript,
      takes
    });
  } catch (err) {
    console.error('[SPLICE] Error:', err);
    res.status(500).json({ error: err.message });
  }
});

// Groq Whisper transcription
async function transcribeAudio(wavPath) {
  console.log('[SPLICE] Starting Groq Whisper transcription...');

  const transcription = await groq.audio.transcriptions.create({
    file: fs.createReadStream(wavPath),
    model: 'whisper-large-v3',
    response_format: 'verbose_json',
    language: 'en',
  });

  console.log(`[SPLICE] Transcription complete: ${transcription.text.slice(0, 100)}...`);

  return {
    text: transcription.text,
    segments: transcription.segments || [],
    language: transcription.language,
    duration: transcription.duration
  };
}

// GPT-4o-mini take detection
async function detectTakes(transcript) {
  console.log('[SPLICE] Starting GPT-4o-mini take detection...');

  const segmentsText = transcript.segments
    .map(s => `[${s.start.toFixed(2)}-${s.end.toFixed(2)}] ${s.text}`)
    .join('\n');

  const prompt = `Analyze this video transcript and identify distinct "takes" (repeated attempts at the same content).

Look for:
- Explicit markers: "take 1", "take 2", "cut", "again", "one more time"
- Content repetition: same lines delivered multiple times
- Natural breaks: long pauses, restarts, or topic shifts that indicate a new attempt

TRANSCRIPT WITH TIMESTAMPS:
${segmentsText}

Respond with JSON only (no markdown):
{
  "takes": [
    {
      "takeNumber": 1,
      "start": 0.00,
      "end": 10.50,
      "description": "Brief description of this take",
      "isBest": false,
      "reason": "Why this is/isn't the best take"
    }
  ],
  "analysis": "Brief overall analysis of the recording"
}

If no distinct takes are found (continuous recording), return a single take covering the full duration.`;

  const response = await openai.chat.completions.create({
    model: 'gpt-4o-mini',
    messages: [{ role: 'user', content: prompt }],
    temperature: 0.3,
  });

  const content = response.choices[0].message.content;
  console.log(`[SPLICE] Take detection complete`);

  try {
    const result = JSON.parse(content);
    return result;
  } catch (_e) {
    console.error('[SPLICE] Failed to parse GPT response:', content);
    return {
      takes: [{
        takeNumber: 1,
        start: 0,
        end: transcript.duration || 0,
        description: 'Full recording (parsing failed)',
        isBest: true,
        reason: 'Single continuous take'
      }],
      analysis: 'Could not parse take detection response'
    };
  }
}

https.createServer(httpsOptions, app).listen(PORT, () => {
  console.log(`[SPLICE] Backend running at https://127.0.0.1:${PORT}`);
  console.log(`[SPLICE] POST /analyze with { "wavPath": "/path/to/audio.wav" }`);
});
