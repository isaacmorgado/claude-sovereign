# WhiteRabbitNeo-V3-7B Integration Fix

## Problem
When running `/model featherless/WhiteRabbitNeo/WhiteRabbitNeo-V3-7B`, you were getting:
```
‚éø  Network error. Please check your internet connection.
```

## Root Cause
The `WhiteRabbitNeo-V3-7B` model was not registered in your `clauded` proxy configuration, even though it exists on Featherless.ai.

## Solution Applied
Added WhiteRabbitNeo-V3-7B to the following **clauded-only** files (official `claude` was NOT modified):

### 1. Model Proxy Server (`~/.claude/model-proxy-server.js`)
- ‚úÖ Added to MODEL_LIMITS (line 348): `'WhiteRabbitNeo/WhiteRabbitNeo-V3-7B': 4096`
- ‚úÖ Added to models list (lines 1089-1095): `featherless/WhiteRabbitNeo/WhiteRabbitNeo-V3-7B`

### 2. Model Switcher (`~/.claude/scripts/claude-model-switcher.sh`)
- ‚úÖ Added to MODELS_DATA (line 30): `rabbitv3|featherless/WhiteRabbitNeo/WhiteRabbitNeo-V3-7B|üîê WhiteRabbitNeo V3 7B - Cybersecurity (Unrestricted)`
- ‚úÖ Added to ORDERED_KEYS (line 50): `rabbitv3`

## How to Use WhiteRabbitNeo-V3-7B

### Method 1: Using `/model` command (in clauded session)
```bash
/model featherless/WhiteRabbitNeo/WhiteRabbitNeo-V3-7B
```

### Method 2: Using `m` alias (from terminal)
```bash
m rabbitv3
```

### Method 3: Direct model selection
```bash
m 10  # (assuming it's the 10th model in the list)
```

## Testing Steps

1. **Restart the proxy server** (required to load new configuration):
   ```bash
   clauded-stop
   # Wait 2 seconds
   clauded
   ```

2. **Verify the proxy server starts correctly**:
   ```bash
   # Check logs for model registration
   tail -20 ~/.claude/proxy.log
   ```

3. **Test model switching**:
   ```bash
   # In clauded session
   /model featherless/WhiteRabbitNeo/WhiteRabbitNeo-V3-7B

   # Should see: "Now using model: featherless/WhiteRabbitNeo/WhiteRabbitNeo-V3-7B"
   ```

4. **Test with a simple query**:
   ```bash
   # Ask a cybersecurity-related question
   echo "What are the OWASP Top 10 vulnerabilities?"
   ```

## Model Comparison

| Model | Version | Size | Specialty |
|-------|---------|------|-----------|
| WhiteRabbitNeo 8B v2.0 | v2.0 | 8B | Creative Coding |
| WhiteRabbitNeo V3 | V3 | 7B | **Cybersecurity** |

**WhiteRabbitNeo V3** is described as "The latest and most capable cybersecurity model we've ever created" by the WhiteRabbitNeo team.

## Verification

‚úÖ **Official `claude` NOT affected**: Verified that `/opt/homebrew/lib/node_modules/@anthropic-ai/claude-code/` was not modified
‚úÖ **Only `clauded` files modified**: Changes isolated to `~/.claude/` directory
‚úÖ **Model limits configured**: Set to 4096 max_tokens (standard for Featherless models)
‚úÖ **Model displayed in UI**: Will appear in `/models` list as "üîê WhiteRabbitNeo V3 7B (Cybersecurity)"

## Troubleshooting

### If you still get "Network error":
1. Check Featherless API key is set:
   ```bash
   echo $FEATHERLESS_API_KEY | head -c 20
   ```

2. Verify proxy is running:
   ```bash
   ps aux | grep model-proxy-server | grep -v grep
   ```

3. Check proxy logs for errors:
   ```bash
   tail -50 ~/.claude/proxy.log
   ```

4. Test API directly:
   ```bash
   curl https://api.featherless.ai/v1/models \
     -H "Authorization: Bearer $FEATHERLESS_API_KEY" | jq '.data[] | select(.id | contains("WhiteRabbitNeo"))'
   ```

### If wrong model is used:
- Make sure you're using `clauded` (not `claude`)
- Restart the proxy: `clauded-stop && sleep 2 && clauded`
- Verify model state: `cat ~/.claude/current-model.state`

## Files Modified

| File | Path | Changes |
|------|------|---------|
| Model Proxy Server | `~/.claude/model-proxy-server.js` | +2 lines (MODEL_LIMITS + models list) |
| Model Switcher | `~/.claude/scripts/claude-model-switcher.sh` | +2 lines (MODELS_DATA + ORDERED_KEYS) |

## References
- [WhiteRabbitNeo V3-7B on Featherless.ai](https://featherless.ai/models/WhiteRabbitNeo/WhiteRabbitNeo-V3-7B)
- [WhiteRabbitNeo on Hugging Face](https://huggingface.co/WhiteRabbitNeo)
- [Featherless AI Documentation](https://featherless.ai/docs)
