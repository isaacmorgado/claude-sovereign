# LOOKSMAXX - FaceIQ Parity Fixes

## Session Date: 2025-12-20

## Current State Summary

### What's Complete
- [x] Core exponential decay scoring formula (exact match)
- [x] Bezier curve interpolation with Newton-Raphson
- [x] Updated all metric ideal ranges to match FaceIQ exactly
- [x] Updated maxScore weights (2.5-30 scale)
- [x] Results page layout with 6 tabs
- [x] Surgery database (100+ procedures in `hardmaxxing.ts`)
- [x] Softmaxxing treatments database
- [x] Non-surgical treatments database
- [x] Supplements database
- [x] TypeScript compilation passing

### What's Complete (Added 2025-12-20)
- [x] InsightFace on Railway - FIXED! detection_ready: true
- [x] Detailed flaw mappings for 28 metrics (METRIC_FLAW_MAPPINGS)
- [x] Custom Bezier curves for 12 metrics (METRIC_CUSTOM_CURVES) - expanded from 5

---

## Gaps to Fix (FaceIQ Parity)

### 1. Detailed Flaw Mappings Per Metric [COMPLETED]

**Current:** Basic string arrays like `["Wide face", "Long midface"]`

**FaceIQ Format:**
```typescript
interface FlawMapping {
  category: string;           // "Occlusion/Jaw Growth"
  flawName: string;           // "Hyper-divergent jaw growth"
  confidence: 'confirmed' | 'likely' | 'possible';
  actualValue: string;        // "38.05%"
  idealRange: string;         // "31-33.5%"
  deviation: string;          // "4.55% above ideal"
  score: number;              // 0.19
  severity: 'extremely severe' | 'severe' | 'major' | 'moderate' | 'minor';
  reasoning: string;          // AI-generated explanation
  isUnlocked: boolean;
}
```

**Example from FaceIQ (Lower Third Proportion at 38.05%):**
```json
{
  "mayIndicateFlaws": [
    {
      "category": "Occlusion/Jaw Growth",
      "flawName": "Hyper-divergent jaw growth",
      "confidence": "confirmed",
      "actualValue": "38.05%",
      "idealRange": "31-33.5%",
      "deviation": "4.55% above ideal",
      "score": 0.19,
      "severity": "extremely severe",
      "reasoning": "The upper jaw is too long relative to lower jaw, possibly from a long upper jaw or short lower jaw, or a combination of both. This disrupts facial harmony by elongating the lower face."
    },
    {
      "category": "Jaw Shape",
      "flawName": "Disproportionate lower face (short chin or long philtrum)",
      "confidence": "confirmed",
      ...
    },
    {
      "category": "Midface/Face Shape",
      "flawName": "Long upper jaw",
      "confidence": "confirmed",
      ...
    },
    {
      "category": "Midface/Face Shape",
      "flawName": "Short lower jaw",
      "confidence": "confirmed",
      ...
    }
  ]
}
```

**Files to modify:**
- `src/lib/faceiq-scoring.ts` - Add FLAW_MAPPINGS constant
- `src/contexts/ResultsContext.tsx` - Update `getFlawStrengthMappings()` function
- `src/types/results.ts` - Add FlawMapping interface

---

### 2. Custom Bezier Curves for ALL Metrics [MOSTLY COMPLETE - 12 metrics added]

**Current:** 12 metrics have custom Bezier curves extracted from FaceIQ:
- faceWidthToHeight, lowerThirdProportion, lateralCanthalTilt, gonialAngle, nasolabialAngle
- middleThirdProportion, upperThirdProportion, eyeSeparationRatio, eyebrowLowSetedness
- submentalCervicalAngle, facialConvexityGlabella

**Remaining:** ~8 more curves could be extracted for remaining metrics

**FaceIQ Format:** 12 control points with Bezier handles per metric
```typescript
interface CurvePoint {
  x: number;
  y: number;
  leftHandleX?: number;
  leftHandleY?: number;
  rightHandleX?: number;
  rightHandleY?: number;
  fixed?: boolean;
}

interface CurveConfig {
  mode: 'custom' | 'exponential';
  customPoints?: CurvePoint[];
  idealMin: number;
  idealMax: number;
  maxScore: number;
  chartRange: { min: number; max: number };
  decayRate?: number;
}
```

**Example from FaceIQ (Lower Third Proportion):**
```json
{
  "customPoints": [
    {"x": 25.6, "y": 0, "leftHandleX": 24.8, "leftHandleY": 0, "rightHandleX": 26.4, "rightHandleY": 0},
    {"x": 28.01, "y": 1.58, "leftHandleX": 27.23, "leftHandleY": 0.53, "rightHandleX": 28.27, "rightHandleY": 1.97},
    {"x": 28.83, "y": 3.21, ...},
    {"x": 29.63, "y": 5.85, ...},
    {"x": 30.27, "y": 8.56, ...},
    {"x": 31, "y": 10, "fixed": true},
    {"x": 33.5, "y": 10, "fixed": true},
    {"x": 34.23, "y": 8.56, ...},
    {"x": 34.87, "y": 5.85, ...},
    {"x": 35.67, "y": 3.21, ...},
    {"x": 36.49, "y": 1.58, ...},
    {"x": 38.9, "y": 0, ...}
  ]
}
```

**Files to modify:**
- `src/lib/faceiq-scoring.ts` - Add `customCurve` to each metric in FACEIQ_METRICS

**Data source:** Extract from `/Users/imorgado/Desktop/FACEIQCOPY/FACEIQPAID/FACEIQ-FRONT RATIOS.html`

---

### 3. Enhanced Illustration Configs [COMPLETED]

**Status:** DONE - Added 30+ illustration configs for all metrics

**Changes made:**
- Added illustration configs for all missing front profile metrics (cupidsBow, mouthCorner, iaaJfa, etc.)
- Added illustration configs for all missing side profile metrics (nasolabialAngle, nasalTipAngle, mentolabialAngle, etc.)
- Now have ~70 metric illustration configs total covering front and side profiles

**Files modified:**
- `src/contexts/ResultsContext.tsx` - Expanded `ILLUSTRATION_CONFIGS` constant

---

### 4. Improved Flaw-to-Treatment Matching [COMPLETED]

**Status:** DONE - Enhanced scoring algorithm with metric-based prioritization

**Changes made:**
- Enhanced `calculateRelevanceScore()` with metric score weighting (lower scores get higher priority)
- Added `calculateExpectedImprovement()` function for severity-based improvement calculations
- Improved `generateRecommendations()` with:
  - Priority scoring based on relevance, multi-flaw bonus, severity weight, and procedure effectiveness
  - Direction-aware ratio impacts (increase/decrease based on deviation)
  - Percentage effect calculations based on how far metrics are from ideal
- Added keyword weighting (primary matches worth more than secondary)

**Files modified:**
- `src/contexts/ResultsContext.tsx` - Enhanced all recommendation functions

---

### 5. Severity Display Enhancement [COMPLETED]

**Status:** DONE - Severity badges now prominently displayed in card headers

**Changes made:**
- Added `getSeverityIndicator()` helper function with FaceIQ-style colors
- MeasurementCard collapsed header now shows:
  - Severity-colored ring around score box for moderate+ issues
  - Colored severity indicator dot in top-right corner
  - Compact severity badge next to metric name
- CompactMeasurementCard now shows:
  - Severity dot indicator for non-optimal metrics
  - Inline "Severe" or "Critical" badges for severe issues
- Color scheme matches FaceIQ:
  - Extremely Severe: #dc2626 (deep red)
  - Severe: #ef4444 (red)
  - Major: #f97316 (orange)
  - Moderate: #fbbf24 (yellow)
  - Minor/Optimal: #22c55e / #67e8f9 (green/cyan)

**Files modified:**
- `src/components/results/cards/MeasurementCard.tsx` - Added severity indicators to headers

---

### 6. Railway InsightFace Deployment [FIXED ✓]

**Status:** WORKING - detection_ready: true
- Deployed using `railway up --service api`
- python:3.11-bookworm base with cmake & libopenblas-dev
- onnxruntime-cpu==1.16.3

---

### 7. AI-Generated Descriptions [LOW PRIORITY]

**Current:** Static descriptions per metric

**Target:** Add `aiDescription` field with personalized explanations based on the user's actual values

---

### 8. Decay Curve Charts [LOW PRIORITY]

**Current:** Not implemented

**Target:** Visualize the scoring curve showing where user's value falls

---

### 9. Potential Score Calculations [LOW PRIORITY]

**Current:** Basic in Plan tab

**Target:** "Your score could be X with treatment Y" with projected improvements

---

### 10. Radar Chart Visualization [LOW PRIORITY]

**Current:** Not implemented

**Target:** Add a radar/spider chart showing scores across facial categories (Eyes, Jaw, Nose, Lips, Proportions, etc.) for quick visual overview of strengths/weaknesses.

**Implementation:** Use Recharts RadarChart component
```bash
npm install recharts
```

```typescript
// src/components/results/visualization/FacialRadarChart.tsx
import { ResponsiveContainer, RadarChart, PolarGrid, PolarAngleAxis, Radar } from 'recharts';

const data = [
  { category: 'Eyes', score: 8.5, fullMark: 10 },
  { category: 'Jaw', score: 7.2, fullMark: 10 },
  { category: 'Nose', score: 6.8, fullMark: 10 },
  { category: 'Lips', score: 9.1, fullMark: 10 },
  { category: 'Proportions', score: 7.5, fullMark: 10 },
  { category: 'Symmetry', score: 8.0, fullMark: 10 },
];

export const FacialRadarChart = () => (
  <ResponsiveContainer width="100%" height={300}>
    <RadarChart outerRadius="80%" data={data}>
      <PolarGrid stroke="#374151" />
      <PolarAngleAxis dataKey="category" stroke="#9ca3af" />
      <Radar name="Score" dataKey="score" stroke="#00f3ff" fill="#00f3ff" fillOpacity={0.3} />
    </RadarChart>
  </ResponsiveContainer>
);
```

**Reference:** [recharts/recharts](https://github.com/recharts/recharts), [yezihaohao/react-admin](https://github.com/yezihaohao/react-admin)

**Files to modify:**
- `src/components/results/visualization/FacialRadarChart.tsx` (new)
- `src/components/results/tabs/OverviewTab.tsx`

---

### 11. Before/After Comparison Slider [LOW PRIORITY]

**Current:** Not implemented

**Target:** Allow users to upload a "before" photo and compare with current analysis using an interactive slider

**Implementation:** Use `react-compare-slider` package
```bash
npm install react-compare-slider
```

```typescript
// src/components/results/visualization/CompareSlider.tsx
import { ReactCompareSlider, ReactCompareSliderImage } from 'react-compare-slider';

interface CompareSliderProps {
  beforeImage: string;
  afterImage: string;
}

export const CompareSlider = ({ beforeImage, afterImage }: CompareSliderProps) => (
  <ReactCompareSlider
    itemOne={<ReactCompareSliderImage src={beforeImage} alt="Before" />}
    itemTwo={<ReactCompareSliderImage src={afterImage} alt="After" />}
    style={{ width: '100%', height: '400px' }}
  />
);
```

**Reference:** [nerdyman/react-compare-slider](https://github.com/nerdyman/react-compare-slider), [Nutlope/roomGPT](https://github.com/Nutlope/roomGPT)

**Files to modify:**
- `src/components/results/visualization/CompareSlider.tsx` (new)
- `src/components/results/tabs/OverviewTab.tsx`

---

### 12. Share Results Functionality [LOW PRIORITY]

**Current:** Not implemented

**Target:** Allow users to share their results via:
- Native share API (mobile)
- Copy link to clipboard
- Social media sharing (Twitter, Instagram stories)

**Implementation:**
```typescript
// src/lib/shareResults.ts
export async function shareResults(score: number, shareableUrl: string) {
  const shareData = {
    title: 'My LOOKSMAXX Analysis',
    text: `My facial harmony score: ${score.toFixed(1)}/10`,
    url: shareableUrl,
  };

  if (navigator.share && navigator.canShare?.(shareData)) {
    try {
      await navigator.share(shareData);
      return { success: true };
    } catch (error) {
      if ((error as Error).name !== 'AbortError') {
        console.error('Share failed:', error);
      }
    }
  }

  // Fallback: copy to clipboard
  await navigator.clipboard.writeText(shareableUrl);
  return { success: true, fallback: 'clipboard' };
}
```

**Reference:** [excalidraw/excalidraw](https://github.com/excalidraw/excalidraw), [mastodon/mastodon](https://github.com/mastodon/mastodon)

**Files to modify:**
- `src/lib/shareResults.ts` (new)
- `src/components/results/shared/ShareButton.tsx` (new)
- `src/components/results/tabs/OverviewTab.tsx`

---

### 13. PDF/Image Export [LOW PRIORITY]

**Current:** Not implemented

**Target:** Export analysis results as:
- PDF report with all metrics
- Image summary for sharing
- Printable format

**Implementation:** Use `html2canvas` + `jsPDF`
```bash
npm install html2canvas jspdf
```

```typescript
// src/lib/exportReport.ts
import html2canvas from 'html2canvas';
import { jsPDF } from 'jspdf';

export async function exportToPDF(elementId: string, filename: string) {
  const element = document.getElementById(elementId);
  if (!element) return;

  const canvas = await html2canvas(element);
  const dataUrl = canvas.toDataURL('image/png');

  const contentWidth = canvas.width;
  const contentHeight = canvas.height;
  const orientation = contentWidth > contentHeight ? 'l' : 'p';

  const pdf = new jsPDF(orientation, 'pt', [contentWidth, contentHeight]);
  pdf.addImage(dataUrl, 'PNG', 0, 0, contentWidth, contentHeight);
  pdf.save(`${filename}.pdf`);
}

export async function exportToImage(elementId: string, filename: string) {
  const element = document.getElementById(elementId);
  if (!element) return;

  const canvas = await html2canvas(element);
  const link = document.createElement('a');
  link.href = canvas.toDataURL('image/png');
  link.download = `${filename}.png`;
  link.click();
}
```

**Reference:** [metabase/metabase](https://github.com/metabase/metabase), [dataease/dataease](https://github.com/dataease/dataease)

**Files to modify:**
- `src/lib/exportReport.ts` (new)
- `src/components/results/tabs/OptionsTab.tsx`

---

### 14. Analysis History & Progress Tracking [LOW PRIORITY]

**Current:** Not implemented

**Target:** Store analysis history and show:
- Timeline of past analyses
- Score progression over time
- Changes after treatments

**Implementation:** Store in localStorage or database
```typescript
// src/lib/analysisHistory.ts
interface AnalysisRecord {
  id: string;
  date: string;
  overallScore: number;
  categoryScores: Record<string, number>;
  photoThumbnail?: string;
}

const HISTORY_KEY = 'looksmaxx_history';
const MAX_HISTORY = 50;

export function getHistory(): AnalysisRecord[] {
  return JSON.parse(localStorage.getItem(HISTORY_KEY) || '[]');
}

export function saveToHistory(record: AnalysisRecord) {
  const history = getHistory();
  history.unshift(record);
  if (history.length > MAX_HISTORY) history.pop();
  localStorage.setItem(HISTORY_KEY, JSON.stringify(history));
}

export function clearHistory() {
  localStorage.setItem(HISTORY_KEY, JSON.stringify([]));
}
```

**Reference:** [gedoor/legado](https://github.com/gedoor/legado), [m4tt72/terminal](https://github.com/m4tt72/terminal)

**Files to modify:**
- `src/lib/analysisHistory.ts` (new)
- `src/contexts/HistoryContext.tsx` (new)
- `src/components/results/tabs/HistoryTab.tsx` (new)

---

### 15. Detailed Symmetry Analysis [LOW PRIORITY]

**Current:** Basic asymmetry detection

**Target:** Show detailed left/right comparison:
- Per-feature symmetry scores (eyes, brows, jaw, etc.)
- Visual overlay showing asymmetric regions
- Percentage deviation per side

**Files to modify:**
- `src/lib/symmetryAnalysis.ts` (new)
- `src/components/results/visualization/SymmetryOverlay.tsx` (new)

---

### 16. Ethnicity-Based Ideal Ranges [LOW PRIORITY]

**Current:** Single set of ideal ranges

**Target:** Adjust ideal ranges based on user's selected ethnicity:
- Different nose width ideals for different ethnicities
- Adjusted eye shape parameters
- Cultural beauty standard variations

**Files to modify:**
- `src/lib/faceiq-scoring.ts` - Add ethnicity parameter to scoring functions
- `src/lib/ethnicityRanges.ts` (new) - Ethnicity-specific ideal ranges

---

### 17. Animated Score Reveal [LOW PRIORITY]

**Current:** Static score display

**Target:** Add engaging animations when revealing scores:
- Count-up animation for overall score
- Staggered reveal of individual metrics
- Confetti/celebration for high scores

**Implementation:** Use `react-countup` + `canvas-confetti`
```bash
npm install react-countup canvas-confetti
npm install -D @types/canvas-confetti
```

```typescript
// src/components/results/shared/AnimatedScore.tsx
'use client';
import CountUp from 'react-countup';
import confetti from 'canvas-confetti';
import { useEffect } from 'react';

interface AnimatedScoreProps {
  score: number;
  duration?: number;
}

export const AnimatedScore = ({ score, duration = 2 }: AnimatedScoreProps) => {
  useEffect(() => {
    // Trigger confetti for high scores
    if (score >= 7.5) {
      confetti({ particleCount: 100, spread: 70, origin: { y: 0.6 } });
    }
  }, [score]);

  return (
    <CountUp
      end={score}
      decimals={1}
      duration={duration}
      suffix="/10"
      className="text-5xl font-bold text-[#00f3ff]"
    />
  );
};
```

**Reference:** [ant-design/ant-design](https://github.com/ant-design/ant-design), [adrianhajdin/banking](https://github.com/adrianhajdin/banking), [openai/openai-testing-agent-demo](https://github.com/openai/openai-testing-agent-demo)

**Files to modify:**
- `src/components/results/shared/AnimatedScore.tsx` (new)
- `src/components/results/tabs/OverviewTab.tsx`

---

### 18. Celebrity Comparison [LOW PRIORITY]

**Current:** Not implemented

**Target:** Compare user's metrics to celebrity facial proportions:
- "Your eye shape is similar to X"
- Show celebrities with similar scores
- Aspirational comparisons

**Note:** Requires celebrity metrics database

---

### 19. Mobile Camera Capture [LOW PRIORITY]

**Current:** File upload only

**Target:** Direct camera capture with:
- Face positioning guide overlay
- Auto-capture when face is aligned
- Front/side profile guidance

**Implementation:**
```typescript
// src/components/CameraCapture.tsx
'use client';
import { useRef, useState, useEffect } from 'react';

interface CameraCaptureProps {
  onCapture: (imageData: string) => void;
  facingMode?: 'user' | 'environment';
}

export function CameraCapture({ onCapture, facingMode = 'user' }: CameraCaptureProps) {
  const videoRef = useRef<HTMLVideoElement>(null);
  const [stream, setStream] = useState<MediaStream | null>(null);

  useEffect(() => {
    const startCamera = async () => {
      try {
        const mediaStream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode },
          audio: false,
        });
        setStream(mediaStream);
        if (videoRef.current) {
          videoRef.current.srcObject = mediaStream;
        }
      } catch (err) {
        console.error('Camera access denied:', err);
      }
    };
    startCamera();

    return () => {
      stream?.getTracks().forEach(track => track.stop());
    };
  }, [facingMode]);

  const capture = () => {
    if (!videoRef.current) return;
    const canvas = document.createElement('canvas');
    canvas.width = videoRef.current.videoWidth;
    canvas.height = videoRef.current.videoHeight;
    canvas.getContext('2d')?.drawImage(videoRef.current, 0, 0);
    onCapture(canvas.toDataURL('image/jpeg', 0.9));
  };

  return (
    <div className="relative">
      <video ref={videoRef} autoPlay playsInline className="rounded-xl" />
      {/* Face positioning guide overlay */}
      <div className="absolute inset-0 flex items-center justify-center pointer-events-none">
        <div className="w-64 h-80 border-2 border-dashed border-cyan-400 rounded-full opacity-50" />
      </div>
      <button onClick={capture} className="mt-4 btn-primary w-full">
        Capture Photo
      </button>
    </div>
  );
}
```

**Reference:** [weaigc/bingo](https://github.com/weaigc/bingo), [acmutd/hackportal](https://github.com/acmutd/hackportal)

**Files to modify:**
- `src/components/CameraCapture.tsx` (new)
- `src/app/upload/page.tsx`

---

### 20. Metric Tooltips & Education [LOW PRIORITY]

**Current:** Basic descriptions

**Target:** Rich educational content:
- Interactive diagrams showing what each metric measures
- Video explanations
- "Why this matters" sections
- Scientific references

**Implementation:**
```typescript
// src/lib/metricEducation.ts
interface MetricEducation {
  id: string;
  title: string;
  shortDescription: string;
  detailedExplanation: string;
  whyItMatters: string;
  scientificReference?: string;
  diagramUrl?: string;
  videoUrl?: string;
}

export const METRIC_EDUCATION: Record<string, MetricEducation> = {
  totalFacialWidthToHeight: {
    id: 'totalFacialWidthToHeight',
    title: 'Facial Width-to-Height Ratio',
    shortDescription: 'The ratio of face width to face height',
    detailedExplanation: 'Measured from zygion to zygion (bizygomatic width) divided by the height from nasion to menton.',
    whyItMatters: 'This ratio affects perceived masculinity/femininity and facial harmony. Values around 1.96-2.0 are considered ideal.',
    scientificReference: 'Carré & McCormick, 2008 - Proceedings of the Royal Society B',
  },
  // ... more metrics
};

// src/components/results/shared/MetricTooltip.tsx
import { Tooltip, TooltipContent, TooltipProvider, TooltipTrigger } from '@/components/ui/tooltip';
import { Info } from 'lucide-react';
import { METRIC_EDUCATION } from '@/lib/metricEducation';

export function MetricTooltip({ metricId }: { metricId: string }) {
  const edu = METRIC_EDUCATION[metricId];
  if (!edu) return null;

  return (
    <TooltipProvider>
      <Tooltip>
        <TooltipTrigger>
          <Info size={14} className="text-neutral-500 hover:text-cyan-400" />
        </TooltipTrigger>
        <TooltipContent className="max-w-xs">
          <p className="font-medium">{edu.title}</p>
          <p className="text-sm text-neutral-400 mt-1">{edu.detailedExplanation}</p>
          <p className="text-xs text-cyan-400 mt-2">{edu.whyItMatters}</p>
        </TooltipContent>
      </Tooltip>
    </TooltipProvider>
  );
}
```

**Reference:** [facebook/sapling](https://github.com/facebook/sapling), [recharts/recharts](https://github.com/recharts/recharts)

**Files to modify:**
- `src/lib/metricEducation.ts` (new)
- `src/components/results/shared/MetricTooltip.tsx` (new)
- `src/components/results/cards/MeasurementCard.tsx`

---

### 21. Facial Landmark Visualization Overlay [LOW PRIORITY]

**Current:** Landmarks calculated but not displayed on photo

**Target:** Draw facial landmarks and connections on the uploaded photo:
- Toggle overlay on/off
- Show measurement lines between key points
- Color-code by metric category (eyes, nose, jaw, etc.)

**Implementation:**
```typescript
// src/components/results/visualization/LandmarkOverlay.tsx
'use client';
import { useRef, useEffect } from 'react';
import { DrawingUtils, FaceLandmarker } from '@mediapipe/tasks-vision';

interface LandmarkOverlayProps {
  imageUrl: string;
  landmarks: { x: number; y: number; z: number }[];
  showConnections?: boolean;
}

export function LandmarkOverlay({ imageUrl, landmarks, showConnections = true }: LandmarkOverlayProps) {
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const imgRef = useRef<HTMLImageElement>(null);

  useEffect(() => {
    const canvas = canvasRef.current;
    const img = imgRef.current;
    if (!canvas || !img || !landmarks.length) return;

    const ctx = canvas.getContext('2d');
    if (!ctx) return;

    canvas.width = img.naturalWidth;
    canvas.height = img.naturalHeight;

    ctx.clearRect(0, 0, canvas.width, canvas.height);
    ctx.drawImage(img, 0, 0);

    const drawingUtils = new DrawingUtils(ctx);

    // Draw face mesh tesselation
    if (showConnections) {
      drawingUtils.drawConnectors(landmarks, FaceLandmarker.FACE_LANDMARKS_TESSELATION, {
        color: 'rgba(0, 243, 255, 0.3)',
        lineWidth: 1,
      });
    }

    // Draw key landmarks as points
    drawingUtils.drawLandmarks(landmarks, {
      color: '#00f3ff',
      lineWidth: 1,
      radius: 2,
    });
  }, [landmarks, showConnections]);

  return (
    <div className="relative">
      <img ref={imgRef} src={imageUrl} alt="Face" className="hidden" onLoad={() => {}} />
      <canvas ref={canvasRef} className="w-full h-auto rounded-xl" />
    </div>
  );
}
```

**Reference:** [Suryansh777777/Jarvis-CV](https://github.com/Suryansh777777/Jarvis-CV), [ayushgdev/MediaPipeCodeSamples](https://github.com/ayushgdev/MediaPipeCodeSamples)

**Files to modify:**
- `src/components/results/visualization/LandmarkOverlay.tsx` (new)
- `src/components/results/tabs/OverviewTab.tsx`

---

### 22. Dark Mode / Theme Toggle [LOW PRIORITY]

**Current:** Single dark theme

**Target:** Add theme toggle with:
- Dark mode (current)
- Light mode
- System preference detection

**Implementation:**
```typescript
// src/components/ThemeToggle.tsx
'use client';
import { useTheme } from 'next-themes';
import { Sun, Moon, Monitor } from 'lucide-react';

export function ThemeToggle() {
  const { theme, setTheme } = useTheme();

  return (
    <div className="flex items-center gap-1 p-1 rounded-lg bg-neutral-800">
      <button
        onClick={() => setTheme('light')}
        className={`p-2 rounded ${theme === 'light' ? 'bg-neutral-700' : ''}`}
        title="Light theme"
      >
        <Sun size={16} className={theme === 'light' ? 'text-white' : 'text-neutral-400'} />
      </button>
      <button
        onClick={() => setTheme('dark')}
        className={`p-2 rounded ${theme === 'dark' ? 'bg-neutral-700' : ''}`}
        title="Dark theme"
      >
        <Moon size={16} className={theme === 'dark' ? 'text-white' : 'text-neutral-400'} />
      </button>
      <button
        onClick={() => setTheme('system')}
        className={`p-2 rounded ${theme === 'system' ? 'bg-neutral-700' : ''}`}
        title="System theme"
      >
        <Monitor size={16} className={theme === 'system' ? 'text-white' : 'text-neutral-400'} />
      </button>
    </div>
  );
}
```

```bash
npm install next-themes
```

**Reference:** [supabase/supabase](https://github.com/supabase/supabase), [prometheus/prometheus](https://github.com/prometheus/prometheus), [boxyhq/saas-starter-kit](https://github.com/boxyhq/saas-starter-kit)

**Files to modify:**
- `src/components/ThemeToggle.tsx` (new)
- `src/app/layout.tsx` - wrap with ThemeProvider
- `tailwind.config.ts` - add darkMode: 'class'

---

### 23. PWA / Offline Support [LOW PRIORITY]

**Current:** Web-only, requires internet

**Target:** Progressive Web App with:
- Offline access to previous results
- Install to home screen
- Service worker caching

**Implementation:**
```bash
npm install next-pwa
```

```typescript
// next.config.js
const withPWA = require('next-pwa')({
  dest: 'public',
  register: true,
  skipWaiting: true,
  disable: process.env.NODE_ENV === 'development',
});

module.exports = withPWA({
  // existing config
});

// public/manifest.json
{
  "name": "LOOKSMAXX",
  "short_name": "LOOKSMAXX",
  "description": "Facial metrics analysis and visualization",
  "start_url": "/",
  "display": "standalone",
  "background_color": "#0a0a0a",
  "theme_color": "#00f3ff",
  "icons": [
    { "src": "/icon-192.png", "sizes": "192x192", "type": "image/png" },
    { "src": "/icon-512.png", "sizes": "512x512", "type": "image/png" }
  ]
}
```

**Reference:** [vite-pwa/vite-plugin-pwa](https://github.com/vite-pwa/vite-plugin-pwa), [GoogleChrome/workbox](https://github.com/GoogleChrome/workbox), [vuetifyjs/vuetify](https://github.com/vuetifyjs/vuetify)

**Files to modify:**
- `next.config.js`
- `public/manifest.json` (new)
- `src/app/layout.tsx` - add manifest link

---

### 24. Premium Tier / Stripe Subscriptions [LOW PRIORITY]

**Current:** All features free

**Target:** Monetization with:
- Free tier (basic metrics)
- Premium tier (all metrics, recommendations, exports)
- Stripe checkout integration

**Implementation:**
```typescript
// src/lib/stripe.ts
import Stripe from 'stripe';

export const stripe = new Stripe(process.env.STRIPE_SECRET_KEY!, {
  apiVersion: '2023-10-16',
});

// src/app/api/checkout/route.ts
import { stripe } from '@/lib/stripe';
import { NextResponse } from 'next/server';

export async function POST(req: Request) {
  const { priceId, userId } = await req.json();

  const session = await stripe.checkout.sessions.create({
    mode: 'subscription',
    line_items: [{ price: priceId, quantity: 1 }],
    success_url: `${process.env.NEXT_PUBLIC_URL}/billing?success=true`,
    cancel_url: `${process.env.NEXT_PUBLIC_URL}/billing?canceled=true`,
    metadata: { userId },
  });

  return NextResponse.json({ url: session.url });
}
```

```bash
npm install stripe @stripe/stripe-js
```

**Reference:** [calcom/cal.com](https://github.com/calcom/cal.com), [civitai/civitai](https://github.com/civitai/civitai), [toeverything/AFFiNE](https://github.com/toeverything/AFFiNE)

**Files to modify:**
- `src/lib/stripe.ts` (new)
- `src/app/api/checkout/route.ts` (new)
- `src/app/api/webhooks/stripe/route.ts` (new)
- `src/components/PricingCard.tsx` (new)

---

### 25. Analytics Integration (Mixpanel) [LOW PRIORITY]

**Current:** No analytics

**Target:** Track user behavior:
- Photo uploads
- Feature usage
- Conversion funnel
- Session recordings

**Implementation:**
```typescript
// src/lib/analytics.ts
import mixpanel from 'mixpanel-browser';

const MIXPANEL_TOKEN = process.env.NEXT_PUBLIC_MIXPANEL_TOKEN;

export function initAnalytics() {
  if (MIXPANEL_TOKEN) {
    mixpanel.init(MIXPANEL_TOKEN, {
      debug: process.env.NODE_ENV === 'development',
      track_pageview: true,
      persistence: 'localStorage',
    });
  }
}

export function trackEvent(event: string, properties?: Record<string, unknown>) {
  if (MIXPANEL_TOKEN) {
    mixpanel.track(event, properties);
  }
}

export function identifyUser(userId: string, traits?: Record<string, unknown>) {
  if (MIXPANEL_TOKEN) {
    mixpanel.identify(userId);
    if (traits) mixpanel.people.set(traits);
  }
}

// Usage in components
trackEvent('analysis_completed', { score: 7.5, metricsCount: 45 });
trackEvent('recommendation_viewed', { type: 'surgery', procedure: 'rhinoplasty' });
```

```bash
npm install mixpanel-browser
npm install -D @types/mixpanel-browser
```

**Reference:** [novuhq/novu](https://github.com/novuhq/novu), [appsmithorg/appsmith](https://github.com/appsmithorg/appsmith), [toeverything/AFFiNE](https://github.com/toeverything/AFFiNE)

**Files to modify:**
- `src/lib/analytics.ts` (new)
- `src/app/layout.tsx` - initialize analytics
- Components - add tracking calls

---

### 26. Error Tracking (Sentry) [LOW PRIORITY]

**Current:** Console errors only

**Target:** Production error monitoring:
- Automatic error capture
- Performance monitoring
- Session replay for debugging

**Implementation:**
```bash
npx @sentry/wizard@latest -i nextjs
```

```typescript
// sentry.client.config.ts
import * as Sentry from '@sentry/nextjs';

Sentry.init({
  dsn: process.env.NEXT_PUBLIC_SENTRY_DSN,
  tracesSampleRate: 0.1,
  replaysSessionSampleRate: 0.1,
  replaysOnErrorSampleRate: 1.0,
  integrations: [
    Sentry.replayIntegration(),
  ],
});

// Usage - errors are auto-captured, but you can add context:
Sentry.setUser({ id: userId });
Sentry.addBreadcrumb({ category: 'analysis', message: 'Started face detection' });
```

**Reference:** [getsentry/sentry-javascript](https://github.com/getsentry/sentry-javascript), [electron/fiddle](https://github.com/electron/fiddle)

**Files to modify:**
- `sentry.client.config.ts` (new)
- `sentry.server.config.ts` (new)
- `next.config.js` - wrap with withSentryConfig

---

### 27. Internationalization (i18n) [LOW PRIORITY]

**Current:** English only

**Target:** Multi-language support:
- English (default)
- Spanish, Portuguese, French, German
- RTL support for Arabic

**Implementation:**
```bash
npm install next-intl
```

```typescript
// src/i18n.ts
import { getRequestConfig } from 'next-intl/server';

export default getRequestConfig(async ({ locale }) => ({
  messages: (await import(`./messages/${locale}.json`)).default,
}));

// src/messages/en.json
{
  "results": {
    "overallScore": "Overall Score",
    "flaws": "Areas for Improvement",
    "strengths": "Your Strengths",
    "recommendations": "Recommendations"
  },
  "metrics": {
    "totalFacialWidthToHeight": "Facial Width-to-Height Ratio",
    "middleThirdProportion": "Middle Third Proportion"
  }
}

// Usage in components
import { useTranslations } from 'next-intl';

export function OverviewTab() {
  const t = useTranslations('results');
  return <h1>{t('overallScore')}</h1>;
}
```

**Reference:** [flowinquiry/flowinquiry](https://github.com/flowinquiry/flowinquiry)

**Files to modify:**
- `src/i18n.ts` (new)
- `src/messages/en.json` (new)
- `src/messages/es.json` (new)
- `src/middleware.ts` - locale detection
- Components - use useTranslations hook

---

## File Locations

### Key Files to Modify
```
src/lib/faceiq-scoring.ts          # Scoring configs, ideal ranges, curves
src/contexts/ResultsContext.tsx     # Data transformation, flaw mappings
src/types/results.ts                # Type definitions
src/lib/recommendations/severity.ts # Flaw-to-treatment mapping
src/components/results/cards/       # UI components for flaws/strengths
```

### FaceIQ Reference Data
```
/Users/imorgado/Desktop/FACEIQCOPY/FACEIQPAID/
├── FACEIQ-FRONT RATIOS.html   # Front profile metrics with curves
├── FACEIQ-SIDERATIOS.html     # Side profile metrics
├── FACEIQ-ALL.har             # API calls with full response data
├── FACEIQALL-HTML.html        # Full page capture
└── site-capture-*.json        # Additional capture data
```

---

## Metrics Updated This Session

### Front Profile (Updated ideal ranges + maxScores)
| Metric | New Ideal | maxScore |
|--------|-----------|----------|
| Face Width to Height | 1.96-2.0 | 30 |
| Middle Third | 31.4-33.4% | 10 |
| Upper Third | 30-32% | 10 |
| Cheekbone Height | 83-100% | 15 |
| Midface Ratio | 0.97-1.0 | 12.5 |
| Jaw Frontal Angle | 86.5-92.5° | 20 |
| Bigonial Width | 87.75-91.75% | 15 |
| Lateral Canthal Tilt | 6.1-7.8° | 10 |
| Eye Aspect Ratio | 3.0-3.5 | 15 |
| Eye Separation | 45.7-46.8% | 10 |
| IPD-Mouth Ratio | 0.83-0.87 | 10 |
| Eyebrow Tilt | 6.5-11° | 10 |
| Eyebrow Low Setedness | 0-0.45 | 10 |
| Intercanthal-Nasal | 1.04-1.16 | 10 |
| Nose Tip Position | 0.5-3.5mm | 2.5 |
| Mouth/Nose Ratio | 1.43-1.51 | 10 |
| Lower/Upper Lip | 1.58-1.88 | 7.5 |
| Chin/Philtrum | 2.15-2.45 | 12.5 |
| IAA-JFA Deviation | 0-2.5° | 10 |
| Neck Width | 92-98% | 10 |

### Side Profile (Updated ideal ranges)
| Metric | New Ideal |
|--------|-----------|
| Nasofrontal Angle | 116-128° |
| Nasofacial Angle | 31-35° |
| Nasomental Angle | 126-131° |
| Submental Cervical | 94-106° |
| Facial Depth/Height | 1.3-1.44 |
| Anterior Facial Depth | 64.5-67.5° |
| S-Line Lower Lip | -0.4 to 0.4mm |

### New Metrics Added
- Ipsilateral Alar Angle (front)
- Ear Protrusion Angle (front)
- Ear Protrusion Ratio (front)
- Interior Midface Projection Angle (side)
- Recession from Frankfort Plane (side)

---

## Commands Reference

### Run Type Check
```bash
cd /Users/imorgado/LOOKSMAXX/looksmaxx-app && npx tsc --noEmit
```

### Run Lint
```bash
cd /Users/imorgado/LOOKSMAXX/looksmaxx-app && npm run lint
```

### Extract FaceIQ Data
```bash
# Extract metric configs from HTML
cat "/Users/imorgado/Desktop/FACEIQCOPY/FACEIQPAID/FACEIQ-FRONT RATIOS.html" | sed 's/\\"/"/g' | grep -oE '"name":"[^"]+","value":[0-9.-]+.*?"idealMax":[0-9.-]+'

# Extract flaw mappings
cat "/Users/imorgado/Desktop/FACEIQCOPY/FACEIQPAID/FACEIQ-FRONT RATIOS.html" | sed 's/\\"/"/g' | grep -oE '"mayIndicateFlaws":\[\{[^]]+'

# Extract custom curves
cat "/Users/imorgado/Desktop/FACEIQCOPY/FACEIQPAID/FACEIQ-FRONT RATIOS.html" | sed 's/\\"/"/g' | grep -oE '"customPoints":\[[^\]]+\]'
```

---

## Continuation Prompt

Use this prompt to continue this work:

```
Continue work on LOOKSMAXX FaceIQ parity. Read /Users/imorgado/LOOKSMAXX/fixit.md for context.

Current priorities:
1. Add detailed FLAW_MAPPINGS to faceiq-scoring.ts with FaceIQ's structure (category, flawName, confidence, severity, reasoning)
2. Extract and add custom Bezier curves for all metrics from the FaceIQ HTML files
3. Update ResultsContext.tsx to use the new flaw mappings

Reference data is in /Users/imorgado/Desktop/FACEIQCOPY/FACEIQPAID/

Start with the flaw mappings - extract them from FACEIQ-FRONT RATIOS.html and create a comprehensive FLAW_MAPPINGS constant.
```
