     1→# Complete FaceIQ-Style Facial Analysis Calculation Engine
     2→
     3→## Prompt for AI Assistant
     4→
     5→Copy everything below this line and paste it to a new AI conversation:
     6→
     7→---
     8→
     9→# BUILD REQUEST: Facial Analysis Calculation Engine
    10→
    11→I need you to build a complete facial analysis calculation engine that replicates FaceIQ Labs functionality. I have reverse-engineered their system and captured all necessary data. Build this as a **TypeScript/JavaScript library** that can run in Node.js or browser.
    12→
    13→## Project Location
    14→Create all files in: `~/Desktop/reverse-engineer/faceiq-engine/`
    15→
    16→## Available Reference Data
    17→
    18→I have the following files from reverse engineering FaceIQ Labs:
    19→
    20→### 1. Captured Landmark Data
    21→**File:** `~/Desktop/reverse-engineer/landmark_data.json`
    22→- Contains 106 side profile landmark coordinates from actual FaceIQ API responses
    23→- Each landmark is `{x, y}` floating-point pixel coordinates
    24→
    25→**File:** `~/Desktop/reverse-engineer/captured_api/251_POST_api_side-landmarks.json`
    26→- Full API response with landmarks, rotation angle, bounding box, crop data
    27→
    28→### 2. API Response Structures
    29→**File:** `~/Desktop/reverse-engineer/captured_api/ALL_FACEIQ_RESPONSES.json`
    30→- All captured API responses from mitmproxy session
    31→
    32→### 3. Documentation
    33→**File:** `~/Desktop/reverse-engineer/CALCULATION_ANALYSIS.md`
    34→- Standard facial analysis formulas
    35→- Landmark index mapping attempts
    36→- API endpoint documentation
    37→
    38→**File:** `~/Desktop/reverse-engineer/FACEIQ_REVERSE_ENGINEERING_SUMMARY.md`
    39→- Complete reverse engineering summary
    40→- All known information about FaceIQ
    41→
    42→---
    43→
    44→## LANDMARK MAPPING (106 Side Profile Points)
    45→
    46→Based on coordinate analysis and standard cephalometric landmarks, here's the mapping to implement:
    47→
    48→```typescript
    49→// Side Profile Landmark Indices (106 points)
    50→export const SIDE_LANDMARKS = {
    51→  // Face Contour (0-16) - Jaw/Chin outline
    52→  MENTON: 0,              // Chin bottom (lowest point)
    53→  POGONION: 2,            // Chin prominence
    54→  GNATHION: 3,            // Chin point
    55→  MANDIBLE_CONTOUR: [2, 3, 4, 5, 6, 7, 8],  // Jaw line
    56→
    57→  // Posterior Points (1, 9-16) - Ear/Back of head
    58→  TRAGION: 1,             // Ear point
    59→  EAR_CONTOUR: [9, 10, 11, 12, 13, 14, 15, 16],
    60→
    61→  // Forehead/Hairline (17)
    62→  TRICHION: 17,           // Hairline
    63→
    64→  // Nose Profile (18-32)
    65→  NASION: 25,             // Bridge of nose (deepest point)
    66→  PRONASALE: 32,          // Nose tip
    67→  SUBNASALE: 52,          // Base of nose
    68→  COLUMELLA: 53,          // Nose columella
    69→  NOSE_BRIDGE: [25, 26, 27, 28, 29, 30, 31, 32],
    70→  NOSE_TIP_CONTOUR: [52, 53, 54, 55, 56, 57, 58, 59, 60],
    71→
    72→  // Eye Region (33-51)
    73→  EYE_LATERAL_CANTHUS: 33,   // Outer eye corner
    74→  EYE_MEDIAL_CANTHUS: 35,    // Inner eye corner
    75→  UPPER_EYELID: [37, 38, 39],
    76→  LOWER_EYELID: [40, 41, 42],
    77→  PUPIL: 34,
    78→  BROW_HEAD: 44,          // Inner brow
    79→  BROW_ARCH: 45,          // Brow peak
    80→  BROW_TAIL: 46,          // Outer brow
    81→
    82→  // Lip Region (52-75)
    83→  LABRALE_SUPERIUS: 63,   // Upper lip top
    84→  LABRALE_INFERIUS: 66,   // Lower lip bottom
    85→  STOMION: 65,            // Lip meeting point
    86→  UPPER_LIP_CONTOUR: [63, 64, 65],
    87→  LOWER_LIP_CONTOUR: [66, 67, 68],
    88→
    89→  // Additional Profile Points (76-105)
    90→  GLABELLA: 76,           // Between eyebrows
    91→  SELLION: 77,            // Deepest point of nasal bridge
    92→  SOFT_TISSUE_NASION: 78,
    93→  ORBITALE: 79,           // Lowest point of eye socket
    94→  GONION: 85,             // Jaw angle
    95→  CONDYLION: 86,          // Top of jaw joint
    96→};
    97→
    98→// Front Face Landmark Indices (MediaPipe 478 points)
    99→export const FRONT_LANDMARKS = {
   100→  // Key points from MediaPipe Face Mesh
   101→  NOSE_TIP: 1,
   102→  LEFT_EYE_INNER: 133,
   103→  LEFT_EYE_OUTER: 33,
   104→  RIGHT_EYE_INNER: 362,
   105→  RIGHT_EYE_OUTER: 263,
   106→  LEFT_CHEEK: 234,
   107→  RIGHT_CHEEK: 454,
   108→  UPPER_LIP: 13,
   109→  LOWER_LIP: 14,
   110→  CHIN: 152,
   111→  FOREHEAD: 10,
   112→  LEFT_EAR: 234,
   113→  RIGHT_EAR: 454,
   114→  LEFT_BROW_INNER: 107,
   115→  LEFT_BROW_OUTER: 70,
   116→  RIGHT_BROW_INNER: 336,
   117→  RIGHT_BROW_OUTER: 300,
   118→  NOSE_BRIDGE: 6,
   119→  LEFT_NOSTRIL: 129,
   120→  RIGHT_NOSTRIL: 358,
   121→};
   122→```
   123→
   124→---
   125→
   126→## MEASUREMENTS TO IMPLEMENT
   127→
   128→### Front Face Measurements
   129→
   130→```typescript
   131→interface FrontFaceMeasurements {
   132→  // Ratios
   133→  fwhr: number;                    // Facial Width-to-Height Ratio
   134→  facialIndex: number;             // Face height / Face width
   135→  jawWidth: number;                // Bigonial width
   136→  cheekboneWidth: number;          // Bizygomatic width
   137→
   138→  // Thirds
   139→  upperThird: number;              // Trichion to Glabella (%)
   140→  middleThird: number;             // Glabella to Subnasale (%)
   141→  lowerThird: number;              // Subnasale to Menton (%)
   142→
   143→  // Fifths
   144→  facialFifths: number[];          // 5 vertical sections
   145→
   146→  // Symmetry
   147→  overallSymmetry: number;         // 0-100%
   148→  eyeSymmetry: number;
   149→  browSymmetry: number;
   150→  lipSymmetry: number;
   151→  jawSymmetry: number;
   152→
   153→  // Eye Measurements
   154→  canthalTilt: number;             // Degrees
   155→  interpupillaryDistance: number;  // Pixels
   156→  palpebralFissureLength: number;  // Eye width
   157→  intercanthalWidth: number;       // Between inner corners
   158→
   159→  // Nose Measurements
   160→  nasalWidth: number;
   161→  nasalHeight: number;
   162→  nasalIndex: number;              // Width / Height
   163→
   164→  // Mouth Measurements
   165→  lipRatio: number;                // Upper / Lower lip
   166→  mouthWidth: number;
   167→  philtrumLength: number;
   168→
   169→  // Golden Ratio Scores
   170→  goldenRatioScores: {
   171→    faceHeightWidth: number;
   172→    noseMouth: number;
   173→    eyeSpacing: number;
   174→    lipChin: number;
   175→  };
   176→}
   177→```
   178→
   179→### Side Profile Measurements
   180→
   181→```typescript
   182→interface SideProfileMeasurements {
   183→  // Angles
   184→  nasofrontalAngle: number;        // Forehead to nose bridge
   185→  nasofacialAngle: number;         // Nose projection from face
   186→  nasolabialAngle: number;         // Nose to upper lip (90-110° ideal)
   187→  nasomental Angle: number;        // Nose tip to chin
   188→  mentocervicalAngle: number;      // Chin to neck
   189→  gonialAngle: number;             // Jaw angle (120-130° ideal)
   190→
   191→  // Profile Analysis
   192→  profileType: 'straight' | 'convex' | 'concave';
   193→  facialConvexity: number;         // Glabella-Subnasale-Pogonion angle
   194→
   195→  // Nose Profile
   196→  nasalDorsumShape: 'straight' | 'convex' | 'concave';
   197→  nasalProjection: number;         // Goode ratio
   198→  nasalTipRotation: number;
   199→  columellaLobularRatio: number;
   200→
   201→  // Lip Analysis
   202→  lipProjection: number;
   203→  upperLipAngle: number;
   204→  lowerLipAngle: number;
   205→
   206→  // Chin Analysis
   207→  chinProjection: number;          // Relative to nose
   208→  chinHeight: number;
   209→
   210→  // Jaw Analysis
   211→  mandibularPlaneAngle: number;
   212→  ramusalHeight: number;
   213→}
   214→```
   215→
   216→---
   217→
   218→## SCORING SYSTEM
   219→
   220→Implement a bell curve scoring system where the ideal value is at the center:
   221→
   222→```typescript
   223→interface ScoringConfig {
   224→  idealValue: number;
   225→  standardDeviation: number;
   226→  minScore: number;
   227→  maxScore: number;
   228→  weight: number;  // For overall harmony score
   229→}
   230→
   231→const SCORING_CONFIGS: Record<string, ScoringConfig> = {
   232→  fwhr: {
   233→    idealValue: 1.9,           // Ideal FWHR
   234→    standardDeviation: 0.15,   // How much variation is acceptable
   235→    minScore: 0,
   236→    maxScore: 100,
   237→    weight: 0.15               // 15% of overall score
   238→  },
   239→  canthalTilt: {
   240→    idealValue: 6,             // +6 degrees ideal
   241→    standardDeviation: 3,
   242→    minScore: 0,
   243→    maxScore: 100,
   244→    weight: 0.10
   245→  },
   246→  facialThirds: {
   247→    idealValue: 33.33,         // Equal thirds
   248→    standardDeviation: 3,
   249→    minScore: 0,
   250→    maxScore: 100,
   251→    weight: 0.10
   252→  },
   253→  nasolabialAngle: {
   254→    idealValue: 102,           // Degrees (male: 95, female: 105)
   255→    standardDeviation: 8,
   256→    minScore: 0,
   257→    maxScore: 100,
   258→    weight: 0.08
   259→  },
   260→  gonialAngle: {
   261→    idealValue: 125,           // Degrees
   262→    standardDeviation: 5,
   263→    minScore: 0,
   264→    maxScore: 100,
   265→    weight: 0.08
   266→  },
   267→  overallSymmetry: {
   268→    idealValue: 100,           // Perfect symmetry
   269→    standardDeviation: 5,
   270→    minScore: 0,
   271→    maxScore: 100,
   272→    weight: 0.15
   273→  },
   274→  goldenRatio: {
   275→    idealValue: 1.618,         // Phi
   276→    standardDeviation: 0.1,
   277→    minScore: 0,
   278→    maxScore: 100,
   279→    weight: 0.12
   280→  },
   281→  nosalIndex: {
   282→    idealValue: 0.7,           // Width/Height
   283→    standardDeviation: 0.08,
   284→    minScore: 0,
   285→    maxScore: 100,
   286→    weight: 0.06
   287→  },
   288→  lipRatio: {
   289→    idealValue: 0.5,           // Upper/Lower (1:2 ratio)
   290→    standardDeviation: 0.1,
   291→    minScore: 0,
   292→    maxScore: 100,
   293→    weight: 0.06
   294→  },
   295→  chinProjection: {
   296→    idealValue: 0,             // On the line from nose
   297→    standardDeviation: 3,      // mm deviation
   298→    minScore: 0,
   299→    maxScore: 100,
   300→    weight: 0.05
   301→  },
   302→  noseProjection: {
   303→    idealValue: 0.67,          // Goode ratio
   304→    standardDeviation: 0.05,
   305→    minScore: 0,
   306→    maxScore: 100,
   307→    weight: 0.05
   308→  }
   309→};
   310→
   311→// Bell curve scoring function
   312→function calculateScore(value: number, config: ScoringConfig): number {
   313→  const z = (value - config.idealValue) / config.standardDeviation;
   314→  const bellCurve = Math.exp(-0.5 * z * z);
   315→  return config.minScore + (config.maxScore - config.minScore) * bellCurve;
   316→}
   317→
   318→// Overall harmony score (weighted average)
   319→function calculateHarmonyScore(scores: Record<string, number>): number {
   320→  let totalWeight = 0;
   321→  let weightedSum = 0;
   322→
   323→  for (const [key, score] of Object.entries(scores)) {
   324→    const config = SCORING_CONFIGS[key];
   325→    if (config) {
   326→      weightedSum += score * config.weight;
   327→      totalWeight += config.weight;
   328→    }
   329→  }
   330→
   331→  return weightedSum / totalWeight;
   332→}
   333→```
   334→
   335→---
   336→
   337→## POPULATION DISTRIBUTION (Bell Curve Comparison)
   338→
   339→Implement percentile ranking based on normal distribution:
   340→
   341→```typescript
   342→interface PopulationStats {
   343→  mean: number;
   344→  standardDeviation: number;
   345→  sampleSize: number;
   346→}
   347→
   348→const POPULATION_STATS: Record<string, PopulationStats> = {
   349→  harmonyScore: { mean: 65, standardDeviation: 12, sampleSize: 10000 },
   350→  fwhr: { mean: 1.85, standardDeviation: 0.2, sampleSize: 10000 },
   351→  canthalTilt: { mean: 4, standardDeviation: 4, sampleSize: 10000 },
   352→  symmetry: { mean: 85, standardDeviation: 8, sampleSize: 10000 },
   353→  goldenRatioMatch: { mean: 70, standardDeviation: 15, sampleSize: 10000 },
   354→};
   355→
   356→// Calculate percentile (where you fall on the bell curve)
   357→function calculatePercentile(value: number, stats: PopulationStats): number {
   358→  const z = (value - stats.mean) / stats.standardDeviation;
   359→  return normalCDF(z) * 100;
   360→}
   361→
   362→// Standard normal CDF approximation
   363→function normalCDF(z: number): number {
   364→  const a1 =  0.254829592;
   365→  const a2 = -0.284496736;
   366→  const a3 =  1.421413741;
   367→  const a4 = -1.453152027;
   368→  const a5 =  1.061405429;
   369→  const p  =  0.3275911;
   370→
   371→  const sign = z < 0 ? -1 : 1;
   372→  z = Math.abs(z) / Math.sqrt(2);
   373→
   374→  const t = 1.0 / (1.0 + p * z);
   375→  const y = 1.0 - (((((a5 * t + a4) * t) + a3) * t + a2) * t + a1) * t * Math.exp(-z * z);
   376→
   377→  return 0.5 * (1.0 + sign * y);
   378→}
   379→
   380→// Generate bell curve data for visualization
   381→function generateBellCurveData(stats: PopulationStats, userValue: number): BellCurveData {
   382→  const points: {x: number, y: number}[] = [];
   383→
   384→  for (let i = -4; i <= 4; i += 0.1) {
   385→    const x = stats.mean + i * stats.standardDeviation;
   386→    const y = (1 / (stats.standardDeviation * Math.sqrt(2 * Math.PI))) *
   387→              Math.exp(-0.5 * Math.pow((x - stats.mean) / stats.standardDeviation, 2));
   388→    points.push({ x, y });
   389→  }
   390→
   391→  return {
   392→    points,
   393→    userValue,
   394→    userPercentile: calculatePercentile(userValue, stats),
   395→    mean: stats.mean,
   396→    standardDeviation: stats.standardDeviation
   397→  };
   398→}
   399→```
   400→
   401→---
   402→
   403→## FILE STRUCTURE TO CREATE
   404→
   405→```
   406→~/Desktop/reverse-engineer/faceiq-engine/
   407→├── package.json
   408→├── tsconfig.json
   409→├── src/
   410→│   ├── index.ts                 # Main exports
   411→│   ├── types/
   412→│   │   ├── landmarks.ts         # Landmark type definitions
   413→│   │   ├── measurements.ts      # Measurement interfaces
   414→│   │   └── scoring.ts           # Scoring types
   415→│   ├── constants/
   416→│   │   ├── landmarkIndices.ts   # SIDE_LANDMARKS, FRONT_LANDMARKS
   417→│   │   ├── idealValues.ts       # All ideal measurements
   418→│   │   └── populationStats.ts   # Bell curve statistics
   419→│   ├── utils/
   420→│   │   ├── geometry.ts          # distance, angle, midpoint functions
   421→│   │   ├── statistics.ts        # normalCDF, percentile functions
   422→│   │   └── imageProcessing.ts   # Coordinate normalization
   423→│   ├── measurements/
   424→│   │   ├── frontFace.ts         # Front face measurement functions
   425→│   │   ├── sideProfile.ts       # Side profile measurement functions
   426→│   │   └── index.ts
   427→│   ├── scoring/
   428→│   │   ├── bellCurve.ts         # Bell curve scoring
   429→│   │   ├── harmonyScore.ts      # Overall harmony calculation
   430→│   │   ├── percentile.ts        # Population comparison
   431→│   │   └── index.ts
   432→│   └── analysis/
   433→│       ├── FacialAnalyzer.ts    # Main analyzer class
   434→│       ├── ReportGenerator.ts   # Generate analysis reports
   435→│       └── index.ts
   436→├── tests/
   437→│   ├── measurements.test.ts
   438→│   ├── scoring.test.ts
   439→│   └── testData/
   440→│       └── sampleLandmarks.json # Copy from captured data
   441→└── examples/
   442→    ├── analyzeFromLandmarks.ts
   443→    └── generateReport.ts
   444→```
   445→
   446→---
   447→
   448→## CORE IMPLEMENTATION REQUIREMENTS
   449→
   450→### 1. Geometry Utilities (`src/utils/geometry.ts`)
   451→
   452→```typescript
   453→export function distance(p1: Point, p2: Point): number;
   454→export function angle(p1: Point, vertex: Point, p2: Point): number;
   455→export function midpoint(p1: Point, p2: Point): Point;
   456→export function slope(p1: Point, p2: Point): number;
   457→export function perpendicularDistance(point: Point, lineP1: Point, lineP2: Point): number;
   458→export function normalizeCoordinates(landmarks: Point[], imageWidth: number, imageHeight: number): Point[];
   459→```
   460→
   461→### 2. Main Analyzer Class (`src/analysis/FacialAnalyzer.ts`)
   462→
   463→```typescript
   464→export class FacialAnalyzer {
   465→  constructor(options?: AnalyzerOptions);
   466→
   467→  // Input methods
   468→  setFrontLandmarks(landmarks: Point[]): void;
   469→  setSideLandmarks(landmarks: Point[]): void;
   470→  setGender(gender: 'male' | 'female'): void;
   471→
   472→  // Measurement methods
   473→  calculateFrontMeasurements(): FrontFaceMeasurements;
   474→  calculateSideMeasurements(): SideProfileMeasurements;
   475→
   476→  // Scoring methods
   477→  calculateScores(): MeasurementScores;
   478→  calculateHarmonyScore(): number;
   479→  calculatePercentiles(): PercentileResults;
   480→
   481→  // Bell curve data
   482→  getBellCurveData(measurement: string): BellCurveData;
   483→
   484→  // Full analysis
   485→  analyze(): FullAnalysisReport;
   486→}
   487→```
   488→
   489→### 3. Report Generator (`src/analysis/ReportGenerator.ts`)
   490→
   491→```typescript
   492→export class ReportGenerator {
   493→  constructor(analysis: FullAnalysisReport);
   494→
   495→  toJSON(): string;
   496→  toMarkdown(): string;
   497→  toHTML(): string;
   498→
   499→  // Individual sections
   500→  getMeasurementsSection(): string;
   501→  getScoresSection(): string;
   502→  getPercentileSection(): string;
   503→  getRecommendationsSection(): string;
   504→}
   505→```
   506→
   507→---
   508→
   509→## GENDER-SPECIFIC IDEAL VALUES
   510→
   511→```typescript
   512→export const IDEAL_VALUES = {
   513→  male: {
   514→    fwhr: { ideal: 1.9, range: [1.8, 2.1] },
   515→    canthalTilt: { ideal: 4, range: [2, 7] },
   516→    nasolabialAngle: { ideal: 95, range: [90, 100] },
   517→    gonialAngle: { ideal: 125, range: [120, 130] },
   518→    nasalIndex: { ideal: 0.7, range: [0.65, 0.75] },
   519→    lipRatio: { ideal: 0.5, range: [0.4, 0.6] },
   520→    facialConvexity: { ideal: 170, range: [165, 175] },
   521→    chinProjection: { ideal: 0, range: [-3, 3] },
   522→  },
   523→  female: {
   524→    fwhr: { ideal: 1.75, range: [1.6, 1.9] },
   525→    canthalTilt: { ideal: 6, range: [4, 10] },
   526→    nasolabialAngle: { ideal: 105, range: [100, 115] },
   527→    gonialAngle: { ideal: 128, range: [125, 135] },
   528→    nasalIndex: { ideal: 0.65, range: [0.6, 0.7] },
   529→    lipRatio: { ideal: 0.5, range: [0.45, 0.55] },
   530→    facialConvexity: { ideal: 168, range: [163, 173] },
   531→    chinProjection: { ideal: -2, range: [-5, 1] },
   532→  }
   533→};
   534→```
   535→
   536→---
   537→
   538→## EXAMPLE USAGE
   539→
   540→```typescript
   541→import { FacialAnalyzer, ReportGenerator } from 'faceiq-engine';
   542→
   543→// Load landmarks from your detection system
   544→const frontLandmarks = await detectFrontFace(image);
   545→const sideLandmarks = await detectSideProfile(sideImage);
   546→
   547→// Create analyzer
   548→const analyzer = new FacialAnalyzer({ gender: 'male' });
   549→analyzer.setFrontLandmarks(frontLandmarks);
   550→analyzer.setSideLandmarks(sideLandmarks);
   551→
   552→// Get full analysis
   553→const analysis = analyzer.analyze();
   554→
   555→console.log('Harmony Score:', analysis.harmonyScore);
   556→console.log('FWHR:', analysis.measurements.front.fwhr);
   557→console.log('Your percentile:', analysis.percentiles.overall);
   558→
   559→// Generate report
   560→const report = new ReportGenerator(analysis);
   561→console.log(report.toMarkdown());
   562→
   563→// Get bell curve data for visualization
   564→const bellCurve = analyzer.getBellCurveData('harmonyScore');
   565→// Use bellCurve.points for chart visualization
   566→```
   567→
   568→---
   569→
   570→## REFERENCE FILES TO READ
   571→
   572→Before building, read these files for context:
   573→
   574→1. `~/Desktop/reverse-engineer/landmark_data.json` - Actual landmark coordinates
   575→2. `~/Desktop/reverse-engineer/captured_api/251_POST_api_side-landmarks.json` - Full API response
   576→3. `~/Desktop/reverse-engineer/CALCULATION_ANALYSIS.md` - Formula documentation
   577→4. `~/Desktop/reverse-engineer/FACEIQ_REVERSE_ENGINEERING_SUMMARY.md` - Full context
   578→
   579→---
   580→
   581→## BUILD INSTRUCTIONS
   582→
   583→1. Create the folder structure
   584→2. Initialize npm package with TypeScript
   585→3. Implement all utility functions first
   586→4. Implement measurement calculations
   587→5. Implement scoring system with bell curves
   588→6. Create the main FacialAnalyzer class
   589→7. Create tests using the captured landmark data
   590→8. Create example scripts
   591→
   592→Build everything as working, production-ready code. Include all necessary type definitions, error handling, and documentation comments.
   593→
   594→---
   595→
   596→END OF PROMPT
   597→

<system-reminder>
Whenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.
</system-reminder>
