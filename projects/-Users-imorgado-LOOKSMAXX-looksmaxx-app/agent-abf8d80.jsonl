{"parentUuid":null,"isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"faeb714a-61c5-410d-b669-0ebc662cf207","version":"2.0.70","gitBranch":"main","agentId":"abf8d80","type":"user","message":{"role":"user","content":"Research COMPLETE website cloning solutions on GitHub using the mcp__grep__searchGitHub tool. Focus on finding all-in-one tools that can clone entire websites. Search for patterns like:\n- 'website-cloner' or 'site-cloner'\n- 'SingleFile' (popular browser extension for saving pages)\n- 'puppeteer.*save' or 'playwright.*download'\n- Full page archiving tools\n\nUse queries like 'SingleFile', 'website.*cloner', 'full.*page.*save', 'puppeteer.*serialize', 'mhtml', 'archive.*page', 'offline.*website'. Look across all major languages. Summarize the best comprehensive tools you find with their GitHub URLs and key features for complete website preservation."},"uuid":"c84a3b83-5efc-4821-ba63-1f0be23eca62","timestamp":"2025-12-19T04:43:37.346Z"}
{"parentUuid":"c84a3b83-5efc-4821-ba63-1f0be23eca62","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"faeb714a-61c5-410d-b669-0ebc662cf207","version":"2.0.70","gitBranch":"main","agentId":"abf8d80","message":{"model":"claude-opus-4-5-20251101","id":"msg_01UDVMKpLByCtoWJHvQRKeW4","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_018ahB9e6SuYBEZsrugtjkQJ","name":"mcp__grep__searchGitHub","input":{"query":"SingleFile"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":13149,"cache_read_input_tokens":0,"cache_creation":{"ephemeral_5m_input_tokens":13149,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWFSAg2NHNaZXrRvMff8J","type":"assistant","uuid":"434dd860-d33c-4ecd-a1f7-577ff1da5c10","timestamp":"2025-12-19T04:43:41.238Z"}
{"parentUuid":"434dd860-d33c-4ecd-a1f7-577ff1da5c10","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"faeb714a-61c5-410d-b669-0ebc662cf207","version":"2.0.70","gitBranch":"main","agentId":"abf8d80","message":{"model":"claude-opus-4-5-20251101","id":"msg_01UDVMKpLByCtoWJHvQRKeW4","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_0147Hd1zBdcspr6M7p5tHhit","name":"mcp__grep__searchGitHub","input":{"query":"website-cloner"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":13149,"cache_read_input_tokens":0,"cache_creation":{"ephemeral_5m_input_tokens":13149,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWFSAg2NHNaZXrRvMff8J","type":"assistant","uuid":"1a4b32b2-233b-46a0-b055-3944a0e7939f","timestamp":"2025-12-19T04:43:41.719Z"}
{"parentUuid":"1a4b32b2-233b-46a0-b055-3944a0e7939f","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"faeb714a-61c5-410d-b669-0ebc662cf207","version":"2.0.70","gitBranch":"main","agentId":"abf8d80","message":{"model":"claude-opus-4-5-20251101","id":"msg_01UDVMKpLByCtoWJHvQRKeW4","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_017sJWPeh5vVAhroUifJrJcJ","name":"mcp__grep__searchGitHub","input":{"query":"site-cloner"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":13149,"cache_read_input_tokens":0,"cache_creation":{"ephemeral_5m_input_tokens":13149,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWFSAg2NHNaZXrRvMff8J","type":"assistant","uuid":"e7b7eb44-746f-45f6-bd2e-1e615247880f","timestamp":"2025-12-19T04:43:42.182Z"}
{"parentUuid":"e7b7eb44-746f-45f6-bd2e-1e615247880f","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"faeb714a-61c5-410d-b669-0ebc662cf207","version":"2.0.70","gitBranch":"main","agentId":"abf8d80","message":{"model":"claude-opus-4-5-20251101","id":"msg_01UDVMKpLByCtoWJHvQRKeW4","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01VFy62J6hHviscmET6d2Rmm","name":"mcp__grep__searchGitHub","input":{"query":"(?s)puppeteer.*serialize","useRegexp":true}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":13149,"cache_read_input_tokens":0,"cache_creation":{"ephemeral_5m_input_tokens":13149,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWFSAg2NHNaZXrRvMff8J","type":"assistant","uuid":"a5fe3c6b-e13e-4abc-a042-acaf71546cc6","timestamp":"2025-12-19T04:43:43.129Z"}
{"parentUuid":"a5fe3c6b-e13e-4abc-a042-acaf71546cc6","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"faeb714a-61c5-410d-b669-0ebc662cf207","version":"2.0.70","gitBranch":"main","agentId":"abf8d80","message":{"model":"claude-opus-4-5-20251101","id":"msg_01UDVMKpLByCtoWJHvQRKeW4","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_0151u68ni1ZqouNkci7FX1fu","name":"mcp__grep__searchGitHub","input":{"query":"mhtml"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":13149,"cache_read_input_tokens":0,"cache_creation":{"ephemeral_5m_input_tokens":13149,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWFSAg2NHNaZXrRvMff8J","type":"assistant","uuid":"eeb20a9d-0fc2-4748-bc94-12a92b0a8b8e","timestamp":"2025-12-19T04:43:43.524Z"}
{"parentUuid":"eeb20a9d-0fc2-4748-bc94-12a92b0a8b8e","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"faeb714a-61c5-410d-b669-0ebc662cf207","version":"2.0.70","gitBranch":"main","agentId":"abf8d80","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_018ahB9e6SuYBEZsrugtjkQJ","type":"tool_result","content":[{"type":"text","text":"Repository: microsoft/TypeScript\nPath: src/testRunner/unittests/services/textChanges.ts\nURL: https://github.com/microsoft/TypeScript/blob/main/src/testRunner/unittests/services/textChanges.ts\nLicense: Apache-2.0\n\nSnippets:\n--- Snippet 1 (Line 45) ---\n                return ts.isArray(n) ? ts.forEach(n, walk) : ts.forEachChild(n, walk, walk);\n            }\n        }\n    }\n\n    function runSingleFileTest(caption: string, placeOpenBraceOnNewLineForFunctions: boolean, text: string, validateNodes: boolean, testBlock: (sourceFile: ts.SourceFile, changeTracker: ts.textChanges.ChangeTracker) => void) {\n        it(caption, () => {\n            const sourceFile = ts.createSourceFile(\"source.ts\", text, ts.ScriptTarget.ES2015, /*setParentNodes*/ true);\n            const rulesProvider = getRuleProvider(placeOpenBraceOnNewLineForFunctions);\n            const changeTracker = new ts.textChanges.ChangeTracker(newLineCharacter, rulesProvider);\n            testBlock(sourceFile, changeTracker);\n\n\n--- Snippet 2 (Line 81) ---\n            const y = 2; // comment 3\n            return 1;\n        }\n    }\n}`;\n        runSingleFileTest(\"extractMethodLike\", /*placeOpenBraceOnNewLineForFunctions*/ true, text, /*validateNodes*/ true, (sourceFile, changeTracker) => {\n            const statements = (findChild(\"foo\", sourceFile) as ts.FunctionDeclaration).body!.statements.slice(1);\n            const newFunction = ts.factory.createFunctionDeclaration(\n                /*modifiers*/ undefined,\n"},{"type":"text","text":"Repository: duckdb/duckdb\nPath: src/storage/single_file_block_manager.cpp\nURL: https://github.com/duckdb/duckdb/blob/main/src/storage/single_file_block_manager.cpp\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 243) ---\nDatabaseHeader DeserializeDatabaseHeader(const MainHeader &main_header, data_ptr_t ptr) {\n\tMemoryStream source(ptr, Storage::FILE_HEADER_SIZE);\n\treturn DatabaseHeader::Read(main_header, source);\n}\n\nSingleFileBlockManager::SingleFileBlockManager(AttachedDatabase &db_p, const string &path_p,\n                                               const StorageManagerOptions &options)\n    : BlockManager(BufferManager::GetBufferManager(db_p), options.block_alloc_size, options.block_header_size),\n      db(db_p), path(path_p), header_buffer(BlockAllocator::Get(db_p), FileBufferType::MANAGED_BUFFER,\n                                            Storage::FILE_HEADER_SIZE - options.block_header_size.GetIndex(),\n                                            options.block_header_size.GetIndex()),\n      iteration_count(0), options(options) {\n}\n\nFileOpenFlags SingleFileBlockManager::GetFileFlags(bool create_new) const {\n\tFileOpenFlags result;\n\tif (options.read_only) {\n\t\tD_ASSERT(!create_new);\n\t\tresult = FileFlags::FILE_FLAGS_READ | FileFlags::FILE_FLAGS_NULL_IF_NOT_EXISTS | FileLockType::READ_LOCK;\n\t} else {\n"},{"type":"text","text":"Repository: duckdb/duckdb\nPath: src/storage/storage_manager.cpp\nURL: https://github.com/duckdb/duckdb/blob/main/src/storage/storage_manager.cpp\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 171) ---\n\tauto &fs = FileSystem::Get(db);\n\tfs.TryRemoveFile(checkpoint_wal_path);\n\n\t// the checkpoint WAL belongs to the NEXT checkpoint - when we are done we will overwrite the current WAL with it\n\t// as such override the checkpoint iteration number to the next one\n\tauto &single_file_block_manager = GetBlockManager().Cast<SingleFileBlockManager>();\n\tauto next_checkpoint_iteration = single_file_block_manager.GetCheckpointIteration() + 1;\n\twal = make_uniq<WriteAheadLog>(*this, checkpoint_wal_path, 0ULL, WALInitState::NO_WAL, next_checkpoint_iteration);\n\treturn true;\n}\n\n\n\n--- Snippet 2 (Line 267) ---\n\tif (storage_options.encryption) {\n\t\tClearUserKey(storage_options.user_key);\n\t}\n}\n\nclass SingleFileTableIOManager : public TableIOManager {\npublic:\n\texplicit SingleFileTableIOManager(BlockManager &block_manager, idx_t row_group_size)\n\t    : block_manager(block_manager), row_group_size(row_group_size) {\n"},{"type":"text","text":"Repository: dotnet/runtime\nPath: src/native/corehost/apphost/static/CMakeLists.txt\nURL: https://github.com/dotnet/runtime/blob/main/src/native/corehost/apphost/static/CMakeLists.txt\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n# Licensed to the .NET Foundation under one or more agreements.\n# The .NET Foundation licenses this file to you under the MIT license.\n\nproject(singlefilehost)\nset(DOTNET_PROJECT_NAME \"singlefilehost\")\n\ninclude_directories(..)\ninclude_directories(../..)\ninclude_directories(../../hostmisc)\ninclude_directories(../../json)\n\n\n--- Snippet 2 (Line 72) ---\n    add_linker_flag(\"/DEF:${CMAKE_CURRENT_SOURCE_DIR}/singlefilehost.def\")\n\nelse()\n    if(CLR_CMAKE_TARGET_FREEBSD)\n        set(DEF_SOURCES ${CMAKE_CURRENT_SOURCE_DIR}/singlefilehost_freebsdexports.src)\n    else()\n        set(DEF_SOURCES ${CMAKE_CURRENT_SOURCE_DIR}/singlefilehost_unixexports.src)\n    endif()\n\n    set(EXPORTS_FILE ${CMAKE_CURRENT_BINARY_DIR}/singlefilehost.exports)\n"},{"type":"text","text":"Repository: ppy/osu\nPath: osu.Game/OsuGame.cs\nURL: https://github.com/ppy/osu/blob/master/osu.Game/OsuGame.cs\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 1175) ---\n            loadComponentSingleFile(fpsCounter = new FPSCounter\n            {\n                Anchor = Anchor.BottomRight,\n                Origin = Anchor.BottomRight,\n                Margin = new MarginPadding(5),\n            }, topMostOverlayContent.Add);\n\n            if (!IsDeployedBuild)\n                loadComponentSingleFile(devBuildBanner = new DevBuildBanner(), ScreenContainer.Add);\n\n            loadComponentSingleFile(osuLogo, _ =>\n            {\n                osuLogo.SetupDefaultContainer(logoContainer);\n\n                // Loader has to be created after the logo has finished loading as Loader performs logo transformations on entering.\n                ScreenStack.Push(CreateLoader().With(l => l.RelativeSizeAxes = Axes.Both));\n            });\n\n            LocalUserStatisticsProvider statisticsProvider;\n\n            loadComponentSingleFile(statisticsProvider = new LocalUserStatisticsProvider(), Add, true);\n"},{"type":"text","text":"Repository: apache/hive\nPath: ql/src/java/org/apache/hadoop/hive/ql/io/SingleFileSystem.java\nURL: https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/io/SingleFileSystem.java\nLicense: Apache-2.0\n\nSnippets:\n--- Snippet 1 (Line 45) ---\n *\n * sfs+file://somedir/f1.txt/#SINGLEFILE#\n *\n * This will be a directory containing only the f1.txt and nothing else.\n *\n */\n/*\n * Thru out this file there are paths of both the overlay filesystem and the underlying fs.\n * To avoid confusion between these path types - all paths which are in the overlay fs are refered\n * with the upper keyword - and paths on the underlying fs are identified with the lower keyword.\n *\n *  For example:\n *    'sfs+file:///foo/bar/#SINGLEFILE#/bar' is an upper path\n *    'file:///foo/bar' is a lower path\n */\npublic abstract class SingleFileSystem extends FileSystem {\n\n  public static class HDFS extends SingleFileSystem {\n  }\n\n  public static class S3A extends SingleFileSystem {\n"},{"type":"text","text":"Repository: telegramdesktop/tdesktop\nPath: Telegram/SourceFiles/ui/chat/attach/attach_abstract_single_file_preview.cpp\nURL: https://github.com/telegramdesktop/tdesktop/blob/dev/Telegram/SourceFiles/ui/chat/attach/attach_abstract_single_file_preview.cpp\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 17) ---\n#include \"styles/style_chat.h\"\n#include \"styles/style_chat_helpers.h\"\n\nnamespace Ui {\n\nAbstractSingleFilePreview::AbstractSingleFilePreview(\n\tQWidget *parent,\n\tconst style::ComposeControls &st,\n\tAttachControls::Type type)\n: AbstractSinglePreview(parent)\n, _st(st)\n\n\n--- Snippet 2 (Line 47) ---\nAbstractSingleFilePreview::~AbstractSingleFilePreview() = default;\n\nrpl::producer<> AbstractSingleFilePreview::editRequests() const {\n\treturn _editMedia->clicks() | rpl::map([] {\n\t\treturn base::timer_once(st::historyAttach.ripple.hideDuration);\n\t}) | rpl::flatten_latest();\n}\n\nrpl::producer<> AbstractSingleFilePreview::deleteRequests() const {\n"},{"type":"text","text":"Repository: ArchiveBox/ArchiveBox\nPath: archivebox/pkgs/abx-plugin-singlefile/abx_plugin_singlefile/singlefile.py\nURL: https://github.com/ArchiveBox/ArchiveBox/blob/dev/archivebox/pkgs/abx-plugin-singlefile/abx_plugin_singlefile/singlefile.py\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n__package__ = 'abx_plugin_singlefile'\n\nimport json\nfrom pathlib import Path\nfrom typing import Optional\n\n\n\n--- Snippet 2 (Line 11) ---\n\nfrom abx_plugin_chrome.config import CHROME_CONFIG\nfrom abx_plugin_chrome.binaries import CHROME_BINARY\n\nfrom .config import SINGLEFILE_CONFIG\nfrom .binaries import SINGLEFILE_BINARY\n\n\ndef get_output_path():\n    return 'singlefile.html'\n\n\n@enforce_types\ndef should_save_singlefile(link: Link, out_dir: Optional[Path]=None, overwrite: Optional[bool]=False) -> bool:\n"},{"type":"text","text":"Repository: gildas-lormeau/SingleFile\nPath: src/ui/content/content-ui-editor-web.js\nURL: https://github.com/gildas-lormeau/SingleFile/blob/master/src/ui/content/content-ui-editor-web.js\nLicense: AGPL-3.0\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n/*\n * Copyright 2010-2020 Gildas Lormeau\n * contact : gildas.lormeau <at> gmail.com\n * \n * This file is part of SingleFile.\n *\n *   The code in this file is free software: you can redistribute it and/or \n *   modify it under the terms of the GNU Affero General Public License \n *   (GNU AGPL) as published by the Free Software Foundation, either version 3\n *   of the License, or (at your option) any later version.\n\n\n--- Snippet 2 (Line 29) ---\n\n(globalThis => {\n\n\tconst IS_NOT_SAFARI = !/Safari/.test(navigator.userAgent) || /Chrome/.test(navigator.userAgent) || /Vivaldi/.test(navigator.userAgent) || /OPR/.test(navigator.userAgent);\n\n\tconst singlefile = globalThis.singlefile;\n\n\tconst FORBIDDEN_TAG_NAMES = [\"a\", \"area\", \"audio\", \"base\", \"br\", \"col\", \"command\", \"embed\", \"hr\", \"img\", \"iframe\", \"input\", \"keygen\", \"link\", \"meta\", \"param\", \"source\", \"track\", \"video\", \"wbr\"];\n"},{"type":"text","text":"Repository: 99designs/gqlgen\nPath: codegen/testserver/singlefile/generated.go\nURL: https://github.com/99designs/gqlgen/blob/master/codegen/testserver/singlefile/generated.go\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n// Code generated by github.com/99designs/gqlgen, DO NOT EDIT.\n\npackage singlefile\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"errors\"\n\n\n--- Snippet 2 (Line 10) ---\n\t\"strconv\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"time\"\n\n\tintrospection1 \"github.com/99designs/gqlgen/codegen/testserver/singlefile/introspection\"\n\tinvalid_packagename \"github.com/99designs/gqlgen/codegen/testserver/singlefile/invalid-packagename\"\n\t\"github.com/99designs/gqlgen/codegen/testserver/singlefile/otherpkg\"\n\t\"github.com/99designs/gqlgen/graphql\"\n\t\"github.com/99designs/gqlgen/graphql/introspection\"\n\tgqlparser \"github.com/vektah/gqlparser/v2\"\n\t\"github.com/vektah/gqlparser/v2/ast\"\n"}]}]},"uuid":"88f01e54-3134-479d-b51f-bdc9bb438289","timestamp":"2025-12-19T04:43:44.355Z","toolUseResult":[{"type":"text","text":"Repository: microsoft/TypeScript\nPath: src/testRunner/unittests/services/textChanges.ts\nURL: https://github.com/microsoft/TypeScript/blob/main/src/testRunner/unittests/services/textChanges.ts\nLicense: Apache-2.0\n\nSnippets:\n--- Snippet 1 (Line 45) ---\n                return ts.isArray(n) ? ts.forEach(n, walk) : ts.forEachChild(n, walk, walk);\n            }\n        }\n    }\n\n    function runSingleFileTest(caption: string, placeOpenBraceOnNewLineForFunctions: boolean, text: string, validateNodes: boolean, testBlock: (sourceFile: ts.SourceFile, changeTracker: ts.textChanges.ChangeTracker) => void) {\n        it(caption, () => {\n            const sourceFile = ts.createSourceFile(\"source.ts\", text, ts.ScriptTarget.ES2015, /*setParentNodes*/ true);\n            const rulesProvider = getRuleProvider(placeOpenBraceOnNewLineForFunctions);\n            const changeTracker = new ts.textChanges.ChangeTracker(newLineCharacter, rulesProvider);\n            testBlock(sourceFile, changeTracker);\n\n\n--- Snippet 2 (Line 81) ---\n            const y = 2; // comment 3\n            return 1;\n        }\n    }\n}`;\n        runSingleFileTest(\"extractMethodLike\", /*placeOpenBraceOnNewLineForFunctions*/ true, text, /*validateNodes*/ true, (sourceFile, changeTracker) => {\n            const statements = (findChild(\"foo\", sourceFile) as ts.FunctionDeclaration).body!.statements.slice(1);\n            const newFunction = ts.factory.createFunctionDeclaration(\n                /*modifiers*/ undefined,\n"},{"type":"text","text":"Repository: duckdb/duckdb\nPath: src/storage/single_file_block_manager.cpp\nURL: https://github.com/duckdb/duckdb/blob/main/src/storage/single_file_block_manager.cpp\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 243) ---\nDatabaseHeader DeserializeDatabaseHeader(const MainHeader &main_header, data_ptr_t ptr) {\n\tMemoryStream source(ptr, Storage::FILE_HEADER_SIZE);\n\treturn DatabaseHeader::Read(main_header, source);\n}\n\nSingleFileBlockManager::SingleFileBlockManager(AttachedDatabase &db_p, const string &path_p,\n                                               const StorageManagerOptions &options)\n    : BlockManager(BufferManager::GetBufferManager(db_p), options.block_alloc_size, options.block_header_size),\n      db(db_p), path(path_p), header_buffer(BlockAllocator::Get(db_p), FileBufferType::MANAGED_BUFFER,\n                                            Storage::FILE_HEADER_SIZE - options.block_header_size.GetIndex(),\n                                            options.block_header_size.GetIndex()),\n      iteration_count(0), options(options) {\n}\n\nFileOpenFlags SingleFileBlockManager::GetFileFlags(bool create_new) const {\n\tFileOpenFlags result;\n\tif (options.read_only) {\n\t\tD_ASSERT(!create_new);\n\t\tresult = FileFlags::FILE_FLAGS_READ | FileFlags::FILE_FLAGS_NULL_IF_NOT_EXISTS | FileLockType::READ_LOCK;\n\t} else {\n"},{"type":"text","text":"Repository: duckdb/duckdb\nPath: src/storage/storage_manager.cpp\nURL: https://github.com/duckdb/duckdb/blob/main/src/storage/storage_manager.cpp\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 171) ---\n\tauto &fs = FileSystem::Get(db);\n\tfs.TryRemoveFile(checkpoint_wal_path);\n\n\t// the checkpoint WAL belongs to the NEXT checkpoint - when we are done we will overwrite the current WAL with it\n\t// as such override the checkpoint iteration number to the next one\n\tauto &single_file_block_manager = GetBlockManager().Cast<SingleFileBlockManager>();\n\tauto next_checkpoint_iteration = single_file_block_manager.GetCheckpointIteration() + 1;\n\twal = make_uniq<WriteAheadLog>(*this, checkpoint_wal_path, 0ULL, WALInitState::NO_WAL, next_checkpoint_iteration);\n\treturn true;\n}\n\n\n\n--- Snippet 2 (Line 267) ---\n\tif (storage_options.encryption) {\n\t\tClearUserKey(storage_options.user_key);\n\t}\n}\n\nclass SingleFileTableIOManager : public TableIOManager {\npublic:\n\texplicit SingleFileTableIOManager(BlockManager &block_manager, idx_t row_group_size)\n\t    : block_manager(block_manager), row_group_size(row_group_size) {\n"},{"type":"text","text":"Repository: dotnet/runtime\nPath: src/native/corehost/apphost/static/CMakeLists.txt\nURL: https://github.com/dotnet/runtime/blob/main/src/native/corehost/apphost/static/CMakeLists.txt\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n# Licensed to the .NET Foundation under one or more agreements.\n# The .NET Foundation licenses this file to you under the MIT license.\n\nproject(singlefilehost)\nset(DOTNET_PROJECT_NAME \"singlefilehost\")\n\ninclude_directories(..)\ninclude_directories(../..)\ninclude_directories(../../hostmisc)\ninclude_directories(../../json)\n\n\n--- Snippet 2 (Line 72) ---\n    add_linker_flag(\"/DEF:${CMAKE_CURRENT_SOURCE_DIR}/singlefilehost.def\")\n\nelse()\n    if(CLR_CMAKE_TARGET_FREEBSD)\n        set(DEF_SOURCES ${CMAKE_CURRENT_SOURCE_DIR}/singlefilehost_freebsdexports.src)\n    else()\n        set(DEF_SOURCES ${CMAKE_CURRENT_SOURCE_DIR}/singlefilehost_unixexports.src)\n    endif()\n\n    set(EXPORTS_FILE ${CMAKE_CURRENT_BINARY_DIR}/singlefilehost.exports)\n"},{"type":"text","text":"Repository: ppy/osu\nPath: osu.Game/OsuGame.cs\nURL: https://github.com/ppy/osu/blob/master/osu.Game/OsuGame.cs\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 1175) ---\n            loadComponentSingleFile(fpsCounter = new FPSCounter\n            {\n                Anchor = Anchor.BottomRight,\n                Origin = Anchor.BottomRight,\n                Margin = new MarginPadding(5),\n            }, topMostOverlayContent.Add);\n\n            if (!IsDeployedBuild)\n                loadComponentSingleFile(devBuildBanner = new DevBuildBanner(), ScreenContainer.Add);\n\n            loadComponentSingleFile(osuLogo, _ =>\n            {\n                osuLogo.SetupDefaultContainer(logoContainer);\n\n                // Loader has to be created after the logo has finished loading as Loader performs logo transformations on entering.\n                ScreenStack.Push(CreateLoader().With(l => l.RelativeSizeAxes = Axes.Both));\n            });\n\n            LocalUserStatisticsProvider statisticsProvider;\n\n            loadComponentSingleFile(statisticsProvider = new LocalUserStatisticsProvider(), Add, true);\n"},{"type":"text","text":"Repository: apache/hive\nPath: ql/src/java/org/apache/hadoop/hive/ql/io/SingleFileSystem.java\nURL: https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/io/SingleFileSystem.java\nLicense: Apache-2.0\n\nSnippets:\n--- Snippet 1 (Line 45) ---\n *\n * sfs+file://somedir/f1.txt/#SINGLEFILE#\n *\n * This will be a directory containing only the f1.txt and nothing else.\n *\n */\n/*\n * Thru out this file there are paths of both the overlay filesystem and the underlying fs.\n * To avoid confusion between these path types - all paths which are in the overlay fs are refered\n * with the upper keyword - and paths on the underlying fs are identified with the lower keyword.\n *\n *  For example:\n *    'sfs+file:///foo/bar/#SINGLEFILE#/bar' is an upper path\n *    'file:///foo/bar' is a lower path\n */\npublic abstract class SingleFileSystem extends FileSystem {\n\n  public static class HDFS extends SingleFileSystem {\n  }\n\n  public static class S3A extends SingleFileSystem {\n"},{"type":"text","text":"Repository: telegramdesktop/tdesktop\nPath: Telegram/SourceFiles/ui/chat/attach/attach_abstract_single_file_preview.cpp\nURL: https://github.com/telegramdesktop/tdesktop/blob/dev/Telegram/SourceFiles/ui/chat/attach/attach_abstract_single_file_preview.cpp\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 17) ---\n#include \"styles/style_chat.h\"\n#include \"styles/style_chat_helpers.h\"\n\nnamespace Ui {\n\nAbstractSingleFilePreview::AbstractSingleFilePreview(\n\tQWidget *parent,\n\tconst style::ComposeControls &st,\n\tAttachControls::Type type)\n: AbstractSinglePreview(parent)\n, _st(st)\n\n\n--- Snippet 2 (Line 47) ---\nAbstractSingleFilePreview::~AbstractSingleFilePreview() = default;\n\nrpl::producer<> AbstractSingleFilePreview::editRequests() const {\n\treturn _editMedia->clicks() | rpl::map([] {\n\t\treturn base::timer_once(st::historyAttach.ripple.hideDuration);\n\t}) | rpl::flatten_latest();\n}\n\nrpl::producer<> AbstractSingleFilePreview::deleteRequests() const {\n"},{"type":"text","text":"Repository: ArchiveBox/ArchiveBox\nPath: archivebox/pkgs/abx-plugin-singlefile/abx_plugin_singlefile/singlefile.py\nURL: https://github.com/ArchiveBox/ArchiveBox/blob/dev/archivebox/pkgs/abx-plugin-singlefile/abx_plugin_singlefile/singlefile.py\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n__package__ = 'abx_plugin_singlefile'\n\nimport json\nfrom pathlib import Path\nfrom typing import Optional\n\n\n\n--- Snippet 2 (Line 11) ---\n\nfrom abx_plugin_chrome.config import CHROME_CONFIG\nfrom abx_plugin_chrome.binaries import CHROME_BINARY\n\nfrom .config import SINGLEFILE_CONFIG\nfrom .binaries import SINGLEFILE_BINARY\n\n\ndef get_output_path():\n    return 'singlefile.html'\n\n\n@enforce_types\ndef should_save_singlefile(link: Link, out_dir: Optional[Path]=None, overwrite: Optional[bool]=False) -> bool:\n"},{"type":"text","text":"Repository: gildas-lormeau/SingleFile\nPath: src/ui/content/content-ui-editor-web.js\nURL: https://github.com/gildas-lormeau/SingleFile/blob/master/src/ui/content/content-ui-editor-web.js\nLicense: AGPL-3.0\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n/*\n * Copyright 2010-2020 Gildas Lormeau\n * contact : gildas.lormeau <at> gmail.com\n * \n * This file is part of SingleFile.\n *\n *   The code in this file is free software: you can redistribute it and/or \n *   modify it under the terms of the GNU Affero General Public License \n *   (GNU AGPL) as published by the Free Software Foundation, either version 3\n *   of the License, or (at your option) any later version.\n\n\n--- Snippet 2 (Line 29) ---\n\n(globalThis => {\n\n\tconst IS_NOT_SAFARI = !/Safari/.test(navigator.userAgent) || /Chrome/.test(navigator.userAgent) || /Vivaldi/.test(navigator.userAgent) || /OPR/.test(navigator.userAgent);\n\n\tconst singlefile = globalThis.singlefile;\n\n\tconst FORBIDDEN_TAG_NAMES = [\"a\", \"area\", \"audio\", \"base\", \"br\", \"col\", \"command\", \"embed\", \"hr\", \"img\", \"iframe\", \"input\", \"keygen\", \"link\", \"meta\", \"param\", \"source\", \"track\", \"video\", \"wbr\"];\n"},{"type":"text","text":"Repository: 99designs/gqlgen\nPath: codegen/testserver/singlefile/generated.go\nURL: https://github.com/99designs/gqlgen/blob/master/codegen/testserver/singlefile/generated.go\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n// Code generated by github.com/99designs/gqlgen, DO NOT EDIT.\n\npackage singlefile\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"errors\"\n\n\n--- Snippet 2 (Line 10) ---\n\t\"strconv\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"time\"\n\n\tintrospection1 \"github.com/99designs/gqlgen/codegen/testserver/singlefile/introspection\"\n\tinvalid_packagename \"github.com/99designs/gqlgen/codegen/testserver/singlefile/invalid-packagename\"\n\t\"github.com/99designs/gqlgen/codegen/testserver/singlefile/otherpkg\"\n\t\"github.com/99designs/gqlgen/graphql\"\n\t\"github.com/99designs/gqlgen/graphql/introspection\"\n\tgqlparser \"github.com/vektah/gqlparser/v2\"\n\t\"github.com/vektah/gqlparser/v2/ast\"\n"}]}
{"parentUuid":"88f01e54-3134-479d-b51f-bdc9bb438289","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"faeb714a-61c5-410d-b669-0ebc662cf207","version":"2.0.70","gitBranch":"main","agentId":"abf8d80","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_0147Hd1zBdcspr6M7p5tHhit","type":"tool_result","content":[{"type":"text","text":"Repository: dazzyddos/HSC24RedTeamInfra\nPath: Final_Project/modules/aws/webserver-clone/main.tf\nURL: https://github.com/dazzyddos/HSC24RedTeamInfra/blob/main/Final_Project/modules/aws/webserver-clone/main.tf\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 60) ---\n  }\n\n  provisioner \"remote-exec\" {\n    inline = [\n      \"sudo -- sh -c 'echo ${var.hostname} ${aws_instance.websiteclone-host[count.index].private_ip} >> /etc/hosts'\",\n      \"ANSIBLE_HOST_KEY_CHECKING=False ansible-playbook /home/ubuntu/ansible-playbooks/website-cloner/main.yml -i ${aws_instance.websiteclone-host[count.index].private_ip}, -e 'website_url=${var.website_url[count.index]}'\"\n    ]\n  }\n}\n\nresource \"null_resource\" \"run_ansbile_sslsetup\" {\n\n\n--- Snippet 2 (Line 85) ---\n    destination = \"/tmp/server-ssl.conf\"\n  }\n\n  provisioner \"remote-exec\" {\n    inline = [\n      \"ANSIBLE_HOST_KEY_CHECKING=False ansible-playbook /home/ubuntu/ansible-playbooks/website-cloner/ssl-setup.yml -i ${aws_instance.websiteclone-host[count.index].private_ip}, -e 'DOMAIN=${var.domain_names[count.index]}'\"\n    ]\n  }\n"},{"type":"text","text":"Repository: dazzyddos/HSC24RedTeamInfra\nPath: Final_Project/main.tf\nURL: https://github.com/dazzyddos/HSC24RedTeamInfra/blob/main/Final_Project/main.tf\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 199) ---\n#   private_key          = tls_private_key.terra_sshkey.private_key_pem\n#   bastionhostprivateip = module.redteambastion.bastion-private-ip\n#   bastionhostpublicip  = module.redteambastion.bastion-public-ip\n#   open_ports           = [443, 80]\n#   domain_names         = [\"newhireintro.com\"]\n#   ansible_playbook     =  \"./Ansilble-Playbooks/website-cloner/main.yml\"\n# }\n\n// we are creating an azure cdn with redirection rule based on the header (check the azure-ad module's main.tf for more info)\n# module \"azure-cdn\" {\n#     source              = \"./modules/azure/azure-cdn\"\n"},{"type":"text","text":"Repository: X-SLAYER/Website-Cloner\nPath: README.md\nURL: https://github.com/X-SLAYER/Website-Cloner/blob/master/README.md\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 5) ---\nhtml,css,js,images ...\n\n### Downloads Linux Version:\n| Platform | Version | Link                                                                                                                         |\n| -------- | ------- | ---------------------------------------------------------------------------------------------------------------------------- |\n| Linux    | ✅   | [Download (.deb)](https://github.com/X-SLAYER/website-cloner-dart)  |\n \n # Show some ⭐ to the repo for support\n\n## Screenshots\n\n"},{"type":"text","text":"Repository: Kaustubh72/Website-Cloner\nPath: package.json\nURL: https://github.com/Kaustubh72/Website-Cloner/blob/master/package.json\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n{\n  \"name\": \"website-cloner\",\n  \"version\": \"1.0.0\",\n  \"description\": \"A script which can create a clone of any website\",\n  \"main\": \"index.js\",\n  \"scripts\": {\n    \"start\": \"node index.js\",\n    \"test\": \"node index.js\"\n  },\n  \"repository\": {\n    \"type\": \"git\",\n    \"url\": \"git+https://github.com/Kaustubh72/Website-Cloner.git\"\n  },\n  \"keywords\": [\n    \"NodeJS\",\n    \"Cloning\",\n    \"Website\",\n"},{"type":"text","text":"Repository: kaxap/arl\nPath: README-VB.net.md\nURL: https://github.com/kaxap/arl/blob/master/README-VB.net.md\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 60) ---\n| 161 | 74 | 0 | 3 years ago | [COMRaider](https://github.com/dzzie/COMRaider)/57 | ActiveX Fuzzing tool with GUI, object browser, system scanner, and distributed auditing capabilities |\n| 147 | 94 | 0 | 3 years ago | [Lime-Miner](https://github.com/NYAN-x-CAT/Lime-Miner)/58 | a simple hidden silent XMR miner. |\n| 147 | 52 | 0 | 6 months ago | [Website-Cloner](https://github.com/X-SLAYER/Website-Cloner)/59 | It allows you to download a website from the Internet to a local directory, building recursively all directories, getting HTML, images, and other files from the server to your computer.  |\n| 144 | 8 | 3 | 11 days ago | [gbm](https://github.com/MikeMaximus/gbm)/60 | Game Backup Monitor - Automatically backup your saved games! |\n| 144 | 61 | 21 | a day ago | [dwsim](https://github.com/DanWBR/dwsim)/61 | DWSIM is a Steady-State and Dynamic Sequential Modular Chemical Process Simulator for Windows, Linux and macOS. |\n| 141 | 65 | 7 | 2 years ago | [dwsim5](https://github.com/DanWBR/dwsim5)/62 | DWSIM - Open Source Chemical Process Simulator (5.x series) |\n| 140 | 12 | 10 | 7 years ago | [MetroSteamSettings](https://github.com/SoapyHamHocks/MetroSteamSettings)/63 | None |\n| 136 | 57 | 1 | 4 months ago | [VisualStudioRevitAddinWizard](https://github.com/jeremytammik/VisualStudioRevitAddinWizard)/64 | Visual Studio templates to generate C# and VB .NET Revit add-ins |\n"},{"type":"text","text":"Repository: AI-Native-Dev-Community/ai-native-dev-landscape\nPath: aind-landing-Page/public/tools-data.yaml\nURL: https://github.com/AI-Native-Dev-Community/ai-native-dev-landscape/blob/main/aind-landing-Page/public/tools-data.yaml\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 780) ---\n      tags:\n      - GA\n      - Nocode\n      - Product\n      verified: false\n      website_url: https://wowslider.com/website-builder/ai-website-cloner.html\n  - description: Application Prototyping tools\n    level: 4\n    name: Prototyping\n    tools:\n    - date_added: 12/03/2025\n"},{"type":"text","text":"Repository: Kaustubh72/Website-Cloner\nPath: package-lock.json\nURL: https://github.com/Kaustubh72/Website-Cloner/blob/master/package-lock.json\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n{\n  \"name\": \"website-cloner\",\n  \"version\": \"1.0.0\",\n  \"lockfileVersion\": 1,\n  \"requires\": true,\n  \"dependencies\": {\n    \"@types/mime-types\": {\n"},{"type":"text","text":"Repository: AI-Native-Dev-Community/ai-native-dev-landscape\nPath: aind-landing-Page/public/tools-data.json\nURL: https://github.com/AI-Native-Dev-Community/ai-native-dev-landscape/blob/main/aind-landing-Page/public/tools-data.json\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n, {\"name\": \"Wowslider\", \"description\": \"Generate stunning websites with AI, no-code, free!\", \"website_url\": \"https://wowslider.com/website-builder/ai-website-cloner.html\", \"icon_url\": \"https://wowslider.com/favicon.ico\", \"tags\": [\"GA\", \"Nocode\", \"Product\"], \"verified\": false, \"oss\": false, \"popular\": false, \"date"}]}]},"uuid":"af09c3d8-6502-45eb-8f1f-ec205886c684","timestamp":"2025-12-19T04:43:44.742Z","toolUseResult":[{"type":"text","text":"Repository: dazzyddos/HSC24RedTeamInfra\nPath: Final_Project/modules/aws/webserver-clone/main.tf\nURL: https://github.com/dazzyddos/HSC24RedTeamInfra/blob/main/Final_Project/modules/aws/webserver-clone/main.tf\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 60) ---\n  }\n\n  provisioner \"remote-exec\" {\n    inline = [\n      \"sudo -- sh -c 'echo ${var.hostname} ${aws_instance.websiteclone-host[count.index].private_ip} >> /etc/hosts'\",\n      \"ANSIBLE_HOST_KEY_CHECKING=False ansible-playbook /home/ubuntu/ansible-playbooks/website-cloner/main.yml -i ${aws_instance.websiteclone-host[count.index].private_ip}, -e 'website_url=${var.website_url[count.index]}'\"\n    ]\n  }\n}\n\nresource \"null_resource\" \"run_ansbile_sslsetup\" {\n\n\n--- Snippet 2 (Line 85) ---\n    destination = \"/tmp/server-ssl.conf\"\n  }\n\n  provisioner \"remote-exec\" {\n    inline = [\n      \"ANSIBLE_HOST_KEY_CHECKING=False ansible-playbook /home/ubuntu/ansible-playbooks/website-cloner/ssl-setup.yml -i ${aws_instance.websiteclone-host[count.index].private_ip}, -e 'DOMAIN=${var.domain_names[count.index]}'\"\n    ]\n  }\n"},{"type":"text","text":"Repository: dazzyddos/HSC24RedTeamInfra\nPath: Final_Project/main.tf\nURL: https://github.com/dazzyddos/HSC24RedTeamInfra/blob/main/Final_Project/main.tf\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 199) ---\n#   private_key          = tls_private_key.terra_sshkey.private_key_pem\n#   bastionhostprivateip = module.redteambastion.bastion-private-ip\n#   bastionhostpublicip  = module.redteambastion.bastion-public-ip\n#   open_ports           = [443, 80]\n#   domain_names         = [\"newhireintro.com\"]\n#   ansible_playbook     =  \"./Ansilble-Playbooks/website-cloner/main.yml\"\n# }\n\n// we are creating an azure cdn with redirection rule based on the header (check the azure-ad module's main.tf for more info)\n# module \"azure-cdn\" {\n#     source              = \"./modules/azure/azure-cdn\"\n"},{"type":"text","text":"Repository: X-SLAYER/Website-Cloner\nPath: README.md\nURL: https://github.com/X-SLAYER/Website-Cloner/blob/master/README.md\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 5) ---\nhtml,css,js,images ...\n\n### Downloads Linux Version:\n| Platform | Version | Link                                                                                                                         |\n| -------- | ------- | ---------------------------------------------------------------------------------------------------------------------------- |\n| Linux    | ✅   | [Download (.deb)](https://github.com/X-SLAYER/website-cloner-dart)  |\n \n # Show some ⭐ to the repo for support\n\n## Screenshots\n\n"},{"type":"text","text":"Repository: Kaustubh72/Website-Cloner\nPath: package.json\nURL: https://github.com/Kaustubh72/Website-Cloner/blob/master/package.json\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n{\n  \"name\": \"website-cloner\",\n  \"version\": \"1.0.0\",\n  \"description\": \"A script which can create a clone of any website\",\n  \"main\": \"index.js\",\n  \"scripts\": {\n    \"start\": \"node index.js\",\n    \"test\": \"node index.js\"\n  },\n  \"repository\": {\n    \"type\": \"git\",\n    \"url\": \"git+https://github.com/Kaustubh72/Website-Cloner.git\"\n  },\n  \"keywords\": [\n    \"NodeJS\",\n    \"Cloning\",\n    \"Website\",\n"},{"type":"text","text":"Repository: kaxap/arl\nPath: README-VB.net.md\nURL: https://github.com/kaxap/arl/blob/master/README-VB.net.md\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 60) ---\n| 161 | 74 | 0 | 3 years ago | [COMRaider](https://github.com/dzzie/COMRaider)/57 | ActiveX Fuzzing tool with GUI, object browser, system scanner, and distributed auditing capabilities |\n| 147 | 94 | 0 | 3 years ago | [Lime-Miner](https://github.com/NYAN-x-CAT/Lime-Miner)/58 | a simple hidden silent XMR miner. |\n| 147 | 52 | 0 | 6 months ago | [Website-Cloner](https://github.com/X-SLAYER/Website-Cloner)/59 | It allows you to download a website from the Internet to a local directory, building recursively all directories, getting HTML, images, and other files from the server to your computer.  |\n| 144 | 8 | 3 | 11 days ago | [gbm](https://github.com/MikeMaximus/gbm)/60 | Game Backup Monitor - Automatically backup your saved games! |\n| 144 | 61 | 21 | a day ago | [dwsim](https://github.com/DanWBR/dwsim)/61 | DWSIM is a Steady-State and Dynamic Sequential Modular Chemical Process Simulator for Windows, Linux and macOS. |\n| 141 | 65 | 7 | 2 years ago | [dwsim5](https://github.com/DanWBR/dwsim5)/62 | DWSIM - Open Source Chemical Process Simulator (5.x series) |\n| 140 | 12 | 10 | 7 years ago | [MetroSteamSettings](https://github.com/SoapyHamHocks/MetroSteamSettings)/63 | None |\n| 136 | 57 | 1 | 4 months ago | [VisualStudioRevitAddinWizard](https://github.com/jeremytammik/VisualStudioRevitAddinWizard)/64 | Visual Studio templates to generate C# and VB .NET Revit add-ins |\n"},{"type":"text","text":"Repository: AI-Native-Dev-Community/ai-native-dev-landscape\nPath: aind-landing-Page/public/tools-data.yaml\nURL: https://github.com/AI-Native-Dev-Community/ai-native-dev-landscape/blob/main/aind-landing-Page/public/tools-data.yaml\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 780) ---\n      tags:\n      - GA\n      - Nocode\n      - Product\n      verified: false\n      website_url: https://wowslider.com/website-builder/ai-website-cloner.html\n  - description: Application Prototyping tools\n    level: 4\n    name: Prototyping\n    tools:\n    - date_added: 12/03/2025\n"},{"type":"text","text":"Repository: Kaustubh72/Website-Cloner\nPath: package-lock.json\nURL: https://github.com/Kaustubh72/Website-Cloner/blob/master/package-lock.json\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n{\n  \"name\": \"website-cloner\",\n  \"version\": \"1.0.0\",\n  \"lockfileVersion\": 1,\n  \"requires\": true,\n  \"dependencies\": {\n    \"@types/mime-types\": {\n"},{"type":"text","text":"Repository: AI-Native-Dev-Community/ai-native-dev-landscape\nPath: aind-landing-Page/public/tools-data.json\nURL: https://github.com/AI-Native-Dev-Community/ai-native-dev-landscape/blob/main/aind-landing-Page/public/tools-data.json\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n, {\"name\": \"Wowslider\", \"description\": \"Generate stunning websites with AI, no-code, free!\", \"website_url\": \"https://wowslider.com/website-builder/ai-website-cloner.html\", \"icon_url\": \"https://wowslider.com/favicon.ico\", \"tags\": [\"GA\", \"Nocode\", \"Product\"], \"verified\": false, \"oss\": false, \"popular\": false, \"date"}]}
{"parentUuid":"af09c3d8-6502-45eb-8f1f-ec205886c684","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"faeb714a-61c5-410d-b669-0ebc662cf207","version":"2.0.70","gitBranch":"main","agentId":"abf8d80","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_017sJWPeh5vVAhroUifJrJcJ","type":"tool_result","content":[{"type":"text","text":"Repository: WordPress/wordcamp.org\nPath: public_html/wp-content/plugins/wordcamp-site-cloner/wordcamp-site-cloner.php\nURL: https://github.com/WordPress/wordcamp.org/blob/production/public_html/wp-content/plugins/wordcamp-site-cloner/wordcamp-site-cloner.php\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 46) ---\nfunction register_scripts() {\n\twp_register_style(\n\t\t'wordcamp-site-cloner',\n\t\tplugin_dir_url( __FILE__ ) . 'wordcamp-site-cloner.css',\n\t\tarray(),\n\t\t2\n\t);\n\n\twp_register_script(\n\t\t'wordcamp-site-cloner',\n\t\tplugin_dir_url( __FILE__ ) . 'wordcamp-site-cloner.js',\n\t\tarray( 'jquery', 'customize-controls', 'wp-backbone' ),\n\t\t2,\n\t\ttrue\n\t);\n\n\twp_localize_script(\n\t\t'wordcamp-site-cloner',\n\t\t'_wcscSettings',\n\t\tarray(\n\t\t\t'apiUrl'        => get_rest_url( null, '/wordcamp-site-cloner/v1/sites/' ),\n"},{"type":"text","text":"Repository: WordPress/wordcamp.org\nPath: public_html/wp-content/mu-plugins/wcorg-network-plugin-control.php\nURL: https://github.com/WordPress/wordcamp.org/blob/production/public_html/wp-content/mu-plugins/wcorg-network-plugin-control.php\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 50) ---\n\t\t\t'wordcamp-coming-soon-page/bootstrap.php',\n\t\t\t'wordcamp-dashboard-widgets/wordcamp-dashboard-widgets.php',\n\t\t\t'wordcamp-docs/wordcamp-docs.php',\n\t\t\t'wordcamp-forms-to-drafts/wordcamp-forms-to-drafts.php',\n\t\t\t'wordcamp-remote-css/bootstrap.php',\n\t\t\t'wordcamp-site-cloner/wordcamp-site-cloner.php',\n\t\t\t'wordcamp-speaker-feedback/wordcamp-speaker-feedback.php',\n\t\t\t'wc-fonts/wc-fonts.php',\n\t\t\t'wc-post-types/wc-post-types.php',\n\t\t\t'wordcamp-qbo-client/wordcamp-qbo-client.php',\n\t\t\t'wordpress-importer/wordpress-importer.php',\n\n\n--- Snippet 2 (Line 104) ---\n\t\t$network_plugin_state['deactivated'][] = 'wordcamp-payments/bootstrap.php';\n\t\t$network_plugin_state['deactivated'][] = 'wordcamp-payments-network/bootstrap.php';\n\t\t$network_plugin_state['deactivated'][] = 'wordcamp-docs/wordcamp-docs.php';\n\t\t$network_plugin_state['deactivated'][] = 'wordcamp-forms-to-drafts/wordcamp-forms-to-drafts.php';\n\t\t$network_plugin_state['deactivated'][] = 'wordcamp-remote-css/bootstrap.php';\n\t\t$network_plugin_state['deactivated'][] = 'wordcamp-site-cloner/wordcamp-site-cloner.php';\n\t\t$network_plugin_state['deactivated'][] = 'wordcamp-speaker-feedback/wordcamp-speaker-feedback.php';\n\t\t$network_plugin_state['deactivated'][] = 'wc-post-types/wc-post-types.php';\n\n"},{"type":"text","text":"Repository: WordPress/wordcamp.org\nPath: public_html/wp-content/plugins/wordcamp-site-cloner/includes/site-control.php\nURL: https://github.com/WordPress/wordcamp.org/blob/production/public_html/wp-content/plugins/wordcamp-site-cloner/includes/site-control.php\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 19) ---\n\t * Enqueue scripts and styles\n\t */\n\tpublic function enqueue() {\n\t\tadd_action( 'customize_controls_print_footer_scripts', array( $this, 'print_view_templates' ) );\n\n\t\twp_enqueue_style(  'wordcamp-site-cloner' );\n\t\twp_enqueue_script( 'wordcamp-site-cloner' );\n\t}\n\n\t/**\n\t * Render the control's content\n\t */\n"},{"type":"text","text":"Repository: dazzyddos/HSC24RedTeamInfra\nPath: Final_Project/modules/aws/webserver-clone/main.tf\nURL: https://github.com/dazzyddos/HSC24RedTeamInfra/blob/main/Final_Project/modules/aws/webserver-clone/main.tf\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 60) ---\n  }\n\n  provisioner \"remote-exec\" {\n    inline = [\n      \"sudo -- sh -c 'echo ${var.hostname} ${aws_instance.websiteclone-host[count.index].private_ip} >> /etc/hosts'\",\n      \"ANSIBLE_HOST_KEY_CHECKING=False ansible-playbook /home/ubuntu/ansible-playbooks/website-cloner/main.yml -i ${aws_instance.websiteclone-host[count.index].private_ip}, -e 'website_url=${var.website_url[count.index]}'\"\n    ]\n  }\n}\n\nresource \"null_resource\" \"run_ansbile_sslsetup\" {\n\n\n--- Snippet 2 (Line 85) ---\n    destination = \"/tmp/server-ssl.conf\"\n  }\n\n  provisioner \"remote-exec\" {\n    inline = [\n      \"ANSIBLE_HOST_KEY_CHECKING=False ansible-playbook /home/ubuntu/ansible-playbooks/website-cloner/ssl-setup.yml -i ${aws_instance.websiteclone-host[count.index].private_ip}, -e 'DOMAIN=${var.domain_names[count.index]}'\"\n    ]\n  }\n"},{"type":"text","text":"Repository: dazzyddos/HSC24RedTeamInfra\nPath: Final_Project/main.tf\nURL: https://github.com/dazzyddos/HSC24RedTeamInfra/blob/main/Final_Project/main.tf\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 199) ---\n#   private_key          = tls_private_key.terra_sshkey.private_key_pem\n#   bastionhostprivateip = module.redteambastion.bastion-private-ip\n#   bastionhostpublicip  = module.redteambastion.bastion-public-ip\n#   open_ports           = [443, 80]\n#   domain_names         = [\"newhireintro.com\"]\n#   ansible_playbook     =  \"./Ansilble-Playbooks/website-cloner/main.yml\"\n# }\n\n// we are creating an azure cdn with redirection rule based on the header (check the azure-ad module's main.tf for more info)\n# module \"azure-cdn\" {\n#     source              = \"./modules/azure/azure-cdn\"\n"},{"type":"text","text":"Repository: Py-Contributors/Site-Cloner\nPath: setup.py\nURL: https://github.com/Py-Contributors/Site-Cloner/blob/dev/setup.py\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 3) ---\n\nwith open(\"README.md\", \"r\") as fh:\n    long_description = fh.read()\n\nsetuptools.setup(\n    name=\"site-cloner\",\n    version=\"0.0.1\",\n    author=\"Deepak Raj\",\n    author_email=\"deepak008@live.com\",\n    description=\"Clone a website\",\n    long_description=long_description,\n    long_description_content_type=\"text/markdown\",\n    url=\"https://github.com/Py-Contributors/site-cloner\",\n    packages=setuptools.find_packages(),\n    classifiers=[\n        \"Programming Language :: Python :: 3\",\n        \"License :: OSI Approved :: MIT License\",\n        \"Operating System :: OS Independent\",\n"},{"type":"text","text":"Repository: Py-Contributors/Site-Cloner\nPath: README.md\nURL: https://github.com/Py-Contributors/Site-Cloner/blob/dev/README.md\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n<h1 align=\"center\"><a href=\"https://pypi.org/project/site-cloner/\">Site Cloner</a></h1>\n<p align=\"center\">A simple tool to clone a website</p>\n<p align=\"center\">This tool is for educational purposes only.Please follow the copyright \n    laws of your country. Our team is not responsible for any misuse.</p>\n<p align=\"center\">\n<img src=\"https://img.shields.io/pypi/v/site-cloner.svg\">\n<img src=\"https://img.shields.io/pypi/pyversions/site-cloner.svg\">\n<img src=\"https://img.shields.io/pypi/l/site-cloner.svg\">\n</p>\n<p align=\"center\">\n<img src=\"https://img.shields.io/pypi/dd/site-cloner.svg\">\n<img src=\"https://img.shields.io/pypi/dw/site-cloner.svg\">\n<img src=\"https://img.shields.io/pypi/dm/site-cloner.svg\">\n</p>\n\n## Installation\n\n```bash\npip install site-cloner\n```\n\n"},{"type":"text","text":"Repository: Py-Contributors/Site-Cloner\nPath: docs/README.md\nURL: https://github.com/Py-Contributors/Site-Cloner/blob/dev/docs/README.md\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n<h1 align=\"center\"><a href=\"https://pypi.org/project/site-cloner/\">Site Cloner</a></h1>\n<p align=\"center\">A simple tool to clone a website</p>\n<p align=\"center\">This tool is for educational purposes only.Please follow the copyright \n    laws of your country. Our team is not responsible for any misuse.</p>\n<p align=\"center\">\n<img src=\"https://img.shields.io/pypi/v/site-cloner.svg\">\n<img src=\"https://img.shields.io/pypi/pyversions/site-cloner.svg\">\n<img src=\"https://img.shields.io/pypi/l/site-cloner.svg\">\n</p>\n<p align=\"center\">\n<img src=\"https://img.shields.io/pypi/dd/site-cloner.svg\">\n<img src=\"https://img.shields.io/pypi/dw/site-cloner.svg\">\n<img src=\"https://img.shields.io/pypi/dm/site-cloner.svg\">\n</p>\n\n## Installation\n\n```bash\npip install site-cloner\n```\n\n"},{"type":"text","text":"Repository: stuttter/wp-site-cloner\nPath: wp-site-cloner.php\nURL: https://github.com/stuttter/wp-site-cloner/blob/master/wp-site-cloner.php\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n<?php\n\n/**\n * Plugin Name: WP Site Cloner\n * Plugin URI:  https://wordpress.org/plugins/wp-site-cloner/\n * Author:      John James Jacoby\n * Author URI:  https://profiles.wordpress.org/johnjamesjacoby/\n * License:     GPLv2 or later\n * License URI: https://www.gnu.org/licenses/gpl-2.0.html\n * Description: Create sites with content from other sites\n * Version:     0.1.0\n * Text Domain: wp-site-cloner\n * Domain Path: /assets/lang/\n */\n\n// Exit if accessed directly\ndefined( 'ABSPATH' ) || exit;\n"},{"type":"text","text":"Repository: X-SLAYER/Website-Cloner\nPath: README.md\nURL: https://github.com/X-SLAYER/Website-Cloner/blob/master/README.md\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 5) ---\nhtml,css,js,images ...\n\n### Downloads Linux Version:\n| Platform | Version | Link                                                                                                                         |\n| -------- | ------- | ---------------------------------------------------------------------------------------------------------------------------- |\n| Linux    | ✅   | [Download (.deb)](https://github.com/X-SLAYER/website-cloner-dart)  |\n \n # Show some ⭐ to the repo for support\n\n## Screenshots\n\n"}]}]},"uuid":"81a3ed7e-0ef8-40ff-9adb-900bfc62a4e5","timestamp":"2025-12-19T04:43:45.032Z","toolUseResult":[{"type":"text","text":"Repository: WordPress/wordcamp.org\nPath: public_html/wp-content/plugins/wordcamp-site-cloner/wordcamp-site-cloner.php\nURL: https://github.com/WordPress/wordcamp.org/blob/production/public_html/wp-content/plugins/wordcamp-site-cloner/wordcamp-site-cloner.php\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 46) ---\nfunction register_scripts() {\n\twp_register_style(\n\t\t'wordcamp-site-cloner',\n\t\tplugin_dir_url( __FILE__ ) . 'wordcamp-site-cloner.css',\n\t\tarray(),\n\t\t2\n\t);\n\n\twp_register_script(\n\t\t'wordcamp-site-cloner',\n\t\tplugin_dir_url( __FILE__ ) . 'wordcamp-site-cloner.js',\n\t\tarray( 'jquery', 'customize-controls', 'wp-backbone' ),\n\t\t2,\n\t\ttrue\n\t);\n\n\twp_localize_script(\n\t\t'wordcamp-site-cloner',\n\t\t'_wcscSettings',\n\t\tarray(\n\t\t\t'apiUrl'        => get_rest_url( null, '/wordcamp-site-cloner/v1/sites/' ),\n"},{"type":"text","text":"Repository: WordPress/wordcamp.org\nPath: public_html/wp-content/mu-plugins/wcorg-network-plugin-control.php\nURL: https://github.com/WordPress/wordcamp.org/blob/production/public_html/wp-content/mu-plugins/wcorg-network-plugin-control.php\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 50) ---\n\t\t\t'wordcamp-coming-soon-page/bootstrap.php',\n\t\t\t'wordcamp-dashboard-widgets/wordcamp-dashboard-widgets.php',\n\t\t\t'wordcamp-docs/wordcamp-docs.php',\n\t\t\t'wordcamp-forms-to-drafts/wordcamp-forms-to-drafts.php',\n\t\t\t'wordcamp-remote-css/bootstrap.php',\n\t\t\t'wordcamp-site-cloner/wordcamp-site-cloner.php',\n\t\t\t'wordcamp-speaker-feedback/wordcamp-speaker-feedback.php',\n\t\t\t'wc-fonts/wc-fonts.php',\n\t\t\t'wc-post-types/wc-post-types.php',\n\t\t\t'wordcamp-qbo-client/wordcamp-qbo-client.php',\n\t\t\t'wordpress-importer/wordpress-importer.php',\n\n\n--- Snippet 2 (Line 104) ---\n\t\t$network_plugin_state['deactivated'][] = 'wordcamp-payments/bootstrap.php';\n\t\t$network_plugin_state['deactivated'][] = 'wordcamp-payments-network/bootstrap.php';\n\t\t$network_plugin_state['deactivated'][] = 'wordcamp-docs/wordcamp-docs.php';\n\t\t$network_plugin_state['deactivated'][] = 'wordcamp-forms-to-drafts/wordcamp-forms-to-drafts.php';\n\t\t$network_plugin_state['deactivated'][] = 'wordcamp-remote-css/bootstrap.php';\n\t\t$network_plugin_state['deactivated'][] = 'wordcamp-site-cloner/wordcamp-site-cloner.php';\n\t\t$network_plugin_state['deactivated'][] = 'wordcamp-speaker-feedback/wordcamp-speaker-feedback.php';\n\t\t$network_plugin_state['deactivated'][] = 'wc-post-types/wc-post-types.php';\n\n"},{"type":"text","text":"Repository: WordPress/wordcamp.org\nPath: public_html/wp-content/plugins/wordcamp-site-cloner/includes/site-control.php\nURL: https://github.com/WordPress/wordcamp.org/blob/production/public_html/wp-content/plugins/wordcamp-site-cloner/includes/site-control.php\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 19) ---\n\t * Enqueue scripts and styles\n\t */\n\tpublic function enqueue() {\n\t\tadd_action( 'customize_controls_print_footer_scripts', array( $this, 'print_view_templates' ) );\n\n\t\twp_enqueue_style(  'wordcamp-site-cloner' );\n\t\twp_enqueue_script( 'wordcamp-site-cloner' );\n\t}\n\n\t/**\n\t * Render the control's content\n\t */\n"},{"type":"text","text":"Repository: dazzyddos/HSC24RedTeamInfra\nPath: Final_Project/modules/aws/webserver-clone/main.tf\nURL: https://github.com/dazzyddos/HSC24RedTeamInfra/blob/main/Final_Project/modules/aws/webserver-clone/main.tf\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 60) ---\n  }\n\n  provisioner \"remote-exec\" {\n    inline = [\n      \"sudo -- sh -c 'echo ${var.hostname} ${aws_instance.websiteclone-host[count.index].private_ip} >> /etc/hosts'\",\n      \"ANSIBLE_HOST_KEY_CHECKING=False ansible-playbook /home/ubuntu/ansible-playbooks/website-cloner/main.yml -i ${aws_instance.websiteclone-host[count.index].private_ip}, -e 'website_url=${var.website_url[count.index]}'\"\n    ]\n  }\n}\n\nresource \"null_resource\" \"run_ansbile_sslsetup\" {\n\n\n--- Snippet 2 (Line 85) ---\n    destination = \"/tmp/server-ssl.conf\"\n  }\n\n  provisioner \"remote-exec\" {\n    inline = [\n      \"ANSIBLE_HOST_KEY_CHECKING=False ansible-playbook /home/ubuntu/ansible-playbooks/website-cloner/ssl-setup.yml -i ${aws_instance.websiteclone-host[count.index].private_ip}, -e 'DOMAIN=${var.domain_names[count.index]}'\"\n    ]\n  }\n"},{"type":"text","text":"Repository: dazzyddos/HSC24RedTeamInfra\nPath: Final_Project/main.tf\nURL: https://github.com/dazzyddos/HSC24RedTeamInfra/blob/main/Final_Project/main.tf\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 199) ---\n#   private_key          = tls_private_key.terra_sshkey.private_key_pem\n#   bastionhostprivateip = module.redteambastion.bastion-private-ip\n#   bastionhostpublicip  = module.redteambastion.bastion-public-ip\n#   open_ports           = [443, 80]\n#   domain_names         = [\"newhireintro.com\"]\n#   ansible_playbook     =  \"./Ansilble-Playbooks/website-cloner/main.yml\"\n# }\n\n// we are creating an azure cdn with redirection rule based on the header (check the azure-ad module's main.tf for more info)\n# module \"azure-cdn\" {\n#     source              = \"./modules/azure/azure-cdn\"\n"},{"type":"text","text":"Repository: Py-Contributors/Site-Cloner\nPath: setup.py\nURL: https://github.com/Py-Contributors/Site-Cloner/blob/dev/setup.py\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 3) ---\n\nwith open(\"README.md\", \"r\") as fh:\n    long_description = fh.read()\n\nsetuptools.setup(\n    name=\"site-cloner\",\n    version=\"0.0.1\",\n    author=\"Deepak Raj\",\n    author_email=\"deepak008@live.com\",\n    description=\"Clone a website\",\n    long_description=long_description,\n    long_description_content_type=\"text/markdown\",\n    url=\"https://github.com/Py-Contributors/site-cloner\",\n    packages=setuptools.find_packages(),\n    classifiers=[\n        \"Programming Language :: Python :: 3\",\n        \"License :: OSI Approved :: MIT License\",\n        \"Operating System :: OS Independent\",\n"},{"type":"text","text":"Repository: Py-Contributors/Site-Cloner\nPath: README.md\nURL: https://github.com/Py-Contributors/Site-Cloner/blob/dev/README.md\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n<h1 align=\"center\"><a href=\"https://pypi.org/project/site-cloner/\">Site Cloner</a></h1>\n<p align=\"center\">A simple tool to clone a website</p>\n<p align=\"center\">This tool is for educational purposes only.Please follow the copyright \n    laws of your country. Our team is not responsible for any misuse.</p>\n<p align=\"center\">\n<img src=\"https://img.shields.io/pypi/v/site-cloner.svg\">\n<img src=\"https://img.shields.io/pypi/pyversions/site-cloner.svg\">\n<img src=\"https://img.shields.io/pypi/l/site-cloner.svg\">\n</p>\n<p align=\"center\">\n<img src=\"https://img.shields.io/pypi/dd/site-cloner.svg\">\n<img src=\"https://img.shields.io/pypi/dw/site-cloner.svg\">\n<img src=\"https://img.shields.io/pypi/dm/site-cloner.svg\">\n</p>\n\n## Installation\n\n```bash\npip install site-cloner\n```\n\n"},{"type":"text","text":"Repository: Py-Contributors/Site-Cloner\nPath: docs/README.md\nURL: https://github.com/Py-Contributors/Site-Cloner/blob/dev/docs/README.md\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n<h1 align=\"center\"><a href=\"https://pypi.org/project/site-cloner/\">Site Cloner</a></h1>\n<p align=\"center\">A simple tool to clone a website</p>\n<p align=\"center\">This tool is for educational purposes only.Please follow the copyright \n    laws of your country. Our team is not responsible for any misuse.</p>\n<p align=\"center\">\n<img src=\"https://img.shields.io/pypi/v/site-cloner.svg\">\n<img src=\"https://img.shields.io/pypi/pyversions/site-cloner.svg\">\n<img src=\"https://img.shields.io/pypi/l/site-cloner.svg\">\n</p>\n<p align=\"center\">\n<img src=\"https://img.shields.io/pypi/dd/site-cloner.svg\">\n<img src=\"https://img.shields.io/pypi/dw/site-cloner.svg\">\n<img src=\"https://img.shields.io/pypi/dm/site-cloner.svg\">\n</p>\n\n## Installation\n\n```bash\npip install site-cloner\n```\n\n"},{"type":"text","text":"Repository: stuttter/wp-site-cloner\nPath: wp-site-cloner.php\nURL: https://github.com/stuttter/wp-site-cloner/blob/master/wp-site-cloner.php\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n<?php\n\n/**\n * Plugin Name: WP Site Cloner\n * Plugin URI:  https://wordpress.org/plugins/wp-site-cloner/\n * Author:      John James Jacoby\n * Author URI:  https://profiles.wordpress.org/johnjamesjacoby/\n * License:     GPLv2 or later\n * License URI: https://www.gnu.org/licenses/gpl-2.0.html\n * Description: Create sites with content from other sites\n * Version:     0.1.0\n * Text Domain: wp-site-cloner\n * Domain Path: /assets/lang/\n */\n\n// Exit if accessed directly\ndefined( 'ABSPATH' ) || exit;\n"},{"type":"text","text":"Repository: X-SLAYER/Website-Cloner\nPath: README.md\nURL: https://github.com/X-SLAYER/Website-Cloner/blob/master/README.md\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 5) ---\nhtml,css,js,images ...\n\n### Downloads Linux Version:\n| Platform | Version | Link                                                                                                                         |\n| -------- | ------- | ---------------------------------------------------------------------------------------------------------------------------- |\n| Linux    | ✅   | [Download (.deb)](https://github.com/X-SLAYER/website-cloner-dart)  |\n \n # Show some ⭐ to the repo for support\n\n## Screenshots\n\n"}]}
{"parentUuid":"81a3ed7e-0ef8-40ff-9adb-900bfc62a4e5","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"faeb714a-61c5-410d-b669-0ebc662cf207","version":"2.0.70","gitBranch":"main","agentId":"abf8d80","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01VFy62J6hHviscmET6d2Rmm","type":"tool_result","content":[{"type":"text","text":"Repository: devlikeapro/waha\nPath: src/core/engines/webjs/WebjsClientCore.ts\nURL: https://github.com/devlikeapro/waha/blob/core/src/core/engines/webjs/WebjsClientCore.ts\nLicense: Apache-2.0\n\nSnippets:\n--- Snippet 1 (Line 1) ---\nimport { exposeFunctionIfAbsent } from '@waha/core/engines/webjs/Puppeteer';\nimport { WebJSPresence } from '@waha/core/engines/webjs/types';\nimport { GetChatMessagesFilter } from '@waha/structures/chats.dto';\nimport { Label } from '@waha/structures/labels.dto';\nimport { LidToPhoneNumber } from '@waha/structures/lids.dto';\nimport { PaginationParams } from '@waha/structures/pagination.dto';\nimport { TextStatus } from '@waha/structures/status.dto';\nimport { sleep } from '@waha/utils/promiseTimeout';\nimport { EventEmitter } from 'events';\nimport * as lodash from 'lodash';\nimport { Page } from 'puppeteer';\nimport { Client, Events } from 'whatsapp-web.js';\nimport { Message } from 'whatsapp-web.js/src/structures';\n\nimport { CallErrorEvent, PAGE_CALL_ERROR_EVENT, WPage } from './WPage';\n\n// eslint-disable-next-line @typescript-eslint/no-var-requires\nconst { LoadWAHA } = require('./_WAHA.js');\n\n// eslint-disable-next-line @typescript-eslint/no-var-requires\nconst { LoadLodash } = require('./_lodash.js');\n"},{"type":"text","text":"Repository: codigoencasa/builderbot\nPath: packages/provider-wppconnect/src/index.ts\nURL: https://github.com/codigoencasa/builderbot/blob/builderbot/packages/provider-wppconnect/src/index.ts\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 60) ---\n                puppeteerOptions: {\n                    headless: true,\n                    args: ['--no-sandbox'],\n                },\n                ...this.globalVendorArgs,\n                folderNameToken: NAME_DIR_SESSION,\n            })\n            this.vendor = createInstance\n            const hostDevice = await createInstance.getWid()\n            const parseNumber = `${hostDevice}`.split('@').shift()\n            const host = { phone: parseNumber }\n            this.emit('ready', true)\n            this.emit('host', host)\n\n            return createInstance\n        } catch (error) {\n            this.emit('auth_failure', {\n                instructions: [`An error occurred during WPP initialization`, `trying again in 5 seconds...`],\n            })\n            WppDeleteTokens(NAME_DIR_SESSION)\n            setTimeout(async () => {\n"},{"type":"text","text":"Repository: FlowiseAI/Flowise\nPath: packages/components/src/utils.ts\nURL: https://github.com/FlowiseAI/Flowise/blob/main/packages/components/src/utils.ts\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 115) ---\n    'puppeteer',\n    'redis',\n    'replicate',\n    'srt-parser-2',\n    'typeorm',\n    'weaviate-ts-client'\n]\n\nconst defaultAllowExternalDependencies = ['axios', 'moment', 'node-fetch']\n\nexport const defaultAllowBuiltInDep = [\n    'assert',\n    'buffer',\n    'crypto',\n    'events',\n    'http',\n    'https',\n    'net',\n    'path',\n    'querystring',\n    'timers',\n"},{"type":"text","text":"Repository: devlikeapro/waha\nPath: src/core/abc/session.abc.ts\nURL: https://github.com/devlikeapro/waha/blob/core/src/core/abc/session.abc.ts\nLicense: Apache-2.0\n\nSnippets:\n--- Snippet 1 (Line 366) ---\n  getBrowserArgsForPuppeteer() {\n    // Run optimized version of Chrome\n    // References:\n    // https://github.com/pedroslopez/whatsapp-web.js/issues/1420\n    // https://github.com/wppconnect-team/wppconnect/issues/1326\n    // https://superuser.com/questions/654565/how-to-run-google-chrome-in-a-single-process\n    // https://www.bannerbear.com/blog/ways-to-speed-up-puppeteer-screenshots/\n    return [\n      '--disable-accelerated-2d-canvas',\n      '--disable-application-cache',\n      // DO NOT disable software rasterizer, it will break the video\n      // https://github.com/devlikeapro/waha/issues/629\n      // '--disable-software-rasterizer',\n      '--disable-client-side-phishing-detection',\n      '--disable-component-update',\n      '--disable-default-apps',\n      '--disable-dev-shm-usage',\n      '--disable-extensions',\n      // '--disable-features=site-per-process', // COMMENTED to test WEBJS stability\n      '--disable-gpu', // COMMENTED to test WEBJS stability\n      '--disable-offer-store-unmasked-wallet-cards',\n"},{"type":"text","text":"Repository: cloudflare/cloudflare-go\nPath: browser_rendering/snapshot.go\nURL: https://github.com/cloudflare/cloudflare-go/blob/main/browser_rendering/snapshot.go\nLicense: Apache-2.0\n\nSnippets:\n--- Snippet 1 (Line 106) ---\n\t// Check [options](https://pptr.dev/api/puppeteer.page.setcookie).\n\tCookies          param.Field[[]SnapshotNewParamsCookie] `json:\"cookies\"`\n\tEmulateMediaType param.Field[string]                    `json:\"emulateMediaType\"`\n\t// Check [options](https://pptr.dev/api/puppeteer.gotooptions).\n\tGotoOptions param.Field[SnapshotNewParamsGotoOptions] `json:\"gotoOptions\"`\n\t// Set the content of the page, eg: `<h1>Hello World!!</h1>`. Either `html` or\n\t// `url` must be set.\n\tHTML param.Field[string] `json:\"html\"`\n\t// Block undesired requests that match the provided regex patterns, eg.\n\t// '/^.\\*\\.(css)'.\n\tRejectRequestPattern param.Field[[]string] `json:\"rejectRequestPattern\"`\n\t// Block undesired requests that match the provided resource types, eg. 'image' or\n\t// 'script'.\n\tRejectResourceTypes  param.Field[[]SnapshotNewParamsRejectResourceType] `json:\"rejectResourceTypes\"`\n\tScreenshotOptions    param.Field[SnapshotNewParamsScreenshotOptions]    `json:\"screenshotOptions\"`\n\tSetExtraHTTPHeaders  param.Field[map[string]string]                     `json:\"setExtraHTTPHeaders\"`\n\tSetJavaScriptEnabled param.Field[bool]                                  `json:\"setJavaScriptEnabled\"`\n\t// URL to navigate to, eg. `https://example.com`.\n\tURL       param.Field[string] `json:\"url\" format:\"uri\"`\n\tUserAgent param.Field[string] `json:\"userAgent\"`\n\t// Check [options](https://pptr.dev/api/puppeteer.page.setviewport).\n"},{"type":"text","text":"Repository: sindresorhus/capture-website\nPath: index.js\nURL: https://github.com/sindresorhus/capture-website/blob/main/index.js\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 8) ---\nimport puppeteer, {KnownDevices} from 'puppeteer';\nimport * as toughCookie from 'tough-cookie';\nimport {PuppeteerBlocker} from '@ghostery/adblocker-puppeteer';\n\nconst isUrl = string => /^(https?|file):\\/\\/|^data:/.test(string);\n\nconst assert = (value, message) => {\n\tif (!value) {\n\t\tthrow new Error(message);\n\t}\n};\n\nconst validateOptions = options => {\n\tassert(!(options.clip && options.element), 'The `clip` and `element` option are mutually exclusive');\n\tassert(!(options.clip && options.fullPage), 'The `clip` and `fullPage` option are mutually exclusive');\n\tassert(!(options.type === 'pdf' && options.clip), 'The `clip` option is not supported when type is `pdf`');\n\tassert(!(options.type === 'pdf' && options.element), 'The `element` option is not supported when type is `pdf`');\n\tassert(!(options.type === 'pdf' && options.quality), 'The `quality` option is not supported when type is `pdf`');\n};\n\nconst scrollToElement = (element, options) => {\n"},{"type":"text","text":"Repository: platonai/Browser4\nPath: pulsar-core/pulsar-tools/pulsar-browser/src/main/kotlin/ai/platon/pulsar/browser/driver/chrome/impl/ChromeDevToolsImpl.kt\nURL: https://github.com/platonai/Browser4/blob/master/pulsar-core/pulsar-tools/pulsar-browser/src/main/kotlin/ai/platon/pulsar/browser/driver/chrome/impl/ChromeDevToolsImpl.kt\nLicense: Apache-2.0\n\nSnippets:\n--- Snippet 1 (Line 198) ---\n     * Send the message to the server and return immediately\n     * */\n    private suspend fun sendToBrowser(method: String, message: String) {\n        // See https://github.com/hardkoded/puppeteer-sharp/issues/796 to understand why we need handle Target methods\n        // differently.\n        if (method.startsWith(\"Target.\")) {\n            browserTransport.send(message)\n        } else {\n            pageTransport.send(message)\n        }\n    }\n\n    @Throws(ChromeRPCException::class, IOException::class)\n    private fun handleFailedFurther(result: RpcResult): CDPReturnError {\n        return handleFailedFurther(result.result)\n    }\n\n    @Throws(ChromeRPCException::class, IOException::class)\n    private fun handleFailedFurther(error: JsonNode?): CDPReturnError {\n        // Received an error\n        val error = dispatcher.deserialize(ErrorObject::class.java, error)\n"},{"type":"text","text":"Repository: adriancooney/puppeteer-heap-snapshot\nPath: src/capture.ts\nURL: https://github.com/adriancooney/puppeteer-heap-snapshot/blob/master/src/capture.ts\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 1) ---\nimport { Target } from \"puppeteer\";\nimport { deserializeHeapSnapshot } from \"./serialize\";\nimport { HeapSnapshot, SerializedHeapSnapshot } from \"./types\";\nimport { debug } from \"./util\";\n\nconst HEAP_SNAPSHOT_TIMEOUT = 30000;\n\nexport async function captureHeapSnapshot(\n  target: Target\n): Promise<HeapSnapshot> {\n  const cdpSession = await target.createCDPSession();\n  const cdpSessionConnection = cdpSession.connection()!;\n\n  debug(\"taking heap snapshot\");\n\n  return await new Promise((_resolve, _reject) => {\n    let heapSnapshotSize = 0;\n    let heapSnapshotResolved = false;\n    let heapSnapshotTimeout: ReturnType<typeof setTimeout> | null = null;\n    const heapSnapshotChunks: string[] = [];\n\n"},{"type":"text","text":"Repository: hkbus/hk-independent-bus-eta\nPath: scripts/pre-rendering.js\nURL: https://github.com/hkbus/hk-independent-bus-eta/blob/master/scripts/pre-rendering.js\nLicense: GPL-3.0\n\nSnippets:\n--- Snippet 1 (Line 4) ---\nimport puppeteer from \"puppeteer\";\nimport jsdom from \"jsdom\";\nimport CleanCSS from \"clean-css\";\nimport dotenv from \"dotenv\";\n\ndotenv.config();\n\nconst cleanCss = new CleanCSS();\nlet app;\n\n/**\n * @returns {object}\n */\nasync function readOptionsFromFile() {\n  try {\n    const config = await fs.readFileSync(\"./.rsp.json\");\n    const options = JSON.parse(config.toString());\n    return options;\n  } catch (err) {\n    throw new Error(\n      `Error: Failed to read options from '.rsp.json'.\\nMessage: ${err}`\n"},{"type":"text","text":"Repository: microsoft/TypeAgent\nPath: ts/examples/websiteAliases/src/searchEngineKeywords.ts\nURL: https://github.com/microsoft/TypeAgent/blob/main/ts/examples/websiteAliases/src/searchEngineKeywords.ts\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 7) ---\nimport puppeteer, { TimeoutError } from \"puppeteer\";\nimport chalk from \"chalk\";\nimport { urlResolver } from \"azure-ai-foundry\";\nimport {\n    closeChrome,\n    getRandomDelay,\n    keywordSiteMapFile,\n    resolvedKeyWordFile,\n} from \"./common.js\";\nimport { AIProjectClient } from \"@azure/ai-projects\";\n\nexport class searchKeywordExtractor {\n    project: AIProjectClient;\n    groundingConfig: bingWithGrounding.ApiSettings;\n\n    constructor(\n        project: AIProjectClient,\n        groundingConfig: bingWithGrounding.ApiSettings,\n    ) {\n        this.project = project;\n        this.groundingConfig = groundingConfig;\n"}]}]},"uuid":"0d56cf5e-1495-4c22-a367-d20f9a1920b5","timestamp":"2025-12-19T04:43:45.924Z","toolUseResult":[{"type":"text","text":"Repository: devlikeapro/waha\nPath: src/core/engines/webjs/WebjsClientCore.ts\nURL: https://github.com/devlikeapro/waha/blob/core/src/core/engines/webjs/WebjsClientCore.ts\nLicense: Apache-2.0\n\nSnippets:\n--- Snippet 1 (Line 1) ---\nimport { exposeFunctionIfAbsent } from '@waha/core/engines/webjs/Puppeteer';\nimport { WebJSPresence } from '@waha/core/engines/webjs/types';\nimport { GetChatMessagesFilter } from '@waha/structures/chats.dto';\nimport { Label } from '@waha/structures/labels.dto';\nimport { LidToPhoneNumber } from '@waha/structures/lids.dto';\nimport { PaginationParams } from '@waha/structures/pagination.dto';\nimport { TextStatus } from '@waha/structures/status.dto';\nimport { sleep } from '@waha/utils/promiseTimeout';\nimport { EventEmitter } from 'events';\nimport * as lodash from 'lodash';\nimport { Page } from 'puppeteer';\nimport { Client, Events } from 'whatsapp-web.js';\nimport { Message } from 'whatsapp-web.js/src/structures';\n\nimport { CallErrorEvent, PAGE_CALL_ERROR_EVENT, WPage } from './WPage';\n\n// eslint-disable-next-line @typescript-eslint/no-var-requires\nconst { LoadWAHA } = require('./_WAHA.js');\n\n// eslint-disable-next-line @typescript-eslint/no-var-requires\nconst { LoadLodash } = require('./_lodash.js');\n"},{"type":"text","text":"Repository: codigoencasa/builderbot\nPath: packages/provider-wppconnect/src/index.ts\nURL: https://github.com/codigoencasa/builderbot/blob/builderbot/packages/provider-wppconnect/src/index.ts\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 60) ---\n                puppeteerOptions: {\n                    headless: true,\n                    args: ['--no-sandbox'],\n                },\n                ...this.globalVendorArgs,\n                folderNameToken: NAME_DIR_SESSION,\n            })\n            this.vendor = createInstance\n            const hostDevice = await createInstance.getWid()\n            const parseNumber = `${hostDevice}`.split('@').shift()\n            const host = { phone: parseNumber }\n            this.emit('ready', true)\n            this.emit('host', host)\n\n            return createInstance\n        } catch (error) {\n            this.emit('auth_failure', {\n                instructions: [`An error occurred during WPP initialization`, `trying again in 5 seconds...`],\n            })\n            WppDeleteTokens(NAME_DIR_SESSION)\n            setTimeout(async () => {\n"},{"type":"text","text":"Repository: FlowiseAI/Flowise\nPath: packages/components/src/utils.ts\nURL: https://github.com/FlowiseAI/Flowise/blob/main/packages/components/src/utils.ts\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 115) ---\n    'puppeteer',\n    'redis',\n    'replicate',\n    'srt-parser-2',\n    'typeorm',\n    'weaviate-ts-client'\n]\n\nconst defaultAllowExternalDependencies = ['axios', 'moment', 'node-fetch']\n\nexport const defaultAllowBuiltInDep = [\n    'assert',\n    'buffer',\n    'crypto',\n    'events',\n    'http',\n    'https',\n    'net',\n    'path',\n    'querystring',\n    'timers',\n"},{"type":"text","text":"Repository: devlikeapro/waha\nPath: src/core/abc/session.abc.ts\nURL: https://github.com/devlikeapro/waha/blob/core/src/core/abc/session.abc.ts\nLicense: Apache-2.0\n\nSnippets:\n--- Snippet 1 (Line 366) ---\n  getBrowserArgsForPuppeteer() {\n    // Run optimized version of Chrome\n    // References:\n    // https://github.com/pedroslopez/whatsapp-web.js/issues/1420\n    // https://github.com/wppconnect-team/wppconnect/issues/1326\n    // https://superuser.com/questions/654565/how-to-run-google-chrome-in-a-single-process\n    // https://www.bannerbear.com/blog/ways-to-speed-up-puppeteer-screenshots/\n    return [\n      '--disable-accelerated-2d-canvas',\n      '--disable-application-cache',\n      // DO NOT disable software rasterizer, it will break the video\n      // https://github.com/devlikeapro/waha/issues/629\n      // '--disable-software-rasterizer',\n      '--disable-client-side-phishing-detection',\n      '--disable-component-update',\n      '--disable-default-apps',\n      '--disable-dev-shm-usage',\n      '--disable-extensions',\n      // '--disable-features=site-per-process', // COMMENTED to test WEBJS stability\n      '--disable-gpu', // COMMENTED to test WEBJS stability\n      '--disable-offer-store-unmasked-wallet-cards',\n"},{"type":"text","text":"Repository: cloudflare/cloudflare-go\nPath: browser_rendering/snapshot.go\nURL: https://github.com/cloudflare/cloudflare-go/blob/main/browser_rendering/snapshot.go\nLicense: Apache-2.0\n\nSnippets:\n--- Snippet 1 (Line 106) ---\n\t// Check [options](https://pptr.dev/api/puppeteer.page.setcookie).\n\tCookies          param.Field[[]SnapshotNewParamsCookie] `json:\"cookies\"`\n\tEmulateMediaType param.Field[string]                    `json:\"emulateMediaType\"`\n\t// Check [options](https://pptr.dev/api/puppeteer.gotooptions).\n\tGotoOptions param.Field[SnapshotNewParamsGotoOptions] `json:\"gotoOptions\"`\n\t// Set the content of the page, eg: `<h1>Hello World!!</h1>`. Either `html` or\n\t// `url` must be set.\n\tHTML param.Field[string] `json:\"html\"`\n\t// Block undesired requests that match the provided regex patterns, eg.\n\t// '/^.\\*\\.(css)'.\n\tRejectRequestPattern param.Field[[]string] `json:\"rejectRequestPattern\"`\n\t// Block undesired requests that match the provided resource types, eg. 'image' or\n\t// 'script'.\n\tRejectResourceTypes  param.Field[[]SnapshotNewParamsRejectResourceType] `json:\"rejectResourceTypes\"`\n\tScreenshotOptions    param.Field[SnapshotNewParamsScreenshotOptions]    `json:\"screenshotOptions\"`\n\tSetExtraHTTPHeaders  param.Field[map[string]string]                     `json:\"setExtraHTTPHeaders\"`\n\tSetJavaScriptEnabled param.Field[bool]                                  `json:\"setJavaScriptEnabled\"`\n\t// URL to navigate to, eg. `https://example.com`.\n\tURL       param.Field[string] `json:\"url\" format:\"uri\"`\n\tUserAgent param.Field[string] `json:\"userAgent\"`\n\t// Check [options](https://pptr.dev/api/puppeteer.page.setviewport).\n"},{"type":"text","text":"Repository: sindresorhus/capture-website\nPath: index.js\nURL: https://github.com/sindresorhus/capture-website/blob/main/index.js\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 8) ---\nimport puppeteer, {KnownDevices} from 'puppeteer';\nimport * as toughCookie from 'tough-cookie';\nimport {PuppeteerBlocker} from '@ghostery/adblocker-puppeteer';\n\nconst isUrl = string => /^(https?|file):\\/\\/|^data:/.test(string);\n\nconst assert = (value, message) => {\n\tif (!value) {\n\t\tthrow new Error(message);\n\t}\n};\n\nconst validateOptions = options => {\n\tassert(!(options.clip && options.element), 'The `clip` and `element` option are mutually exclusive');\n\tassert(!(options.clip && options.fullPage), 'The `clip` and `fullPage` option are mutually exclusive');\n\tassert(!(options.type === 'pdf' && options.clip), 'The `clip` option is not supported when type is `pdf`');\n\tassert(!(options.type === 'pdf' && options.element), 'The `element` option is not supported when type is `pdf`');\n\tassert(!(options.type === 'pdf' && options.quality), 'The `quality` option is not supported when type is `pdf`');\n};\n\nconst scrollToElement = (element, options) => {\n"},{"type":"text","text":"Repository: platonai/Browser4\nPath: pulsar-core/pulsar-tools/pulsar-browser/src/main/kotlin/ai/platon/pulsar/browser/driver/chrome/impl/ChromeDevToolsImpl.kt\nURL: https://github.com/platonai/Browser4/blob/master/pulsar-core/pulsar-tools/pulsar-browser/src/main/kotlin/ai/platon/pulsar/browser/driver/chrome/impl/ChromeDevToolsImpl.kt\nLicense: Apache-2.0\n\nSnippets:\n--- Snippet 1 (Line 198) ---\n     * Send the message to the server and return immediately\n     * */\n    private suspend fun sendToBrowser(method: String, message: String) {\n        // See https://github.com/hardkoded/puppeteer-sharp/issues/796 to understand why we need handle Target methods\n        // differently.\n        if (method.startsWith(\"Target.\")) {\n            browserTransport.send(message)\n        } else {\n            pageTransport.send(message)\n        }\n    }\n\n    @Throws(ChromeRPCException::class, IOException::class)\n    private fun handleFailedFurther(result: RpcResult): CDPReturnError {\n        return handleFailedFurther(result.result)\n    }\n\n    @Throws(ChromeRPCException::class, IOException::class)\n    private fun handleFailedFurther(error: JsonNode?): CDPReturnError {\n        // Received an error\n        val error = dispatcher.deserialize(ErrorObject::class.java, error)\n"},{"type":"text","text":"Repository: adriancooney/puppeteer-heap-snapshot\nPath: src/capture.ts\nURL: https://github.com/adriancooney/puppeteer-heap-snapshot/blob/master/src/capture.ts\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 1) ---\nimport { Target } from \"puppeteer\";\nimport { deserializeHeapSnapshot } from \"./serialize\";\nimport { HeapSnapshot, SerializedHeapSnapshot } from \"./types\";\nimport { debug } from \"./util\";\n\nconst HEAP_SNAPSHOT_TIMEOUT = 30000;\n\nexport async function captureHeapSnapshot(\n  target: Target\n): Promise<HeapSnapshot> {\n  const cdpSession = await target.createCDPSession();\n  const cdpSessionConnection = cdpSession.connection()!;\n\n  debug(\"taking heap snapshot\");\n\n  return await new Promise((_resolve, _reject) => {\n    let heapSnapshotSize = 0;\n    let heapSnapshotResolved = false;\n    let heapSnapshotTimeout: ReturnType<typeof setTimeout> | null = null;\n    const heapSnapshotChunks: string[] = [];\n\n"},{"type":"text","text":"Repository: hkbus/hk-independent-bus-eta\nPath: scripts/pre-rendering.js\nURL: https://github.com/hkbus/hk-independent-bus-eta/blob/master/scripts/pre-rendering.js\nLicense: GPL-3.0\n\nSnippets:\n--- Snippet 1 (Line 4) ---\nimport puppeteer from \"puppeteer\";\nimport jsdom from \"jsdom\";\nimport CleanCSS from \"clean-css\";\nimport dotenv from \"dotenv\";\n\ndotenv.config();\n\nconst cleanCss = new CleanCSS();\nlet app;\n\n/**\n * @returns {object}\n */\nasync function readOptionsFromFile() {\n  try {\n    const config = await fs.readFileSync(\"./.rsp.json\");\n    const options = JSON.parse(config.toString());\n    return options;\n  } catch (err) {\n    throw new Error(\n      `Error: Failed to read options from '.rsp.json'.\\nMessage: ${err}`\n"},{"type":"text","text":"Repository: microsoft/TypeAgent\nPath: ts/examples/websiteAliases/src/searchEngineKeywords.ts\nURL: https://github.com/microsoft/TypeAgent/blob/main/ts/examples/websiteAliases/src/searchEngineKeywords.ts\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 7) ---\nimport puppeteer, { TimeoutError } from \"puppeteer\";\nimport chalk from \"chalk\";\nimport { urlResolver } from \"azure-ai-foundry\";\nimport {\n    closeChrome,\n    getRandomDelay,\n    keywordSiteMapFile,\n    resolvedKeyWordFile,\n} from \"./common.js\";\nimport { AIProjectClient } from \"@azure/ai-projects\";\n\nexport class searchKeywordExtractor {\n    project: AIProjectClient;\n    groundingConfig: bingWithGrounding.ApiSettings;\n\n    constructor(\n        project: AIProjectClient,\n        groundingConfig: bingWithGrounding.ApiSettings,\n    ) {\n        this.project = project;\n        this.groundingConfig = groundingConfig;\n"}]}
{"parentUuid":"0d56cf5e-1495-4c22-a367-d20f9a1920b5","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"faeb714a-61c5-410d-b669-0ebc662cf207","version":"2.0.70","gitBranch":"main","agentId":"abf8d80","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_0151u68ni1ZqouNkci7FX1fu","type":"tool_result","content":[{"type":"text","text":"Repository: flutter/flutter\nPath: engine/src/flutter/lib/web_ui/lib/src/engine/dom.dart\nURL: https://github.com/flutter/flutter/blob/master/engine/src/flutter/lib/web_ui/lib/src/engine/dom.dart\nLicense: BSD-3-Clause\n\nSnippets:\n--- Snippet 1 (Line 264) ---\n    } else {\n      return _createElement(name, options.toJSAnyDeep);\n    }\n  }\n\n  external DomHTMLScriptElement? get currentScript;\n  external DomElement createElementNS(String namespaceURI, String qualifiedName);\n  external DomText createTextNode(String data);\n  external DomEvent createEvent(String eventType);\n  external DomElement? get activeElement;\n  external DomElement? elementFromPoint(int x, int y);\n}\n\n@JS('HTMLDocument')\nextension type DomHTMLDocument._(JSObject _) implements DomDocument {\n  external DomFontFaceSet? get fonts;\n  external DomHTMLHeadElement? get head;\n  external DomHTMLBodyElement? get body;\n  external String? title;\n\n  @JS('getElementsByTagName')\n"},{"type":"text","text":"Repository: flutter/flutter\nPath: engine/src/flutter/lib/web_ui/lib/src/engine/text_editing/text_editing.dart\nURL: https://github.com/flutter/flutter/blob/master/engine/src/flutter/lib/web_ui/lib/src/engine/text_editing/text_editing.dart\nLicense: BSD-3-Clause\n\nSnippets:\n--- Snippet 1 (Line 53) ---\n\n/// These style attributes are constant throughout the life time of an input\n/// element.\n///\n/// They are assigned once during the creation of the DOM element.\nvoid _setStaticStyleAttributes(DomHTMLElement domElement) {\n  domElement.classList.add(HybridTextEditing.textEditingClass);\n\n  final DomCSSStyleDeclaration elementStyle = domElement.style;\n  elementStyle\n    // Prevent (forced-colors: active) from making our invisible text fields visible.\n\n\n--- Snippet 2 (Line 97) ---\n/// These style attributes are constant throughout the life time of an input\n/// element.\n///\n/// They are assigned once during the creation of the DOM element.\nvoid _styleAutofillElements(\n  DomHTMLElement domElement, {\n  bool isOffScreen = false,\n  bool shouldHideElement = true,\n  bool shouldDisablePointerEvents = false,\n"},{"type":"text","text":"Repository: ClickHouse/ClickHouse\nPath: tests/queries/0_stateless/01746_extract_text_from_html.sql\nURL: https://github.com/ClickHouse/ClickHouse/blob/master/tests/queries/0_stateless/01746_extract_text_from_html.sql\nLicense: Apache-2.0\n\nSnippets:\n--- Snippet 1 (Line 2) ---\n\nSELECT extractTextFromHTML('');\nSELECT extractTextFromHTML(' ');\nSELECT extractTextFromHTML('  ');\nSELECT extractTextFromHTML('Hello');\nSELECT extractTextFromHTML('Hello, world');\nSELECT extractTextFromHTML('Hello,  world');\nSELECT extractTextFromHTML(' Hello,  world');\nSELECT extractTextFromHTML(' Hello,  world ');\nSELECT extractTextFromHTML(' \\t Hello,\\rworld \\n ');\n\nSELECT extractTextFromHTML('Hello<world');\nSELECT extractTextFromHTML('Hello < world');\nSELECT extractTextFromHTML('Hello > world');\nSELECT extractTextFromHTML('Hello<world>');\nSELECT extractTextFromHTML('Hello<>world');\nSELECT extractTextFromHTML('Hello<!>world');\nSELECT extractTextFromHTML('Hello<!->world');\nSELECT extractTextFromHTML('Hello<!-->world');\nSELECT extractTextFromHTML('Hello<!--->world');\nSELECT extractTextFromHTML('Hello<!---->world');\n"},{"type":"text","text":"Repository: ValveSoftware/Proton\nPath: lsteamclient/winISteamHTMLSurface.c\nURL: https://github.com/ValveSoftware/Proton/blob/proton_10.0/lsteamclient/winISteamHTMLSurface.c\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 6) ---\nDEFINE_THISCALL_WRAPPER(winISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_destructor, 4)\nDEFINE_THISCALL_WRAPPER(winISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_Init, 4)\nDEFINE_THISCALL_WRAPPER(winISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_Shutdown, 4)\nDEFINE_THISCALL_WRAPPER(winISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_CreateBrowser, 12)\nDEFINE_THISCALL_WRAPPER(winISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_RemoveBrowser, 8)\nDEFINE_THISCALL_WRAPPER(winISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_LoadURL, 16)\nDEFINE_THISCALL_WRAPPER(winISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_SetSize, 16)\nDEFINE_THISCALL_WRAPPER(winISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_StopLoad, 8)\nDEFINE_THISCALL_WRAPPER(winISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_Reload, 8)\nDEFINE_THISCALL_WRAPPER(winISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_GoBack, 8)\nDEFINE_THISCALL_WRAPPER(winISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_GoForward, 8)\nDEFINE_THISCALL_WRAPPER(winISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_AddHeader, 16)\nDEFINE_THISCALL_WRAPPER(winISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_ExecuteJavascript, 12)\nDEFINE_THISCALL_WRAPPER(winISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_MouseUp, 12)\nDEFINE_THISCALL_WRAPPER(winISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_MouseDown, 12)\nDEFINE_THISCALL_WRAPPER(winISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_MouseDoubleClick, 12)\nDEFINE_THISCALL_WRAPPER(winISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_MouseMove, 16)\nDEFINE_THISCALL_WRAPPER(winISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_MouseWheel, 12)\nDEFINE_THISCALL_WRAPPER(winISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_KeyDown, 16)\nDEFINE_THISCALL_WRAPPER(winISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_KeyUp, 16)\nDEFINE_THISCALL_WRAPPER(winISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_KeyChar, 16)\n"},{"type":"text","text":"Repository: ValveSoftware/Proton\nPath: lsteamclient/cppISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_005.cpp\nURL: https://github.com/ValveSoftware/Proton/blob/proton_10.0/lsteamclient/cppISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_005.cpp\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 8) ---\nNTSTATUS ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_005_Init( void *args )\n{\n    struct ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_005_Init_params *params = (struct ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_005_Init_params *)args;\n    struct u_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_005 *iface = (struct u_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_005 *)params->u_iface;\n    params->_ret = iface->Init(  );\n    return 0;\n}\n\n#if defined(__x86_64__) || defined(__aarch64__)\nNTSTATUS wow64_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_005_Init( void *args )\n{\n    struct wow64_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_005_Init_params *params = (struct wow64_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_005_Init_params *)args;\n    struct u_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_005 *iface = (struct u_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_005 *)params->u_iface;\n    params->_ret = iface->Init(  );\n    return 0;\n}\n#endif\n\nNTSTATUS ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_005_Shutdown( void *args )\n{\n    struct ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_005_Shutdown_params *params = (struct ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_005_Shutdown_params *)args;\n"},{"type":"text","text":"Repository: ValveSoftware/Proton\nPath: lsteamclient/cppISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_004.cpp\nURL: https://github.com/ValveSoftware/Proton/blob/proton_10.0/lsteamclient/cppISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_004.cpp\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 8) ---\nNTSTATUS ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_004_Init( void *args )\n{\n    struct ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_004_Init_params *params = (struct ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_004_Init_params *)args;\n    struct u_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_004 *iface = (struct u_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_004 *)params->u_iface;\n    params->_ret = iface->Init(  );\n    return 0;\n}\n\n#if defined(__x86_64__) || defined(__aarch64__)\nNTSTATUS wow64_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_004_Init( void *args )\n{\n    struct wow64_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_004_Init_params *params = (struct wow64_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_004_Init_params *)args;\n    struct u_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_004 *iface = (struct u_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_004 *)params->u_iface;\n    params->_ret = iface->Init(  );\n    return 0;\n}\n#endif\n\nNTSTATUS ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_004_Shutdown( void *args )\n{\n    struct ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_004_Shutdown_params *params = (struct ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_004_Shutdown_params *)args;\n"},{"type":"text","text":"Repository: ValveSoftware/Proton\nPath: lsteamclient/cppISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_002.cpp\nURL: https://github.com/ValveSoftware/Proton/blob/proton_10.0/lsteamclient/cppISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_002.cpp\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 8) ---\nNTSTATUS ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_002_Init( void *args )\n{\n    struct ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_002_Init_params *params = (struct ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_002_Init_params *)args;\n    struct u_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_002 *iface = (struct u_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_002 *)params->u_iface;\n    params->_ret = iface->Init(  );\n    return 0;\n}\n\n#if defined(__x86_64__) || defined(__aarch64__)\nNTSTATUS wow64_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_002_Init( void *args )\n{\n    struct wow64_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_002_Init_params *params = (struct wow64_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_002_Init_params *)args;\n    struct u_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_002 *iface = (struct u_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_002 *)params->u_iface;\n    params->_ret = iface->Init(  );\n    return 0;\n}\n#endif\n\nNTSTATUS ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_002_Shutdown( void *args )\n{\n    struct ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_002_Shutdown_params *params = (struct ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_002_Shutdown_params *)args;\n"},{"type":"text","text":"Repository: ValveSoftware/Proton\nPath: lsteamclient/cppISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_003.cpp\nURL: https://github.com/ValveSoftware/Proton/blob/proton_10.0/lsteamclient/cppISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_003.cpp\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 8) ---\nNTSTATUS ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_003_Init( void *args )\n{\n    struct ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_003_Init_params *params = (struct ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_003_Init_params *)args;\n    struct u_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_003 *iface = (struct u_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_003 *)params->u_iface;\n    params->_ret = iface->Init(  );\n    return 0;\n}\n\n#if defined(__x86_64__) || defined(__aarch64__)\nNTSTATUS wow64_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_003_Init( void *args )\n{\n    struct wow64_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_003_Init_params *params = (struct wow64_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_003_Init_params *)args;\n    struct u_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_003 *iface = (struct u_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_003 *)params->u_iface;\n    params->_ret = iface->Init(  );\n    return 0;\n}\n#endif\n\nNTSTATUS ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_003_Shutdown( void *args )\n{\n    struct ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_003_Shutdown_params *params = (struct ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_003_Shutdown_params *)args;\n"},{"type":"text","text":"Repository: ValveSoftware/Proton\nPath: lsteamclient/cppISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001.cpp\nURL: https://github.com/ValveSoftware/Proton/blob/proton_10.0/lsteamclient/cppISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001.cpp\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 8) ---\nNTSTATUS ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_Init( void *args )\n{\n    struct ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_Init_params *params = (struct ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_Init_params *)args;\n    struct u_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001 *iface = (struct u_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001 *)params->u_iface;\n    params->_ret = iface->Init(  );\n    return 0;\n}\n\n#if defined(__x86_64__) || defined(__aarch64__)\nNTSTATUS wow64_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_Init( void *args )\n{\n    struct wow64_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_Init_params *params = (struct wow64_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_Init_params *)args;\n    struct u_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001 *iface = (struct u_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001 *)params->u_iface;\n    params->_ret = iface->Init(  );\n    return 0;\n}\n#endif\n\nNTSTATUS ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_Shutdown( void *args )\n{\n    struct ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_Shutdown_params *params = (struct ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_Shutdown_params *)args;\n"},{"type":"text","text":"Repository: mono/mono\nPath: mcs/class/Mono.WebBrowser/Mono.Mozilla/DOM/Document.cs\nURL: https://github.com/mono/mono/blob/main/mcs/class/Mono.WebBrowser/Mono.Mozilla/DOM/Document.cs\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 38) ---\n\t\tinternal nsIDOMDocument node {\n\t\t\tget { return base.node as nsIDOMDocument;}\n\t\t\tset { base.node = value as nsIDOMDocument; }\n\t\t}\n\t\t\n\t\tpublic Document (WebBrowser control, nsIDOMHTMLDocument document)\n\t\t\t: base (control, document)\n\t\t{\n\t\t\tif (control.platform != control.enginePlatform)\n\t\t\t\tthis.node = nsDOMHTMLDocument.GetProxy (control, document);\n\t\t\telse\n\t\t\t\tthis.node = document;\n\t\t}\n\n\t\tpublic Document (WebBrowser control, nsIDOMDocument document)\n\n\n--- Snippet 2 (Line 88) ---\n\t\t\t\t\treturn null;\n\t\t\t\twebBrowserFocus.getFocusedElement (out element);\n\t\t\t\treturn (IElement)GetTypedNode (element);\n//\t\t\t\tif ((element as nsIDOMHTMLElement) != null)\n//\t\t\t\t\treturn new HTMLElement (control, element as nsIDOMHTMLElement) as IElement;\n"}]}]},"uuid":"632e6afc-21fe-4c01-a28b-65331c3106bc","timestamp":"2025-12-19T04:43:46.222Z","toolUseResult":[{"type":"text","text":"Repository: flutter/flutter\nPath: engine/src/flutter/lib/web_ui/lib/src/engine/dom.dart\nURL: https://github.com/flutter/flutter/blob/master/engine/src/flutter/lib/web_ui/lib/src/engine/dom.dart\nLicense: BSD-3-Clause\n\nSnippets:\n--- Snippet 1 (Line 264) ---\n    } else {\n      return _createElement(name, options.toJSAnyDeep);\n    }\n  }\n\n  external DomHTMLScriptElement? get currentScript;\n  external DomElement createElementNS(String namespaceURI, String qualifiedName);\n  external DomText createTextNode(String data);\n  external DomEvent createEvent(String eventType);\n  external DomElement? get activeElement;\n  external DomElement? elementFromPoint(int x, int y);\n}\n\n@JS('HTMLDocument')\nextension type DomHTMLDocument._(JSObject _) implements DomDocument {\n  external DomFontFaceSet? get fonts;\n  external DomHTMLHeadElement? get head;\n  external DomHTMLBodyElement? get body;\n  external String? title;\n\n  @JS('getElementsByTagName')\n"},{"type":"text","text":"Repository: flutter/flutter\nPath: engine/src/flutter/lib/web_ui/lib/src/engine/text_editing/text_editing.dart\nURL: https://github.com/flutter/flutter/blob/master/engine/src/flutter/lib/web_ui/lib/src/engine/text_editing/text_editing.dart\nLicense: BSD-3-Clause\n\nSnippets:\n--- Snippet 1 (Line 53) ---\n\n/// These style attributes are constant throughout the life time of an input\n/// element.\n///\n/// They are assigned once during the creation of the DOM element.\nvoid _setStaticStyleAttributes(DomHTMLElement domElement) {\n  domElement.classList.add(HybridTextEditing.textEditingClass);\n\n  final DomCSSStyleDeclaration elementStyle = domElement.style;\n  elementStyle\n    // Prevent (forced-colors: active) from making our invisible text fields visible.\n\n\n--- Snippet 2 (Line 97) ---\n/// These style attributes are constant throughout the life time of an input\n/// element.\n///\n/// They are assigned once during the creation of the DOM element.\nvoid _styleAutofillElements(\n  DomHTMLElement domElement, {\n  bool isOffScreen = false,\n  bool shouldHideElement = true,\n  bool shouldDisablePointerEvents = false,\n"},{"type":"text","text":"Repository: ClickHouse/ClickHouse\nPath: tests/queries/0_stateless/01746_extract_text_from_html.sql\nURL: https://github.com/ClickHouse/ClickHouse/blob/master/tests/queries/0_stateless/01746_extract_text_from_html.sql\nLicense: Apache-2.0\n\nSnippets:\n--- Snippet 1 (Line 2) ---\n\nSELECT extractTextFromHTML('');\nSELECT extractTextFromHTML(' ');\nSELECT extractTextFromHTML('  ');\nSELECT extractTextFromHTML('Hello');\nSELECT extractTextFromHTML('Hello, world');\nSELECT extractTextFromHTML('Hello,  world');\nSELECT extractTextFromHTML(' Hello,  world');\nSELECT extractTextFromHTML(' Hello,  world ');\nSELECT extractTextFromHTML(' \\t Hello,\\rworld \\n ');\n\nSELECT extractTextFromHTML('Hello<world');\nSELECT extractTextFromHTML('Hello < world');\nSELECT extractTextFromHTML('Hello > world');\nSELECT extractTextFromHTML('Hello<world>');\nSELECT extractTextFromHTML('Hello<>world');\nSELECT extractTextFromHTML('Hello<!>world');\nSELECT extractTextFromHTML('Hello<!->world');\nSELECT extractTextFromHTML('Hello<!-->world');\nSELECT extractTextFromHTML('Hello<!--->world');\nSELECT extractTextFromHTML('Hello<!---->world');\n"},{"type":"text","text":"Repository: ValveSoftware/Proton\nPath: lsteamclient/winISteamHTMLSurface.c\nURL: https://github.com/ValveSoftware/Proton/blob/proton_10.0/lsteamclient/winISteamHTMLSurface.c\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 6) ---\nDEFINE_THISCALL_WRAPPER(winISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_destructor, 4)\nDEFINE_THISCALL_WRAPPER(winISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_Init, 4)\nDEFINE_THISCALL_WRAPPER(winISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_Shutdown, 4)\nDEFINE_THISCALL_WRAPPER(winISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_CreateBrowser, 12)\nDEFINE_THISCALL_WRAPPER(winISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_RemoveBrowser, 8)\nDEFINE_THISCALL_WRAPPER(winISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_LoadURL, 16)\nDEFINE_THISCALL_WRAPPER(winISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_SetSize, 16)\nDEFINE_THISCALL_WRAPPER(winISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_StopLoad, 8)\nDEFINE_THISCALL_WRAPPER(winISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_Reload, 8)\nDEFINE_THISCALL_WRAPPER(winISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_GoBack, 8)\nDEFINE_THISCALL_WRAPPER(winISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_GoForward, 8)\nDEFINE_THISCALL_WRAPPER(winISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_AddHeader, 16)\nDEFINE_THISCALL_WRAPPER(winISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_ExecuteJavascript, 12)\nDEFINE_THISCALL_WRAPPER(winISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_MouseUp, 12)\nDEFINE_THISCALL_WRAPPER(winISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_MouseDown, 12)\nDEFINE_THISCALL_WRAPPER(winISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_MouseDoubleClick, 12)\nDEFINE_THISCALL_WRAPPER(winISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_MouseMove, 16)\nDEFINE_THISCALL_WRAPPER(winISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_MouseWheel, 12)\nDEFINE_THISCALL_WRAPPER(winISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_KeyDown, 16)\nDEFINE_THISCALL_WRAPPER(winISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_KeyUp, 16)\nDEFINE_THISCALL_WRAPPER(winISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_KeyChar, 16)\n"},{"type":"text","text":"Repository: ValveSoftware/Proton\nPath: lsteamclient/cppISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_005.cpp\nURL: https://github.com/ValveSoftware/Proton/blob/proton_10.0/lsteamclient/cppISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_005.cpp\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 8) ---\nNTSTATUS ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_005_Init( void *args )\n{\n    struct ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_005_Init_params *params = (struct ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_005_Init_params *)args;\n    struct u_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_005 *iface = (struct u_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_005 *)params->u_iface;\n    params->_ret = iface->Init(  );\n    return 0;\n}\n\n#if defined(__x86_64__) || defined(__aarch64__)\nNTSTATUS wow64_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_005_Init( void *args )\n{\n    struct wow64_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_005_Init_params *params = (struct wow64_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_005_Init_params *)args;\n    struct u_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_005 *iface = (struct u_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_005 *)params->u_iface;\n    params->_ret = iface->Init(  );\n    return 0;\n}\n#endif\n\nNTSTATUS ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_005_Shutdown( void *args )\n{\n    struct ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_005_Shutdown_params *params = (struct ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_005_Shutdown_params *)args;\n"},{"type":"text","text":"Repository: ValveSoftware/Proton\nPath: lsteamclient/cppISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_004.cpp\nURL: https://github.com/ValveSoftware/Proton/blob/proton_10.0/lsteamclient/cppISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_004.cpp\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 8) ---\nNTSTATUS ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_004_Init( void *args )\n{\n    struct ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_004_Init_params *params = (struct ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_004_Init_params *)args;\n    struct u_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_004 *iface = (struct u_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_004 *)params->u_iface;\n    params->_ret = iface->Init(  );\n    return 0;\n}\n\n#if defined(__x86_64__) || defined(__aarch64__)\nNTSTATUS wow64_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_004_Init( void *args )\n{\n    struct wow64_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_004_Init_params *params = (struct wow64_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_004_Init_params *)args;\n    struct u_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_004 *iface = (struct u_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_004 *)params->u_iface;\n    params->_ret = iface->Init(  );\n    return 0;\n}\n#endif\n\nNTSTATUS ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_004_Shutdown( void *args )\n{\n    struct ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_004_Shutdown_params *params = (struct ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_004_Shutdown_params *)args;\n"},{"type":"text","text":"Repository: ValveSoftware/Proton\nPath: lsteamclient/cppISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_002.cpp\nURL: https://github.com/ValveSoftware/Proton/blob/proton_10.0/lsteamclient/cppISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_002.cpp\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 8) ---\nNTSTATUS ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_002_Init( void *args )\n{\n    struct ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_002_Init_params *params = (struct ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_002_Init_params *)args;\n    struct u_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_002 *iface = (struct u_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_002 *)params->u_iface;\n    params->_ret = iface->Init(  );\n    return 0;\n}\n\n#if defined(__x86_64__) || defined(__aarch64__)\nNTSTATUS wow64_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_002_Init( void *args )\n{\n    struct wow64_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_002_Init_params *params = (struct wow64_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_002_Init_params *)args;\n    struct u_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_002 *iface = (struct u_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_002 *)params->u_iface;\n    params->_ret = iface->Init(  );\n    return 0;\n}\n#endif\n\nNTSTATUS ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_002_Shutdown( void *args )\n{\n    struct ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_002_Shutdown_params *params = (struct ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_002_Shutdown_params *)args;\n"},{"type":"text","text":"Repository: ValveSoftware/Proton\nPath: lsteamclient/cppISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_003.cpp\nURL: https://github.com/ValveSoftware/Proton/blob/proton_10.0/lsteamclient/cppISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_003.cpp\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 8) ---\nNTSTATUS ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_003_Init( void *args )\n{\n    struct ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_003_Init_params *params = (struct ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_003_Init_params *)args;\n    struct u_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_003 *iface = (struct u_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_003 *)params->u_iface;\n    params->_ret = iface->Init(  );\n    return 0;\n}\n\n#if defined(__x86_64__) || defined(__aarch64__)\nNTSTATUS wow64_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_003_Init( void *args )\n{\n    struct wow64_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_003_Init_params *params = (struct wow64_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_003_Init_params *)args;\n    struct u_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_003 *iface = (struct u_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_003 *)params->u_iface;\n    params->_ret = iface->Init(  );\n    return 0;\n}\n#endif\n\nNTSTATUS ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_003_Shutdown( void *args )\n{\n    struct ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_003_Shutdown_params *params = (struct ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_003_Shutdown_params *)args;\n"},{"type":"text","text":"Repository: ValveSoftware/Proton\nPath: lsteamclient/cppISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001.cpp\nURL: https://github.com/ValveSoftware/Proton/blob/proton_10.0/lsteamclient/cppISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001.cpp\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 8) ---\nNTSTATUS ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_Init( void *args )\n{\n    struct ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_Init_params *params = (struct ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_Init_params *)args;\n    struct u_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001 *iface = (struct u_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001 *)params->u_iface;\n    params->_ret = iface->Init(  );\n    return 0;\n}\n\n#if defined(__x86_64__) || defined(__aarch64__)\nNTSTATUS wow64_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_Init( void *args )\n{\n    struct wow64_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_Init_params *params = (struct wow64_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_Init_params *)args;\n    struct u_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001 *iface = (struct u_ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001 *)params->u_iface;\n    params->_ret = iface->Init(  );\n    return 0;\n}\n#endif\n\nNTSTATUS ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_Shutdown( void *args )\n{\n    struct ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_Shutdown_params *params = (struct ISteamHTMLSurface_STEAMHTMLSURFACE_INTERFACE_VERSION_001_Shutdown_params *)args;\n"},{"type":"text","text":"Repository: mono/mono\nPath: mcs/class/Mono.WebBrowser/Mono.Mozilla/DOM/Document.cs\nURL: https://github.com/mono/mono/blob/main/mcs/class/Mono.WebBrowser/Mono.Mozilla/DOM/Document.cs\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 38) ---\n\t\tinternal nsIDOMDocument node {\n\t\t\tget { return base.node as nsIDOMDocument;}\n\t\t\tset { base.node = value as nsIDOMDocument; }\n\t\t}\n\t\t\n\t\tpublic Document (WebBrowser control, nsIDOMHTMLDocument document)\n\t\t\t: base (control, document)\n\t\t{\n\t\t\tif (control.platform != control.enginePlatform)\n\t\t\t\tthis.node = nsDOMHTMLDocument.GetProxy (control, document);\n\t\t\telse\n\t\t\t\tthis.node = document;\n\t\t}\n\n\t\tpublic Document (WebBrowser control, nsIDOMDocument document)\n\n\n--- Snippet 2 (Line 88) ---\n\t\t\t\t\treturn null;\n\t\t\t\twebBrowserFocus.getFocusedElement (out element);\n\t\t\t\treturn (IElement)GetTypedNode (element);\n//\t\t\t\tif ((element as nsIDOMHTMLElement) != null)\n//\t\t\t\t\treturn new HTMLElement (control, element as nsIDOMHTMLElement) as IElement;\n"}]}
{"parentUuid":"632e6afc-21fe-4c01-a28b-65331c3106bc","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"faeb714a-61c5-410d-b669-0ebc662cf207","version":"2.0.70","gitBranch":"main","agentId":"abf8d80","message":{"model":"claude-opus-4-5-20251101","id":"msg_01499M8oLtQwm5HEtYNZyCkA","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01PAuPfSgPt3HxnmriXSDuqm","name":"mcp__grep__searchGitHub","input":{"query":"ArchiveBox"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":18585,"cache_read_input_tokens":13149,"cache_creation":{"ephemeral_5m_input_tokens":18585,"ephemeral_1h_input_tokens":0},"output_tokens":29,"service_tier":"standard"}},"requestId":"req_011CWFSBKwAhYscXooQRUqng","type":"assistant","uuid":"131b6617-8a91-4e9e-b5d5-c4da0dfbf30e","timestamp":"2025-12-19T04:43:50.313Z"}
{"parentUuid":"131b6617-8a91-4e9e-b5d5-c4da0dfbf30e","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"faeb714a-61c5-410d-b669-0ebc662cf207","version":"2.0.70","gitBranch":"main","agentId":"abf8d80","message":{"model":"claude-opus-4-5-20251101","id":"msg_01499M8oLtQwm5HEtYNZyCkA","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01VKmqRTT4MpBFTeGc2NhTut","name":"mcp__grep__searchGitHub","input":{"query":"httrack"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":18585,"cache_read_input_tokens":13149,"cache_creation":{"ephemeral_5m_input_tokens":18585,"ephemeral_1h_input_tokens":0},"output_tokens":29,"service_tier":"standard"}},"requestId":"req_011CWFSBKwAhYscXooQRUqng","type":"assistant","uuid":"a519d81a-3803-44d3-b2a7-1bbeca913cd4","timestamp":"2025-12-19T04:43:51.160Z"}
{"parentUuid":"a519d81a-3803-44d3-b2a7-1bbeca913cd4","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"faeb714a-61c5-410d-b669-0ebc662cf207","version":"2.0.70","gitBranch":"main","agentId":"abf8d80","message":{"model":"claude-opus-4-5-20251101","id":"msg_01499M8oLtQwm5HEtYNZyCkA","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01TRL2d7y1Ur6JWaza3ZmjWG","name":"mcp__grep__searchGitHub","input":{"query":"wget --mirror"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":18585,"cache_read_input_tokens":13149,"cache_creation":{"ephemeral_5m_input_tokens":18585,"ephemeral_1h_input_tokens":0},"output_tokens":29,"service_tier":"standard"}},"requestId":"req_011CWFSBKwAhYscXooQRUqng","type":"assistant","uuid":"7e4624cb-fc0d-4d18-be80-bed8b0e3f14e","timestamp":"2025-12-19T04:43:51.608Z"}
{"parentUuid":"7e4624cb-fc0d-4d18-be80-bed8b0e3f14e","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"faeb714a-61c5-410d-b669-0ebc662cf207","version":"2.0.70","gitBranch":"main","agentId":"abf8d80","message":{"model":"claude-opus-4-5-20251101","id":"msg_01499M8oLtQwm5HEtYNZyCkA","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_017Uhb4NV2o71mp3mBed2KLf","name":"mcp__grep__searchGitHub","input":{"query":"monolith","language":["Rust"]}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":18585,"cache_read_input_tokens":13149,"cache_creation":{"ephemeral_5m_input_tokens":18585,"ephemeral_1h_input_tokens":0},"output_tokens":29,"service_tier":"standard"}},"requestId":"req_011CWFSBKwAhYscXooQRUqng","type":"assistant","uuid":"0320cbeb-2fbb-4a97-bfba-28e9a2818965","timestamp":"2025-12-19T04:43:52.964Z"}
{"parentUuid":"0320cbeb-2fbb-4a97-bfba-28e9a2818965","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"faeb714a-61c5-410d-b669-0ebc662cf207","version":"2.0.70","gitBranch":"main","agentId":"abf8d80","message":{"model":"claude-opus-4-5-20251101","id":"msg_01499M8oLtQwm5HEtYNZyCkA","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01P4S3gkEQTvyntiCQfs9dti","name":"mcp__grep__searchGitHub","input":{"query":"web-archive"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":18585,"cache_read_input_tokens":13149,"cache_creation":{"ephemeral_5m_input_tokens":18585,"ephemeral_1h_input_tokens":0},"output_tokens":29,"service_tier":"standard"}},"requestId":"req_011CWFSBKwAhYscXooQRUqng","type":"assistant","uuid":"5588474f-7405-499c-8f0d-9f9fc7cac286","timestamp":"2025-12-19T04:43:53.333Z"}
{"parentUuid":"5588474f-7405-499c-8f0d-9f9fc7cac286","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"faeb714a-61c5-410d-b669-0ebc662cf207","version":"2.0.70","gitBranch":"main","agentId":"abf8d80","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01PAuPfSgPt3HxnmriXSDuqm","type":"tool_result","content":[{"type":"text","text":"Repository: ArchiveBox/ArchiveBox\nPath: bin/setup.sh\nURL: https://github.com/ArchiveBox/ArchiveBox/blob/dev/bin/setup.sh\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n#!/usr/bin/env bash\n# ArchiveBox Setup Script (Ubuntu/Debian/FreeBSD/macOS)\n#   - Project Homepage: https://github.com/ArchiveBox/ArchiveBox\n#   - Install Documentation: https://github.com/ArchiveBox/ArchiveBox/wiki/Install\n# Script Usage:\n#    curl -fsSL 'https://raw.githubusercontent.com/ArchiveBox/ArchiveBox/dev/bin/setup.sh' | bash\n#           (aka https://docker-compose.archivebox.io)\n\n### Bash Environment Setup\n# http://redsymbol.net/articles/unofficial-bash-strict-mode/\n# https://www.gnu.org/software/bash/manual/html_node/The-Set-Builtin.html\n# set -o xtrace\n\n\n--- Snippet 2 (Line 21) ---\nclear\n\nif [ $(id -u) -eq 0 ]; then\n    echo\n    echo \"[X] You cannot run this script as root. You must run it as a non-root user with sudo ability.\"\n    echo \"    Create a new non-privileged user 'archivebox' if necessary.\"\n    echo \"      adduser archivebox && usermod -a archivebox -G sudo && su archivebox\"\n    echo \"    https://www.digitalocean.com/community/tutorials/how-to-create-a-new-sudo-enabled-user-on-ubuntu-20-04-quickstart\"\n"},{"type":"text","text":"Repository: ArchiveBox/ArchiveBox\nPath: archivebox/misc/checks.py\nURL: https://github.com/ArchiveBox/ArchiveBox/blob/dev/archivebox/misc/checks.py\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n__package__ = 'archivebox.misc'\n\nimport os\nimport sys\nfrom pathlib import Path\n\nfrom rich import print\nfrom rich.panel import Panel\n\n# DO NOT ADD ANY TOP-LEVEL IMPORTS HERE to anything other than builtin python libraries\n# this file is imported by archivebox/__init__.py\n# and any imports here will be imported by EVERYTHING else\n# so this file should only be used for pure python checks\n# that don't need to import other parts of ArchiveBox\n\n# if a check needs to import other parts of ArchiveBox,\n# the imports should be done inside the check function\n# and you should make sure if you need to import any django stuff\n# that the check is called after django.setup() has been called\n\n\n"},{"type":"text","text":"Repository: ArchiveBox/ArchiveBox\nPath: Dockerfile\nURL: https://github.com/ArchiveBox/ArchiveBox/blob/dev/Dockerfile\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n# This is the Dockerfile for ArchiveBox, it bundles the following main dependencies:\n#     python3.11, pip, pipx, uv, python3-ldap\n#     curl, wget, git, dig, ping, tree, nano\n#     node, npm, single-file, readability-extractor, postlight-parser\n#     ArchiveBox, yt-dlp, playwright, chromium\n# Usage:\n#     git clone https://github.com/ArchiveBox/ArchiveBox && cd ArchiveBox\n#     docker build . -t archivebox\n#     docker run -v \"$PWD/data\":/data archivebox init\n#     docker run -v \"$PWD/data\":/data archivebox add 'https://example.com'\n#     docker run -v \"$PWD/data\":/data -it archivebox manage createsuperuser\n#     docker run -v \"$PWD/data\":/data -p 8000:8000 archivebox server\n# Multi-arch build:\n#     docker buildx create --use\n#     docker buildx build . --platform=linux/amd64,linux/arm64--push -t archivebox/archivebox:dev -t archivebox/archivebox:sha-abc123\n# Read more here: https://github.com/ArchiveBox/ArchiveBox#archivebox-development\n\n\n#########################################################################################\n\n### Example: Using ArchiveBox in your own project's Dockerfile ########\n"},{"type":"text","text":"Repository: ArchiveBox/ArchiveBox\nPath: archivebox/config/paths.py\nURL: https://github.com/ArchiveBox/ArchiveBox/blob/dev/archivebox/config/paths.py\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n__package__ = 'archivebox.config'\n\nimport os\nimport socket\nimport hashlib\nimport tempfile\n\n\n--- Snippet 2 (Line 9) ---\nfrom functools import cache\nfrom datetime import datetime\n\nfrom benedict import benedict\n\nfrom .permissions import SudoPermission, IS_ROOT, ARCHIVEBOX_USER\n\n#############################################################################################\n\nPACKAGE_DIR: Path = Path(__file__).resolve().parent.parent    # archivebox source code dir\nDATA_DIR: Path = Path(os.getcwd()).resolve()                  # archivebox user data dir\nARCHIVE_DIR: Path = DATA_DIR / 'archive'                      # archivebox snapshot data dir\n\nIN_DOCKER = os.environ.get('IN_DOCKER', False) in ('1', 'true', 'True', 'TRUE', 'yes')\n"},{"type":"text","text":"Repository: ArchiveBox/ArchiveBox\nPath: archivebox/cli/archivebox_help.py\nURL: https://github.com/ArchiveBox/ArchiveBox/blob/dev/archivebox/cli/archivebox_help.py\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n#!/usr/bin/env python3\n__package__ = 'archivebox.cli'\n__command__ = 'archivebox help'\n\nimport os    \nfrom pathlib import Path\n\nimport click\nfrom rich import print\nfrom rich.panel import Panel\n\n\ndef help() -> None:\n    \"\"\"Print the ArchiveBox help message and usage\"\"\"\n\n    from archivebox.cli import ArchiveBoxGroup\n    from archivebox.config import CONSTANTS\n    from archivebox.config.permissions import IN_DOCKER\n    from archivebox.misc.logging_util import log_cli_command\n    \n    log_cli_command('help', [], None, '.')\n"},{"type":"text","text":"Repository: ArchiveBox/ArchiveBox\nPath: archivebox/cli/__init__.py\nURL: https://github.com/ArchiveBox/ArchiveBox/blob/dev/archivebox/cli/__init__.py\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n__package__ = 'archivebox.cli'\n__command__ = 'archivebox'\nimport os\nimport sys\nfrom importlib import import_module\n\nimport rich_click as click\nfrom rich import print\n\nfrom archivebox.config.version import VERSION\n\n\n\nif '--debug' in sys.argv:\n    os.environ['DEBUG'] = 'True'\n    sys.argv.remove('--debug')\n\n\nclass ArchiveBoxGroup(click.Group):\n    \"\"\"lazy loading click group for archivebox commands\"\"\"\n    meta_commands = {\n"},{"type":"text","text":"Repository: ArchiveBox/ArchiveBox\nPath: archivebox/pkgs/abx-spec-archivebox/abx_spec_archivebox/states.py\nURL: https://github.com/ArchiveBox/ArchiveBox/blob/dev/archivebox/pkgs/abx-spec-archivebox/abx_spec_archivebox/states.py\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n# __package__ = 'archivebox.crawls'\n\n# import time\n\n# import abx\n# import abx.archivebox.events\n# import abx.hookimpl\n\n# from datetime import datetime\n\n# from django_stubs_ext.db.models import TypedModelMeta\n\n\n--- Snippet 2 (Line 31) ---\n# #   - object: an instance of a django model that represents a single row in the database\n\n\n# # ORCHESTRATOR:\n# # An orchestrator is a single long-running daemon process that manages spawning and killing actors for different queues of objects.\n# # The orchestrator first starts when the archivebox starts, and it stops when archivebox is killed.\n# # Only one orchestrator process can be running per collection per machine.\n# # An orchestrator is aware of all of the ActorTypes that are defined in the system, and their associated queues.\n# # When started, the orchestrator runs a single runloop that continues until the archivebox process is killed.\n"},{"type":"text","text":"Repository: ArchiveBox/ArchiveBox\nPath: bin/docker_entrypoint.sh\nURL: https://github.com/ArchiveBox/ArchiveBox/blob/dev/bin/docker_entrypoint.sh\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n#!/bin/bash\n\n# This Docker ENTRYPOINT script is called by `docker run archivebox ...` or `docker compose run archivebox ...`.\n# It takes a CMD as $* shell arguments and runs it following these setup steps:\n\n# - Set the archivebox user to use the correct PUID & PGID\n#     1. highest precedence is for valid PUID and PGID env vars passsed in explicitly\n#     2. fall back to DETECTED_PUID of files found within existing data dir\n#     3. fall back to DEFAULT_PUID if no data dir or its owned by root\n# - Create a new /data dir if necessary and set the correct ownership on it\n# - Create a new /browsers dir if necessary and set the correct ownership on it\n# - Check whether we're running inside QEMU emulation and show a warning if so.\n# - Check that enough free space is available on / and /data\n# - Drop down to archivebox user permisisons and execute passed CMD command.\n\n# Bash Environment Setup\n# http://redsymbol.net/articles/unofficial-bash-strict-mode/\n# https://www.gnu.org/software/bash/manual/html_node/The-Set-Builtin.html\n# set -o xtrace\n"},{"type":"text","text":"Repository: ArchiveBox/ArchiveBox\nPath: archivebox/cli/archivebox_init.py\nURL: https://github.com/ArchiveBox/ArchiveBox/blob/dev/archivebox/cli/archivebox_init.py\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 3) ---\n__package__ = 'archivebox.cli'\n\nimport os\nimport sys\nfrom pathlib import Path\n\nfrom rich import print\nimport rich_click as click\n\nfrom archivebox.misc.util import docstring, enforce_types\n\n\n@enforce_types\ndef init(force: bool=False, quick: bool=False, install: bool=False, setup: bool=False) -> None:\n    \"\"\"Initialize a new ArchiveBox collection in the current directory\"\"\"\n    \n    install = install or setup\n    \n    from archivebox.config import CONSTANTS, VERSION, DATA_DIR\n    from archivebox.config.common import SERVER_CONFIG\n    from archivebox.config.collection import write_config_file\n"},{"type":"text","text":"Repository: ArchiveBox/ArchiveBox\nPath: archivebox/core/views.py\nURL: https://github.com/ArchiveBox/ArchiveBox/blob/dev/archivebox/core/views.py\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n__package__ = 'archivebox.core'\n\nimport os\nimport sys\nfrom django.utils import timezone\nimport inspect\n\n\n--- Snippet 2 (Line 20) ---\nfrom django.utils.decorators import method_decorator\n\nfrom admin_data_views.typing import TableContext, ItemContext\nfrom admin_data_views.utils import render_with_table_view, render_with_item_view, ItemLink\n\nimport archivebox\nfrom archivebox.config import CONSTANTS, CONSTANTS_CONFIG, DATA_DIR, VERSION\nfrom archivebox.config.common import SHELL_CONFIG, SERVER_CONFIG\nfrom archivebox.misc.util import base_url, htmlencode, ts_to_date_str\nfrom archivebox.misc.serve_static import serve_static_with_byterange_support\nfrom archivebox.misc.logging_util import printable_filesize\nfrom archivebox.search import query_search_index\n\nfrom core.models import Snapshot\n"}]}]},"uuid":"d9553447-9284-4960-b7e3-3e0f87b9ad11","timestamp":"2025-12-19T04:43:53.729Z","toolUseResult":[{"type":"text","text":"Repository: ArchiveBox/ArchiveBox\nPath: bin/setup.sh\nURL: https://github.com/ArchiveBox/ArchiveBox/blob/dev/bin/setup.sh\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n#!/usr/bin/env bash\n# ArchiveBox Setup Script (Ubuntu/Debian/FreeBSD/macOS)\n#   - Project Homepage: https://github.com/ArchiveBox/ArchiveBox\n#   - Install Documentation: https://github.com/ArchiveBox/ArchiveBox/wiki/Install\n# Script Usage:\n#    curl -fsSL 'https://raw.githubusercontent.com/ArchiveBox/ArchiveBox/dev/bin/setup.sh' | bash\n#           (aka https://docker-compose.archivebox.io)\n\n### Bash Environment Setup\n# http://redsymbol.net/articles/unofficial-bash-strict-mode/\n# https://www.gnu.org/software/bash/manual/html_node/The-Set-Builtin.html\n# set -o xtrace\n\n\n--- Snippet 2 (Line 21) ---\nclear\n\nif [ $(id -u) -eq 0 ]; then\n    echo\n    echo \"[X] You cannot run this script as root. You must run it as a non-root user with sudo ability.\"\n    echo \"    Create a new non-privileged user 'archivebox' if necessary.\"\n    echo \"      adduser archivebox && usermod -a archivebox -G sudo && su archivebox\"\n    echo \"    https://www.digitalocean.com/community/tutorials/how-to-create-a-new-sudo-enabled-user-on-ubuntu-20-04-quickstart\"\n"},{"type":"text","text":"Repository: ArchiveBox/ArchiveBox\nPath: archivebox/misc/checks.py\nURL: https://github.com/ArchiveBox/ArchiveBox/blob/dev/archivebox/misc/checks.py\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n__package__ = 'archivebox.misc'\n\nimport os\nimport sys\nfrom pathlib import Path\n\nfrom rich import print\nfrom rich.panel import Panel\n\n# DO NOT ADD ANY TOP-LEVEL IMPORTS HERE to anything other than builtin python libraries\n# this file is imported by archivebox/__init__.py\n# and any imports here will be imported by EVERYTHING else\n# so this file should only be used for pure python checks\n# that don't need to import other parts of ArchiveBox\n\n# if a check needs to import other parts of ArchiveBox,\n# the imports should be done inside the check function\n# and you should make sure if you need to import any django stuff\n# that the check is called after django.setup() has been called\n\n\n"},{"type":"text","text":"Repository: ArchiveBox/ArchiveBox\nPath: Dockerfile\nURL: https://github.com/ArchiveBox/ArchiveBox/blob/dev/Dockerfile\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n# This is the Dockerfile for ArchiveBox, it bundles the following main dependencies:\n#     python3.11, pip, pipx, uv, python3-ldap\n#     curl, wget, git, dig, ping, tree, nano\n#     node, npm, single-file, readability-extractor, postlight-parser\n#     ArchiveBox, yt-dlp, playwright, chromium\n# Usage:\n#     git clone https://github.com/ArchiveBox/ArchiveBox && cd ArchiveBox\n#     docker build . -t archivebox\n#     docker run -v \"$PWD/data\":/data archivebox init\n#     docker run -v \"$PWD/data\":/data archivebox add 'https://example.com'\n#     docker run -v \"$PWD/data\":/data -it archivebox manage createsuperuser\n#     docker run -v \"$PWD/data\":/data -p 8000:8000 archivebox server\n# Multi-arch build:\n#     docker buildx create --use\n#     docker buildx build . --platform=linux/amd64,linux/arm64--push -t archivebox/archivebox:dev -t archivebox/archivebox:sha-abc123\n# Read more here: https://github.com/ArchiveBox/ArchiveBox#archivebox-development\n\n\n#########################################################################################\n\n### Example: Using ArchiveBox in your own project's Dockerfile ########\n"},{"type":"text","text":"Repository: ArchiveBox/ArchiveBox\nPath: archivebox/config/paths.py\nURL: https://github.com/ArchiveBox/ArchiveBox/blob/dev/archivebox/config/paths.py\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n__package__ = 'archivebox.config'\n\nimport os\nimport socket\nimport hashlib\nimport tempfile\n\n\n--- Snippet 2 (Line 9) ---\nfrom functools import cache\nfrom datetime import datetime\n\nfrom benedict import benedict\n\nfrom .permissions import SudoPermission, IS_ROOT, ARCHIVEBOX_USER\n\n#############################################################################################\n\nPACKAGE_DIR: Path = Path(__file__).resolve().parent.parent    # archivebox source code dir\nDATA_DIR: Path = Path(os.getcwd()).resolve()                  # archivebox user data dir\nARCHIVE_DIR: Path = DATA_DIR / 'archive'                      # archivebox snapshot data dir\n\nIN_DOCKER = os.environ.get('IN_DOCKER', False) in ('1', 'true', 'True', 'TRUE', 'yes')\n"},{"type":"text","text":"Repository: ArchiveBox/ArchiveBox\nPath: archivebox/cli/archivebox_help.py\nURL: https://github.com/ArchiveBox/ArchiveBox/blob/dev/archivebox/cli/archivebox_help.py\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n#!/usr/bin/env python3\n__package__ = 'archivebox.cli'\n__command__ = 'archivebox help'\n\nimport os    \nfrom pathlib import Path\n\nimport click\nfrom rich import print\nfrom rich.panel import Panel\n\n\ndef help() -> None:\n    \"\"\"Print the ArchiveBox help message and usage\"\"\"\n\n    from archivebox.cli import ArchiveBoxGroup\n    from archivebox.config import CONSTANTS\n    from archivebox.config.permissions import IN_DOCKER\n    from archivebox.misc.logging_util import log_cli_command\n    \n    log_cli_command('help', [], None, '.')\n"},{"type":"text","text":"Repository: ArchiveBox/ArchiveBox\nPath: archivebox/cli/__init__.py\nURL: https://github.com/ArchiveBox/ArchiveBox/blob/dev/archivebox/cli/__init__.py\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n__package__ = 'archivebox.cli'\n__command__ = 'archivebox'\nimport os\nimport sys\nfrom importlib import import_module\n\nimport rich_click as click\nfrom rich import print\n\nfrom archivebox.config.version import VERSION\n\n\n\nif '--debug' in sys.argv:\n    os.environ['DEBUG'] = 'True'\n    sys.argv.remove('--debug')\n\n\nclass ArchiveBoxGroup(click.Group):\n    \"\"\"lazy loading click group for archivebox commands\"\"\"\n    meta_commands = {\n"},{"type":"text","text":"Repository: ArchiveBox/ArchiveBox\nPath: archivebox/pkgs/abx-spec-archivebox/abx_spec_archivebox/states.py\nURL: https://github.com/ArchiveBox/ArchiveBox/blob/dev/archivebox/pkgs/abx-spec-archivebox/abx_spec_archivebox/states.py\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n# __package__ = 'archivebox.crawls'\n\n# import time\n\n# import abx\n# import abx.archivebox.events\n# import abx.hookimpl\n\n# from datetime import datetime\n\n# from django_stubs_ext.db.models import TypedModelMeta\n\n\n--- Snippet 2 (Line 31) ---\n# #   - object: an instance of a django model that represents a single row in the database\n\n\n# # ORCHESTRATOR:\n# # An orchestrator is a single long-running daemon process that manages spawning and killing actors for different queues of objects.\n# # The orchestrator first starts when the archivebox starts, and it stops when archivebox is killed.\n# # Only one orchestrator process can be running per collection per machine.\n# # An orchestrator is aware of all of the ActorTypes that are defined in the system, and their associated queues.\n# # When started, the orchestrator runs a single runloop that continues until the archivebox process is killed.\n"},{"type":"text","text":"Repository: ArchiveBox/ArchiveBox\nPath: bin/docker_entrypoint.sh\nURL: https://github.com/ArchiveBox/ArchiveBox/blob/dev/bin/docker_entrypoint.sh\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n#!/bin/bash\n\n# This Docker ENTRYPOINT script is called by `docker run archivebox ...` or `docker compose run archivebox ...`.\n# It takes a CMD as $* shell arguments and runs it following these setup steps:\n\n# - Set the archivebox user to use the correct PUID & PGID\n#     1. highest precedence is for valid PUID and PGID env vars passsed in explicitly\n#     2. fall back to DETECTED_PUID of files found within existing data dir\n#     3. fall back to DEFAULT_PUID if no data dir or its owned by root\n# - Create a new /data dir if necessary and set the correct ownership on it\n# - Create a new /browsers dir if necessary and set the correct ownership on it\n# - Check whether we're running inside QEMU emulation and show a warning if so.\n# - Check that enough free space is available on / and /data\n# - Drop down to archivebox user permisisons and execute passed CMD command.\n\n# Bash Environment Setup\n# http://redsymbol.net/articles/unofficial-bash-strict-mode/\n# https://www.gnu.org/software/bash/manual/html_node/The-Set-Builtin.html\n# set -o xtrace\n"},{"type":"text","text":"Repository: ArchiveBox/ArchiveBox\nPath: archivebox/cli/archivebox_init.py\nURL: https://github.com/ArchiveBox/ArchiveBox/blob/dev/archivebox/cli/archivebox_init.py\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 3) ---\n__package__ = 'archivebox.cli'\n\nimport os\nimport sys\nfrom pathlib import Path\n\nfrom rich import print\nimport rich_click as click\n\nfrom archivebox.misc.util import docstring, enforce_types\n\n\n@enforce_types\ndef init(force: bool=False, quick: bool=False, install: bool=False, setup: bool=False) -> None:\n    \"\"\"Initialize a new ArchiveBox collection in the current directory\"\"\"\n    \n    install = install or setup\n    \n    from archivebox.config import CONSTANTS, VERSION, DATA_DIR\n    from archivebox.config.common import SERVER_CONFIG\n    from archivebox.config.collection import write_config_file\n"},{"type":"text","text":"Repository: ArchiveBox/ArchiveBox\nPath: archivebox/core/views.py\nURL: https://github.com/ArchiveBox/ArchiveBox/blob/dev/archivebox/core/views.py\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n__package__ = 'archivebox.core'\n\nimport os\nimport sys\nfrom django.utils import timezone\nimport inspect\n\n\n--- Snippet 2 (Line 20) ---\nfrom django.utils.decorators import method_decorator\n\nfrom admin_data_views.typing import TableContext, ItemContext\nfrom admin_data_views.utils import render_with_table_view, render_with_item_view, ItemLink\n\nimport archivebox\nfrom archivebox.config import CONSTANTS, CONSTANTS_CONFIG, DATA_DIR, VERSION\nfrom archivebox.config.common import SHELL_CONFIG, SERVER_CONFIG\nfrom archivebox.misc.util import base_url, htmlencode, ts_to_date_str\nfrom archivebox.misc.serve_static import serve_static_with_byterange_support\nfrom archivebox.misc.logging_util import printable_filesize\nfrom archivebox.search import query_search_index\n\nfrom core.models import Snapshot\n"}]}
{"parentUuid":"d9553447-9284-4960-b7e3-3e0f87b9ad11","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"faeb714a-61c5-410d-b669-0ebc662cf207","version":"2.0.70","gitBranch":"main","agentId":"abf8d80","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01VKmqRTT4MpBFTeGc2NhTut","type":"tool_result","content":[{"type":"text","text":"Repository: ApolloAuto/apollo\nPath: modules/perception/traffic_light_tracking/traffic_light_tracking_component.cc\nURL: https://github.com/ApolloAuto/apollo/blob/master/modules/perception/traffic_light_tracking/traffic_light_tracking_component.cc\nLicense: Apache-2.0\n\nSnippets:\n--- Snippet 1 (Line 60) ---\nbool TrafficLightTrackComponent::Init() {\n  // init component config\n  if (InitConfig() != cyber::SUCC) {\n    AERROR << \"TrafficLightTrackComponent InitConfig failed.\";\n    return false;\n  }\n  // init algorithm plugin\n  if (InitAlgorithmPlugin() != cyber::SUCC) {\n    AERROR << \"TrafficLightTrackComponent InitAlgorithmPlugin failed.\";\n    return false;\n  }\n\n  if (InitV2XListener() != cyber::SUCC) {\n    AERROR << \"TrafficLightTrackComponent InitV2XListener failed.\";\n    return false;\n  }\n\n  return true;\n}\n\nbool TrafficLightTrackComponent::Proc(\n"},{"type":"text","text":"Repository: apernet/hysteria\nPath: core/internal/congestion/bbr/bandwidth_sampler.go\nURL: https://github.com/apernet/hysteria/blob/master/core/internal/congestion/bbr/bandwidth_sampler.go\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 94) ---\n\treturn &bandwidthSample{\n\t\tsendRate: infBandwidth,\n\t}\n}\n\n// MaxAckHeightTracker is part of the BandwidthSampler. It is called after every\n// ack event to keep track the degree of ack aggregation(a.k.a \"ack height\").\ntype maxAckHeightTracker struct {\n\t// Tracks the maximum number of bytes acked faster than the estimated\n\t// bandwidth.\n\tmaxAckHeightFilter *WindowedFilter[extraAckedEvent, roundTripCount]\n\t// The time this aggregation started and the number of bytes acked during it.\n\taggregationEpochStartTime time.Time\n\n\n--- Snippet 2 (Line 113) ---\n\tackAggregationBandwidthThreshold       float64\n\tstartNewAggregationEpochAfterFullRound bool\n\treduceExtraAckedOnBandwidthIncrease    bool\n}\n\nfunc newMaxAckHeightTracker(windowLength roundTripCount) *maxAckHeightTracker {\n\treturn &maxAckHeightTracker{\n"},{"type":"text","text":"Repository: xroche/httrack\nPath: src/Makefile.in\nURL: https://github.com/xroche/httrack/blob/master/src/Makefile.in\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 89) ---\nNORMAL_UNINSTALL = :\nPRE_UNINSTALL = :\nPOST_UNINSTALL = :\nbuild_triplet = @build@\nhost_triplet = @host@\nbin_PROGRAMS = proxytrack$(EXEEXT) httrack$(EXEEXT) htsserver$(EXEEXT)\nsubdir = src\nACLOCAL_M4 = $(top_srcdir)/aclocal.m4\nam__aclocal_m4_deps = $(top_srcdir)/m4/check_zlib.m4 \\\n\t$(top_srcdir)/m4/libtool.m4 $(top_srcdir)/m4/ltoptions.m4 \\\n\t$(top_srcdir)/m4/ltsugar.m4 $(top_srcdir)/m4/ltversion.m4 \\\n\n\n--- Snippet 2 (Line 105) ---\nmkinstalldirs = $(install_sh) -d\nCONFIG_HEADER = $(top_builddir)/config.h\nCONFIG_CLEAN_FILES =\nCONFIG_CLEAN_VPATH_FILES =\nam__installdirs = \"$(DESTDIR)$(bindir)\" \"$(DESTDIR)$(libdir)\" \\\n\t\"$(DESTDIR)$(whttrackrundir)\" \"$(DESTDIR)$(DevIncludesdir)\"\nPROGRAMS = $(bin_PROGRAMS)\nam__vpath_adj_setup = srcdirstrip=`echo \"$(srcdir)\" | sed 's|.|.|g'`;\nam__vpath_adj = case $$p in \\\n"},{"type":"text","text":"Repository: flutter/flutter\nPath: packages/flutter/lib/src/material/slider_parts.dart\nURL: https://github.com/flutter/flutter/blob/master/packages/flutter/lib/src/material/slider_parts.dart\nLicense: BSD-3-Clause\n\nSnippets:\n--- Snippet 1 (Line 326) ---\n      begin: sliderTheme.disabledInactiveTrackColor,\n      end: sliderTheme.inactiveTrackColor,\n    );\n    final activePaint = Paint()..color = activeTrackColorTween.evaluate(enableAnimation)!;\n    final inactivePaint = Paint()..color = inactiveTrackColorTween.evaluate(enableAnimation)!;\n    final (Paint leftTrackPaint, Paint rightTrackPaint) = switch (textDirection) {\n      TextDirection.ltr => (activePaint, inactivePaint),\n      TextDirection.rtl => (inactivePaint, activePaint),\n    };\n\n    final Rect trackRect = getPreferredRect(\n\n\n--- Snippet 2 (Line 352) ---\n    }\n    final rightTrackSegment = Rect.fromLTRB(\n      thumbCenter.dx,\n      trackRect.top,\n      trackRect.right,\n      trackRect.bottom,\n    );\n    if (!rightTrackSegment.isEmpty) {\n      context.canvas.drawRect(rightTrackSegment, rightTrackPaint);\n"},{"type":"text","text":"Repository: xroche/httrack\nPath: libtest/example-main.c\nURL: https://github.com/xroche/httrack/blob/master/libtest/example-main.c\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n/*\n    HTTrack library example\n    .c file\n\n    Prerequisites:\n      - install winhttrack\n      - set the proper path in the project settings (especially for the httrack lib and dll)\n\n    How to build: (callback.so or callback.dll)\n      With GNU-GCC:\n        gcc -I/usr/include/httrack -O -g3 -Wall -D_REENTRANT -o example example.c -lhttrack2\n      With MS-Visual C++:\n        cl -nologo -W3 -Zi -Zp4 -DWIN32 -Fe\"mycallback.exe\" callbacks-example.c wsock32.lib libhttrack.lib\n*/\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n"},{"type":"text","text":"Repository: xroche/httrack\nPath: tests/11_crawl-international.test\nURL: https://github.com/xroche/httrack/blob/master/tests/11_crawl-international.test\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 9) ---\n\t--found ut.httrack.com/unicode-links/caf%a91bce.html \\\n\t--found ut.httrack.com/unicode-links/café30f4.html \\\n\t--found ut.httrack.com/unicode-links/café3860.html \\\n\t--found ut.httrack.com/unicode-links/café463e.html \\\n\t--found ut.httrack.com/unicode-links/café5e1f.html \\\n\t--found ut.httrack.com/unicode-links/café7b30.html \\\n\t--found ut.httrack.com/unicode-links/café8007.html \\\n\t--found ut.httrack.com/unicode-links/café9fa8.html \\\n\t--found ut.httrack.com/unicode-links/caféae52.html \\\n\t--found ut.httrack.com/unicode-links/caféc009.html \\\n\t--found ut.httrack.com/unicode-links/utf8.html \\\n\thttrack http://ut.httrack.com/unicode-links/utf8.html\n\nbash crawl-test.sh \\\n\t--errors 4 --files  7 \\\n\t--found ut.httrack.com/unicode-links/cafÃ©3860.html \\\n\t--found ut.httrack.com/unicode-links/cafÃ©9fa8.html \\\n\t--found ut.httrack.com/unicode-links/café30f4.html \\\n\t--found ut.httrack.com/unicode-links/café5e1f.html \\\n\t--found ut.httrack.com/unicode-links/café7b30.html \\\n\t--found ut.httrack.com/unicode-links/café8007.html \\\n"},{"type":"text","text":"Repository: Homebrew/homebrew-core\nPath: Formula/h/httrack.rb\nURL: https://github.com/Homebrew/homebrew-core/blob/main/Formula/h/httrack.rb\nLicense: BSD-2-Clause\n\nSnippets:\n--- Snippet 1 (Line 1) ---\nclass Httrack < Formula\n  desc \"Website copier/offline browser\"\n  homepage \"https://www.httrack.com/\"\n  # Always use mirror.httrack.com when you link to a new version of HTTrack, as\n  # link to download.httrack.com will break on next HTTrack update.\n  url \"https://mirror.httrack.com/historical/httrack-3.49.2.tar.gz\"\n  sha256 \"3477a0e5568e241c63c9899accbfcdb6aadef2812fcce0173688567b4c7d4025\"\n  license \"GPL-3.0-or-later\" => { with: \"openvpn-openssl-exception\" }\n  revision 1\n\n  livecheck do\n    url \"https://mirror.httrack.com/historical/\"\n    regex(/href=.*?httrack[._-]v?(\\d+(?:\\.\\d+)+)\\./i)\n  end\n\n  no_autobump! because: :requires_manual_review\n\n  bottle do\n"},{"type":"text","text":"Repository: xroche/httrack\nPath: src/htsweb.c\nURL: https://github.com/xroche/httrack/blob/master/src/htsweb.c\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n/* ------------------------------------------------------------ */\n/*\nHTTrack Website Copier, Offline Browser for Windows and Unix\nCopyright (C) 1998-2017 Xavier Roche and other contributors\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n\n\n--- Snippet 2 (Line 20) ---\n\n- We hereby ask people using this source NOT to use it in purpose of grabbing\nemails addresses, or collecting any other private information on persons.\nThis would disgrace our work, and spoil the many hours we spent on it.\n\nPlease visit our Website: http://www.httrack.com\n*/\n\n/* ------------------------------------------------------------ */\n/* File: webhttrack.c routines                                  */\n/* Author: Xavier Roche                                         */\n/* ------------------------------------------------------------ */\n"},{"type":"text","text":"Repository: xroche/httrack\nPath: libtest/example-main.h\nURL: https://github.com/xroche/httrack/blob/master/libtest/example-main.h\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n/*\n    HTTrack library example\n    .h file\n*/\n\n#ifdef __WIN32\n#define CDECL __cdecl\n#else\n#define CDECL\n#endif\n\nstatic void CDECL httrack_wrapper_init(t_hts_callbackarg * carg);\nstatic void CDECL httrack_wrapper_uninit(t_hts_callbackarg * carg);\nstatic int CDECL httrack_wrapper_start(t_hts_callbackarg * carg,\n                                       httrackp * opt);\nstatic int CDECL httrack_wrapper_chopt(t_hts_callbackarg * carg,\n                                       httrackp * opt);\nstatic int CDECL httrack_wrapper_end(t_hts_callbackarg * carg, httrackp * opt);\nstatic int CDECL httrack_wrapper_checkhtml(t_hts_callbackarg * carg,\n                                           httrackp * opt, char *html, int len,\n                                           const char *url_address,\n"},{"type":"text","text":"Repository: xroche/httrack\nPath: src/httrack-library.h\nURL: https://github.com/xroche/httrack/blob/master/src/httrack-library.h\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n/* ------------------------------------------------------------ */\n/*\nHTTrack Website Copier, Offline Browser for Windows and Unix\nCopyright (C) 1998-2017 Xavier Roche and other contributors\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n\n\n--- Snippet 2 (Line 23) ---\nThis would disgrace our work, and spoil the many hours we spent on it.\n\nPlease visit our Website: http://www.httrack.com\n*/\n\n/* ------------------------------------------------------------ */\n/* File: HTTrack definition file for library usage              */\n/* Author: Xavier Roche                                         */\n/* ------------------------------------------------------------ */\n\n#ifndef HTTRACK_DEFLIB\n#define HTTRACK_DEFLIB\n"}]}]},"uuid":"d715b252-3be0-4057-9f98-d554a1bb9726","timestamp":"2025-12-19T04:43:54.054Z","toolUseResult":[{"type":"text","text":"Repository: ApolloAuto/apollo\nPath: modules/perception/traffic_light_tracking/traffic_light_tracking_component.cc\nURL: https://github.com/ApolloAuto/apollo/blob/master/modules/perception/traffic_light_tracking/traffic_light_tracking_component.cc\nLicense: Apache-2.0\n\nSnippets:\n--- Snippet 1 (Line 60) ---\nbool TrafficLightTrackComponent::Init() {\n  // init component config\n  if (InitConfig() != cyber::SUCC) {\n    AERROR << \"TrafficLightTrackComponent InitConfig failed.\";\n    return false;\n  }\n  // init algorithm plugin\n  if (InitAlgorithmPlugin() != cyber::SUCC) {\n    AERROR << \"TrafficLightTrackComponent InitAlgorithmPlugin failed.\";\n    return false;\n  }\n\n  if (InitV2XListener() != cyber::SUCC) {\n    AERROR << \"TrafficLightTrackComponent InitV2XListener failed.\";\n    return false;\n  }\n\n  return true;\n}\n\nbool TrafficLightTrackComponent::Proc(\n"},{"type":"text","text":"Repository: apernet/hysteria\nPath: core/internal/congestion/bbr/bandwidth_sampler.go\nURL: https://github.com/apernet/hysteria/blob/master/core/internal/congestion/bbr/bandwidth_sampler.go\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 94) ---\n\treturn &bandwidthSample{\n\t\tsendRate: infBandwidth,\n\t}\n}\n\n// MaxAckHeightTracker is part of the BandwidthSampler. It is called after every\n// ack event to keep track the degree of ack aggregation(a.k.a \"ack height\").\ntype maxAckHeightTracker struct {\n\t// Tracks the maximum number of bytes acked faster than the estimated\n\t// bandwidth.\n\tmaxAckHeightFilter *WindowedFilter[extraAckedEvent, roundTripCount]\n\t// The time this aggregation started and the number of bytes acked during it.\n\taggregationEpochStartTime time.Time\n\n\n--- Snippet 2 (Line 113) ---\n\tackAggregationBandwidthThreshold       float64\n\tstartNewAggregationEpochAfterFullRound bool\n\treduceExtraAckedOnBandwidthIncrease    bool\n}\n\nfunc newMaxAckHeightTracker(windowLength roundTripCount) *maxAckHeightTracker {\n\treturn &maxAckHeightTracker{\n"},{"type":"text","text":"Repository: xroche/httrack\nPath: src/Makefile.in\nURL: https://github.com/xroche/httrack/blob/master/src/Makefile.in\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 89) ---\nNORMAL_UNINSTALL = :\nPRE_UNINSTALL = :\nPOST_UNINSTALL = :\nbuild_triplet = @build@\nhost_triplet = @host@\nbin_PROGRAMS = proxytrack$(EXEEXT) httrack$(EXEEXT) htsserver$(EXEEXT)\nsubdir = src\nACLOCAL_M4 = $(top_srcdir)/aclocal.m4\nam__aclocal_m4_deps = $(top_srcdir)/m4/check_zlib.m4 \\\n\t$(top_srcdir)/m4/libtool.m4 $(top_srcdir)/m4/ltoptions.m4 \\\n\t$(top_srcdir)/m4/ltsugar.m4 $(top_srcdir)/m4/ltversion.m4 \\\n\n\n--- Snippet 2 (Line 105) ---\nmkinstalldirs = $(install_sh) -d\nCONFIG_HEADER = $(top_builddir)/config.h\nCONFIG_CLEAN_FILES =\nCONFIG_CLEAN_VPATH_FILES =\nam__installdirs = \"$(DESTDIR)$(bindir)\" \"$(DESTDIR)$(libdir)\" \\\n\t\"$(DESTDIR)$(whttrackrundir)\" \"$(DESTDIR)$(DevIncludesdir)\"\nPROGRAMS = $(bin_PROGRAMS)\nam__vpath_adj_setup = srcdirstrip=`echo \"$(srcdir)\" | sed 's|.|.|g'`;\nam__vpath_adj = case $$p in \\\n"},{"type":"text","text":"Repository: flutter/flutter\nPath: packages/flutter/lib/src/material/slider_parts.dart\nURL: https://github.com/flutter/flutter/blob/master/packages/flutter/lib/src/material/slider_parts.dart\nLicense: BSD-3-Clause\n\nSnippets:\n--- Snippet 1 (Line 326) ---\n      begin: sliderTheme.disabledInactiveTrackColor,\n      end: sliderTheme.inactiveTrackColor,\n    );\n    final activePaint = Paint()..color = activeTrackColorTween.evaluate(enableAnimation)!;\n    final inactivePaint = Paint()..color = inactiveTrackColorTween.evaluate(enableAnimation)!;\n    final (Paint leftTrackPaint, Paint rightTrackPaint) = switch (textDirection) {\n      TextDirection.ltr => (activePaint, inactivePaint),\n      TextDirection.rtl => (inactivePaint, activePaint),\n    };\n\n    final Rect trackRect = getPreferredRect(\n\n\n--- Snippet 2 (Line 352) ---\n    }\n    final rightTrackSegment = Rect.fromLTRB(\n      thumbCenter.dx,\n      trackRect.top,\n      trackRect.right,\n      trackRect.bottom,\n    );\n    if (!rightTrackSegment.isEmpty) {\n      context.canvas.drawRect(rightTrackSegment, rightTrackPaint);\n"},{"type":"text","text":"Repository: xroche/httrack\nPath: libtest/example-main.c\nURL: https://github.com/xroche/httrack/blob/master/libtest/example-main.c\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n/*\n    HTTrack library example\n    .c file\n\n    Prerequisites:\n      - install winhttrack\n      - set the proper path in the project settings (especially for the httrack lib and dll)\n\n    How to build: (callback.so or callback.dll)\n      With GNU-GCC:\n        gcc -I/usr/include/httrack -O -g3 -Wall -D_REENTRANT -o example example.c -lhttrack2\n      With MS-Visual C++:\n        cl -nologo -W3 -Zi -Zp4 -DWIN32 -Fe\"mycallback.exe\" callbacks-example.c wsock32.lib libhttrack.lib\n*/\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n"},{"type":"text","text":"Repository: xroche/httrack\nPath: tests/11_crawl-international.test\nURL: https://github.com/xroche/httrack/blob/master/tests/11_crawl-international.test\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 9) ---\n\t--found ut.httrack.com/unicode-links/caf%a91bce.html \\\n\t--found ut.httrack.com/unicode-links/café30f4.html \\\n\t--found ut.httrack.com/unicode-links/café3860.html \\\n\t--found ut.httrack.com/unicode-links/café463e.html \\\n\t--found ut.httrack.com/unicode-links/café5e1f.html \\\n\t--found ut.httrack.com/unicode-links/café7b30.html \\\n\t--found ut.httrack.com/unicode-links/café8007.html \\\n\t--found ut.httrack.com/unicode-links/café9fa8.html \\\n\t--found ut.httrack.com/unicode-links/caféae52.html \\\n\t--found ut.httrack.com/unicode-links/caféc009.html \\\n\t--found ut.httrack.com/unicode-links/utf8.html \\\n\thttrack http://ut.httrack.com/unicode-links/utf8.html\n\nbash crawl-test.sh \\\n\t--errors 4 --files  7 \\\n\t--found ut.httrack.com/unicode-links/cafÃ©3860.html \\\n\t--found ut.httrack.com/unicode-links/cafÃ©9fa8.html \\\n\t--found ut.httrack.com/unicode-links/café30f4.html \\\n\t--found ut.httrack.com/unicode-links/café5e1f.html \\\n\t--found ut.httrack.com/unicode-links/café7b30.html \\\n\t--found ut.httrack.com/unicode-links/café8007.html \\\n"},{"type":"text","text":"Repository: Homebrew/homebrew-core\nPath: Formula/h/httrack.rb\nURL: https://github.com/Homebrew/homebrew-core/blob/main/Formula/h/httrack.rb\nLicense: BSD-2-Clause\n\nSnippets:\n--- Snippet 1 (Line 1) ---\nclass Httrack < Formula\n  desc \"Website copier/offline browser\"\n  homepage \"https://www.httrack.com/\"\n  # Always use mirror.httrack.com when you link to a new version of HTTrack, as\n  # link to download.httrack.com will break on next HTTrack update.\n  url \"https://mirror.httrack.com/historical/httrack-3.49.2.tar.gz\"\n  sha256 \"3477a0e5568e241c63c9899accbfcdb6aadef2812fcce0173688567b4c7d4025\"\n  license \"GPL-3.0-or-later\" => { with: \"openvpn-openssl-exception\" }\n  revision 1\n\n  livecheck do\n    url \"https://mirror.httrack.com/historical/\"\n    regex(/href=.*?httrack[._-]v?(\\d+(?:\\.\\d+)+)\\./i)\n  end\n\n  no_autobump! because: :requires_manual_review\n\n  bottle do\n"},{"type":"text","text":"Repository: xroche/httrack\nPath: src/htsweb.c\nURL: https://github.com/xroche/httrack/blob/master/src/htsweb.c\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n/* ------------------------------------------------------------ */\n/*\nHTTrack Website Copier, Offline Browser for Windows and Unix\nCopyright (C) 1998-2017 Xavier Roche and other contributors\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n\n\n--- Snippet 2 (Line 20) ---\n\n- We hereby ask people using this source NOT to use it in purpose of grabbing\nemails addresses, or collecting any other private information on persons.\nThis would disgrace our work, and spoil the many hours we spent on it.\n\nPlease visit our Website: http://www.httrack.com\n*/\n\n/* ------------------------------------------------------------ */\n/* File: webhttrack.c routines                                  */\n/* Author: Xavier Roche                                         */\n/* ------------------------------------------------------------ */\n"},{"type":"text","text":"Repository: xroche/httrack\nPath: libtest/example-main.h\nURL: https://github.com/xroche/httrack/blob/master/libtest/example-main.h\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n/*\n    HTTrack library example\n    .h file\n*/\n\n#ifdef __WIN32\n#define CDECL __cdecl\n#else\n#define CDECL\n#endif\n\nstatic void CDECL httrack_wrapper_init(t_hts_callbackarg * carg);\nstatic void CDECL httrack_wrapper_uninit(t_hts_callbackarg * carg);\nstatic int CDECL httrack_wrapper_start(t_hts_callbackarg * carg,\n                                       httrackp * opt);\nstatic int CDECL httrack_wrapper_chopt(t_hts_callbackarg * carg,\n                                       httrackp * opt);\nstatic int CDECL httrack_wrapper_end(t_hts_callbackarg * carg, httrackp * opt);\nstatic int CDECL httrack_wrapper_checkhtml(t_hts_callbackarg * carg,\n                                           httrackp * opt, char *html, int len,\n                                           const char *url_address,\n"},{"type":"text","text":"Repository: xroche/httrack\nPath: src/httrack-library.h\nURL: https://github.com/xroche/httrack/blob/master/src/httrack-library.h\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n/* ------------------------------------------------------------ */\n/*\nHTTrack Website Copier, Offline Browser for Windows and Unix\nCopyright (C) 1998-2017 Xavier Roche and other contributors\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n\n\n--- Snippet 2 (Line 23) ---\nThis would disgrace our work, and spoil the many hours we spent on it.\n\nPlease visit our Website: http://www.httrack.com\n*/\n\n/* ------------------------------------------------------------ */\n/* File: HTTrack definition file for library usage              */\n/* Author: Xavier Roche                                         */\n/* ------------------------------------------------------------ */\n\n#ifndef HTTRACK_DEFLIB\n#define HTTRACK_DEFLIB\n"}]}
{"parentUuid":"d715b252-3be0-4057-9f98-d554a1bb9726","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"faeb714a-61c5-410d-b669-0ebc662cf207","version":"2.0.70","gitBranch":"main","agentId":"abf8d80","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01TRL2d7y1Ur6JWaza3ZmjWG","type":"tool_result","content":[{"type":"text","text":"Repository: pr0v3rbs/FirmAE\nPath: sources/scraper/ftp.sh\nURL: https://github.com/pr0v3rbs/FirmAE/blob/master/sources/scraper/ftp.sh\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n#!/bin/sh\n\nwget --mirror -A zip,pkg,rar,bin,img --ignore-case ftp://ftp2.dlink.com/PRODUCTS -P output\n# wget --mirror -A zip,pkg,rar,bin,img ftp://ftp.dlink.eu/Products -P output\n# wget --mirror -A zip,pkg,rar,bin,img ftp://ftp.dlink.ru/pub -P output -P output\n# wget --mirror -A zip,pkg,rar,bin,img ftp://ftp.d-link.co.za -P output\n\nwget --mirror -A image --ignore-case ftp://ftp.avm.de/fritz.box -P output\n\nwget --mirror -A img,chk,bin,stk,zip,tar,sys,rar,pkg,rmt --ignore-case ftp://downloads.netgear.com -P output\n\nwget --mirror -A zip --ignore-case ftp://ftp.zyxel.com -P output\n\nwget --mirror -A bin --ignore-case ftp://ftp.dd-wrt.com -P output\n\n"},{"type":"text","text":"Repository: firmadyne/scraper\nPath: ftp.sh\nURL: https://github.com/firmadyne/scraper/blob/master/ftp.sh\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n#!/bin/sh\n\nwget --mirror -A zip,pkg,rar,bin,img --ignore-case ftp://ftp2.dlink.com/PRODUCTS -P output\n# wget --mirror -A zip,pkg,rar,bin,img ftp://ftp.dlink.eu/Products -P output\n# wget --mirror -A zip,pkg,rar,bin,img ftp://ftp.dlink.ru/pub -P output -P output\n# wget --mirror -A zip,pkg,rar,bin,img ftp://ftp.d-link.co.za -P output\n\nwget --mirror -A image --ignore-case ftp://ftp.avm.de/fritz.box -P output\n\nwget --mirror -A img,chk,bin,stk,zip,tar,sys,rar,pkg,rmt --ignore-case ftp://downloads.netgear.com -P output\n\nwget --mirror -A zip --ignore-case ftp://ftp.zyxel.com -P output\n\nwget --mirror -A bin --ignore-case ftp://ftp.dd-wrt.com -P output\n\n"},{"type":"text","text":"Repository: uwrit/postgis-docker\nPath: examples/wa.sh\nURL: https://github.com/uwrit/postgis-docker/blob/master/examples/wa.sh\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 59) ---\nwget --mirror  https://www2.census.gov/geo/tiger/TIGER2017/FACES/tl_2017_53001_faces.zip \n wget --mirror  https://www2.census.gov/geo/tiger/TIGER2017/FACES/tl_2017_53003_faces.zip \n wget --mirror  https://www2.census.gov/geo/tiger/TIGER2017/FACES/tl_2017_53005_faces.zip \n wget --mirror  https://www2.census.gov/geo/tiger/TIGER2017/FACES/tl_2017_53007_faces.zip \n wget --mirror  https://www2.census.gov/geo/tiger/TIGER2017/FACES/tl_2017_53009_faces.zip \n wget --mirror  https://www2.census.gov/geo/tiger/TIGER2017/FACES/tl_2017_53011_faces.zip \n wget --mirror  https://www2.census.gov/geo/tiger/TIGER2017/FACES/tl_2017_53013_faces.zip \n wget --mirror  https://www2.census.gov/geo/tiger/TIGER2017/FACES/tl_2017_53015_faces.zip \n wget --mirror  https://www2.census.gov/geo/tiger/TIGER2017/FACES/tl_2017_53017_faces.zip \n wget --mirror  https://www2.census.gov/geo/tiger/TIGER2017/FACES/tl_2017_53019_faces.zip \n wget --mirror  https://www2.census.gov/geo/tiger/TIGER2017/FACES/tl_2017_53021_faces.zip \n wget --mirror  https://www2.census.gov/geo/tiger/TIGER2017/FACES/tl_2017_53023_faces.zip \n wget --mirror  https://www2.census.gov/geo/tiger/TIGER2017/FACES/tl_2017_53025_faces.zip \n wget --mirror  https://www2.census.gov/geo/tiger/TIGER2017/FACES/tl_2017_53027_faces.zip \n wget --mirror  https://www2.census.gov/geo/tiger/TIGER2017/FACES/tl_2017_53029_faces.zip \n wget --mirror  https://www2.census.gov/geo/tiger/TIGER2017/FACES/tl_2017_53031_faces.zip \n wget --mirror  https://www2.census.gov/geo/tiger/TIGER2017/FACES/tl_2017_53033_faces.zip \n wget --mirror  https://www2.census.gov/geo/tiger/TIGER2017/FACES/tl_2017_53035_faces.zip \n wget --mirror  https://www2.census.gov/geo/tiger/TIGER2017/FACES/tl_2017_53037_faces.zip \n wget --mirror  https://www2.census.gov/geo/tiger/TIGER2017/FACES/tl_2017_53039_faces.zip \n wget --mirror  https://www2.census.gov/geo/tiger/TIGER2017/FACES/tl_2017_53041_faces.zip \n"},{"type":"text","text":"Repository: fleschutz/PowerShell\nPath: scripts/download-file.ps1\nURL: https://github.com/fleschutz/PowerShell/blob/main/scripts/download-file.ps1\nLicense: CC0-1.0\n\nSnippets:\n--- Snippet 1 (Line 21) ---\n\t$StopWatch = [system.diagnostics.stopwatch]::startNew()\n\n\t& wget --version\n\tif ($lastExitCode -ne 0) { throw \"Can't execute 'wget' - make sure wget is installed and available\" }\n\n\t& wget --mirror --convert-links --adjust-extension --page-requisites --no-parent $URL --directory-prefix . --no-verbose\n\tif ($lastExitCode -ne 0) { throw \"Can't execute 'wget --mirror $URL'\" }\n\n\t[int]$Elapsed = $StopWatch.Elapsed.TotalSeconds\n\t\"✅ downloaded file from $URL in $Elapsed sec\"\n\texit 0 # success\n} catch {\n"},{"type":"text","text":"Repository: fleschutz/PowerShell\nPath: scripts/download-dir.ps1\nURL: https://github.com/fleschutz/PowerShell/blob/main/scripts/download-dir.ps1\nLicense: CC0-1.0\n\nSnippets:\n--- Snippet 1 (Line 21) ---\n\t$StopWatch = [system.diagnostics.stopwatch]::startNew()\n\n\t& wget --version\n\tif ($lastExitCode -ne 0) { throw \"Can't execute 'wget' - make sure wget is installed and available\" }\n\n\t& wget --mirror --convert-links --adjust-extension --page-requisites --no-parent $URL --directory-prefix . --no-verbose\n\tif ($lastExitCode -ne 0) { throw \"Can't execute 'wget --mirror $URL'\" }\n\n\t[int]$Elapsed = $StopWatch.Elapsed.TotalSeconds\n\t\"✅ downloaded directory from $URL in $Elapsed sec\"\n\texit 0 # success\n} catch {\n"},{"type":"text","text":"Repository: starship/starship\nPath: install/macos_packages/build_component_package.sh\nURL: https://github.com/starship/starship/blob/master/install/macos_packages/build_component_package.sh\nLicense: ISC\n\nSnippets:\n--- Snippet 1 (Line 75) ---\n\n# Use wget to make a mirror of the site and move it into the package. Not installed\n# on MacOS by default, but lucky for us, it does exist on GHActions runners.\n# Wget may return nonzero exit codes even if things were mostly fine (e.g. 404 for\n# some links on translated pages) so we simply ignore if it has a failure\nwget --mirror --convert-links --adjust-extension --page-requisites --no-parent 127.0.0.1:8000 &>wget.log || true\nmkdir -p \"$pkgdir/usr/local/share/doc/\"\nmv 127.0.0.1:8000 \"$pkgdir/usr/local/share/doc/starship\"\n\n# Technically a race condition here, but very unlikely to hit it in practice.\ncleanup_server\n"},{"type":"text","text":"Repository: kubespray-offline/kubespray-offline\nPath: deprecated/mirror-docker-ce.sh\nURL: https://github.com/kubespray-offline/kubespray-offline/blob/develop/deprecated/mirror-docker-ce.sh\nLicense: Apache-2.0\n\nSnippets:\n--- Snippet 1 (Line 16) ---\n            VERSION_ID=8\n        elif echo \"$VERSION_ID\" | grep \"^7\\.\"; then\n            VERSION_ID=7\n        fi\n\n        wget --mirror --no-parent \\\n             https://download.docker.com/linux/${type}/${VERSION_ID}/x86_64/stable/   # need last slash for --no-parent\n\n        curl -SL https://download.docker.com/linux/${type}/gpg >download.docker.com/linux/${type}/gpg || exit 1\n\n        /bin/rm -rf outputs/rpms/docker-ce\n        mkdir -p outputs/rpms/\n        mv download.docker.com/linux/${type} outputs/rpms/docker-ce\n    else\n        # Ubuntu\n        wget --mirror --no-parent \\\n             -X linux/ubuntu/dists/${VERSION_CODENAME}/pool/edge \\\n             -X linux/ubuntu/dists/${VERSION_CODENAME}/pool/nightly \\\n             -X linux/ubuntu/dists/${VERSION_CODENAME}/pool/test \\\n             -X linux/ubuntu/dists/${VERSION_CODENAME}/pool/stable/arm64 \\\n             -X linux/ubuntu/dists/${VERSION_CODENAME}/pool/stable/ppc64el \\\n"},{"type":"text","text":"Repository: AhmadIbrahiim/Website-downloader\nPath: wget/index.js\nURL: https://github.com/AhmadIbrahiim/Website-downloader/blob/master/wget/index.js\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 6) ---\n\nmodule.exports=(io,data)=>{\n\n// download all website assets \n/**\n * wget --mirror --convert-links --adjust-extension --page-requisites \n * --no-parent http://example.org\n * --mirror – Makes (among other things) the download recursive.\n * --convert-links – convert all the links (also to stuff like CSS stylesheets) to relative, so it will be suitable for offline viewing.\n * --adjust-extension – Adds suitable extensions to filenames (html or css) depending on their content-type.\n * --page-requisites – Download things like CSS style-sheets and images required to properly display the page offline.\n"},{"type":"text","text":"Repository: cinemagoer/cinemagoer\nPath: docs/goodies/download-from-s3\nURL: https://github.com/cinemagoer/cinemagoer/blob/master/docs/goodies/download-from-s3\nLicense: GPL-2.0\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n#!/bin/sh\n\ntoday=\"`date +'%Y-%m-%d'`\"\n\nwget --mirror --no-parent -A tsv.gz --no-host-directories --directory-prefix=imdb-dataset-${today}  https://datasets.imdbws.com/\n"},{"type":"text","text":"Repository: erlyaws/yaws\nPath: scripts/update-gh-pages\nURL: https://github.com/erlyaws/yaws/blob/master/scripts/update-gh-pages\nLicense: BSD-3-Clause\n\nSnippets:\n--- Snippet 1 (Line 31) ---\n# clone erlyaws.github.io gh-pages repo\ncd \"$BUILD_DIR\"\ngit clone git@github.com:erlyaws/$REPO\n\n# mirror the site\nwget --mirror \\\n     --max-redirect 0 \\\n     --directory-prefix $REPO \\\n     --no-host-directories \\\n     localhost:8000\n\n"}]}]},"uuid":"298587fb-4dca-49e1-a55b-f94af995efac","timestamp":"2025-12-19T04:43:54.325Z","toolUseResult":[{"type":"text","text":"Repository: pr0v3rbs/FirmAE\nPath: sources/scraper/ftp.sh\nURL: https://github.com/pr0v3rbs/FirmAE/blob/master/sources/scraper/ftp.sh\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n#!/bin/sh\n\nwget --mirror -A zip,pkg,rar,bin,img --ignore-case ftp://ftp2.dlink.com/PRODUCTS -P output\n# wget --mirror -A zip,pkg,rar,bin,img ftp://ftp.dlink.eu/Products -P output\n# wget --mirror -A zip,pkg,rar,bin,img ftp://ftp.dlink.ru/pub -P output -P output\n# wget --mirror -A zip,pkg,rar,bin,img ftp://ftp.d-link.co.za -P output\n\nwget --mirror -A image --ignore-case ftp://ftp.avm.de/fritz.box -P output\n\nwget --mirror -A img,chk,bin,stk,zip,tar,sys,rar,pkg,rmt --ignore-case ftp://downloads.netgear.com -P output\n\nwget --mirror -A zip --ignore-case ftp://ftp.zyxel.com -P output\n\nwget --mirror -A bin --ignore-case ftp://ftp.dd-wrt.com -P output\n\n"},{"type":"text","text":"Repository: firmadyne/scraper\nPath: ftp.sh\nURL: https://github.com/firmadyne/scraper/blob/master/ftp.sh\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n#!/bin/sh\n\nwget --mirror -A zip,pkg,rar,bin,img --ignore-case ftp://ftp2.dlink.com/PRODUCTS -P output\n# wget --mirror -A zip,pkg,rar,bin,img ftp://ftp.dlink.eu/Products -P output\n# wget --mirror -A zip,pkg,rar,bin,img ftp://ftp.dlink.ru/pub -P output -P output\n# wget --mirror -A zip,pkg,rar,bin,img ftp://ftp.d-link.co.za -P output\n\nwget --mirror -A image --ignore-case ftp://ftp.avm.de/fritz.box -P output\n\nwget --mirror -A img,chk,bin,stk,zip,tar,sys,rar,pkg,rmt --ignore-case ftp://downloads.netgear.com -P output\n\nwget --mirror -A zip --ignore-case ftp://ftp.zyxel.com -P output\n\nwget --mirror -A bin --ignore-case ftp://ftp.dd-wrt.com -P output\n\n"},{"type":"text","text":"Repository: uwrit/postgis-docker\nPath: examples/wa.sh\nURL: https://github.com/uwrit/postgis-docker/blob/master/examples/wa.sh\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 59) ---\nwget --mirror  https://www2.census.gov/geo/tiger/TIGER2017/FACES/tl_2017_53001_faces.zip \n wget --mirror  https://www2.census.gov/geo/tiger/TIGER2017/FACES/tl_2017_53003_faces.zip \n wget --mirror  https://www2.census.gov/geo/tiger/TIGER2017/FACES/tl_2017_53005_faces.zip \n wget --mirror  https://www2.census.gov/geo/tiger/TIGER2017/FACES/tl_2017_53007_faces.zip \n wget --mirror  https://www2.census.gov/geo/tiger/TIGER2017/FACES/tl_2017_53009_faces.zip \n wget --mirror  https://www2.census.gov/geo/tiger/TIGER2017/FACES/tl_2017_53011_faces.zip \n wget --mirror  https://www2.census.gov/geo/tiger/TIGER2017/FACES/tl_2017_53013_faces.zip \n wget --mirror  https://www2.census.gov/geo/tiger/TIGER2017/FACES/tl_2017_53015_faces.zip \n wget --mirror  https://www2.census.gov/geo/tiger/TIGER2017/FACES/tl_2017_53017_faces.zip \n wget --mirror  https://www2.census.gov/geo/tiger/TIGER2017/FACES/tl_2017_53019_faces.zip \n wget --mirror  https://www2.census.gov/geo/tiger/TIGER2017/FACES/tl_2017_53021_faces.zip \n wget --mirror  https://www2.census.gov/geo/tiger/TIGER2017/FACES/tl_2017_53023_faces.zip \n wget --mirror  https://www2.census.gov/geo/tiger/TIGER2017/FACES/tl_2017_53025_faces.zip \n wget --mirror  https://www2.census.gov/geo/tiger/TIGER2017/FACES/tl_2017_53027_faces.zip \n wget --mirror  https://www2.census.gov/geo/tiger/TIGER2017/FACES/tl_2017_53029_faces.zip \n wget --mirror  https://www2.census.gov/geo/tiger/TIGER2017/FACES/tl_2017_53031_faces.zip \n wget --mirror  https://www2.census.gov/geo/tiger/TIGER2017/FACES/tl_2017_53033_faces.zip \n wget --mirror  https://www2.census.gov/geo/tiger/TIGER2017/FACES/tl_2017_53035_faces.zip \n wget --mirror  https://www2.census.gov/geo/tiger/TIGER2017/FACES/tl_2017_53037_faces.zip \n wget --mirror  https://www2.census.gov/geo/tiger/TIGER2017/FACES/tl_2017_53039_faces.zip \n wget --mirror  https://www2.census.gov/geo/tiger/TIGER2017/FACES/tl_2017_53041_faces.zip \n"},{"type":"text","text":"Repository: fleschutz/PowerShell\nPath: scripts/download-file.ps1\nURL: https://github.com/fleschutz/PowerShell/blob/main/scripts/download-file.ps1\nLicense: CC0-1.0\n\nSnippets:\n--- Snippet 1 (Line 21) ---\n\t$StopWatch = [system.diagnostics.stopwatch]::startNew()\n\n\t& wget --version\n\tif ($lastExitCode -ne 0) { throw \"Can't execute 'wget' - make sure wget is installed and available\" }\n\n\t& wget --mirror --convert-links --adjust-extension --page-requisites --no-parent $URL --directory-prefix . --no-verbose\n\tif ($lastExitCode -ne 0) { throw \"Can't execute 'wget --mirror $URL'\" }\n\n\t[int]$Elapsed = $StopWatch.Elapsed.TotalSeconds\n\t\"✅ downloaded file from $URL in $Elapsed sec\"\n\texit 0 # success\n} catch {\n"},{"type":"text","text":"Repository: fleschutz/PowerShell\nPath: scripts/download-dir.ps1\nURL: https://github.com/fleschutz/PowerShell/blob/main/scripts/download-dir.ps1\nLicense: CC0-1.0\n\nSnippets:\n--- Snippet 1 (Line 21) ---\n\t$StopWatch = [system.diagnostics.stopwatch]::startNew()\n\n\t& wget --version\n\tif ($lastExitCode -ne 0) { throw \"Can't execute 'wget' - make sure wget is installed and available\" }\n\n\t& wget --mirror --convert-links --adjust-extension --page-requisites --no-parent $URL --directory-prefix . --no-verbose\n\tif ($lastExitCode -ne 0) { throw \"Can't execute 'wget --mirror $URL'\" }\n\n\t[int]$Elapsed = $StopWatch.Elapsed.TotalSeconds\n\t\"✅ downloaded directory from $URL in $Elapsed sec\"\n\texit 0 # success\n} catch {\n"},{"type":"text","text":"Repository: starship/starship\nPath: install/macos_packages/build_component_package.sh\nURL: https://github.com/starship/starship/blob/master/install/macos_packages/build_component_package.sh\nLicense: ISC\n\nSnippets:\n--- Snippet 1 (Line 75) ---\n\n# Use wget to make a mirror of the site and move it into the package. Not installed\n# on MacOS by default, but lucky for us, it does exist on GHActions runners.\n# Wget may return nonzero exit codes even if things were mostly fine (e.g. 404 for\n# some links on translated pages) so we simply ignore if it has a failure\nwget --mirror --convert-links --adjust-extension --page-requisites --no-parent 127.0.0.1:8000 &>wget.log || true\nmkdir -p \"$pkgdir/usr/local/share/doc/\"\nmv 127.0.0.1:8000 \"$pkgdir/usr/local/share/doc/starship\"\n\n# Technically a race condition here, but very unlikely to hit it in practice.\ncleanup_server\n"},{"type":"text","text":"Repository: kubespray-offline/kubespray-offline\nPath: deprecated/mirror-docker-ce.sh\nURL: https://github.com/kubespray-offline/kubespray-offline/blob/develop/deprecated/mirror-docker-ce.sh\nLicense: Apache-2.0\n\nSnippets:\n--- Snippet 1 (Line 16) ---\n            VERSION_ID=8\n        elif echo \"$VERSION_ID\" | grep \"^7\\.\"; then\n            VERSION_ID=7\n        fi\n\n        wget --mirror --no-parent \\\n             https://download.docker.com/linux/${type}/${VERSION_ID}/x86_64/stable/   # need last slash for --no-parent\n\n        curl -SL https://download.docker.com/linux/${type}/gpg >download.docker.com/linux/${type}/gpg || exit 1\n\n        /bin/rm -rf outputs/rpms/docker-ce\n        mkdir -p outputs/rpms/\n        mv download.docker.com/linux/${type} outputs/rpms/docker-ce\n    else\n        # Ubuntu\n        wget --mirror --no-parent \\\n             -X linux/ubuntu/dists/${VERSION_CODENAME}/pool/edge \\\n             -X linux/ubuntu/dists/${VERSION_CODENAME}/pool/nightly \\\n             -X linux/ubuntu/dists/${VERSION_CODENAME}/pool/test \\\n             -X linux/ubuntu/dists/${VERSION_CODENAME}/pool/stable/arm64 \\\n             -X linux/ubuntu/dists/${VERSION_CODENAME}/pool/stable/ppc64el \\\n"},{"type":"text","text":"Repository: AhmadIbrahiim/Website-downloader\nPath: wget/index.js\nURL: https://github.com/AhmadIbrahiim/Website-downloader/blob/master/wget/index.js\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 6) ---\n\nmodule.exports=(io,data)=>{\n\n// download all website assets \n/**\n * wget --mirror --convert-links --adjust-extension --page-requisites \n * --no-parent http://example.org\n * --mirror – Makes (among other things) the download recursive.\n * --convert-links – convert all the links (also to stuff like CSS stylesheets) to relative, so it will be suitable for offline viewing.\n * --adjust-extension – Adds suitable extensions to filenames (html or css) depending on their content-type.\n * --page-requisites – Download things like CSS style-sheets and images required to properly display the page offline.\n"},{"type":"text","text":"Repository: cinemagoer/cinemagoer\nPath: docs/goodies/download-from-s3\nURL: https://github.com/cinemagoer/cinemagoer/blob/master/docs/goodies/download-from-s3\nLicense: GPL-2.0\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n#!/bin/sh\n\ntoday=\"`date +'%Y-%m-%d'`\"\n\nwget --mirror --no-parent -A tsv.gz --no-host-directories --directory-prefix=imdb-dataset-${today}  https://datasets.imdbws.com/\n"},{"type":"text","text":"Repository: erlyaws/yaws\nPath: scripts/update-gh-pages\nURL: https://github.com/erlyaws/yaws/blob/master/scripts/update-gh-pages\nLicense: BSD-3-Clause\n\nSnippets:\n--- Snippet 1 (Line 31) ---\n# clone erlyaws.github.io gh-pages repo\ncd \"$BUILD_DIR\"\ngit clone git@github.com:erlyaws/$REPO\n\n# mirror the site\nwget --mirror \\\n     --max-redirect 0 \\\n     --directory-prefix $REPO \\\n     --no-host-directories \\\n     localhost:8000\n\n"}]}
{"parentUuid":"298587fb-4dca-49e1-a55b-f94af995efac","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"faeb714a-61c5-410d-b669-0ebc662cf207","version":"2.0.70","gitBranch":"main","agentId":"abf8d80","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_017Uhb4NV2o71mp3mBed2KLf","type":"tool_result","content":[{"type":"text","text":"Repository: Y2Z/monolith\nPath: src/core.rs\nURL: https://github.com/Y2Z/monolith/blob/master/src/core.rs\nLicense: CC0-1.0\n\nSnippets:\n--- Snippet 1 (Line 19) ---\n\n#[derive(Debug)]\npub struct MonolithError {\n    details: String,\n}\n\nimpl MonolithError {\n    fn new(msg: &str) -> MonolithError {\n        MonolithError {\n            details: msg.to_string(),\n        }\n    }\n}\n\nimpl fmt::Display for MonolithError {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        write!(f, \"{}\", self.details)\n    }\n}\n\nimpl Error for MonolithError {\n"},{"type":"text","text":"Repository: Y2Z/monolith\nPath: src/gui.rs\nURL: https://github.com/Y2Z/monolith/blob/master/src/gui.rs\nLicense: CC0-1.0\n\nSnippets:\n--- Snippet 1 (Line 9) ---\n    commands, AppDelegate, AppLauncher, Command, Data, DelegateCtx, Env, FileDialogOptions,\n    FileSpec, Handled, Lens, LocalizedString, PlatformError, Target, Widget, WidgetExt, WindowDesc,\n};\nuse tempfile::{Builder, NamedTempFile};\n\nuse monolith::cache::Cache;\nuse monolith::core::{\n    create_monolithic_document, format_output_path, MonolithError, MonolithOptions,\n    MonolithOutputFormat,\n};\nuse monolith::session::Session;\n\nconst CACHE_ASSET_FILE_SIZE_THRESHOLD: usize = 1024 * 20; // Minimum file size for on-disk caching (in bytes)\nconst FILESPEC_HTML: FileSpec = FileSpec::new(\"HTML files\", &[\"html\"]);\nconst MONOLITH_GUI_WRITE_OUTPUT: druid::Selector<(Vec<u8>, Option<String>)> =\n    druid::Selector::new(\"monolith-gui.write-output\");\nconst MONOLITH_GUI_ERROR: druid::Selector<MonolithError> =\n    druid::Selector::new(\"monolith-gui.error\");\nconst TEXT_BOX_WIDTH: f64 = 512_f64;\n\nstruct Delegate;\n"},{"type":"text","text":"Repository: Y2Z/monolith\nPath: tests/html/embed_srcset.rs\nURL: https://github.com/Y2Z/monolith/blob/master/tests/html/embed_srcset.rs\nLicense: CC0-1.0\n\nSnippets:\n--- Snippet 1 (Line 7) ---\n\n#[cfg(test)]\nmod passing {\n    use reqwest::Url;\n\n    use monolith::core::MonolithOptions;\n    use monolith::html;\n    use monolith::session::Session;\n    use monolith::url::EMPTY_IMAGE_DATA_URL;\n\n    #[test]\n    fn small_medium_large() {\n        let srcset_value = \"small.png 1x, medium.png 1.5x, large.png 2x\";\n        let mut options = MonolithOptions::default();\n        options.no_images = true;\n        options.silent = true;\n        let mut session: Session = Session::new(None, None, options);\n        let embedded_css =\n            html::embed_srcset(&mut session, &Url::parse(\"data:,\").unwrap(), srcset_value);\n"},{"type":"text","text":"Repository: Y2Z/monolith\nPath: tests/html/walk.rs\nURL: https://github.com/Y2Z/monolith/blob/master/tests/html/walk.rs\nLicense: CC0-1.0\n\nSnippets:\n--- Snippet 1 (Line 9) ---\nmod passing {\n    use html5ever::serialize::{serialize, SerializeOpts};\n    use markup5ever_rcdom::SerializableHandle;\n    use url::Url;\n\n    use monolith::core::MonolithOptions;\n    use monolith::html;\n    use monolith::session::Session;\n    use monolith::url::EMPTY_IMAGE_DATA_URL;\n\n    #[test]\n    fn basic() {\n        let html: &str = \"<div><P></P></div>\";\n        let dom = html::html_to_dom(&html.as_bytes().to_vec(), \"\".to_string());\n        let url: Url = Url::parse(\"http://localhost\").unwrap();\n\n        let mut options = MonolithOptions::default();\n        options.silent = true;\n\n        let mut session: Session = Session::new(None, None, options);\n\n"},{"type":"text","text":"Repository: Y2Z/monolith\nPath: tests/css/embed_css.rs\nURL: https://github.com/Y2Z/monolith/blob/master/tests/css/embed_css.rs\nLicense: CC0-1.0\n\nSnippets:\n--- Snippet 1 (Line 9) ---\nmod passing {\n    use reqwest::Url;\n\n    use monolith::core::MonolithOptions;\n    use monolith::css;\n    use monolith::session::Session;\n    use monolith::url::EMPTY_IMAGE_DATA_URL;\n\n    #[test]\n    fn empty_input() {\n        let document_url: Url = Url::parse(\"data:,\").unwrap();\n        let options = MonolithOptions::default();\n        let mut session: Session = Session::new(None, None, options);\n\n        assert_eq!(css::embed_css(&mut session, &document_url, \"\"), \"\");\n    }\n\n    #[test]\n    fn trim_if_empty() {\n        let document_url: Url = Url::parse(\"https://doesntmatter.local/\").unwrap();\n        let options = MonolithOptions::default();\n"},{"type":"text","text":"Repository: Y2Z/monolith\nPath: src/main.rs\nURL: https://github.com/Y2Z/monolith/blob/master/src/main.rs\nLicense: CC0-1.0\n\nSnippets:\n--- Snippet 1 (Line 3) ---\nuse std::process;\n\nuse clap::Parser;\nuse tempfile::{Builder, NamedTempFile};\n\nuse monolith::cache::Cache;\nuse monolith::cookies::{parse_cookie_file_contents, Cookie};\nuse monolith::core::{\n    create_monolithic_document, create_monolithic_document_from_data, format_output_path,\n    print_error_message, MonolithOptions, MonolithOutputFormat,\n};\nuse monolith::session::Session;\n\nconst ASCII: &str = \" \\\n _____    _____________   __________     ___________________    ___\n|     \\\\  /             \\\\ |          |   |                   |  |   |\n|      \\\\/       __      \\\\|    __    |   |    ___     ___    |__|   |\n"},{"type":"text","text":"Repository: Y2Z/monolith\nPath: tests/core/format_output_path.rs\nURL: https://github.com/Y2Z/monolith/blob/master/tests/core/format_output_path.rs\nLicense: CC0-1.0\n\nSnippets:\n--- Snippet 1 (Line 8) ---\n#[cfg(test)]\nmod passing {\n    use monolith::core::{format_output_path, MonolithOutputFormat};\n\n    #[test]\n    fn as_is() {\n        let final_destination = format_output_path(\n            \"/home/username/Downloads/website.html\",\n            \"\",\n            MonolithOutputFormat::HTML,\n        );\n\n        assert_eq!(final_destination, \"/home/username/Downloads/website.html\");\n    }\n\n    #[test]\n    fn substitute_title() {\n        let final_destination = format_output_path(\n            \"/home/username/Downloads/%title%.html\",\n            \"Document Title\",\n            MonolithOutputFormat::HTML,\n"},{"type":"text","text":"Repository: Y2Z/monolith\nPath: tests/session/retrieve_asset.rs\nURL: https://github.com/Y2Z/monolith/blob/master/tests/session/retrieve_asset.rs\nLicense: CC0-1.0\n\nSnippets:\n--- Snippet 1 (Line 8) ---\n#[cfg(test)]\nmod passing {\n    use reqwest::Url;\n    use std::env;\n\n    use monolith::core::MonolithOptions;\n    use monolith::session::Session;\n    use monolith::url;\n\n    #[test]\n    fn read_data_url() {\n        let mut options = MonolithOptions::default();\n        options.silent = true;\n\n        let mut session: Session = Session::new(None, None, options);\n\n        // If both source and target are data URLs,\n"},{"type":"text","text":"Repository: Y2Z/monolith\nPath: tests/html/compose_csp.rs\nURL: https://github.com/Y2Z/monolith/blob/master/tests/html/compose_csp.rs\nLicense: CC0-1.0\n\nSnippets:\n--- Snippet 1 (Line 5) ---\n//  ██║     ██║  ██║███████║███████║██║██║ ╚████║╚██████╔╝\n//  ╚═╝     ╚═╝  ╚═╝╚══════╝╚══════╝╚═╝╚═╝  ╚═══╝ ╚═════╝\n\n#[cfg(test)]\nmod passing {\n    use monolith::core::MonolithOptions;\n    use monolith::html;\n\n    #[test]\n    fn isolated() {\n        let mut options = MonolithOptions::default();\n        options.isolate = true;\n        let csp_content = html::compose_csp(&options);\n\n        assert_eq!(\n            csp_content,\n"},{"type":"text","text":"Repository: dyc3/opentogethertube\nPath: crates/ott-balancer/src/balancer.rs\nURL: https://github.com/dyc3/opentogethertube/blob/master/crates/ott-balancer/src/balancer.rs\nLicense: AGPL-3.0\n\nSnippets:\n--- Snippet 1 (Line 1) ---\nuse std::{collections::HashMap, sync::Arc};\n\nuse futures_util::stream::FuturesUnordered;\nuse futures_util::StreamExt;\nuse ott_balancer_protocol::collector::{BalancerState, MonolithState, RoomState};\nuse ott_balancer_protocol::monolith::{\n    B2MClientMsg, B2MJoin, B2MLeave, B2MUnload, MsgB2M, MsgM2B, RoomMetadata,\n};\nuse ott_balancer_protocol::*;\nuse serde_json::value::RawValue;\nuse tokio::sync::RwLock;\n\n\n--- Snippet 2 (Line 20) ---\nuse crate::config::BalancerConfig;\nuse crate::connection::BALANCER_ID;\nuse crate::monolith::{MonolithSendError, Room};\nuse crate::room::RoomLocator;\nuse crate::selection::{MonolithSelection, MonolithSelectionStrategy};\nuse crate::{\n    client::{BalancerClient, NewClient},\n    messages::*,\n    monolith::{BalancerMonolith, NewMonolith},\n"}]}]},"uuid":"8d5b0aa9-e427-4763-9ad1-acdc956f2b6f","timestamp":"2025-12-19T04:43:54.617Z","toolUseResult":[{"type":"text","text":"Repository: Y2Z/monolith\nPath: src/core.rs\nURL: https://github.com/Y2Z/monolith/blob/master/src/core.rs\nLicense: CC0-1.0\n\nSnippets:\n--- Snippet 1 (Line 19) ---\n\n#[derive(Debug)]\npub struct MonolithError {\n    details: String,\n}\n\nimpl MonolithError {\n    fn new(msg: &str) -> MonolithError {\n        MonolithError {\n            details: msg.to_string(),\n        }\n    }\n}\n\nimpl fmt::Display for MonolithError {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        write!(f, \"{}\", self.details)\n    }\n}\n\nimpl Error for MonolithError {\n"},{"type":"text","text":"Repository: Y2Z/monolith\nPath: src/gui.rs\nURL: https://github.com/Y2Z/monolith/blob/master/src/gui.rs\nLicense: CC0-1.0\n\nSnippets:\n--- Snippet 1 (Line 9) ---\n    commands, AppDelegate, AppLauncher, Command, Data, DelegateCtx, Env, FileDialogOptions,\n    FileSpec, Handled, Lens, LocalizedString, PlatformError, Target, Widget, WidgetExt, WindowDesc,\n};\nuse tempfile::{Builder, NamedTempFile};\n\nuse monolith::cache::Cache;\nuse monolith::core::{\n    create_monolithic_document, format_output_path, MonolithError, MonolithOptions,\n    MonolithOutputFormat,\n};\nuse monolith::session::Session;\n\nconst CACHE_ASSET_FILE_SIZE_THRESHOLD: usize = 1024 * 20; // Minimum file size for on-disk caching (in bytes)\nconst FILESPEC_HTML: FileSpec = FileSpec::new(\"HTML files\", &[\"html\"]);\nconst MONOLITH_GUI_WRITE_OUTPUT: druid::Selector<(Vec<u8>, Option<String>)> =\n    druid::Selector::new(\"monolith-gui.write-output\");\nconst MONOLITH_GUI_ERROR: druid::Selector<MonolithError> =\n    druid::Selector::new(\"monolith-gui.error\");\nconst TEXT_BOX_WIDTH: f64 = 512_f64;\n\nstruct Delegate;\n"},{"type":"text","text":"Repository: Y2Z/monolith\nPath: tests/html/embed_srcset.rs\nURL: https://github.com/Y2Z/monolith/blob/master/tests/html/embed_srcset.rs\nLicense: CC0-1.0\n\nSnippets:\n--- Snippet 1 (Line 7) ---\n\n#[cfg(test)]\nmod passing {\n    use reqwest::Url;\n\n    use monolith::core::MonolithOptions;\n    use monolith::html;\n    use monolith::session::Session;\n    use monolith::url::EMPTY_IMAGE_DATA_URL;\n\n    #[test]\n    fn small_medium_large() {\n        let srcset_value = \"small.png 1x, medium.png 1.5x, large.png 2x\";\n        let mut options = MonolithOptions::default();\n        options.no_images = true;\n        options.silent = true;\n        let mut session: Session = Session::new(None, None, options);\n        let embedded_css =\n            html::embed_srcset(&mut session, &Url::parse(\"data:,\").unwrap(), srcset_value);\n"},{"type":"text","text":"Repository: Y2Z/monolith\nPath: tests/html/walk.rs\nURL: https://github.com/Y2Z/monolith/blob/master/tests/html/walk.rs\nLicense: CC0-1.0\n\nSnippets:\n--- Snippet 1 (Line 9) ---\nmod passing {\n    use html5ever::serialize::{serialize, SerializeOpts};\n    use markup5ever_rcdom::SerializableHandle;\n    use url::Url;\n\n    use monolith::core::MonolithOptions;\n    use monolith::html;\n    use monolith::session::Session;\n    use monolith::url::EMPTY_IMAGE_DATA_URL;\n\n    #[test]\n    fn basic() {\n        let html: &str = \"<div><P></P></div>\";\n        let dom = html::html_to_dom(&html.as_bytes().to_vec(), \"\".to_string());\n        let url: Url = Url::parse(\"http://localhost\").unwrap();\n\n        let mut options = MonolithOptions::default();\n        options.silent = true;\n\n        let mut session: Session = Session::new(None, None, options);\n\n"},{"type":"text","text":"Repository: Y2Z/monolith\nPath: tests/css/embed_css.rs\nURL: https://github.com/Y2Z/monolith/blob/master/tests/css/embed_css.rs\nLicense: CC0-1.0\n\nSnippets:\n--- Snippet 1 (Line 9) ---\nmod passing {\n    use reqwest::Url;\n\n    use monolith::core::MonolithOptions;\n    use monolith::css;\n    use monolith::session::Session;\n    use monolith::url::EMPTY_IMAGE_DATA_URL;\n\n    #[test]\n    fn empty_input() {\n        let document_url: Url = Url::parse(\"data:,\").unwrap();\n        let options = MonolithOptions::default();\n        let mut session: Session = Session::new(None, None, options);\n\n        assert_eq!(css::embed_css(&mut session, &document_url, \"\"), \"\");\n    }\n\n    #[test]\n    fn trim_if_empty() {\n        let document_url: Url = Url::parse(\"https://doesntmatter.local/\").unwrap();\n        let options = MonolithOptions::default();\n"},{"type":"text","text":"Repository: Y2Z/monolith\nPath: src/main.rs\nURL: https://github.com/Y2Z/monolith/blob/master/src/main.rs\nLicense: CC0-1.0\n\nSnippets:\n--- Snippet 1 (Line 3) ---\nuse std::process;\n\nuse clap::Parser;\nuse tempfile::{Builder, NamedTempFile};\n\nuse monolith::cache::Cache;\nuse monolith::cookies::{parse_cookie_file_contents, Cookie};\nuse monolith::core::{\n    create_monolithic_document, create_monolithic_document_from_data, format_output_path,\n    print_error_message, MonolithOptions, MonolithOutputFormat,\n};\nuse monolith::session::Session;\n\nconst ASCII: &str = \" \\\n _____    _____________   __________     ___________________    ___\n|     \\\\  /             \\\\ |          |   |                   |  |   |\n|      \\\\/       __      \\\\|    __    |   |    ___     ___    |__|   |\n"},{"type":"text","text":"Repository: Y2Z/monolith\nPath: tests/core/format_output_path.rs\nURL: https://github.com/Y2Z/monolith/blob/master/tests/core/format_output_path.rs\nLicense: CC0-1.0\n\nSnippets:\n--- Snippet 1 (Line 8) ---\n#[cfg(test)]\nmod passing {\n    use monolith::core::{format_output_path, MonolithOutputFormat};\n\n    #[test]\n    fn as_is() {\n        let final_destination = format_output_path(\n            \"/home/username/Downloads/website.html\",\n            \"\",\n            MonolithOutputFormat::HTML,\n        );\n\n        assert_eq!(final_destination, \"/home/username/Downloads/website.html\");\n    }\n\n    #[test]\n    fn substitute_title() {\n        let final_destination = format_output_path(\n            \"/home/username/Downloads/%title%.html\",\n            \"Document Title\",\n            MonolithOutputFormat::HTML,\n"},{"type":"text","text":"Repository: Y2Z/monolith\nPath: tests/session/retrieve_asset.rs\nURL: https://github.com/Y2Z/monolith/blob/master/tests/session/retrieve_asset.rs\nLicense: CC0-1.0\n\nSnippets:\n--- Snippet 1 (Line 8) ---\n#[cfg(test)]\nmod passing {\n    use reqwest::Url;\n    use std::env;\n\n    use monolith::core::MonolithOptions;\n    use monolith::session::Session;\n    use monolith::url;\n\n    #[test]\n    fn read_data_url() {\n        let mut options = MonolithOptions::default();\n        options.silent = true;\n\n        let mut session: Session = Session::new(None, None, options);\n\n        // If both source and target are data URLs,\n"},{"type":"text","text":"Repository: Y2Z/monolith\nPath: tests/html/compose_csp.rs\nURL: https://github.com/Y2Z/monolith/blob/master/tests/html/compose_csp.rs\nLicense: CC0-1.0\n\nSnippets:\n--- Snippet 1 (Line 5) ---\n//  ██║     ██║  ██║███████║███████║██║██║ ╚████║╚██████╔╝\n//  ╚═╝     ╚═╝  ╚═╝╚══════╝╚══════╝╚═╝╚═╝  ╚═══╝ ╚═════╝\n\n#[cfg(test)]\nmod passing {\n    use monolith::core::MonolithOptions;\n    use monolith::html;\n\n    #[test]\n    fn isolated() {\n        let mut options = MonolithOptions::default();\n        options.isolate = true;\n        let csp_content = html::compose_csp(&options);\n\n        assert_eq!(\n            csp_content,\n"},{"type":"text","text":"Repository: dyc3/opentogethertube\nPath: crates/ott-balancer/src/balancer.rs\nURL: https://github.com/dyc3/opentogethertube/blob/master/crates/ott-balancer/src/balancer.rs\nLicense: AGPL-3.0\n\nSnippets:\n--- Snippet 1 (Line 1) ---\nuse std::{collections::HashMap, sync::Arc};\n\nuse futures_util::stream::FuturesUnordered;\nuse futures_util::StreamExt;\nuse ott_balancer_protocol::collector::{BalancerState, MonolithState, RoomState};\nuse ott_balancer_protocol::monolith::{\n    B2MClientMsg, B2MJoin, B2MLeave, B2MUnload, MsgB2M, MsgM2B, RoomMetadata,\n};\nuse ott_balancer_protocol::*;\nuse serde_json::value::RawValue;\nuse tokio::sync::RwLock;\n\n\n--- Snippet 2 (Line 20) ---\nuse crate::config::BalancerConfig;\nuse crate::connection::BALANCER_ID;\nuse crate::monolith::{MonolithSendError, Room};\nuse crate::room::RoomLocator;\nuse crate::selection::{MonolithSelection, MonolithSelectionStrategy};\nuse crate::{\n    client::{BalancerClient, NewClient},\n    messages::*,\n    monolith::{BalancerMonolith, NewMonolith},\n"}]}
{"parentUuid":"8d5b0aa9-e427-4763-9ad1-acdc956f2b6f","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"faeb714a-61c5-410d-b669-0ebc662cf207","version":"2.0.70","gitBranch":"main","agentId":"abf8d80","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01P4S3gkEQTvyntiCQfs9dti","type":"tool_result","content":[{"type":"text","text":"Repository: NixOS/nixpkgs\nPath: pkgs/by-name/we/web-archives/package.nix\nURL: https://github.com/NixOS/nixpkgs/blob/master/pkgs/by-name/we/web-archives/package.nix\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 22) ---\n  pname = \"web-archives\";\n  version = \"0.5.0\";\n\n  src = fetchFromGitHub {\n    owner = \"birros\";\n    repo = \"web-archives\";\n    rev = \"v${finalAttrs.version}\";\n    hash = \"sha256-EYHChI+4tpjRp4KveHTB+5BSLtw0YLp5z2JJmA0xTlM=\";\n  };\n\n  web-archive-darkreader = fetchurl {\n    # This is the same with build-aux/darkreader/Makefile\n    url = \"https://github.com/birros/web-archives-darkreader/releases/download/v0.0.1/web-archives-darkreader_v0.0.1.js\";\n    hash = \"sha256-juhAqs2eCYZKerLnX3NvaW3NS0uOhqB7pyf/PRDvMqE=\";\n  };\n\n  postPatch = ''\n    substituteInPlace meson.build \\\n      --replace-fail \\\n        \"'make', '-C', 'build-aux/darkreader'\" \\\n        \"'cp', '${finalAttrs.web-archive-darkreader}', 'build-aux/darkreader/web-archives-darkreader.js'\"\n"},{"type":"text","text":"Repository: gradle/gradle\nPath: platforms/software/ivy/src/integTest/groovy/org/gradle/api/publish/ivy/IvyPublishArtifactCustomizationIntegTest.groovy\nURL: https://github.com/gradle/gradle/blob/master/platforms/software/ivy/src/integTest/groovy/org/gradle/api/publish/ivy/IvyPublishArtifactCustomizationIntegTest.groovy\nLicense: Apache-2.0\n\nSnippets:\n--- Snippet 1 (Line 100) ---\n                        name = \"regular\"\n                        extension = \"txt\"\n                    }\n                    artifact(customJar) {\n                        extension = \"war\"\n                        type = \"web-archive\"\n                        conf = \"*\"\n                    }\n                }\n            }\n\"\"\")\n\n\n--- Snippet 2 (Line 115) ---\n        module.assertPublished()\n        module.assertArtifactsPublished(\"ivy-2.4.xml\", \"docs-2.4.htm\", \"customFile-2.4-classified.txt\", \"ivyPublish-2.4.war\", \"regular-2.4.txt\")\n\n        and:\n        def ivy = module.parsedIvy\n        ivy.expectArtifact(\"ivyPublish\", \"war\").hasType(\"web-archive\").hasConf([\"*\"])\n        ivy.expectArtifact(\"docs\", \"htm\").hasType(\"html\").hasConf(null)\n        ivy.expectArtifact(\"customFile\", \"txt\", \"classified\").hasType(\"txt\").hasConf([\"foo\", \"bar\"])\n        ivy.expectArtifact(\"regular\", \"txt\").hasType(\"reg\").hasConf(null)\n"},{"type":"text","text":"Repository: Ray-D-Song/web-archive\nPath: packages/web/src/components/card-edit-dialog.tsx\nURL: https://github.com/Ray-D-Song/web-archive/blob/main/packages/web/src/components/card-edit-dialog.tsx\nLicense: GPL-3.0\n\nSnippets:\n--- Snippet 1 (Line 1) ---\nimport { DialogClose, DialogDescription, DialogTitle } from '@radix-ui/react-dialog'\nimport { Dialog, DialogContent, DialogFooter } from '@web-archive/shared/components/dialog'\nimport { Input } from '@web-archive/shared/components/input'\nimport { Switch } from '@web-archive/shared/components/switch'\nimport { useRequest } from 'ahooks'\nimport { useForm } from 'react-hook-form'\nimport { memo, useContext, useEffect } from 'react'\nimport { Form, FormControl, FormField, FormItem, FormLabel, FormMessage } from '@web-archive/shared/components/form'\nimport { z } from 'zod'\nimport { Select, SelectContent, SelectItem, SelectTrigger, SelectValue } from '@web-archive/shared/components/select'\nimport { Textarea } from '@web-archive/shared/components/textarea'\nimport { Button } from '@web-archive/shared/components/button'\nimport { toast } from 'react-hot-toast'\nimport { useOutletContext } from 'react-router-dom'\nimport AutoCompleteTagInput from '@web-archive/shared/components/auto-complete-tag-input'\nimport { useTranslation } from 'react-i18next'\nimport LoadingWrapper from '~/components/loading-wrapper'\nimport { getPageDetail, updatePage } from '~/data/page'\nimport { getAllFolder } from '~/data/folder'\nimport TagContext from '~/store/tag'\n"},{"type":"text","text":"Repository: Ray-D-Song/web-archive\nPath: packages/web/src/components/side-bar-tag-menu.tsx\nURL: https://github.com/Ray-D-Song/web-archive/blob/main/packages/web/src/components/side-bar-tag-menu.tsx\nLicense: GPL-3.0\n\nSnippets:\n--- Snippet 1 (Line 1) ---\nimport { Badge } from '@web-archive/shared/components/badge'\nimport { Collapsible, CollapsibleContent, CollapsibleTrigger } from '@web-archive/shared/components/collapsible'\nimport { ContextMenu, ContextMenuContent, ContextMenuItem, ContextMenuTrigger } from '@web-archive/shared/components/context-menu'\nimport { SidebarMenu, SidebarMenuButton, SidebarMenuSub } from '@web-archive/shared/components/side-bar'\nimport type { Tag } from '@web-archive/shared/types'\nimport { cn } from '@web-archive/shared/utils'\nimport { useRequest } from 'ahooks'\nimport { ChevronDown, Pencil, TagIcon, Trash } from 'lucide-react'\nimport { useContext, useEffect, useState } from 'react'\nimport toast from 'react-hot-toast'\nimport { useTranslation } from 'react-i18next'\n"},{"type":"text","text":"Repository: Ray-D-Song/web-archive\nPath: packages/plugin/popup/components/TagInputWithCache.tsx\nURL: https://github.com/Ray-D-Song/web-archive/blob/main/packages/plugin/popup/components/TagInputWithCache.tsx\nLicense: GPL-3.0\n\nSnippets:\n--- Snippet 1 (Line 1) ---\nimport { useRef } from 'react'\nimport type { AutoCompleteTagInputRef } from '@web-archive/shared/components/auto-complete-tag-input'\nimport AutoCompleteTagInput from '@web-archive/shared/components/auto-complete-tag-input'\nimport { Button } from '@web-archive/shared/components/button'\nimport type { GenerateTagProps } from '@web-archive/shared/utils'\nimport { generateTagByOpenAI } from '@web-archive/shared/utils'\nimport { useRequest } from 'ahooks'\nimport { AlertCircleIcon, Loader2Icon, SparklesIcon } from 'lucide-react'\nimport { sendMessage } from 'webext-bridge/popup'\nimport { Tooltip, TooltipContent, TooltipProvider, TooltipTrigger } from '@web-archive/shared/components/tooltip'\nimport toast from 'react-hot-toast'\nimport { useTranslation } from 'react-i18next'\n\nasync function getAllTags() {\n  const { tags } = await sendMessage('get-all-tags', {})\n"},{"type":"text","text":"Repository: Ray-D-Song/web-archive\nPath: packages/web/src/components/side-bar-folder-menu.tsx\nURL: https://github.com/Ray-D-Song/web-archive/blob/main/packages/web/src/components/side-bar-folder-menu.tsx\nLicense: GPL-3.0\n\nSnippets:\n--- Snippet 1 (Line 1) ---\nimport { Button } from '@web-archive/shared/components/button'\nimport { Collapsible, CollapsibleContent, CollapsibleTrigger } from '@web-archive/shared/components/collapsible'\nimport { SidebarMenu, SidebarMenuButton, SidebarMenuItem, SidebarMenuSub } from '@web-archive/shared/components/side-bar'\nimport { Skeleton } from '@web-archive/shared/components/skeleton'\nimport { cn, isNil } from '@web-archive/shared/utils'\nimport { ChevronDown, FolderIcon, Plus } from 'lucide-react'\nimport { useState } from 'react'\nimport type { Folder as FolderType } from '@web-archive/shared/types'\nimport { useRequest } from 'ahooks'\nimport toast from 'react-hot-toast'\nimport { useTranslation } from 'react-i18next'\nimport NewFolderDialog from './new-folder-dialog'\nimport EditFolderDialog from './edit-folder-dialog'\n"},{"type":"text","text":"Repository: Ray-D-Song/web-archive\nPath: packages/plugin/popup/components/UploadPageForm.tsx\nURL: https://github.com/Ray-D-Song/web-archive/blob/main/packages/plugin/popup/components/UploadPageForm.tsx\nLicense: GPL-3.0\n\nSnippets:\n--- Snippet 1 (Line 1) ---\nimport { Input } from '@web-archive/shared/components/input'\nimport { Label } from '@web-archive/shared/components/label'\nimport type { PageType } from 'popup/PopupPage'\nimport type { ChangeEvent } from 'react'\nimport { useState } from 'react'\nimport { sendMessage } from 'webext-bridge/popup'\nimport { Textarea } from '@web-archive/shared/components/textarea'\nimport { Button } from '@web-archive/shared/components/button'\nimport { useRequest } from 'ahooks'\nimport { isNil } from '@web-archive/shared/utils'\nimport toast from 'react-hot-toast'\nimport { Switch } from '@web-archive/shared/components/switch'\nimport { useTranslation } from 'react-i18next'\nimport FolderSelectWithCache, { getLastChooseFolderId } from './FolderSelectWithCache'\nimport TagInputWithCache from './TagInputWithCache'\nimport { getSingleFileSetting } from '~/popup/utils/singleFile'\nimport { takeScreenshot } from '~/popup/utils/screenshot'\n"},{"type":"text","text":"Repository: internetarchive/dweb-mirror\nPath: install_dev.sh\nURL: https://github.com/internetarchive/dweb-mirror/blob/master/install_dev.sh\nLicense: AGPL-3.0\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n#!/bin/bash\n###### INSTALLATION CODE, MOSTLY DUPLICATED in dweb-mirror/install.sh and dweb-mirror/install_dev.sh . TODO: Merge these scripts to take e.g. a --dev argument.\ncat <<EOT\n  This script is intended to support development and testing of all of the dweb repo's.\n  While its not strictly required to, for example dweb-mirror to work on dweb-archive, the simplicity\n  of one set of installation instructions, and the advantage of being able to test dweb-archive on dweb-mirror\n  makes it preferable.\n\n  This script can be run multiple times without problems.\n\n  The easiest way to run is\n\n\n--- Snippet 2 (Line 16) ---\nset -e # Break on error\n#set -x # Lets see whats happening\n\n# Define a parent directory they will sit under\nPARENTDIRECTORY=git\nREPOS=\"dweb-transports dweb-archivecontroller epubjs-reader bookreader dweb-archive dweb-mirror iaux\"\n# Note that dweb-transport and dweb-gatewahy are not installed they are only useful when running as a gateway server at the archive.\n\nfunction step {\n"},{"type":"text","text":"Repository: Ray-D-Song/web-archive\nPath: packages/web/src/components/ai-tag-setting-collapsible.tsx\nURL: https://github.com/Ray-D-Song/web-archive/blob/main/packages/web/src/components/ai-tag-setting-collapsible.tsx\nLicense: GPL-3.0\n\nSnippets:\n--- Snippet 1 (Line 1) ---\nimport { Button } from '@web-archive/shared/components/button'\nimport { Collapsible, CollapsibleContent, CollapsibleTrigger } from '@web-archive/shared/components/collapsible'\nimport { Input } from '@web-archive/shared/components/input'\nimport { ChevronDown } from 'lucide-react'\nimport { useContext, useState } from 'react'\nimport { useForm } from 'react-hook-form'\nimport { z } from 'zod'\nimport { Form, FormControl, FormDescription, FormField, FormItem, FormLabel, FormMessage } from '@web-archive/shared/components/form'\nimport { useRequest } from 'ahooks'\nimport { Select, SelectContent, SelectItem, SelectTrigger, SelectValue } from '@web-archive/shared/components/select'\nimport { zodResolver } from '@hookform/resolvers/zod'\nimport toast from 'react-hot-toast'\nimport AutoCompleteTagInput from '@web-archive/shared/components/auto-complete-tag-input'\nimport { useTranslation } from 'react-i18next'\nimport LoadingWrapper from './loading-wrapper'\nimport AITagTestConnectionButton from './ai-tag-test-connection-button'\nimport { getAITagConfig, setAITagConfig } from '~/data/config'\nimport TagContext from '~/store/tag'\n"},{"type":"text","text":"Repository: Ray-D-Song/web-archive\nPath: packages/web/src/components/setting-dialog.tsx\nURL: https://github.com/Ray-D-Song/web-archive/blob/main/packages/web/src/components/setting-dialog.tsx\nLicense: GPL-3.0\n\nSnippets:\n--- Snippet 1 (Line 1) ---\nimport { Label } from '@radix-ui/react-context-menu'\nimport { DialogDescription } from '@radix-ui/react-dialog'\nimport { Dialog, DialogContent, DialogHeader, DialogTitle } from '@web-archive/shared/components/dialog'\nimport { Select, SelectContent, SelectItem, SelectTrigger, SelectValue } from '@web-archive/shared/components/select'\nimport { Switch } from '@web-archive/shared/components/switch'\nimport { useTheme } from '@web-archive/shared/components/theme-provider'\nimport { Settings } from 'lucide-react'\nimport { useTranslation } from 'react-i18next'\nimport LanguageCombobox from '@web-archive/shared/components/language-combobox'\nimport AITagSettingCollapsible from './ai-tag-setting-collapsible'\nimport { useShouldShowRecent } from '~/hooks/useShouldShowRecent'\n\nfunction SettingDialog({ open, setOpen }: { open: boolean, setOpen: (open: boolean) => void }) {\n  const { t } = useTranslation()\n"}]}]},"uuid":"86cd0c6c-e7fb-41fb-8a00-f83f93e558a8","timestamp":"2025-12-19T04:43:54.879Z","toolUseResult":[{"type":"text","text":"Repository: NixOS/nixpkgs\nPath: pkgs/by-name/we/web-archives/package.nix\nURL: https://github.com/NixOS/nixpkgs/blob/master/pkgs/by-name/we/web-archives/package.nix\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 22) ---\n  pname = \"web-archives\";\n  version = \"0.5.0\";\n\n  src = fetchFromGitHub {\n    owner = \"birros\";\n    repo = \"web-archives\";\n    rev = \"v${finalAttrs.version}\";\n    hash = \"sha256-EYHChI+4tpjRp4KveHTB+5BSLtw0YLp5z2JJmA0xTlM=\";\n  };\n\n  web-archive-darkreader = fetchurl {\n    # This is the same with build-aux/darkreader/Makefile\n    url = \"https://github.com/birros/web-archives-darkreader/releases/download/v0.0.1/web-archives-darkreader_v0.0.1.js\";\n    hash = \"sha256-juhAqs2eCYZKerLnX3NvaW3NS0uOhqB7pyf/PRDvMqE=\";\n  };\n\n  postPatch = ''\n    substituteInPlace meson.build \\\n      --replace-fail \\\n        \"'make', '-C', 'build-aux/darkreader'\" \\\n        \"'cp', '${finalAttrs.web-archive-darkreader}', 'build-aux/darkreader/web-archives-darkreader.js'\"\n"},{"type":"text","text":"Repository: gradle/gradle\nPath: platforms/software/ivy/src/integTest/groovy/org/gradle/api/publish/ivy/IvyPublishArtifactCustomizationIntegTest.groovy\nURL: https://github.com/gradle/gradle/blob/master/platforms/software/ivy/src/integTest/groovy/org/gradle/api/publish/ivy/IvyPublishArtifactCustomizationIntegTest.groovy\nLicense: Apache-2.0\n\nSnippets:\n--- Snippet 1 (Line 100) ---\n                        name = \"regular\"\n                        extension = \"txt\"\n                    }\n                    artifact(customJar) {\n                        extension = \"war\"\n                        type = \"web-archive\"\n                        conf = \"*\"\n                    }\n                }\n            }\n\"\"\")\n\n\n--- Snippet 2 (Line 115) ---\n        module.assertPublished()\n        module.assertArtifactsPublished(\"ivy-2.4.xml\", \"docs-2.4.htm\", \"customFile-2.4-classified.txt\", \"ivyPublish-2.4.war\", \"regular-2.4.txt\")\n\n        and:\n        def ivy = module.parsedIvy\n        ivy.expectArtifact(\"ivyPublish\", \"war\").hasType(\"web-archive\").hasConf([\"*\"])\n        ivy.expectArtifact(\"docs\", \"htm\").hasType(\"html\").hasConf(null)\n        ivy.expectArtifact(\"customFile\", \"txt\", \"classified\").hasType(\"txt\").hasConf([\"foo\", \"bar\"])\n        ivy.expectArtifact(\"regular\", \"txt\").hasType(\"reg\").hasConf(null)\n"},{"type":"text","text":"Repository: Ray-D-Song/web-archive\nPath: packages/web/src/components/card-edit-dialog.tsx\nURL: https://github.com/Ray-D-Song/web-archive/blob/main/packages/web/src/components/card-edit-dialog.tsx\nLicense: GPL-3.0\n\nSnippets:\n--- Snippet 1 (Line 1) ---\nimport { DialogClose, DialogDescription, DialogTitle } from '@radix-ui/react-dialog'\nimport { Dialog, DialogContent, DialogFooter } from '@web-archive/shared/components/dialog'\nimport { Input } from '@web-archive/shared/components/input'\nimport { Switch } from '@web-archive/shared/components/switch'\nimport { useRequest } from 'ahooks'\nimport { useForm } from 'react-hook-form'\nimport { memo, useContext, useEffect } from 'react'\nimport { Form, FormControl, FormField, FormItem, FormLabel, FormMessage } from '@web-archive/shared/components/form'\nimport { z } from 'zod'\nimport { Select, SelectContent, SelectItem, SelectTrigger, SelectValue } from '@web-archive/shared/components/select'\nimport { Textarea } from '@web-archive/shared/components/textarea'\nimport { Button } from '@web-archive/shared/components/button'\nimport { toast } from 'react-hot-toast'\nimport { useOutletContext } from 'react-router-dom'\nimport AutoCompleteTagInput from '@web-archive/shared/components/auto-complete-tag-input'\nimport { useTranslation } from 'react-i18next'\nimport LoadingWrapper from '~/components/loading-wrapper'\nimport { getPageDetail, updatePage } from '~/data/page'\nimport { getAllFolder } from '~/data/folder'\nimport TagContext from '~/store/tag'\n"},{"type":"text","text":"Repository: Ray-D-Song/web-archive\nPath: packages/web/src/components/side-bar-tag-menu.tsx\nURL: https://github.com/Ray-D-Song/web-archive/blob/main/packages/web/src/components/side-bar-tag-menu.tsx\nLicense: GPL-3.0\n\nSnippets:\n--- Snippet 1 (Line 1) ---\nimport { Badge } from '@web-archive/shared/components/badge'\nimport { Collapsible, CollapsibleContent, CollapsibleTrigger } from '@web-archive/shared/components/collapsible'\nimport { ContextMenu, ContextMenuContent, ContextMenuItem, ContextMenuTrigger } from '@web-archive/shared/components/context-menu'\nimport { SidebarMenu, SidebarMenuButton, SidebarMenuSub } from '@web-archive/shared/components/side-bar'\nimport type { Tag } from '@web-archive/shared/types'\nimport { cn } from '@web-archive/shared/utils'\nimport { useRequest } from 'ahooks'\nimport { ChevronDown, Pencil, TagIcon, Trash } from 'lucide-react'\nimport { useContext, useEffect, useState } from 'react'\nimport toast from 'react-hot-toast'\nimport { useTranslation } from 'react-i18next'\n"},{"type":"text","text":"Repository: Ray-D-Song/web-archive\nPath: packages/plugin/popup/components/TagInputWithCache.tsx\nURL: https://github.com/Ray-D-Song/web-archive/blob/main/packages/plugin/popup/components/TagInputWithCache.tsx\nLicense: GPL-3.0\n\nSnippets:\n--- Snippet 1 (Line 1) ---\nimport { useRef } from 'react'\nimport type { AutoCompleteTagInputRef } from '@web-archive/shared/components/auto-complete-tag-input'\nimport AutoCompleteTagInput from '@web-archive/shared/components/auto-complete-tag-input'\nimport { Button } from '@web-archive/shared/components/button'\nimport type { GenerateTagProps } from '@web-archive/shared/utils'\nimport { generateTagByOpenAI } from '@web-archive/shared/utils'\nimport { useRequest } from 'ahooks'\nimport { AlertCircleIcon, Loader2Icon, SparklesIcon } from 'lucide-react'\nimport { sendMessage } from 'webext-bridge/popup'\nimport { Tooltip, TooltipContent, TooltipProvider, TooltipTrigger } from '@web-archive/shared/components/tooltip'\nimport toast from 'react-hot-toast'\nimport { useTranslation } from 'react-i18next'\n\nasync function getAllTags() {\n  const { tags } = await sendMessage('get-all-tags', {})\n"},{"type":"text","text":"Repository: Ray-D-Song/web-archive\nPath: packages/web/src/components/side-bar-folder-menu.tsx\nURL: https://github.com/Ray-D-Song/web-archive/blob/main/packages/web/src/components/side-bar-folder-menu.tsx\nLicense: GPL-3.0\n\nSnippets:\n--- Snippet 1 (Line 1) ---\nimport { Button } from '@web-archive/shared/components/button'\nimport { Collapsible, CollapsibleContent, CollapsibleTrigger } from '@web-archive/shared/components/collapsible'\nimport { SidebarMenu, SidebarMenuButton, SidebarMenuItem, SidebarMenuSub } from '@web-archive/shared/components/side-bar'\nimport { Skeleton } from '@web-archive/shared/components/skeleton'\nimport { cn, isNil } from '@web-archive/shared/utils'\nimport { ChevronDown, FolderIcon, Plus } from 'lucide-react'\nimport { useState } from 'react'\nimport type { Folder as FolderType } from '@web-archive/shared/types'\nimport { useRequest } from 'ahooks'\nimport toast from 'react-hot-toast'\nimport { useTranslation } from 'react-i18next'\nimport NewFolderDialog from './new-folder-dialog'\nimport EditFolderDialog from './edit-folder-dialog'\n"},{"type":"text","text":"Repository: Ray-D-Song/web-archive\nPath: packages/plugin/popup/components/UploadPageForm.tsx\nURL: https://github.com/Ray-D-Song/web-archive/blob/main/packages/plugin/popup/components/UploadPageForm.tsx\nLicense: GPL-3.0\n\nSnippets:\n--- Snippet 1 (Line 1) ---\nimport { Input } from '@web-archive/shared/components/input'\nimport { Label } from '@web-archive/shared/components/label'\nimport type { PageType } from 'popup/PopupPage'\nimport type { ChangeEvent } from 'react'\nimport { useState } from 'react'\nimport { sendMessage } from 'webext-bridge/popup'\nimport { Textarea } from '@web-archive/shared/components/textarea'\nimport { Button } from '@web-archive/shared/components/button'\nimport { useRequest } from 'ahooks'\nimport { isNil } from '@web-archive/shared/utils'\nimport toast from 'react-hot-toast'\nimport { Switch } from '@web-archive/shared/components/switch'\nimport { useTranslation } from 'react-i18next'\nimport FolderSelectWithCache, { getLastChooseFolderId } from './FolderSelectWithCache'\nimport TagInputWithCache from './TagInputWithCache'\nimport { getSingleFileSetting } from '~/popup/utils/singleFile'\nimport { takeScreenshot } from '~/popup/utils/screenshot'\n"},{"type":"text","text":"Repository: internetarchive/dweb-mirror\nPath: install_dev.sh\nURL: https://github.com/internetarchive/dweb-mirror/blob/master/install_dev.sh\nLicense: AGPL-3.0\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n#!/bin/bash\n###### INSTALLATION CODE, MOSTLY DUPLICATED in dweb-mirror/install.sh and dweb-mirror/install_dev.sh . TODO: Merge these scripts to take e.g. a --dev argument.\ncat <<EOT\n  This script is intended to support development and testing of all of the dweb repo's.\n  While its not strictly required to, for example dweb-mirror to work on dweb-archive, the simplicity\n  of one set of installation instructions, and the advantage of being able to test dweb-archive on dweb-mirror\n  makes it preferable.\n\n  This script can be run multiple times without problems.\n\n  The easiest way to run is\n\n\n--- Snippet 2 (Line 16) ---\nset -e # Break on error\n#set -x # Lets see whats happening\n\n# Define a parent directory they will sit under\nPARENTDIRECTORY=git\nREPOS=\"dweb-transports dweb-archivecontroller epubjs-reader bookreader dweb-archive dweb-mirror iaux\"\n# Note that dweb-transport and dweb-gatewahy are not installed they are only useful when running as a gateway server at the archive.\n\nfunction step {\n"},{"type":"text","text":"Repository: Ray-D-Song/web-archive\nPath: packages/web/src/components/ai-tag-setting-collapsible.tsx\nURL: https://github.com/Ray-D-Song/web-archive/blob/main/packages/web/src/components/ai-tag-setting-collapsible.tsx\nLicense: GPL-3.0\n\nSnippets:\n--- Snippet 1 (Line 1) ---\nimport { Button } from '@web-archive/shared/components/button'\nimport { Collapsible, CollapsibleContent, CollapsibleTrigger } from '@web-archive/shared/components/collapsible'\nimport { Input } from '@web-archive/shared/components/input'\nimport { ChevronDown } from 'lucide-react'\nimport { useContext, useState } from 'react'\nimport { useForm } from 'react-hook-form'\nimport { z } from 'zod'\nimport { Form, FormControl, FormDescription, FormField, FormItem, FormLabel, FormMessage } from '@web-archive/shared/components/form'\nimport { useRequest } from 'ahooks'\nimport { Select, SelectContent, SelectItem, SelectTrigger, SelectValue } from '@web-archive/shared/components/select'\nimport { zodResolver } from '@hookform/resolvers/zod'\nimport toast from 'react-hot-toast'\nimport AutoCompleteTagInput from '@web-archive/shared/components/auto-complete-tag-input'\nimport { useTranslation } from 'react-i18next'\nimport LoadingWrapper from './loading-wrapper'\nimport AITagTestConnectionButton from './ai-tag-test-connection-button'\nimport { getAITagConfig, setAITagConfig } from '~/data/config'\nimport TagContext from '~/store/tag'\n"},{"type":"text","text":"Repository: Ray-D-Song/web-archive\nPath: packages/web/src/components/setting-dialog.tsx\nURL: https://github.com/Ray-D-Song/web-archive/blob/main/packages/web/src/components/setting-dialog.tsx\nLicense: GPL-3.0\n\nSnippets:\n--- Snippet 1 (Line 1) ---\nimport { Label } from '@radix-ui/react-context-menu'\nimport { DialogDescription } from '@radix-ui/react-dialog'\nimport { Dialog, DialogContent, DialogHeader, DialogTitle } from '@web-archive/shared/components/dialog'\nimport { Select, SelectContent, SelectItem, SelectTrigger, SelectValue } from '@web-archive/shared/components/select'\nimport { Switch } from '@web-archive/shared/components/switch'\nimport { useTheme } from '@web-archive/shared/components/theme-provider'\nimport { Settings } from 'lucide-react'\nimport { useTranslation } from 'react-i18next'\nimport LanguageCombobox from '@web-archive/shared/components/language-combobox'\nimport AITagSettingCollapsible from './ai-tag-setting-collapsible'\nimport { useShouldShowRecent } from '~/hooks/useShouldShowRecent'\n\nfunction SettingDialog({ open, setOpen }: { open: boolean, setOpen: (open: boolean) => void }) {\n  const { t } = useTranslation()\n"}]}
{"parentUuid":"86cd0c6c-e7fb-41fb-8a00-f83f93e558a8","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"faeb714a-61c5-410d-b669-0ebc662cf207","version":"2.0.70","gitBranch":"main","agentId":"abf8d80","message":{"model":"claude-opus-4-5-20251101","id":"msg_0149SDtNsuRS57nwLkQtaSGG","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01347h3kbEtzwmvMPzUFQFdx","name":"mcp__grep__searchGitHub","input":{"query":"webrecorder"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":17319,"cache_read_input_tokens":31734,"cache_creation":{"ephemeral_5m_input_tokens":17319,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWFSBxzcYbWRpsS1bpPTR","type":"assistant","uuid":"f5c56b75-564f-4707-acea-5a8f556d7175","timestamp":"2025-12-19T04:43:58.585Z"}
{"parentUuid":"f5c56b75-564f-4707-acea-5a8f556d7175","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"faeb714a-61c5-410d-b669-0ebc662cf207","version":"2.0.70","gitBranch":"main","agentId":"abf8d80","message":{"model":"claude-opus-4-5-20251101","id":"msg_0149SDtNsuRS57nwLkQtaSGG","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01VJWx8jzua7CSSYfEcJxGFz","name":"mcp__grep__searchGitHub","input":{"query":"warc","language":["Python"]}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":17319,"cache_read_input_tokens":31734,"cache_creation":{"ephemeral_5m_input_tokens":17319,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWFSBxzcYbWRpsS1bpPTR","type":"assistant","uuid":"bc444073-de9c-4fee-89d1-2027fce3fa13","timestamp":"2025-12-19T04:43:59.542Z"}
{"parentUuid":"bc444073-de9c-4fee-89d1-2027fce3fa13","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"faeb714a-61c5-410d-b669-0ebc662cf207","version":"2.0.70","gitBranch":"main","agentId":"abf8d80","message":{"model":"claude-opus-4-5-20251101","id":"msg_0149SDtNsuRS57nwLkQtaSGG","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01HRy2Fe8WDG8WcN62qPGhs8","name":"mcp__grep__searchGitHub","input":{"query":"offline-website"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":17319,"cache_read_input_tokens":31734,"cache_creation":{"ephemeral_5m_input_tokens":17319,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWFSBxzcYbWRpsS1bpPTR","type":"assistant","uuid":"901f5e03-03f1-4a79-92db-d9d518db4ea1","timestamp":"2025-12-19T04:44:00.102Z"}
{"parentUuid":"901f5e03-03f1-4a79-92db-d9d518db4ea1","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"faeb714a-61c5-410d-b669-0ebc662cf207","version":"2.0.70","gitBranch":"main","agentId":"abf8d80","message":{"model":"claude-opus-4-5-20251101","id":"msg_0149SDtNsuRS57nwLkQtaSGG","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01M93mMUHZX6iGygsp25kHgD","name":"mcp__grep__searchGitHub","input":{"query":"save-page-as"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":17319,"cache_read_input_tokens":31734,"cache_creation":{"ephemeral_5m_input_tokens":17319,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWFSBxzcYbWRpsS1bpPTR","type":"assistant","uuid":"95e23255-97ad-47ea-92c1-78fad9d1685d","timestamp":"2025-12-19T04:44:00.534Z"}
{"parentUuid":"95e23255-97ad-47ea-92c1-78fad9d1685d","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"faeb714a-61c5-410d-b669-0ebc662cf207","version":"2.0.70","gitBranch":"main","agentId":"abf8d80","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01347h3kbEtzwmvMPzUFQFdx","type":"tool_result","content":[{"type":"text","text":"Repository: Homebrew/homebrew-cask\nPath: Casks/w/webrecorder-player.rb\nURL: https://github.com/Homebrew/homebrew-cask/blob/main/Casks/w/webrecorder-player.rb\nLicense: BSD-2-Clause\n\nSnippets:\n--- Snippet 1 (Line 1) ---\ncask \"webrecorder-player\" do\n  version \"1.8.0\"\n  sha256 \"c7ecc7b19c31814a15a1dc5bff41ac899b239877d5968b057b0946b250aedd3a\"\n\n  url \"https://github.com/webrecorder/webrecorder-player/releases/download/v#{version}/webrecorder-player-#{version}.dmg\"\n  name \"Webrecorder Player\"\n  homepage \"https://github.com/webrecorder/webrecorder-player/\"\n\n  disable! date: \"2024-12-16\", because: :discontinued, replacement_cask: \"replaywebpage\"\n\n  app \"Webrecorder Player.app\"\n\n  zap trash: [\n    \"~/Library/Application Support/Webrecorder Player\",\n    \"~/Library/Preferences/org.webrecorder.webrecorderplayer.helper.plist\",\n    \"~/Library/Preferences/org.webrecorder.webrecorderplayer.plist\",\n    \"~/Library/Saved Application State/org.webrecorder.webrecorderplayer.savedState\",\n  ]\n"},{"type":"text","text":"Repository: Homebrew/homebrew-cask\nPath: Casks/a/archivewebpage.rb\nURL: https://github.com/Homebrew/homebrew-cask/blob/main/Casks/a/archivewebpage.rb\nLicense: BSD-2-Clause\n\nSnippets:\n--- Snippet 1 (Line 1) ---\ncask \"archivewebpage\" do\n  version \"0.16.0\"\n  sha256 \"752f9880793bd82fd93b873bfa448d4e785dae2057db476605b27afcd04afe60\"\n\n  url \"https://github.com/webrecorder/archiveweb.page/releases/download/v#{version}/ArchiveWeb.page-#{version}.dmg\",\n      verified: \"github.com/webrecorder/archiveweb.page/\"\n  name \"ArchiveWeb.page\"\n  desc \"Archive webpages manually to WARC or WACZ files as you browse the web\"\n  homepage \"https://archiveweb.page/\"\n\n  livecheck do\n\n\n--- Snippet 2 (Line 20) ---\n  zap trash: [\n    \"~/Library/Application Support/ArchiveWeb.page\",\n    \"~/Library/Application Support/com.apple.sharedfilelist/com.apple.LSSharedFileList.ApplicationRecentDocuments/net.webrecorder.archivewebpage.sfl*\",\n    \"~/Library/Caches/net.webrecorder.archivewebpage\",\n    \"~/Library/Caches/net.webrecorder.archivewebpage.ShipIt\",\n    \"~/Library/HTTPStorages/net.webrecorder.archivewebpage\",\n    \"~/Library/Logs/ArchiveWeb.page\",\n    \"~/Library/Preferences/net.webrecorder.archivewebpage.plst\",\n    \"~/Library/Saved Application State/net.webrecorder.archivewebpage.savedState\",\n"},{"type":"text","text":"Repository: NixOS/nixpkgs\nPath: pkgs/development/python-modules/warcio/default.nix\nURL: https://github.com/NixOS/nixpkgs/blob/master/pkgs/development/python-modules/warcio/default.nix\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 20) ---\n  format = \"setuptools\";\n\n  disabled = pythonOlder \"3.7\";\n\n  src = fetchFromGitHub {\n    owner = \"webrecorder\";\n    repo = \"warcio\";\n    tag = \"v${version}\"; # Repo has no git tags, see https://github.com/webrecorder/warcio/issues/126\n    hash = \"sha256-i1bVbXf1RQoWCADFwlVEnFhb3sVZ91vijUtzVLWMc2Q=\";\n  };\n\n  patches = [\n    (fetchpatch {\n      # Add offline mode to skip tests that require an internet connection, https://github.com/webrecorder/warcio/pull/135\n      name = \"add-offline-option.patch\";\n      url = \"https://github.com/webrecorder/warcio/pull/135/commits/2546fe457c57ab0b391764a4ce419656458d9d07.patch\";\n      hash = \"sha256-3izm9LvAeOFixiIUUqmd5flZIxH92+NxL7jeu35aObQ=\";\n    })\n  ];\n\n  propagatedBuildInputs = [\n"},{"type":"text","text":"Repository: Rhizome-Conifer/conifer\nPath: webrecorder/webrecorder/maincontroller.py\nURL: https://github.com/Rhizome-Conifer/conifer/blob/main/webrecorder/webrecorder/maincontroller.py\nLicense: Apache-2.0\n\nSnippets:\n--- Snippet 1 (Line 18) ---\nfrom webrecorder.utils import load_wr_config, init_logging, spawn_once\n\nfrom webrecorder.apiutils import APIBottle, wr_api_spec\nfrom webrecorder.admincontroller import AdminController\nfrom webrecorder.contentcontroller import ContentController\nfrom webrecorder.snapshotcontroller import SnapshotController\nfrom webrecorder.websockcontroller import WebsockController\nfrom webrecorder.recscontroller import RecsController\nfrom webrecorder.collscontroller import CollsController\nfrom webrecorder.listscontroller import ListsController\n#from webrecorder.logincontroller import LoginController\nfrom webrecorder.bugreportcontroller import BugReportController\nfrom webrecorder.usercontroller import UserController\nfrom webrecorder.downloadcontroller import DownloadController\nfrom webrecorder.uploadcontroller import UploadController\nfrom webrecorder.appcontroller import AppController\nfrom webrecorder.autocontroller import AutoController\nfrom webrecorder.behaviormgr import BehaviorMgr\n\nfrom webrecorder.browsermanager import BrowserManager\nfrom webrecorder.solrmanager import SolrManager\n"},{"type":"text","text":"Repository: NixOS/nixpkgs\nPath: pkgs/development/python-modules/wacz/default.nix\nURL: https://github.com/NixOS/nixpkgs/blob/master/pkgs/development/python-modules/wacz/default.nix\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 17) ---\n  pname = \"wacz\";\n  version = \"0.5.0\";\n  pyproject = true;\n\n  src = fetchFromGitHub {\n    owner = \"webrecorder\";\n    repo = \"py-wacz\";\n    tag = \"v${version}\";\n    hash = \"sha256-bGY6G7qBAN1Vu+pTNqRG0xh34sR62pMhQFHFGlJaTPQ=\";\n  };\n\n  patches = [\n    # <https://github.com/webrecorder/py-wacz/pull/47>\n    (fetchpatch {\n      name = \"clean-up-deps.patch\";\n      url = \"https://github.com/webrecorder/py-wacz/compare/1e8f724a527f28855eedeb0d969ee39b00b2a80a...9d3ad60f125247b8a4354511d9123b85ce6a23c5.patch\";\n      hash = \"sha256-zH6BKhsq9ybjzaWcNbVkk1sWh8vVCkv7Qxuwl0MQhNM=\";\n    })\n  ];\n\n  postPatch = ''\n"},{"type":"text","text":"Repository: Rhizome-Conifer/conifer\nPath: webrecorder/setup.py\nURL: https://github.com/Rhizome-Conifer/conifer/blob/main/webrecorder/setup.py\nLicense: Apache-2.0\n\nSnippets:\n--- Snippet 1 (Line 4) ---\nfrom setuptools import setup, find_packages\nfrom setuptools.command.test import test as TestCommand\nfrom setuptools.command.install import install\nimport os\n\nfrom webrecorder import __version__\n\n\n# Fix for TypeError: 'NoneType' object is not callable\" error\n# when running 'python setup.py test'\ntry:\n\n\n--- Snippet 2 (Line 59) ---\n        cmdline = '--cov-config .coveragerc --cov ./webrecorder/ -vv ./test/'\n        errcode = pytest.main(cmdline.split(' '))\n        sys.exit(errcode)\n\n\nclass Install(install):\n    def initialize_options(self):\n        from webrecorder.standalone.assetsutils import default_build\n        from webrecorder.load.wamloader import WAMLoader\n"},{"type":"text","text":"Repository: NixOS/nixpkgs\nPath: pkgs/development/python-modules/wsgiprox/default.nix\nURL: https://github.com/NixOS/nixpkgs/blob/master/pkgs/development/python-modules/wsgiprox/default.nix\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 10) ---\n  pname = \"wsgiprox\";\n  version = \"1.5.2\";\n  format = \"setuptools\";\n\n  src = fetchFromGitHub {\n    owner = \"webrecorder\";\n    repo = \"wsgiprox\";\n    # https://github.com/webrecorder/wsgiprox/issues/8\n    rev = \"004870a87959e68ff28ff4362e4f0df28ec22030\";\n    hash = \"sha256-EquddaNrVceyJHuQMCajKHGZX2Q7ebR0Zhvi2pl2WEw=\";\n  };\n\n  propagatedBuildInputs = [\n\n\n--- Snippet 2 (Line 28) ---\n\n  # See https://github.com/webrecorder/wsgiprox/issues/6\n  doCheck = false;\n\n  meta = {\n    description = \"Python WSGI Middleware for adding HTTP/S proxy support to any WSGI Application\";\n    homepage = \"https://github.com/webrecorder/wsgiprox\";\n"},{"type":"text","text":"Repository: Homebrew/homebrew-cask\nPath: Casks/r/replaywebpage.rb\nURL: https://github.com/Homebrew/homebrew-cask/blob/main/Casks/r/replaywebpage.rb\nLicense: BSD-2-Clause\n\nSnippets:\n--- Snippet 1 (Line 1) ---\ncask \"replaywebpage\" do\n  version \"2.4.0\"\n  sha256 \"a4c9ea365a204735a21e7a763c584792d1cfc6e68183a2382e514972544c15eb\"\n\n  url \"https://github.com/webrecorder/replayweb.page/releases/download/v#{version}/ReplayWeb.page-#{version}.dmg\",\n      verified: \"github.com/webrecorder/replayweb.page/\"\n  name \"ReplayWeb.page\"\n  desc \"Web archive viewer for WARC and WACZ files\"\n  homepage \"https://replayweb.page/\"\n\n  livecheck do\n\n\n--- Snippet 2 (Line 18) ---\n  app \"ReplayWeb.page.app\"\n\n  zap trash: [\n    \"~/Library/Application Support/ReplayWeb.page\",\n    \"~/Library/Logs/ReplayWeb.page\",\n    \"~/Library/Preferences/net.webrecorder.replaywebpage.plst\",\n    \"~/Library/Saved Application State/net.webrecorder.replaywebpage.savedState\",\n  ]\n"},{"type":"text","text":"Repository: CapSoftware/Cap\nPath: apps/web/app/(org)/dashboard/caps/components/web-recorder-dialog/web-recorder-dialog.tsx\nURL: https://github.com/CapSoftware/Cap/blob/main/apps/web/app/(org)/dashboard/caps/components/web-recorder-dialog/web-recorder-dialog.tsx\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 27) ---\nimport { SettingsPanel } from \"./SettingsPanel\";\nimport { useCameraDevices } from \"./useCameraDevices\";\nimport { useDevicePreferences } from \"./useDevicePreferences\";\nimport { useDialogInteractions } from \"./useDialogInteractions\";\nimport { useMicrophoneDevices } from \"./useMicrophoneDevices\";\nimport { useWebRecorder } from \"./useWebRecorder\";\nimport {\n\tdialogVariants,\n\tFREE_PLAN_MAX_RECORDING_MS,\n} from \"./web-recorder-constants\";\nimport { WebRecorderDialogHeader } from \"./web-recorder-dialog-header\";\n\nexport const WebRecorderDialog = () => {\n\tconst [open, setOpen] = useState(false);\n\tconst [settingsOpen, setSettingsOpen] = useState(false);\n\tconst [howItWorksOpen, setHowItWorksOpen] = useState(false);\n\tconst [recordingMode, setRecordingMode] =\n\t\tuseState<RecordingMode>(\"fullscreen\");\n"},{"type":"text","text":"Repository: Rhizome-Conifer/conifer\nPath: webrecorder/webrecorder/standalone/webrecorder_full.py\nURL: https://github.com/Rhizome-Conifer/conifer/blob/main/webrecorder/webrecorder/standalone/webrecorder_full.py\nLicense: Apache-2.0\n\nSnippets:\n--- Snippet 1 (Line 1) ---\nimport os\nimport sys\nimport base64\nimport shutil\n\nfrom webrecorder.standalone.standalone import StandaloneRunner\n\nfrom webrecorder.models.usermanager import CLIUserManager\nfrom webrecorder.utils import sanitize_title\n\nfrom webrecorder.standalone.localredisserver import LocalRedisServer\n\nimport redis\nfrom six.moves.urllib.parse import urlsplit\n\n\n# ============================================================================\nclass WebrecorderRunner(StandaloneRunner):\n    REDIS_PORT = 7679\n\n    def __init__(self, argres):\n"}]}]},"uuid":"2277e89e-53f4-4c0c-ae22-4f6e1f7c9e68","timestamp":"2025-12-19T04:44:00.866Z","toolUseResult":[{"type":"text","text":"Repository: Homebrew/homebrew-cask\nPath: Casks/w/webrecorder-player.rb\nURL: https://github.com/Homebrew/homebrew-cask/blob/main/Casks/w/webrecorder-player.rb\nLicense: BSD-2-Clause\n\nSnippets:\n--- Snippet 1 (Line 1) ---\ncask \"webrecorder-player\" do\n  version \"1.8.0\"\n  sha256 \"c7ecc7b19c31814a15a1dc5bff41ac899b239877d5968b057b0946b250aedd3a\"\n\n  url \"https://github.com/webrecorder/webrecorder-player/releases/download/v#{version}/webrecorder-player-#{version}.dmg\"\n  name \"Webrecorder Player\"\n  homepage \"https://github.com/webrecorder/webrecorder-player/\"\n\n  disable! date: \"2024-12-16\", because: :discontinued, replacement_cask: \"replaywebpage\"\n\n  app \"Webrecorder Player.app\"\n\n  zap trash: [\n    \"~/Library/Application Support/Webrecorder Player\",\n    \"~/Library/Preferences/org.webrecorder.webrecorderplayer.helper.plist\",\n    \"~/Library/Preferences/org.webrecorder.webrecorderplayer.plist\",\n    \"~/Library/Saved Application State/org.webrecorder.webrecorderplayer.savedState\",\n  ]\n"},{"type":"text","text":"Repository: Homebrew/homebrew-cask\nPath: Casks/a/archivewebpage.rb\nURL: https://github.com/Homebrew/homebrew-cask/blob/main/Casks/a/archivewebpage.rb\nLicense: BSD-2-Clause\n\nSnippets:\n--- Snippet 1 (Line 1) ---\ncask \"archivewebpage\" do\n  version \"0.16.0\"\n  sha256 \"752f9880793bd82fd93b873bfa448d4e785dae2057db476605b27afcd04afe60\"\n\n  url \"https://github.com/webrecorder/archiveweb.page/releases/download/v#{version}/ArchiveWeb.page-#{version}.dmg\",\n      verified: \"github.com/webrecorder/archiveweb.page/\"\n  name \"ArchiveWeb.page\"\n  desc \"Archive webpages manually to WARC or WACZ files as you browse the web\"\n  homepage \"https://archiveweb.page/\"\n\n  livecheck do\n\n\n--- Snippet 2 (Line 20) ---\n  zap trash: [\n    \"~/Library/Application Support/ArchiveWeb.page\",\n    \"~/Library/Application Support/com.apple.sharedfilelist/com.apple.LSSharedFileList.ApplicationRecentDocuments/net.webrecorder.archivewebpage.sfl*\",\n    \"~/Library/Caches/net.webrecorder.archivewebpage\",\n    \"~/Library/Caches/net.webrecorder.archivewebpage.ShipIt\",\n    \"~/Library/HTTPStorages/net.webrecorder.archivewebpage\",\n    \"~/Library/Logs/ArchiveWeb.page\",\n    \"~/Library/Preferences/net.webrecorder.archivewebpage.plst\",\n    \"~/Library/Saved Application State/net.webrecorder.archivewebpage.savedState\",\n"},{"type":"text","text":"Repository: NixOS/nixpkgs\nPath: pkgs/development/python-modules/warcio/default.nix\nURL: https://github.com/NixOS/nixpkgs/blob/master/pkgs/development/python-modules/warcio/default.nix\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 20) ---\n  format = \"setuptools\";\n\n  disabled = pythonOlder \"3.7\";\n\n  src = fetchFromGitHub {\n    owner = \"webrecorder\";\n    repo = \"warcio\";\n    tag = \"v${version}\"; # Repo has no git tags, see https://github.com/webrecorder/warcio/issues/126\n    hash = \"sha256-i1bVbXf1RQoWCADFwlVEnFhb3sVZ91vijUtzVLWMc2Q=\";\n  };\n\n  patches = [\n    (fetchpatch {\n      # Add offline mode to skip tests that require an internet connection, https://github.com/webrecorder/warcio/pull/135\n      name = \"add-offline-option.patch\";\n      url = \"https://github.com/webrecorder/warcio/pull/135/commits/2546fe457c57ab0b391764a4ce419656458d9d07.patch\";\n      hash = \"sha256-3izm9LvAeOFixiIUUqmd5flZIxH92+NxL7jeu35aObQ=\";\n    })\n  ];\n\n  propagatedBuildInputs = [\n"},{"type":"text","text":"Repository: Rhizome-Conifer/conifer\nPath: webrecorder/webrecorder/maincontroller.py\nURL: https://github.com/Rhizome-Conifer/conifer/blob/main/webrecorder/webrecorder/maincontroller.py\nLicense: Apache-2.0\n\nSnippets:\n--- Snippet 1 (Line 18) ---\nfrom webrecorder.utils import load_wr_config, init_logging, spawn_once\n\nfrom webrecorder.apiutils import APIBottle, wr_api_spec\nfrom webrecorder.admincontroller import AdminController\nfrom webrecorder.contentcontroller import ContentController\nfrom webrecorder.snapshotcontroller import SnapshotController\nfrom webrecorder.websockcontroller import WebsockController\nfrom webrecorder.recscontroller import RecsController\nfrom webrecorder.collscontroller import CollsController\nfrom webrecorder.listscontroller import ListsController\n#from webrecorder.logincontroller import LoginController\nfrom webrecorder.bugreportcontroller import BugReportController\nfrom webrecorder.usercontroller import UserController\nfrom webrecorder.downloadcontroller import DownloadController\nfrom webrecorder.uploadcontroller import UploadController\nfrom webrecorder.appcontroller import AppController\nfrom webrecorder.autocontroller import AutoController\nfrom webrecorder.behaviormgr import BehaviorMgr\n\nfrom webrecorder.browsermanager import BrowserManager\nfrom webrecorder.solrmanager import SolrManager\n"},{"type":"text","text":"Repository: NixOS/nixpkgs\nPath: pkgs/development/python-modules/wacz/default.nix\nURL: https://github.com/NixOS/nixpkgs/blob/master/pkgs/development/python-modules/wacz/default.nix\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 17) ---\n  pname = \"wacz\";\n  version = \"0.5.0\";\n  pyproject = true;\n\n  src = fetchFromGitHub {\n    owner = \"webrecorder\";\n    repo = \"py-wacz\";\n    tag = \"v${version}\";\n    hash = \"sha256-bGY6G7qBAN1Vu+pTNqRG0xh34sR62pMhQFHFGlJaTPQ=\";\n  };\n\n  patches = [\n    # <https://github.com/webrecorder/py-wacz/pull/47>\n    (fetchpatch {\n      name = \"clean-up-deps.patch\";\n      url = \"https://github.com/webrecorder/py-wacz/compare/1e8f724a527f28855eedeb0d969ee39b00b2a80a...9d3ad60f125247b8a4354511d9123b85ce6a23c5.patch\";\n      hash = \"sha256-zH6BKhsq9ybjzaWcNbVkk1sWh8vVCkv7Qxuwl0MQhNM=\";\n    })\n  ];\n\n  postPatch = ''\n"},{"type":"text","text":"Repository: Rhizome-Conifer/conifer\nPath: webrecorder/setup.py\nURL: https://github.com/Rhizome-Conifer/conifer/blob/main/webrecorder/setup.py\nLicense: Apache-2.0\n\nSnippets:\n--- Snippet 1 (Line 4) ---\nfrom setuptools import setup, find_packages\nfrom setuptools.command.test import test as TestCommand\nfrom setuptools.command.install import install\nimport os\n\nfrom webrecorder import __version__\n\n\n# Fix for TypeError: 'NoneType' object is not callable\" error\n# when running 'python setup.py test'\ntry:\n\n\n--- Snippet 2 (Line 59) ---\n        cmdline = '--cov-config .coveragerc --cov ./webrecorder/ -vv ./test/'\n        errcode = pytest.main(cmdline.split(' '))\n        sys.exit(errcode)\n\n\nclass Install(install):\n    def initialize_options(self):\n        from webrecorder.standalone.assetsutils import default_build\n        from webrecorder.load.wamloader import WAMLoader\n"},{"type":"text","text":"Repository: NixOS/nixpkgs\nPath: pkgs/development/python-modules/wsgiprox/default.nix\nURL: https://github.com/NixOS/nixpkgs/blob/master/pkgs/development/python-modules/wsgiprox/default.nix\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 10) ---\n  pname = \"wsgiprox\";\n  version = \"1.5.2\";\n  format = \"setuptools\";\n\n  src = fetchFromGitHub {\n    owner = \"webrecorder\";\n    repo = \"wsgiprox\";\n    # https://github.com/webrecorder/wsgiprox/issues/8\n    rev = \"004870a87959e68ff28ff4362e4f0df28ec22030\";\n    hash = \"sha256-EquddaNrVceyJHuQMCajKHGZX2Q7ebR0Zhvi2pl2WEw=\";\n  };\n\n  propagatedBuildInputs = [\n\n\n--- Snippet 2 (Line 28) ---\n\n  # See https://github.com/webrecorder/wsgiprox/issues/6\n  doCheck = false;\n\n  meta = {\n    description = \"Python WSGI Middleware for adding HTTP/S proxy support to any WSGI Application\";\n    homepage = \"https://github.com/webrecorder/wsgiprox\";\n"},{"type":"text","text":"Repository: Homebrew/homebrew-cask\nPath: Casks/r/replaywebpage.rb\nURL: https://github.com/Homebrew/homebrew-cask/blob/main/Casks/r/replaywebpage.rb\nLicense: BSD-2-Clause\n\nSnippets:\n--- Snippet 1 (Line 1) ---\ncask \"replaywebpage\" do\n  version \"2.4.0\"\n  sha256 \"a4c9ea365a204735a21e7a763c584792d1cfc6e68183a2382e514972544c15eb\"\n\n  url \"https://github.com/webrecorder/replayweb.page/releases/download/v#{version}/ReplayWeb.page-#{version}.dmg\",\n      verified: \"github.com/webrecorder/replayweb.page/\"\n  name \"ReplayWeb.page\"\n  desc \"Web archive viewer for WARC and WACZ files\"\n  homepage \"https://replayweb.page/\"\n\n  livecheck do\n\n\n--- Snippet 2 (Line 18) ---\n  app \"ReplayWeb.page.app\"\n\n  zap trash: [\n    \"~/Library/Application Support/ReplayWeb.page\",\n    \"~/Library/Logs/ReplayWeb.page\",\n    \"~/Library/Preferences/net.webrecorder.replaywebpage.plst\",\n    \"~/Library/Saved Application State/net.webrecorder.replaywebpage.savedState\",\n  ]\n"},{"type":"text","text":"Repository: CapSoftware/Cap\nPath: apps/web/app/(org)/dashboard/caps/components/web-recorder-dialog/web-recorder-dialog.tsx\nURL: https://github.com/CapSoftware/Cap/blob/main/apps/web/app/(org)/dashboard/caps/components/web-recorder-dialog/web-recorder-dialog.tsx\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 27) ---\nimport { SettingsPanel } from \"./SettingsPanel\";\nimport { useCameraDevices } from \"./useCameraDevices\";\nimport { useDevicePreferences } from \"./useDevicePreferences\";\nimport { useDialogInteractions } from \"./useDialogInteractions\";\nimport { useMicrophoneDevices } from \"./useMicrophoneDevices\";\nimport { useWebRecorder } from \"./useWebRecorder\";\nimport {\n\tdialogVariants,\n\tFREE_PLAN_MAX_RECORDING_MS,\n} from \"./web-recorder-constants\";\nimport { WebRecorderDialogHeader } from \"./web-recorder-dialog-header\";\n\nexport const WebRecorderDialog = () => {\n\tconst [open, setOpen] = useState(false);\n\tconst [settingsOpen, setSettingsOpen] = useState(false);\n\tconst [howItWorksOpen, setHowItWorksOpen] = useState(false);\n\tconst [recordingMode, setRecordingMode] =\n\t\tuseState<RecordingMode>(\"fullscreen\");\n"},{"type":"text","text":"Repository: Rhizome-Conifer/conifer\nPath: webrecorder/webrecorder/standalone/webrecorder_full.py\nURL: https://github.com/Rhizome-Conifer/conifer/blob/main/webrecorder/webrecorder/standalone/webrecorder_full.py\nLicense: Apache-2.0\n\nSnippets:\n--- Snippet 1 (Line 1) ---\nimport os\nimport sys\nimport base64\nimport shutil\n\nfrom webrecorder.standalone.standalone import StandaloneRunner\n\nfrom webrecorder.models.usermanager import CLIUserManager\nfrom webrecorder.utils import sanitize_title\n\nfrom webrecorder.standalone.localredisserver import LocalRedisServer\n\nimport redis\nfrom six.moves.urllib.parse import urlsplit\n\n\n# ============================================================================\nclass WebrecorderRunner(StandaloneRunner):\n    REDIS_PORT = 7679\n\n    def __init__(self, argres):\n"}]}
{"parentUuid":"2277e89e-53f4-4c0c-ae22-4f6e1f7c9e68","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"faeb714a-61c5-410d-b669-0ebc662cf207","version":"2.0.70","gitBranch":"main","agentId":"abf8d80","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01VJWx8jzua7CSSYfEcJxGFz","type":"tool_result","content":[{"type":"text","text":"Repository: google-research/google-research\nPath: seq2act/data_generation/crawl_instructions.py\nURL: https://github.com/google-research/google-research/blob/master/seq2act/data_generation/crawl_instructions.py\nLicense: Apache-2.0\n\nSnippets:\n--- Snippet 1 (Line 27) ---\nfrom absl import logging\nfrom bs4 import BeautifulSoup\n\nFLAGS = flags.FLAGS\n\nflags.DEFINE_string('input_warc_dir', None,\n                    'The directory of the downloaded WARC files.')\nflags.DEFINE_string('output_instruction_json', None,\n                    'The path of the generated instruction json file.')\n\n# pylint: disable=line-too-long\nURL_WHITE_LIST = [\n\n\n--- Snippet 2 (Line 146) ---\n  return (set(url_words + instruction_words).intersection(phone_set) and\n          set(instruction_words).intersection(click_set))\n\n\n# DomainStatsIdx\nCOUNT_IN_WARC = 0\nCOUNT_IS_RESPONSE = 1\nCOUNT_HTML = 2\n"},{"type":"text","text":"Repository: fhamborg/news-please\nPath: newsplease/crawler/commoncrawl_crawler.py\nURL: https://github.com/fhamborg/news-please/blob/master/newsplease/crawler/commoncrawl_crawler.py\nLicense: Apache-2.0\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n#!/usr/bin/env python\n\"\"\"\nProvides functionality to crawl and extract news articles from commoncrawl.org. Filter criteria, such as publish date\nand host list, can be defined. Currently, all WARC files will be downloaded to the path WORKINGDIR/cc_download_warc, if\nnot otherwise specified.\n\"\"\"\nimport logging\nimport os\nimport time\n\n\n--- Snippet 2 (Line 31) ---\n\n# log file of fully extracted WARC files\n__log_pathname_fully_extracted_warcs = None\n\n# logging\nlogging.basicConfig(level=logging.INFO)\n__logger = logging.getLogger(__name__)\n\n__number_of_warc_files_on_cc = 0\n\n__extern_callback_on_warc_completed = None\n"},{"type":"text","text":"Repository: fhamborg/news-please\nPath: newsplease/crawler/commoncrawl_extractor.py\nURL: https://github.com/fhamborg/news-please/blob/master/newsplease/crawler/commoncrawl_extractor.py\nLicense: Apache-2.0\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n#!/usr/bin/env python\n\"\"\"\nProvides functionality to crawl and extract news articles from a single WARC file from commoncrawl.org. Filter criteria, such as publish date\nand host list, can be defined. Currently, the WARC file will be downloaded to the path WORKINGDIR/cc_download_warc, if\nnot otherwise specified.\n\"\"\"\nimport logging\nimport os\nimport sys\n\n\n--- Snippet 2 (Line 14) ---\nimport botocore\nfrom dateutil import parser\nfrom hurry.filesize import size\nfrom scrapy.utils.log import configure_logging\nfrom six.moves import urllib\nfrom warcio.archiveiterator import ArchiveIterator\n\nfrom .. import NewsPlease, EmptyResponseError\nfrom . import commoncrawl_crawler\n\n__author__ = \"Felix Hamborg\"\n"},{"type":"text","text":"Repository: Eventual-Inc/Daft\nPath: daft/datasets/common_crawl.py\nURL: https://github.com/Eventual-Inc/Daft/blob/main/daft/datasets/common_crawl.py\nLicense: Apache-2.0\n\nSnippets:\n--- Snippet 1 (Line 4) ---\n\nfrom daft.convert import from_pydict\nfrom daft.datatype import DataType\nfrom daft.expressions import col\nfrom daft.functions import cast, contains, decompress, download, format, split\nfrom daft.io import read_warc\n\nif TYPE_CHECKING:\n    from daft.dataframe import DataFrame\n    from daft.io import IOConfig\n\n\n__all__: tuple[str, ...] = (\"common_crawl\",)\n\n\ndef _get_s3_manifest_path(crawl: str, file_type: Literal[\"warc\", \"wet\", \"wat\"]) -> str:\n    return f\"s3://commoncrawl/crawl-data/{crawl}/{file_type}.paths.gz\"\n\n\ndef _get_http_manifest_path(crawl: str, file_type: Literal[\"warc\", \"wet\", \"wat\"]) -> str:\n    return f\"https://data.commoncrawl.org/crawl-data/{crawl}/{file_type}.paths.gz\"\n"},{"type":"text","text":"Repository: Eventual-Inc/Daft\nPath: daft/io/_warc.py\nURL: https://github.com/Eventual-Inc/Daft/blob/main/daft/io/_warc.py\nLicense: Apache-2.0\n\nSnippets:\n--- Snippet 1 (Line 9) ---\n    FileFormatConfig,\n    IOConfig,\n    StorageConfig,\n    WarcSourceConfig,\n)\nfrom daft.dataframe import DataFrame\nfrom daft.datatype import DataType, TimeUnit\nfrom daft.io.common import get_tabular_files_scan\n\n\n@PublicAPI\ndef read_warc(\n    path: Union[str, list[str]],\n    io_config: Optional[IOConfig] = None,\n    file_path_column: Optional[str] = None,\n    _multithreaded_io: Optional[bool] = None,\n) -> DataFrame:\n    \"\"\"Creates a DataFrame from WARC or gzipped WARC file(s). This is an experimental feature and the API may change in the future.\n\n    Args:\n        path (Union[str, List[str]]): Path to WARC file (allows for wildcards)\n"},{"type":"text","text":"Repository: fhamborg/news-please\nPath: newsplease/examples/commoncrawl.py\nURL: https://github.com/fhamborg/news-please/blob/master/newsplease/examples/commoncrawl.py\nLicense: Apache-2.0\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n#!/usr/bin/env python\n\"\"\"\nThis scripts downloads WARC files from commoncrawl.org's news crawl and extracts articles from these files. You can\ndefine filter criteria that need to be met (see YOUR CONFIG section), otherwise an article is discarded. Currently, the\nscript stores the extracted articles in JSON files, but this behaviour can be adapted to your needs in the method\non_valid_article_extracted. To speed up the crawling and extraction process, the script supports multiprocessing. You can\ncontrol the number of processes with the parameter my_number_of_extraction_processes.\n\n\n\n--- Snippet 2 (Line 19) ---\ngit clone https://github.com/fhamborg/news-please.git\ncd news-please\npython3 -m newsplease.examples.commoncrawl\n\nNote that by default the script does not extract main images since they are not contained\nWARC files. You can enable extraction of main images by setting `my_fetch_images=True`\n\"\"\"\nimport hashlib\nimport json\nimport logging\nimport os\n"},{"type":"text","text":"Repository: webrecorder/pywb\nPath: pywb/warcserver/resource/responseloader.py\nURL: https://github.com/webrecorder/pywb/blob/main/pywb/warcserver/resource/responseloader.py\nLicense: GPL-3.0\n\nSnippets:\n--- Snippet 1 (Line 11) ---\nfrom warcio.statusandheaders import StatusAndHeaders, StatusAndHeadersParser\nfrom warcio.timeutils import (\n    datetime_to_http_date,\n    datetime_to_iso_date,\n    datetime_to_timestamp,\n    http_date_to_datetime,\n    iso_date_to_datetime,\n    timestamp_to_datetime\n)\nfrom warcio.utils import to_native_str\n\nfrom pywb.utils.canonicalize import canonicalize\nfrom pywb.utils.format import ParamFormatter\nfrom pywb.utils.io import StreamIter, call_release_conn, compress_gzip_iter, no_except_close\nfrom pywb.utils.memento import MementoUtils\nfrom pywb.utils.wbexception import LiveResourceException\nfrom pywb.warcserver.http import DefaultAdapters\nfrom pywb.warcserver.resource.pathresolvers import DefaultResolverMixin\nfrom pywb.warcserver.resource.resolvingloader import ResolvingLoader\n\nlogger = logging.getLogger('warcserver')\n"},{"type":"text","text":"Repository: webrecorder/pywb\nPath: pywb/manager/manager.py\nURL: https://github.com/webrecorder/pywb/blob/main/pywb/manager/manager.py\nLicense: GPL-3.0\n\nSnippets:\n--- Snippet 1 (Line 15) ---\nfrom argparse import ArgumentParser, RawTextHelpFormatter\nfrom tempfile import mkdtemp, TemporaryDirectory\nfrom zipfile import ZipFile\n\nfrom pywb.utils.loaders import load_yaml_config\nfrom warcio.timeutils import timestamp20_now\n\nfrom pywb import DEFAULT_CONFIG\n\nfrom six.moves import input\n\n\n\n--- Snippet 2 (Line 49) ---\n\n    COLL_RX = re.compile('^[\\w][-\\w]*$')\n\n    COLLS_DIR = 'collections'\n\n    WARC_RX = re.compile(r'.*\\.w?arc(\\.gz)?$')\n    WACZ_RX = re.compile(r'.*\\.wacz$')\n\n    def __init__(self, coll_name, colls_dir=None, must_exist=True):\n"},{"type":"text","text":"Repository: lutris/lutris\nPath: lutris/services/battlenet.py\nURL: https://github.com/lutris/lutris/blob/master/lutris/services/battlenet.py\nLicense: GPL-3.0\n\nSnippets:\n--- Snippet 1 (Line 30) ---\n    BNET_ENABLED = False\n\nGAME_IDS = {\n    \"s1\": (\"s1\", \"StarCraft\", \"S1\", \"starcraft-remastered\"),\n    \"s2\": (\"s2\", \"StarCraft II\", \"S2\", \"starcraft-ii\"),\n    \"wow\": (\"wow\", \"World of Warcraft\", \"WoW\", \"world-of-warcraft\"),\n    \"wow_classic\": (\"wow_classic\", \"World of Warcraft Classic\", \"WoW_wow_classic\", \"world-of-warcraft-classic\"),\n    \"pro\": (\"pro\", \"Overwatch 2\", \"Pro\", \"overwatch-2\"),\n    \"w2bn\": (\"w2bn\", \"Warcraft II: Battle.net Edition\", \"W2BN\", \"warcraft-ii-battle-net-edition\"),\n    \"w3\": (\"w3\", \"Warcraft III\", \"W3\", \"warcraft-iii-reforged\"),\n    \"hsb\": (\"hsb\", \"Hearthstone\", \"WTCG\", \"hearthstone\"),\n    \"hero\": (\"hero\", \"Heroes of the Storm\", \"Hero\", \"heroes-of-the-storm\"),\n    \"d3cn\": (\"d3cn\", \"暗黑破壞神III\", \"D3CN\", \"diablo-iii\"),\n    \"d3\": (\"d3\", \"Diablo III\", \"D3\", \"diablo-iii\"),\n    \"fenris\": (\"fenris\", \"Diablo IV\", \"Fen\", \"diablo-iv\"),\n\n\n--- Snippet 2 (Line 57) ---\n    \"fore\": (\"fore\", \"Call of Duty: Vanguard\", \"FORE\", \"call-of-duty-vanguard\"),\n    \"d2\": (\"d2\", \"Diablo® II\", \"Diablo II\", \"diablo-ii\"),\n    \"d2LOD\": (\"d2LOD\", \"Diablo® II: Lord of Destruction®\", \"Diablo II\", \"diablo-ii-lord-of-destruction\"),\n    \"w3ROC\": (\"w3ROC\", \"Warcraft® III: Reign of Chaos\", \"Warcraft III\", \"warcraft-iii-reign-of-chaos\"),\n    \"w3tft\": (\"w3tft\", \"Warcraft® III: The Frozen Throne®\", \"Warcraft III\", \"warcraft-iii-the-frozen-throne\"),\n"},{"type":"text","text":"Repository: apify/crawlee-python\nPath: docs/guides/code_examples/creating_web_archive/manual_archiving_parsel_crawler.py\nURL: https://github.com/apify/crawlee-python/blob/master/docs/guides/code_examples/creating_web_archive/manual_archiving_parsel_crawler.py\nLicense: Apache-2.0\n\nSnippets:\n--- Snippet 1 (Line 2) ---\nimport io\nfrom pathlib import Path\n\nfrom warcio.statusandheaders import StatusAndHeaders\nfrom warcio.warcwriter import WARCWriter\n\nfrom crawlee.crawlers import ParselCrawler, ParselCrawlingContext\n\n\nasync def archive_response(context: ParselCrawlingContext, writer: WARCWriter) -> None:\n    \"\"\"Helper function for archiving response in WARC format.\"\"\"\n    # Create WARC records for response\n    response_body = await context.http_response.read()\n    response_payload_stream = io.BytesIO(response_body)\n\n    response_headers = StatusAndHeaders(\n        str(context.http_response.status_code),\n        context.http_response.headers,\n        protocol='HTTP/1.1',\n    )\n    response_record = writer.create_warc_record(\n"}]}]},"uuid":"086dad83-a9e3-4f78-8cc9-b18fe54c7c87","timestamp":"2025-12-19T04:44:01.093Z","toolUseResult":[{"type":"text","text":"Repository: google-research/google-research\nPath: seq2act/data_generation/crawl_instructions.py\nURL: https://github.com/google-research/google-research/blob/master/seq2act/data_generation/crawl_instructions.py\nLicense: Apache-2.0\n\nSnippets:\n--- Snippet 1 (Line 27) ---\nfrom absl import logging\nfrom bs4 import BeautifulSoup\n\nFLAGS = flags.FLAGS\n\nflags.DEFINE_string('input_warc_dir', None,\n                    'The directory of the downloaded WARC files.')\nflags.DEFINE_string('output_instruction_json', None,\n                    'The path of the generated instruction json file.')\n\n# pylint: disable=line-too-long\nURL_WHITE_LIST = [\n\n\n--- Snippet 2 (Line 146) ---\n  return (set(url_words + instruction_words).intersection(phone_set) and\n          set(instruction_words).intersection(click_set))\n\n\n# DomainStatsIdx\nCOUNT_IN_WARC = 0\nCOUNT_IS_RESPONSE = 1\nCOUNT_HTML = 2\n"},{"type":"text","text":"Repository: fhamborg/news-please\nPath: newsplease/crawler/commoncrawl_crawler.py\nURL: https://github.com/fhamborg/news-please/blob/master/newsplease/crawler/commoncrawl_crawler.py\nLicense: Apache-2.0\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n#!/usr/bin/env python\n\"\"\"\nProvides functionality to crawl and extract news articles from commoncrawl.org. Filter criteria, such as publish date\nand host list, can be defined. Currently, all WARC files will be downloaded to the path WORKINGDIR/cc_download_warc, if\nnot otherwise specified.\n\"\"\"\nimport logging\nimport os\nimport time\n\n\n--- Snippet 2 (Line 31) ---\n\n# log file of fully extracted WARC files\n__log_pathname_fully_extracted_warcs = None\n\n# logging\nlogging.basicConfig(level=logging.INFO)\n__logger = logging.getLogger(__name__)\n\n__number_of_warc_files_on_cc = 0\n\n__extern_callback_on_warc_completed = None\n"},{"type":"text","text":"Repository: fhamborg/news-please\nPath: newsplease/crawler/commoncrawl_extractor.py\nURL: https://github.com/fhamborg/news-please/blob/master/newsplease/crawler/commoncrawl_extractor.py\nLicense: Apache-2.0\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n#!/usr/bin/env python\n\"\"\"\nProvides functionality to crawl and extract news articles from a single WARC file from commoncrawl.org. Filter criteria, such as publish date\nand host list, can be defined. Currently, the WARC file will be downloaded to the path WORKINGDIR/cc_download_warc, if\nnot otherwise specified.\n\"\"\"\nimport logging\nimport os\nimport sys\n\n\n--- Snippet 2 (Line 14) ---\nimport botocore\nfrom dateutil import parser\nfrom hurry.filesize import size\nfrom scrapy.utils.log import configure_logging\nfrom six.moves import urllib\nfrom warcio.archiveiterator import ArchiveIterator\n\nfrom .. import NewsPlease, EmptyResponseError\nfrom . import commoncrawl_crawler\n\n__author__ = \"Felix Hamborg\"\n"},{"type":"text","text":"Repository: Eventual-Inc/Daft\nPath: daft/datasets/common_crawl.py\nURL: https://github.com/Eventual-Inc/Daft/blob/main/daft/datasets/common_crawl.py\nLicense: Apache-2.0\n\nSnippets:\n--- Snippet 1 (Line 4) ---\n\nfrom daft.convert import from_pydict\nfrom daft.datatype import DataType\nfrom daft.expressions import col\nfrom daft.functions import cast, contains, decompress, download, format, split\nfrom daft.io import read_warc\n\nif TYPE_CHECKING:\n    from daft.dataframe import DataFrame\n    from daft.io import IOConfig\n\n\n__all__: tuple[str, ...] = (\"common_crawl\",)\n\n\ndef _get_s3_manifest_path(crawl: str, file_type: Literal[\"warc\", \"wet\", \"wat\"]) -> str:\n    return f\"s3://commoncrawl/crawl-data/{crawl}/{file_type}.paths.gz\"\n\n\ndef _get_http_manifest_path(crawl: str, file_type: Literal[\"warc\", \"wet\", \"wat\"]) -> str:\n    return f\"https://data.commoncrawl.org/crawl-data/{crawl}/{file_type}.paths.gz\"\n"},{"type":"text","text":"Repository: Eventual-Inc/Daft\nPath: daft/io/_warc.py\nURL: https://github.com/Eventual-Inc/Daft/blob/main/daft/io/_warc.py\nLicense: Apache-2.0\n\nSnippets:\n--- Snippet 1 (Line 9) ---\n    FileFormatConfig,\n    IOConfig,\n    StorageConfig,\n    WarcSourceConfig,\n)\nfrom daft.dataframe import DataFrame\nfrom daft.datatype import DataType, TimeUnit\nfrom daft.io.common import get_tabular_files_scan\n\n\n@PublicAPI\ndef read_warc(\n    path: Union[str, list[str]],\n    io_config: Optional[IOConfig] = None,\n    file_path_column: Optional[str] = None,\n    _multithreaded_io: Optional[bool] = None,\n) -> DataFrame:\n    \"\"\"Creates a DataFrame from WARC or gzipped WARC file(s). This is an experimental feature and the API may change in the future.\n\n    Args:\n        path (Union[str, List[str]]): Path to WARC file (allows for wildcards)\n"},{"type":"text","text":"Repository: fhamborg/news-please\nPath: newsplease/examples/commoncrawl.py\nURL: https://github.com/fhamborg/news-please/blob/master/newsplease/examples/commoncrawl.py\nLicense: Apache-2.0\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n#!/usr/bin/env python\n\"\"\"\nThis scripts downloads WARC files from commoncrawl.org's news crawl and extracts articles from these files. You can\ndefine filter criteria that need to be met (see YOUR CONFIG section), otherwise an article is discarded. Currently, the\nscript stores the extracted articles in JSON files, but this behaviour can be adapted to your needs in the method\non_valid_article_extracted. To speed up the crawling and extraction process, the script supports multiprocessing. You can\ncontrol the number of processes with the parameter my_number_of_extraction_processes.\n\n\n\n--- Snippet 2 (Line 19) ---\ngit clone https://github.com/fhamborg/news-please.git\ncd news-please\npython3 -m newsplease.examples.commoncrawl\n\nNote that by default the script does not extract main images since they are not contained\nWARC files. You can enable extraction of main images by setting `my_fetch_images=True`\n\"\"\"\nimport hashlib\nimport json\nimport logging\nimport os\n"},{"type":"text","text":"Repository: webrecorder/pywb\nPath: pywb/warcserver/resource/responseloader.py\nURL: https://github.com/webrecorder/pywb/blob/main/pywb/warcserver/resource/responseloader.py\nLicense: GPL-3.0\n\nSnippets:\n--- Snippet 1 (Line 11) ---\nfrom warcio.statusandheaders import StatusAndHeaders, StatusAndHeadersParser\nfrom warcio.timeutils import (\n    datetime_to_http_date,\n    datetime_to_iso_date,\n    datetime_to_timestamp,\n    http_date_to_datetime,\n    iso_date_to_datetime,\n    timestamp_to_datetime\n)\nfrom warcio.utils import to_native_str\n\nfrom pywb.utils.canonicalize import canonicalize\nfrom pywb.utils.format import ParamFormatter\nfrom pywb.utils.io import StreamIter, call_release_conn, compress_gzip_iter, no_except_close\nfrom pywb.utils.memento import MementoUtils\nfrom pywb.utils.wbexception import LiveResourceException\nfrom pywb.warcserver.http import DefaultAdapters\nfrom pywb.warcserver.resource.pathresolvers import DefaultResolverMixin\nfrom pywb.warcserver.resource.resolvingloader import ResolvingLoader\n\nlogger = logging.getLogger('warcserver')\n"},{"type":"text","text":"Repository: webrecorder/pywb\nPath: pywb/manager/manager.py\nURL: https://github.com/webrecorder/pywb/blob/main/pywb/manager/manager.py\nLicense: GPL-3.0\n\nSnippets:\n--- Snippet 1 (Line 15) ---\nfrom argparse import ArgumentParser, RawTextHelpFormatter\nfrom tempfile import mkdtemp, TemporaryDirectory\nfrom zipfile import ZipFile\n\nfrom pywb.utils.loaders import load_yaml_config\nfrom warcio.timeutils import timestamp20_now\n\nfrom pywb import DEFAULT_CONFIG\n\nfrom six.moves import input\n\n\n\n--- Snippet 2 (Line 49) ---\n\n    COLL_RX = re.compile('^[\\w][-\\w]*$')\n\n    COLLS_DIR = 'collections'\n\n    WARC_RX = re.compile(r'.*\\.w?arc(\\.gz)?$')\n    WACZ_RX = re.compile(r'.*\\.wacz$')\n\n    def __init__(self, coll_name, colls_dir=None, must_exist=True):\n"},{"type":"text","text":"Repository: lutris/lutris\nPath: lutris/services/battlenet.py\nURL: https://github.com/lutris/lutris/blob/master/lutris/services/battlenet.py\nLicense: GPL-3.0\n\nSnippets:\n--- Snippet 1 (Line 30) ---\n    BNET_ENABLED = False\n\nGAME_IDS = {\n    \"s1\": (\"s1\", \"StarCraft\", \"S1\", \"starcraft-remastered\"),\n    \"s2\": (\"s2\", \"StarCraft II\", \"S2\", \"starcraft-ii\"),\n    \"wow\": (\"wow\", \"World of Warcraft\", \"WoW\", \"world-of-warcraft\"),\n    \"wow_classic\": (\"wow_classic\", \"World of Warcraft Classic\", \"WoW_wow_classic\", \"world-of-warcraft-classic\"),\n    \"pro\": (\"pro\", \"Overwatch 2\", \"Pro\", \"overwatch-2\"),\n    \"w2bn\": (\"w2bn\", \"Warcraft II: Battle.net Edition\", \"W2BN\", \"warcraft-ii-battle-net-edition\"),\n    \"w3\": (\"w3\", \"Warcraft III\", \"W3\", \"warcraft-iii-reforged\"),\n    \"hsb\": (\"hsb\", \"Hearthstone\", \"WTCG\", \"hearthstone\"),\n    \"hero\": (\"hero\", \"Heroes of the Storm\", \"Hero\", \"heroes-of-the-storm\"),\n    \"d3cn\": (\"d3cn\", \"暗黑破壞神III\", \"D3CN\", \"diablo-iii\"),\n    \"d3\": (\"d3\", \"Diablo III\", \"D3\", \"diablo-iii\"),\n    \"fenris\": (\"fenris\", \"Diablo IV\", \"Fen\", \"diablo-iv\"),\n\n\n--- Snippet 2 (Line 57) ---\n    \"fore\": (\"fore\", \"Call of Duty: Vanguard\", \"FORE\", \"call-of-duty-vanguard\"),\n    \"d2\": (\"d2\", \"Diablo® II\", \"Diablo II\", \"diablo-ii\"),\n    \"d2LOD\": (\"d2LOD\", \"Diablo® II: Lord of Destruction®\", \"Diablo II\", \"diablo-ii-lord-of-destruction\"),\n    \"w3ROC\": (\"w3ROC\", \"Warcraft® III: Reign of Chaos\", \"Warcraft III\", \"warcraft-iii-reign-of-chaos\"),\n    \"w3tft\": (\"w3tft\", \"Warcraft® III: The Frozen Throne®\", \"Warcraft III\", \"warcraft-iii-the-frozen-throne\"),\n"},{"type":"text","text":"Repository: apify/crawlee-python\nPath: docs/guides/code_examples/creating_web_archive/manual_archiving_parsel_crawler.py\nURL: https://github.com/apify/crawlee-python/blob/master/docs/guides/code_examples/creating_web_archive/manual_archiving_parsel_crawler.py\nLicense: Apache-2.0\n\nSnippets:\n--- Snippet 1 (Line 2) ---\nimport io\nfrom pathlib import Path\n\nfrom warcio.statusandheaders import StatusAndHeaders\nfrom warcio.warcwriter import WARCWriter\n\nfrom crawlee.crawlers import ParselCrawler, ParselCrawlingContext\n\n\nasync def archive_response(context: ParselCrawlingContext, writer: WARCWriter) -> None:\n    \"\"\"Helper function for archiving response in WARC format.\"\"\"\n    # Create WARC records for response\n    response_body = await context.http_response.read()\n    response_payload_stream = io.BytesIO(response_body)\n\n    response_headers = StatusAndHeaders(\n        str(context.http_response.status_code),\n        context.http_response.headers,\n        protocol='HTTP/1.1',\n    )\n    response_record = writer.create_warc_record(\n"}]}
{"parentUuid":"086dad83-a9e3-4f78-8cc9-b18fe54c7c87","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"faeb714a-61c5-410d-b669-0ebc662cf207","version":"2.0.70","gitBranch":"main","agentId":"abf8d80","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01HRy2Fe8WDG8WcN62qPGhs8","type":"tool_result","content":[{"type":"text","text":"Repository: janreges/siteone-crawler\nPath: src/Crawler/Export/OfflineWebsiteExporter.php\nURL: https://github.com/janreges/siteone-crawler/blob/main/src/Crawler/Export/OfflineWebsiteExporter.php\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 24) ---\nuse Exception;\n\nclass OfflineWebsiteExporter extends BaseExporter implements Exporter\n{\n\n    const GROUP_OFFLINE_WEBSITE_EXPORTER = 'offline-website-exporter';\n\n    private static $contentTypesThatRequireChanges = [\n        Crawler::CONTENT_TYPE_ID_HTML,\n        Crawler::CONTENT_TYPE_ID_SCRIPT,\n        Crawler::CONTENT_TYPE_ID_STYLESHEET,\n\n\n--- Snippet 2 (Line 138) ---\n            }\n        }\n\n        // add info to summary\n        $this->status->addInfoToSummary(\n            'offline-website-generated',\n            sprintf(\n                \"Offline website generated to '%s' and took %s\",\n                Utils::getOutputFormattedPath($this->offlineExportDirectory),\n"},{"type":"text","text":"Repository: wq/wq\nPath: docs/update_releases.py\nURL: https://github.com/wq/wq/blob/main/docs/update_releases.py\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 375) ---\n    \"django-swappable-models\": \"https://github.com/openwisp/django-swappable-models\",\n    \"django-wq-template\": \"../wq.create/index.md\",\n    \"html-json-forms\": \"https://github.com/wq/html-json-forms\",\n    \"itertable\": \"https://django-data-wizard.wq.io/itertable/\",\n    \"markdown\": \"https://github.com/wq/wq.markdown\",\n    \"offline-website-logger\": \"https://github.com/sheppard/offline-website-logger\",\n    \"python-requirejs\": \"https://github.com/sheppard/python-requirejs\",\n    \"vera\": \"https://github.com/powered-by-wq/vera\",\n    \"wq.core\": \"../wq.build/index.md\",\n    \"wq.start\": \"../wq.create/index.md\",\n    \"wq.start/releases\": \"https://wq.io/releases/?repo=wq.create\",\n"},{"type":"text","text":"Repository: mozilla-mobile/firefox-ios\nPath: firefox-ios/Shared/de.lproj/ClearPrivateData.strings\nURL: https://github.com/mozilla-mobile/firefox-ios/blob/main/firefox-ios/Shared/de.lproj/ClearPrivateData.strings\nLicense: MPL-2.0\n\nSnippets:\n--- Snippet 1 (Line 9) ---\n\n/* Settings item for deleting downloaded files */\n\"Downloaded Files\" = \"Heruntergeladene Dateien\";\n\n/* Settings item for clearing website data */\n\"Offline Website Data\" = \"Offline-Website-Daten\";\n\n/* Settings item for clearing passwords and login data */\n\"Saved Logins\" = \"Gespeicherte Zugangsdaten\";\n\n/* A settings item that allows a user to use Apple's “Spotlight Search” in Data Management's Website Data option to search for and select an item to delete. */\n"},{"type":"text","text":"Repository: WICG/webpackage\nPath: draft-yasskin-http-origin-signed-responses.md\nURL: https://github.com/WICG/webpackage/blob/main/draft-yasskin-http-origin-signed-responses.md\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 1386) ---\n\n{{signature-validity}} can succeed when some delivered headers aren't included\nin the signed set. This accommodates current TLS-terminating intermediates and\nmay be useful for SRI ({{uc-sri}}), but is risky for trusting cross-origin\nresponses ({{uc-pushed-subresources}}, {{uc-explicit-distributor}}, and\n{{uc-offline-websites}}). {{cross-origin-push}} requires all headers to be\nincluded in the signature before trusting cross-origin pushed resources, at Ryan\nSleevi's recommendation.\n\n## application/signed-exchange ## {#security-application-signed-exchange}\n\n\n\n--- Snippet 2 (Line 1824) ---\nWhile full application analysis probably needs to wait until the authority can\nsign bundles of exchanges, authorities may be able to guarantee certain\nproperties by just checking a top-level resource and its {{SRI}}-constrained\nsub-resources.\n\n## Offline websites {#uc-offline-websites}\n\nFully-offline websites can be represented as bundles of signed exchanges,\nalthough an optimization to reduce the number of signature verifications may be\n"},{"type":"text","text":"Repository: ballerine-io/ballerine\nPath: apps/backoffice-v2/src/domains/business-reports/utils/__fixtures__/sandbox-report.json\nURL: https://github.com/ballerine-io/ballerine/blob/dev/apps/backoffice-v2/src/domains/business-reports/utils/__fixtures__/sandbox-report.json\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 740) ---\n      \"companyName\": null,\n      \"isAlert\": false,\n      \"riskLevel\": \"high\",\n      \"allViolations\": [\n        {\n          \"id\": \"content-offline-website\",\n          \"name\": \"Offline Website\",\n          \"riskLevel\": \"critical\",\n          \"domain\": \"content\",\n          \"reason\": \"\",\n\n\n--- Snippet 2 (Line 954) ---\n      \"companyName\": null,\n      \"isAlert\": false,\n      \"riskLevel\": \"high\",\n      \"allViolations\": [\n        {\n          \"id\": \"content-offline-website\",\n          \"name\": \"Offline Website\",\n          \"riskLevel\": \"critical\",\n          \"domain\": \"content\",\n          \"reason\": \"\",\n"},{"type":"text","text":"Repository: wq/wq\nPath: docs/releases/wq.app-0.7.0.md\nURL: https://github.com/wq/wq/blob/main/docs/releases/wq.app-0.7.0.md\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 33) ---\n\n### New Modules\n- **wq/owl.js**:  (Beta) client component for the [Offline Website Logger](https://github.com/sheppard/offline-website-logger)\n"},{"type":"text","text":"Repository: janreges/siteone-crawler\nPath: README.md\nURL: https://github.com/janreges/siteone-crawler/blob/main/README.md\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 20) ---\n- [✨ Features](#-features)\n    * [🕷️ Crawler](#️-crawler)\n    * [🛠️ Dev/DevOps assistant](#️-devdevops-assistant)\n    * [📊 Analyzer](#-analyzer)\n    * [📧 Reporter](#-reporter)\n    * [💾 Offline website generator](#-offline-website-generator)\n    * [🗺️ Sitemap generator](#️-sitemap-generator)\n    * [🤝 For active contributors](#-for-active-contributors)\n- [🚀 Installation](#-installation)\n    * [📦 Ready-to-use releases](#-ready-to-use-releases)\n    * [🐧 Linux (x64)](#-linux-x64)\n"},{"type":"text","text":"Repository: janreges/siteone-crawler\nPath: docs/OUTPUT-crawler.siteone.io.txt\nURL: https://github.com/janreges/siteone-crawler/blob/main/docs/OUTPUT-crawler.siteone.io.txt\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 86) ---\n64/67   | 95%  |>>>>>>>>>>| /features/offline-website-generator/                                                                                           | 200    | HTML     | 14 ms  | 47 kB  | 60 min  | 1/3      | 1/5     \n\n\n--- Snippet 2 (Line 441) ---\n14 ms  | 200    | https://crawler.siteone.io/features/offline-website-generator/                                                                                                                                                  \n"},{"type":"text","text":"Repository: mozilla/policy-templates\nPath: windows/de-DE/firefox.adml\nURL: https://github.com/mozilla/policy-templates/blob/master/windows/de-DE/firefox.adml\nLicense: MPL-2.0\n\nSnippets:\n--- Snippet 1 (Line 609) ---\n\nWenn Sie die Richtlinieneinstellung deaktivieren oder nicht konfigurieren wird eine Upgrade Seite angezeigt.</string>\n      <string id=\"SanitizeOnShutdown\">Die Chronik löschen, wenn Firefox geschlossen wird (Verschoben)</string>\n      <string id=\"SanitizeOnShutdown_Explain\">Wenn Sie die Richtlinieneinstellung aktivieren, werden alle Daten der Chronik gelöscht, wenn Firefox geschlossen wird. Dies beinhaltet Browsing &amp; Download Verlauf, Cookies, Aktive Logins, Cache, Form &amp; Suchverlauf, Website-Einstellungen und Offline-Website-Daten.\n\nWenn Sie die Richtlinieneinstellung deaktivieren oder nicht konfigurieren, wird die keine Daten der Chronik gelöscht.</string>\n      <string id=\"SanitizeOnShutdown_group\">Browserdaten löschen, wenn der Browser geschlossen wird</string>\n\n      <string id=\"SanitizeOnShutdown_Cache\">Cache</string>\n"},{"type":"text","text":"Repository: janreges/siteone-crawler\nPath: docs/OUTPUT-crawler.siteone.io.json\nURL: https://github.com/janreges/siteone-crawler/blob/main/docs/OUTPUT-crawler.siteone.io.json\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 665) ---\n            \"cacheTypeFlags\": 31,\n            \"cacheLifetime\": 31536000,\n            \"extras\": []\n        },\n        {\n            \"url\": \"https:\\/\\/crawler.siteone.io\\/features\\/offline-website-generator\\/\",\n            \"status\": \"200\",\n            \"elapsedTime\": 0.014,\n            \"size\": 47988,\n            \"type\": 1,\n            \"cacheTypeFlags\": 31,\n\n\n--- Snippet 2 (Line 2924) ---\n                },\n                {\n                    \"uqId\": \"06f019a8\",\n                    \"sourceUqId\": \"98eb5e29\",\n                    \"sourceAttr\": 10,\n                    \"url\": \"https:\\/\\/crawler.siteone.io\\/features\\/offline-website-generator\\/\",\n                    \"statusCode\": 200,\n                    \"requestTime\": 0.013763904571533203,\n                    \"requestTimeFormatted\": \"14 ms\",\n"}]}]},"uuid":"6a959957-d137-428c-a5e6-07f5bbfcf054","timestamp":"2025-12-19T04:44:01.503Z","toolUseResult":[{"type":"text","text":"Repository: janreges/siteone-crawler\nPath: src/Crawler/Export/OfflineWebsiteExporter.php\nURL: https://github.com/janreges/siteone-crawler/blob/main/src/Crawler/Export/OfflineWebsiteExporter.php\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 24) ---\nuse Exception;\n\nclass OfflineWebsiteExporter extends BaseExporter implements Exporter\n{\n\n    const GROUP_OFFLINE_WEBSITE_EXPORTER = 'offline-website-exporter';\n\n    private static $contentTypesThatRequireChanges = [\n        Crawler::CONTENT_TYPE_ID_HTML,\n        Crawler::CONTENT_TYPE_ID_SCRIPT,\n        Crawler::CONTENT_TYPE_ID_STYLESHEET,\n\n\n--- Snippet 2 (Line 138) ---\n            }\n        }\n\n        // add info to summary\n        $this->status->addInfoToSummary(\n            'offline-website-generated',\n            sprintf(\n                \"Offline website generated to '%s' and took %s\",\n                Utils::getOutputFormattedPath($this->offlineExportDirectory),\n"},{"type":"text","text":"Repository: wq/wq\nPath: docs/update_releases.py\nURL: https://github.com/wq/wq/blob/main/docs/update_releases.py\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 375) ---\n    \"django-swappable-models\": \"https://github.com/openwisp/django-swappable-models\",\n    \"django-wq-template\": \"../wq.create/index.md\",\n    \"html-json-forms\": \"https://github.com/wq/html-json-forms\",\n    \"itertable\": \"https://django-data-wizard.wq.io/itertable/\",\n    \"markdown\": \"https://github.com/wq/wq.markdown\",\n    \"offline-website-logger\": \"https://github.com/sheppard/offline-website-logger\",\n    \"python-requirejs\": \"https://github.com/sheppard/python-requirejs\",\n    \"vera\": \"https://github.com/powered-by-wq/vera\",\n    \"wq.core\": \"../wq.build/index.md\",\n    \"wq.start\": \"../wq.create/index.md\",\n    \"wq.start/releases\": \"https://wq.io/releases/?repo=wq.create\",\n"},{"type":"text","text":"Repository: mozilla-mobile/firefox-ios\nPath: firefox-ios/Shared/de.lproj/ClearPrivateData.strings\nURL: https://github.com/mozilla-mobile/firefox-ios/blob/main/firefox-ios/Shared/de.lproj/ClearPrivateData.strings\nLicense: MPL-2.0\n\nSnippets:\n--- Snippet 1 (Line 9) ---\n\n/* Settings item for deleting downloaded files */\n\"Downloaded Files\" = \"Heruntergeladene Dateien\";\n\n/* Settings item for clearing website data */\n\"Offline Website Data\" = \"Offline-Website-Daten\";\n\n/* Settings item for clearing passwords and login data */\n\"Saved Logins\" = \"Gespeicherte Zugangsdaten\";\n\n/* A settings item that allows a user to use Apple's “Spotlight Search” in Data Management's Website Data option to search for and select an item to delete. */\n"},{"type":"text","text":"Repository: WICG/webpackage\nPath: draft-yasskin-http-origin-signed-responses.md\nURL: https://github.com/WICG/webpackage/blob/main/draft-yasskin-http-origin-signed-responses.md\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 1386) ---\n\n{{signature-validity}} can succeed when some delivered headers aren't included\nin the signed set. This accommodates current TLS-terminating intermediates and\nmay be useful for SRI ({{uc-sri}}), but is risky for trusting cross-origin\nresponses ({{uc-pushed-subresources}}, {{uc-explicit-distributor}}, and\n{{uc-offline-websites}}). {{cross-origin-push}} requires all headers to be\nincluded in the signature before trusting cross-origin pushed resources, at Ryan\nSleevi's recommendation.\n\n## application/signed-exchange ## {#security-application-signed-exchange}\n\n\n\n--- Snippet 2 (Line 1824) ---\nWhile full application analysis probably needs to wait until the authority can\nsign bundles of exchanges, authorities may be able to guarantee certain\nproperties by just checking a top-level resource and its {{SRI}}-constrained\nsub-resources.\n\n## Offline websites {#uc-offline-websites}\n\nFully-offline websites can be represented as bundles of signed exchanges,\nalthough an optimization to reduce the number of signature verifications may be\n"},{"type":"text","text":"Repository: ballerine-io/ballerine\nPath: apps/backoffice-v2/src/domains/business-reports/utils/__fixtures__/sandbox-report.json\nURL: https://github.com/ballerine-io/ballerine/blob/dev/apps/backoffice-v2/src/domains/business-reports/utils/__fixtures__/sandbox-report.json\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 740) ---\n      \"companyName\": null,\n      \"isAlert\": false,\n      \"riskLevel\": \"high\",\n      \"allViolations\": [\n        {\n          \"id\": \"content-offline-website\",\n          \"name\": \"Offline Website\",\n          \"riskLevel\": \"critical\",\n          \"domain\": \"content\",\n          \"reason\": \"\",\n\n\n--- Snippet 2 (Line 954) ---\n      \"companyName\": null,\n      \"isAlert\": false,\n      \"riskLevel\": \"high\",\n      \"allViolations\": [\n        {\n          \"id\": \"content-offline-website\",\n          \"name\": \"Offline Website\",\n          \"riskLevel\": \"critical\",\n          \"domain\": \"content\",\n          \"reason\": \"\",\n"},{"type":"text","text":"Repository: wq/wq\nPath: docs/releases/wq.app-0.7.0.md\nURL: https://github.com/wq/wq/blob/main/docs/releases/wq.app-0.7.0.md\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 33) ---\n\n### New Modules\n- **wq/owl.js**:  (Beta) client component for the [Offline Website Logger](https://github.com/sheppard/offline-website-logger)\n"},{"type":"text","text":"Repository: janreges/siteone-crawler\nPath: README.md\nURL: https://github.com/janreges/siteone-crawler/blob/main/README.md\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 20) ---\n- [✨ Features](#-features)\n    * [🕷️ Crawler](#️-crawler)\n    * [🛠️ Dev/DevOps assistant](#️-devdevops-assistant)\n    * [📊 Analyzer](#-analyzer)\n    * [📧 Reporter](#-reporter)\n    * [💾 Offline website generator](#-offline-website-generator)\n    * [🗺️ Sitemap generator](#️-sitemap-generator)\n    * [🤝 For active contributors](#-for-active-contributors)\n- [🚀 Installation](#-installation)\n    * [📦 Ready-to-use releases](#-ready-to-use-releases)\n    * [🐧 Linux (x64)](#-linux-x64)\n"},{"type":"text","text":"Repository: janreges/siteone-crawler\nPath: docs/OUTPUT-crawler.siteone.io.txt\nURL: https://github.com/janreges/siteone-crawler/blob/main/docs/OUTPUT-crawler.siteone.io.txt\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 86) ---\n64/67   | 95%  |>>>>>>>>>>| /features/offline-website-generator/                                                                                           | 200    | HTML     | 14 ms  | 47 kB  | 60 min  | 1/3      | 1/5     \n\n\n--- Snippet 2 (Line 441) ---\n14 ms  | 200    | https://crawler.siteone.io/features/offline-website-generator/                                                                                                                                                  \n"},{"type":"text","text":"Repository: mozilla/policy-templates\nPath: windows/de-DE/firefox.adml\nURL: https://github.com/mozilla/policy-templates/blob/master/windows/de-DE/firefox.adml\nLicense: MPL-2.0\n\nSnippets:\n--- Snippet 1 (Line 609) ---\n\nWenn Sie die Richtlinieneinstellung deaktivieren oder nicht konfigurieren wird eine Upgrade Seite angezeigt.</string>\n      <string id=\"SanitizeOnShutdown\">Die Chronik löschen, wenn Firefox geschlossen wird (Verschoben)</string>\n      <string id=\"SanitizeOnShutdown_Explain\">Wenn Sie die Richtlinieneinstellung aktivieren, werden alle Daten der Chronik gelöscht, wenn Firefox geschlossen wird. Dies beinhaltet Browsing &amp; Download Verlauf, Cookies, Aktive Logins, Cache, Form &amp; Suchverlauf, Website-Einstellungen und Offline-Website-Daten.\n\nWenn Sie die Richtlinieneinstellung deaktivieren oder nicht konfigurieren, wird die keine Daten der Chronik gelöscht.</string>\n      <string id=\"SanitizeOnShutdown_group\">Browserdaten löschen, wenn der Browser geschlossen wird</string>\n\n      <string id=\"SanitizeOnShutdown_Cache\">Cache</string>\n"},{"type":"text","text":"Repository: janreges/siteone-crawler\nPath: docs/OUTPUT-crawler.siteone.io.json\nURL: https://github.com/janreges/siteone-crawler/blob/main/docs/OUTPUT-crawler.siteone.io.json\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 665) ---\n            \"cacheTypeFlags\": 31,\n            \"cacheLifetime\": 31536000,\n            \"extras\": []\n        },\n        {\n            \"url\": \"https:\\/\\/crawler.siteone.io\\/features\\/offline-website-generator\\/\",\n            \"status\": \"200\",\n            \"elapsedTime\": 0.014,\n            \"size\": 47988,\n            \"type\": 1,\n            \"cacheTypeFlags\": 31,\n\n\n--- Snippet 2 (Line 2924) ---\n                },\n                {\n                    \"uqId\": \"06f019a8\",\n                    \"sourceUqId\": \"98eb5e29\",\n                    \"sourceAttr\": 10,\n                    \"url\": \"https:\\/\\/crawler.siteone.io\\/features\\/offline-website-generator\\/\",\n                    \"statusCode\": 200,\n                    \"requestTime\": 0.013763904571533203,\n                    \"requestTimeFormatted\": \"14 ms\",\n"}]}
{"parentUuid":"6a959957-d137-428c-a5e6-07f5bbfcf054","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"faeb714a-61c5-410d-b669-0ebc662cf207","version":"2.0.70","gitBranch":"main","agentId":"abf8d80","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01M93mMUHZX6iGygsp25kHgD","type":"tool_result","content":[{"type":"text","text":"Repository: kiwibrowser/src.next\nPath: chrome/browser/ui/browser_command_controller.h\nURL: https://github.com/kiwibrowser/src.next/blob/kiwi/chrome/browser/ui/browser_command_controller.h\nLicense: BSD-3-Clause\n\nSnippets:\n--- Snippet 1 (Line 147) ---\n\n  // Updates commands that affect the bookmark bar.\n  void UpdateCommandsForBookmarkBar();\n\n  // Updates commands that affect file selection dialogs in aggregate,\n  // namely the save-page-as state and the open-file state.\n  void UpdateCommandsForFileSelectionDialogs();\n\n  // Update commands whose state depends on the type of fullscreen mode the\n  // window is in.\n  void UpdateCommandsForFullscreenMode();\n\n\n--- Snippet 2 (Line 170) ---\n  void UpdatePrintingState();\n\n  // Updates the SHOW_SYNC_SETUP menu entry.\n  void OnSigninAllowedPrefChange();\n\n  // Updates the save-page-as command state.\n  void UpdateSaveAsState();\n\n  // Updates the show-sync command state.\n"},{"type":"text","text":"Repository: kiwibrowser/src.next\nPath: chrome/browser/download/save_page_browsertest.cc\nURL: https://github.com/kiwibrowser/src.next/blob/kiwi/chrome/browser/download/save_page_browsertest.cc\nLicense: BSD-3-Clause\n\nSnippets:\n--- Snippet 1 (Line 918) ---\n// was handled as a download (http://crbug.com/42212).\nIN_PROC_BROWSER_TEST_F(SavePageBrowserTest, SaveDownloadableIFrame) {\n  GURL url =\n      embedded_test_server()->GetURL(\"/downloads/iframe-src-is-a-download.htm\");\n\n  // Wait for and then dismiss the non-save-page-as-related download item\n  // (the one associated with downloading of \"thisdayinhistory.xls\" file).\n  {\n    GURL download_url =\n        embedded_test_server()->GetURL(\"/downloads/thisdayinhistory.xls\");\n    DownloadPersistedObserver persisted(\n\n\n--- Snippet 2 (Line 1192) ---\n  EXPECT_TRUE(base::DirectoryExists(dir));\n  EXPECT_TRUE(base::PathExists(full_file_name));\n}\n\n// Test suite that verifies that the frame tree \"looks\" the same before\n// and after a save-page-as.\nclass SavePageOriginalVsSavedComparisonTest\n    : public SavePageSitePerProcessBrowserTest,\n      public ::testing::WithParamInterface<content::SavePageType> {\n"},{"type":"text","text":"Repository: kiwix/kiwix-desktop\nPath: src/kiwixapp.cpp\nURL: https://github.com/kiwix/kiwix-desktop/blob/main/src/kiwixapp.cpp\nLicense: GPL-3.0\n\nSnippets:\n--- Snippet 1 (Line 430) ---\n            this, [=]() { openZimFile(); });\n\n    CREATE_ACTION(OpenRecentAction, gt(\"open-recent\"));\n    HIDE_ACTION(OpenRecentAction);\n\n    CREATE_ACTION_SHORTCUT(SavePageAsAction, gt(\"save-page-as\"), QKeySequence::Save);\n\n    CREATE_ACTION_SHORTCUTS(SearchArticleAction, gt(\"search-article\"), QList<QKeySequence>({QKeySequence(Qt::Key_F6), QKeySequence(Qt::CTRL | Qt::Key_L), QKeySequence(Qt::ALT | Qt::Key_D)}));\n\n    CREATE_ACTION_SHORTCUT(SearchLibraryAction, gt(\"search-in-library\"), QKeySequence(Qt::CTRL | Qt::SHIFT | Qt::Key_R));\n    HIDE_ACTION(SearchLibraryAction);\n"},{"type":"text","text":"Repository: atomontage/chrome-private\nPath: chrome-private.sh\nURL: https://github.com/atomontage/chrome-private/blob/master/chrome-private.sh\nLicense: Unlicense\n\nSnippets:\n--- Snippet 1 (Line 70) ---\n#\n\n\nCHROME_ARGS=(--disable-bundled-ppapi-flash --disable-offline-load-stale-cache\n             --disk-cache-size=1 --media-cache-size=1 --disk-cache-dir=/dev/null\n             --no-first-run --no-referrers --save-page-as-mhtml --no-default-browser-check)\n\nCHROME_NO_GPU_ARGS=(--disable-gpu)\nCHROME_NO_3D_ARGS=(--disable-3d-apis --disable-webgl)\n\nkeep=0\n"},{"type":"text","text":"Repository: yibie/Copy-as-org-mode-chrome\nPath: src/background.ts\nURL: https://github.com/yibie/Copy-as-org-mode-chrome/blob/main/src/background.ts\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 50) ---\n// 创建右键菜单\nchrome.runtime.onInstalled.addListener(() => {\n  chrome.contextMenus.removeAll(() => {\n    chrome.contextMenus.create(\n      {\n        id: \"save-page-as-org\",\n        title: \"Save Page as Org-Mode\",\n        contexts: [\"page\", \"frame\"],\n        documentUrlPatterns: [\"<all_urls>\"],\n      }\n    );\n\n\n--- Snippet 2 (Line 124) ---\n  if (!await canExecuteScript(tabId)) {\n    showBgNotification('Error', 'Cannot execute script on this page');\n    return;\n  }\n\n  if (info.menuItemId === \"save-page-as-org\") {\n    try {\n      await savePageAsOrg(tabId);\n    } catch (err: unknown) {\n"},{"type":"text","text":"Repository: sarkershantonu/Automation-Getting-Started\nPath: ChromeHeadless-Selenium/src/main/java/org/automation/chrome/ChromeArgConstants.java\nURL: https://github.com/sarkershantonu/Automation-Getting-Started/blob/master/ChromeHeadless-Selenium/src/main/java/org/automation/chrome/ChromeArgConstants.java\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 1069) ---\n    String safebrowsing_disable_download_protection = \"safebrowsing-disable-download-protection\";\n    String safebrowsing_disable_extension_blacklist = \"safebrowsing-disable-extension-blacklist\";\n    String safebrowsing_manual_download_blacklist = \"safebrowsing-manual-download-blacklist\";\n    String SafeSites = \"SafeSites\";\n    String sandbox_ipc = \"sandbox-ipc\";\n    String save_page_as_mhtml = \"save-page-as-mhtml\";\n    String screen_config = \"screen-config\";\n    String screenshot = \"screenshot\";\n    String scripts_require_action = \"scripts-require-action\";\n    String search_provider_logo_url = \"search-provider-logo-url\";\n    String secondary = \"secondary\";\n"},{"type":"text","text":"Repository: AnandChowdhary/puppet\nPath: src/index.ts\nURL: https://github.com/AnandChowdhary/puppet/blob/master/src/index.ts\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 2) ---\nimport { start, success, debug } from \"signale\";\nimport got from \"got\";\nimport { readFile } from \"fs-extra\";\nimport { join } from \"path\";\nimport { navigateTo } from \"./commands/navigation\";\nimport { screenshot, saveAsPdf, saveAsHtml } from \"./commands/save-page-as\";\nimport { saveToFile } from \"./commands/files\";\nimport { waitForTime, waitForNavigation } from \"./commands/timers\";\nimport { triggerMouseClickMove } from \"./commands/mouse\";\n\n/**\n"},{"type":"text","text":"Repository: bonitasoft/bonita-ui-designer\nPath: frontend/app/js/editor/header/save-as-popup.html\nURL: https://github.com/bonitasoft/bonita-ui-designer/blob/dev/frontend/app/js/editor/header/save-as-popup.html\nLicense: GPL-2.0\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n<div class=\"modal-header\">\n    <h3 class=\"modal-title break-word\" translate>Save {{ctrl.page.name}} as...</h3>\n</div>\n<form class=\"form\" name=\"newPage\">\n    <div class=\"modal-body\" id=\"modal-save-page-as\">\n        <div class=\"form-group\">\n            <label class=\"control-label\" for=\"page-name\" tranlate>Name</label>\n            <input\n                name=\"name\"\n                ng-model=\"ctrl.newName\"\n"},{"type":"text","text":"Repository: AnandChowdhary/puppet\nPath: src/commands/save-page-as.spec.ts\nURL: https://github.com/AnandChowdhary/puppet/blob/master/src/commands/save-page-as.spec.ts\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 1) ---\nimport { puppet } from \"../\";\nimport { launch } from \"puppeteer\";\nimport { screenshot, saveAsPdf, saveAsHtml } from \"./save-page-as\";\nimport { readFile, unlink } from \"fs-extra\";\nimport { join } from \"path\";\njest.setTimeout(30000);\n\ndescribe(\"puppet - HTML\", () => {\n"},{"type":"text","text":"Repository: Kapeli/cheatsheets\nPath: cheatsheets/Chromium_Command_Line_Switches.rb\nURL: https://github.com/Kapeli/cheatsheets/blob/master/cheatsheets/Chromium_Command_Line_Switches.rb\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 10639) ---\n      END\n    end\n    entry do\n      name <<-'END'\n      ```           \n      --save-page-as-mhtml\n      ```\n      END\n      notes <<-'END'\n      Disable saving pages as HTML-only, disable saving pages as HTML Complete (with a directory of sub-resources). Enable only saving pages as MHTML. See http://crbug.com/120416 for how to remove this switch. \n      END\n"}]}]},"uuid":"b6643eb7-61d3-4b88-a11f-5f6a9855284e","timestamp":"2025-12-19T04:44:01.776Z","toolUseResult":[{"type":"text","text":"Repository: kiwibrowser/src.next\nPath: chrome/browser/ui/browser_command_controller.h\nURL: https://github.com/kiwibrowser/src.next/blob/kiwi/chrome/browser/ui/browser_command_controller.h\nLicense: BSD-3-Clause\n\nSnippets:\n--- Snippet 1 (Line 147) ---\n\n  // Updates commands that affect the bookmark bar.\n  void UpdateCommandsForBookmarkBar();\n\n  // Updates commands that affect file selection dialogs in aggregate,\n  // namely the save-page-as state and the open-file state.\n  void UpdateCommandsForFileSelectionDialogs();\n\n  // Update commands whose state depends on the type of fullscreen mode the\n  // window is in.\n  void UpdateCommandsForFullscreenMode();\n\n\n--- Snippet 2 (Line 170) ---\n  void UpdatePrintingState();\n\n  // Updates the SHOW_SYNC_SETUP menu entry.\n  void OnSigninAllowedPrefChange();\n\n  // Updates the save-page-as command state.\n  void UpdateSaveAsState();\n\n  // Updates the show-sync command state.\n"},{"type":"text","text":"Repository: kiwibrowser/src.next\nPath: chrome/browser/download/save_page_browsertest.cc\nURL: https://github.com/kiwibrowser/src.next/blob/kiwi/chrome/browser/download/save_page_browsertest.cc\nLicense: BSD-3-Clause\n\nSnippets:\n--- Snippet 1 (Line 918) ---\n// was handled as a download (http://crbug.com/42212).\nIN_PROC_BROWSER_TEST_F(SavePageBrowserTest, SaveDownloadableIFrame) {\n  GURL url =\n      embedded_test_server()->GetURL(\"/downloads/iframe-src-is-a-download.htm\");\n\n  // Wait for and then dismiss the non-save-page-as-related download item\n  // (the one associated with downloading of \"thisdayinhistory.xls\" file).\n  {\n    GURL download_url =\n        embedded_test_server()->GetURL(\"/downloads/thisdayinhistory.xls\");\n    DownloadPersistedObserver persisted(\n\n\n--- Snippet 2 (Line 1192) ---\n  EXPECT_TRUE(base::DirectoryExists(dir));\n  EXPECT_TRUE(base::PathExists(full_file_name));\n}\n\n// Test suite that verifies that the frame tree \"looks\" the same before\n// and after a save-page-as.\nclass SavePageOriginalVsSavedComparisonTest\n    : public SavePageSitePerProcessBrowserTest,\n      public ::testing::WithParamInterface<content::SavePageType> {\n"},{"type":"text","text":"Repository: kiwix/kiwix-desktop\nPath: src/kiwixapp.cpp\nURL: https://github.com/kiwix/kiwix-desktop/blob/main/src/kiwixapp.cpp\nLicense: GPL-3.0\n\nSnippets:\n--- Snippet 1 (Line 430) ---\n            this, [=]() { openZimFile(); });\n\n    CREATE_ACTION(OpenRecentAction, gt(\"open-recent\"));\n    HIDE_ACTION(OpenRecentAction);\n\n    CREATE_ACTION_SHORTCUT(SavePageAsAction, gt(\"save-page-as\"), QKeySequence::Save);\n\n    CREATE_ACTION_SHORTCUTS(SearchArticleAction, gt(\"search-article\"), QList<QKeySequence>({QKeySequence(Qt::Key_F6), QKeySequence(Qt::CTRL | Qt::Key_L), QKeySequence(Qt::ALT | Qt::Key_D)}));\n\n    CREATE_ACTION_SHORTCUT(SearchLibraryAction, gt(\"search-in-library\"), QKeySequence(Qt::CTRL | Qt::SHIFT | Qt::Key_R));\n    HIDE_ACTION(SearchLibraryAction);\n"},{"type":"text","text":"Repository: atomontage/chrome-private\nPath: chrome-private.sh\nURL: https://github.com/atomontage/chrome-private/blob/master/chrome-private.sh\nLicense: Unlicense\n\nSnippets:\n--- Snippet 1 (Line 70) ---\n#\n\n\nCHROME_ARGS=(--disable-bundled-ppapi-flash --disable-offline-load-stale-cache\n             --disk-cache-size=1 --media-cache-size=1 --disk-cache-dir=/dev/null\n             --no-first-run --no-referrers --save-page-as-mhtml --no-default-browser-check)\n\nCHROME_NO_GPU_ARGS=(--disable-gpu)\nCHROME_NO_3D_ARGS=(--disable-3d-apis --disable-webgl)\n\nkeep=0\n"},{"type":"text","text":"Repository: yibie/Copy-as-org-mode-chrome\nPath: src/background.ts\nURL: https://github.com/yibie/Copy-as-org-mode-chrome/blob/main/src/background.ts\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 50) ---\n// 创建右键菜单\nchrome.runtime.onInstalled.addListener(() => {\n  chrome.contextMenus.removeAll(() => {\n    chrome.contextMenus.create(\n      {\n        id: \"save-page-as-org\",\n        title: \"Save Page as Org-Mode\",\n        contexts: [\"page\", \"frame\"],\n        documentUrlPatterns: [\"<all_urls>\"],\n      }\n    );\n\n\n--- Snippet 2 (Line 124) ---\n  if (!await canExecuteScript(tabId)) {\n    showBgNotification('Error', 'Cannot execute script on this page');\n    return;\n  }\n\n  if (info.menuItemId === \"save-page-as-org\") {\n    try {\n      await savePageAsOrg(tabId);\n    } catch (err: unknown) {\n"},{"type":"text","text":"Repository: sarkershantonu/Automation-Getting-Started\nPath: ChromeHeadless-Selenium/src/main/java/org/automation/chrome/ChromeArgConstants.java\nURL: https://github.com/sarkershantonu/Automation-Getting-Started/blob/master/ChromeHeadless-Selenium/src/main/java/org/automation/chrome/ChromeArgConstants.java\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 1069) ---\n    String safebrowsing_disable_download_protection = \"safebrowsing-disable-download-protection\";\n    String safebrowsing_disable_extension_blacklist = \"safebrowsing-disable-extension-blacklist\";\n    String safebrowsing_manual_download_blacklist = \"safebrowsing-manual-download-blacklist\";\n    String SafeSites = \"SafeSites\";\n    String sandbox_ipc = \"sandbox-ipc\";\n    String save_page_as_mhtml = \"save-page-as-mhtml\";\n    String screen_config = \"screen-config\";\n    String screenshot = \"screenshot\";\n    String scripts_require_action = \"scripts-require-action\";\n    String search_provider_logo_url = \"search-provider-logo-url\";\n    String secondary = \"secondary\";\n"},{"type":"text","text":"Repository: AnandChowdhary/puppet\nPath: src/index.ts\nURL: https://github.com/AnandChowdhary/puppet/blob/master/src/index.ts\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 2) ---\nimport { start, success, debug } from \"signale\";\nimport got from \"got\";\nimport { readFile } from \"fs-extra\";\nimport { join } from \"path\";\nimport { navigateTo } from \"./commands/navigation\";\nimport { screenshot, saveAsPdf, saveAsHtml } from \"./commands/save-page-as\";\nimport { saveToFile } from \"./commands/files\";\nimport { waitForTime, waitForNavigation } from \"./commands/timers\";\nimport { triggerMouseClickMove } from \"./commands/mouse\";\n\n/**\n"},{"type":"text","text":"Repository: bonitasoft/bonita-ui-designer\nPath: frontend/app/js/editor/header/save-as-popup.html\nURL: https://github.com/bonitasoft/bonita-ui-designer/blob/dev/frontend/app/js/editor/header/save-as-popup.html\nLicense: GPL-2.0\n\nSnippets:\n--- Snippet 1 (Line 1) ---\n<div class=\"modal-header\">\n    <h3 class=\"modal-title break-word\" translate>Save {{ctrl.page.name}} as...</h3>\n</div>\n<form class=\"form\" name=\"newPage\">\n    <div class=\"modal-body\" id=\"modal-save-page-as\">\n        <div class=\"form-group\">\n            <label class=\"control-label\" for=\"page-name\" tranlate>Name</label>\n            <input\n                name=\"name\"\n                ng-model=\"ctrl.newName\"\n"},{"type":"text","text":"Repository: AnandChowdhary/puppet\nPath: src/commands/save-page-as.spec.ts\nURL: https://github.com/AnandChowdhary/puppet/blob/master/src/commands/save-page-as.spec.ts\nLicense: MIT\n\nSnippets:\n--- Snippet 1 (Line 1) ---\nimport { puppet } from \"../\";\nimport { launch } from \"puppeteer\";\nimport { screenshot, saveAsPdf, saveAsHtml } from \"./save-page-as\";\nimport { readFile, unlink } from \"fs-extra\";\nimport { join } from \"path\";\njest.setTimeout(30000);\n\ndescribe(\"puppet - HTML\", () => {\n"},{"type":"text","text":"Repository: Kapeli/cheatsheets\nPath: cheatsheets/Chromium_Command_Line_Switches.rb\nURL: https://github.com/Kapeli/cheatsheets/blob/master/cheatsheets/Chromium_Command_Line_Switches.rb\nLicense: Unknown\n\nSnippets:\n--- Snippet 1 (Line 10639) ---\n      END\n    end\n    entry do\n      name <<-'END'\n      ```           \n      --save-page-as-mhtml\n      ```\n      END\n      notes <<-'END'\n      Disable saving pages as HTML-only, disable saving pages as HTML Complete (with a directory of sub-resources). Enable only saving pages as MHTML. See http://crbug.com/120416 for how to remove this switch. \n      END\n"}]}
{"parentUuid":"b6643eb7-61d3-4b88-a11f-5f6a9855284e","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"faeb714a-61c5-410d-b669-0ebc662cf207","version":"2.0.70","gitBranch":"main","agentId":"abf8d80","message":{"model":"claude-opus-4-5-20251101","id":"msg_01KfcSFj2Ra84F26s6TMyG9n","type":"message","role":"assistant","content":[{"type":"text","text":"Based on my research, here is a comprehensive summary of the best website cloning and archiving tools available on GitHub:\n\n---\n\n## Top Website Cloning/Archiving Tools\n\n### 1. **SingleFile** (Browser Extension)\n- **GitHub**: https://github.com/gildas-lormeau/SingleFile\n- **License**: AGPL-3.0\n- **Language**: JavaScript\n- **Key Features**:\n  - Saves complete web pages as a single HTML file\n  - Embeds CSS, images, fonts, frames as data URIs\n  - Works as browser extension (Chrome, Firefox, Edge, Safari)\n  - CLI version available for automation\n  - Preserves page appearance exactly\n- **Best For**: Single page preservation with perfect fidelity\n\n### 2. **ArchiveBox**\n- **GitHub**: https://github.com/ArchiveBox/ArchiveBox\n- **License**: MIT\n- **Language**: Python\n- **Key Features**:\n  - Self-hosted internet archiving solution\n  - Multiple output formats: HTML, PDF, screenshot, WARC, media\n  - Integrates SingleFile, wget, Chrome, youtube-dl\n  - Web UI for browsing archives\n  - Docker support\n  - Imports from bookmarks, RSS, Pocket, Pinboard\n- **Best For**: Comprehensive personal web archiving\n\n### 3. **Monolith**\n- **GitHub**: https://github.com/Y2Z/monolith\n- **License**: CC0-1.0 (Public Domain)\n- **Language**: Rust\n- **Key Features**:\n  - Fast CLI tool written in Rust\n  - Bundles entire page into single HTML file\n  - Embeds CSS, JS, images, fonts\n  - Options to exclude images/JS/CSS\n  - Isolate mode for security\n- **Best For**: Fast, lightweight single-page archiving\n\n### 4. **HTTrack**\n- **GitHub**: https://github.com/xroche/httrack\n- **Website**: https://www.httrack.com/\n- **License**: GPL-3.0\n- **Language**: C\n- **Key Features**:\n  - Full website mirror/clone tool\n  - Recursive download with link conversion\n  - Bandwidth limiting and scheduling\n  - Resume interrupted downloads\n  - GUI (WinHTTrack) and CLI versions\n- **Best For**: Complete website mirroring for offline browsing\n\n### 5. **Webrecorder / ArchiveWeb.page**\n- **GitHub**: https://github.com/webrecorder/archiveweb.page\n- **License**: AGPL-3.0\n- **Language**: JavaScript/TypeScript\n- **Key Features**:\n  - Browser-based web archiving\n  - Creates WARC/WACZ format archives\n  - Captures dynamic/JavaScript-heavy pages\n  - Desktop app and browser extension\n  - ReplayWeb.page for playback\n- **Best For**: Archiving dynamic web apps, professional archiving\n\n### 6. **pywb (Python Wayback)**\n- **GitHub**: https://github.com/webrecorder/pywb\n- **License**: GPL-3.0\n- **Language**: Python\n- **Key Features**:\n  - WARC file replay and recording\n  - Wayback Machine compatible\n  - Proxy-based recording mode\n  - WACZ support\n- **Best For**: WARC archive creation and replay\n\n### 7. **wget (with mirror flags)**\n- **Command**: `wget --mirror --convert-links --adjust-extension --page-requisites --no-parent URL`\n- **Key Features**:\n  - Built into most Unix systems\n  - Recursive downloading\n  - Link conversion for offline viewing\n  - Highly configurable\n- **Best For**: Quick command-line website mirroring\n\n### 8. **Site-Cloner (Python)**\n- **GitHub**: https://github.com/Py-Contributors/Site-Cloner\n- **License**: MIT\n- **Language**: Python\n- **Key Features**:\n  - Simple Python package\n  - `pip install site-cloner`\n  - Downloads HTML, CSS, JS, images\n- **Best For**: Simple Python-based cloning\n\n### 9. **Website-Cloner (Node.js)**\n- **GitHub**: https://github.com/Kaustubh72/Website-Cloner\n- **Language**: JavaScript/Node.js\n- **Key Features**:\n  - Node.js based website cloner\n  - Downloads all assets recursively\n- **Best For**: Node.js projects\n\n### 10. **SiteOne Crawler**\n- **GitHub**: https://github.com/janreges/siteone-crawler\n- **License**: MIT\n- **Language**: PHP\n- **Key Features**:\n  - Offline website generator\n  - Site analyzer and reporter\n  - Sitemap generation\n  - DevOps assistant features\n- **Best For**: Website analysis with offline export\n\n---\n\n## Comparison Summary\n\n| Tool | Single Page | Full Site | Dynamic JS | Format | Ease of Use |\n|------|-------------|-----------|------------|--------|-------------|\n| SingleFile | Excellent | No | Good | HTML | Easy |\n| ArchiveBox | Good | Excellent | Good | Multiple | Medium |\n| Monolith | Excellent | No | Fair | HTML | Easy |\n| HTTrack | Fair | Excellent | Poor | Directory | Medium |\n| Webrecorder | Good | Good | Excellent | WARC/WACZ | Medium |\n| wget | Fair | Good | Poor | Directory | Easy |\n\n---\n\n## Recommendations\n\n- **For single pages with JS**: SingleFile or Monolith\n- **For complete site archiving**: ArchiveBox or HTTrack  \n- **For dynamic web apps**: Webrecorder/ArchiveWeb.page\n- **For quick CLI usage**: wget or Monolith\n- **For self-hosted archive server**: ArchiveBox with pywb"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":12983,"cache_read_input_tokens":49053,"cache_creation":{"ephemeral_5m_input_tokens":12983,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWFSCVySFTzADgMZ8d8ai","type":"assistant","uuid":"be7a942c-fbd3-4675-864e-9aa302075fba","timestamp":"2025-12-19T04:44:35.232Z"}
