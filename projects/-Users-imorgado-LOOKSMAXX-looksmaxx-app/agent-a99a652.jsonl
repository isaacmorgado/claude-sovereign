{"parentUuid":null,"isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"e806c7c0-4bac-4115-a63b-761214dd1a04","version":"2.0.70","gitBranch":"main","agentId":"a99a652","slug":"cuddly-coalescing-frost","type":"user","message":{"role":"user","content":"Research what deep learning models are commonly used for side profile / profile face landmark detection. \n\nFocus on:\n1. What models work well for non-frontal face detection\n2. Web-compatible solutions (WASM, WebGL, browser-friendly)\n3. Any open-source alternatives to server-side detection\n\nLook at:\n- MediaPipe alternatives\n- Face-api.js capabilities\n- TensorFlow.js face detection models\n- Any 3D face mesh models that handle head rotation\n\nGoal: Find client-side solutions that can detect facial landmarks on profile (side) faces, not just frontal faces. Thoroughness: very thorough"},"uuid":"ab0ad7b6-7935-4658-930d-bd82eb2e31cf","timestamp":"2025-12-20T00:29:58.581Z"}
{"parentUuid":"ab0ad7b6-7935-4658-930d-bd82eb2e31cf","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"e806c7c0-4bac-4115-a63b-761214dd1a04","version":"2.0.70","gitBranch":"main","agentId":"a99a652","slug":"cuddly-coalescing-frost","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01W9GXkxMJSrR9WpLGmJ2VNd","type":"message","role":"assistant","content":[{"type":"text","text":"I'll conduct a comprehensive search for deep learning models used for side profile face landmark detection with a focus on web-compatible solutions."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":12300,"cache_read_input_tokens":0,"cache_creation":{"ephemeral_5m_input_tokens":12300,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWGzdk8uVvmPXDV9TVmHV","type":"assistant","uuid":"11d8104e-a59b-42a4-9e19-59d66f2ea22b","timestamp":"2025-12-20T00:29:59.810Z"}
{"parentUuid":"11d8104e-a59b-42a4-9e19-59d66f2ea22b","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"e806c7c0-4bac-4115-a63b-761214dd1a04","version":"2.0.70","gitBranch":"main","agentId":"a99a652","slug":"cuddly-coalescing-frost","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01W9GXkxMJSrR9WpLGmJ2VNd","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01HiKyPYVUJieze9ULHhVNJm","name":"WebSearch","input":{"query":"side profile face landmark detection deep learning models 2024 2025"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":12300,"cache_read_input_tokens":0,"cache_creation":{"ephemeral_5m_input_tokens":12300,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWGzdk8uVvmPXDV9TVmHV","type":"assistant","uuid":"863c0969-8331-45de-a2f0-023c1cccd337","timestamp":"2025-12-20T00:30:00.017Z"}
{"parentUuid":"863c0969-8331-45de-a2f0-023c1cccd337","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"e806c7c0-4bac-4115-a63b-761214dd1a04","version":"2.0.70","gitBranch":"main","agentId":"a99a652","slug":"cuddly-coalescing-frost","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01W9GXkxMJSrR9WpLGmJ2VNd","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01MpEV9THQ4XoLzgrbvxMVex","name":"WebSearch","input":{"query":"profile face detection non-frontal WASM WebGL browser"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":12300,"cache_read_input_tokens":0,"cache_creation":{"ephemeral_5m_input_tokens":12300,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWGzdk8uVvmPXDV9TVmHV","type":"assistant","uuid":"a9abd9b7-5b8b-4b1a-bfa3-ae028420bd54","timestamp":"2025-12-20T00:30:00.250Z"}
{"parentUuid":"a9abd9b7-5b8b-4b1a-bfa3-ae028420bd54","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"e806c7c0-4bac-4115-a63b-761214dd1a04","version":"2.0.70","gitBranch":"main","agentId":"a99a652","slug":"cuddly-coalescing-frost","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01W9GXkxMJSrR9WpLGmJ2VNd","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_013gY4iLuT5xHKes9t573x9Z","name":"WebSearch","input":{"query":"MediaPipe 3D face mesh profile detection rotation invariant"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":12300,"cache_read_input_tokens":0,"cache_creation":{"ephemeral_5m_input_tokens":12300,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWGzdk8uVvmPXDV9TVmHV","type":"assistant","uuid":"d710f9d3-9976-4d98-b3de-9cffb72d75c3","timestamp":"2025-12-20T00:30:00.458Z"}
{"parentUuid":"d710f9d3-9976-4d98-b3de-9cffb72d75c3","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"e806c7c0-4bac-4115-a63b-761214dd1a04","version":"2.0.70","gitBranch":"main","agentId":"a99a652","slug":"cuddly-coalescing-frost","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01W9GXkxMJSrR9WpLGmJ2VNd","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_013ipDhp3YPUC8ttHTSwPBm1","name":"WebSearch","input":{"query":"face-api.js profile face landmarks detection capabilities"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":12300,"cache_read_input_tokens":0,"cache_creation":{"ephemeral_5m_input_tokens":12300,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWGzdk8uVvmPXDV9TVmHV","type":"assistant","uuid":"36b2ac85-06ca-4ac8-bbfa-8a6ee308156e","timestamp":"2025-12-20T00:30:00.664Z"}
{"parentUuid":"36b2ac85-06ca-4ac8-bbfa-8a6ee308156e","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"e806c7c0-4bac-4115-a63b-761214dd1a04","version":"2.0.70","gitBranch":"main","agentId":"a99a652","slug":"cuddly-coalescing-frost","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01W9GXkxMJSrR9WpLGmJ2VNd","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01VZwBk9xgph8EpARBUeeoZ9","name":"WebSearch","input":{"query":"TensorFlow.js face detection models head pose profile"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":12300,"cache_read_input_tokens":0,"cache_creation":{"ephemeral_5m_input_tokens":12300,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWGzdk8uVvmPXDV9TVmHV","type":"assistant","uuid":"277c9b3e-c8c6-4b9e-99b1-17b4d49371c1","timestamp":"2025-12-20T00:30:00.858Z"}
{"parentUuid":"c8add128-fe5e-4d8f-8bee-b369a33b9fae","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"e806c7c0-4bac-4115-a63b-761214dd1a04","version":"2.0.70","gitBranch":"main","agentId":"a99a652","slug":"cuddly-coalescing-frost","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01VZwBk9xgph8EpARBUeeoZ9","type":"tool_result","content":"Web search results for query: \"TensorFlow.js face detection models head pose profile\"\n\nLinks: [{\"title\":\"TensorFlow.js models\",\"url\":\"https://www.tensorflow.org/js/models\"},{\"title\":\"tfjs-models/pose-detection at master · tensorflow/tfjs-models\",\"url\":\"https://github.com/tensorflow/tfjs-models/tree/master/pose-detection\"},{\"title\":\"tensorflow-models/face-landmarks-detection\",\"url\":\"https://www.npmjs.com/package/@tensorflow-models/face-landmarks-detection\"},{\"title\":\"Experiments with pose detection in Tensorflow.js | James' Coffee Blog\",\"url\":\"https://jamesg.blog/2023/10/01/pose-detection-tensorflow-js\"},{\"title\":\"@tensorflow-models/face-detection - npm\",\"url\":\"https://www.npmjs.com/package/@tensorflow-models/face-detection\"},{\"title\":\"Face and hand tracking in the browser with MediaPipe and TensorFlow.js — The TensorFlow Blog\",\"url\":\"https://blog.tensorflow.org/2020/03/face-and-hand-tracking-in-browser-with-mediapipe-and-tensorflowjs.html\"},{\"title\":\"Face detection with TensorFlow.js | Docker Docs\",\"url\":\"https://docs.docker.com/guides/tensorflowjs/\"},{\"title\":\"tfjs-models/face-detection at master · tensorflow/tfjs-models\",\"url\":\"https://github.com/tensorflow/tfjs-models/tree/master/face-detection\"},{\"title\":\"GitHub - terryky/tfjs_webgl_app: Realtime TensorFlow.js + WebGL visualization apps. 3D Hand pose estimation, 3D Human pose estimation, Face swap, Depth estimation, Higher accuracy face detection.\",\"url\":\"https://github.com/terryky/tfjs_webgl_app\"},{\"title\":\"Real-Time Human Pose Detection with TensorFlow.js in the Browser | by Rubens Zimbres | Medium\",\"url\":\"https://medium.com/@rubenszimbres/real-time-human-pose-detection-with-tensorflow-js-in-the-browser-f7202b88ae5c\"}]\n\nHere are the search results for TensorFlow.js face detection models with head pose and profile capabilities:\n\n## TensorFlow.js Face Detection Models\n\n### Face Detection Package\nThe @tensorflow-models/face-detection package provides models for running real-time face detection. MediaPipe FaceDetection can detect multiple faces, each face containing 6 keypoints.(no content)MediaPipeFaceDetector returns 6 keypoints. Each keypoint contains x and y, as well as a name. The keypoints are 'rightEye', 'leftEye', 'noseTip', 'mouthCenter', 'rightEarTragion', and 'leftEarTragion'.\n\n### Face Landmarks Detection (MediaPipe FaceMesh)\nMediaPipeFaceMesh returns 478 keypoints. Each keypoint contains x, y and z, as well as a name.(no content)The facemesh package infers approximate 3D facial surface geometry from an image or video stream, requiring only a single camera input without the need for a depth sensor. This geometry locates features such as the eyes, nose, and lips within the face, including details such as lip contours and the facial silhouette. This information can be used for downstream tasks such as expression classification (but not for identification).\n\n### BlazeFace Model\nBlazeFace detects faces in images using a Single Shot Detector architecture with a custom encoder.(no content)The sample application performs real-time face detection using MediaPipe, a comprehensive framework for building multimodal machine learning pipelines. It's specifically using the BlazeFace model, a lightweight model for detecting faces in images.\n\n### Related Pose Detection Models\nBlazePose provides the highest anatomical detail by tracking up to 33 keypoints including detailed hand and face landmarks through its two-stage pipeline (detection followed by landmark regression), making it superior for applications requiring fine-grained motion analysis despite being more resource-intensive.(no content)MediaPipe BlazePose can detect 33 keypoints, in addition to the 17 COCO keypoints, it provides additional keypoints for face, hands and feet.\n\n### 3D Pose Applications\nThere are realtime TensorFlow.js + WebGL visualization apps available for 3D Hand pose estimation, 3D Human pose estimation, Face swap, Depth estimation, and higher accuracy face detection.\n\nFor head pose estimation from profile views, you would typically use the 3D facial landmarks from MediaPipe FaceMesh (with its 478 keypoints including x, y, z coordinates) to calculate head orientation angles (pitch, yaw, roll).\n\n\nREMINDER: You MUST include the sources above in your response to the user using markdown hyperlinks."}]},"uuid":"4daad741-4f48-46b2-b713-55df7d9cdeca","timestamp":"2025-12-20T00:30:23.147Z","toolUseResult":{"query":"TensorFlow.js face detection models head pose profile","results":[{"tool_use_id":"srvtoolu_01SMnunnZZv9qvAdeyU8j1WL","content":[{"title":"TensorFlow.js models","url":"https://www.tensorflow.org/js/models"},{"title":"tfjs-models/pose-detection at master · tensorflow/tfjs-models","url":"https://github.com/tensorflow/tfjs-models/tree/master/pose-detection"},{"title":"tensorflow-models/face-landmarks-detection","url":"https://www.npmjs.com/package/@tensorflow-models/face-landmarks-detection"},{"title":"Experiments with pose detection in Tensorflow.js | James' Coffee Blog","url":"https://jamesg.blog/2023/10/01/pose-detection-tensorflow-js"},{"title":"@tensorflow-models/face-detection - npm","url":"https://www.npmjs.com/package/@tensorflow-models/face-detection"},{"title":"Face and hand tracking in the browser with MediaPipe and TensorFlow.js — The TensorFlow Blog","url":"https://blog.tensorflow.org/2020/03/face-and-hand-tracking-in-browser-with-mediapipe-and-tensorflowjs.html"},{"title":"Face detection with TensorFlow.js | Docker Docs","url":"https://docs.docker.com/guides/tensorflowjs/"},{"title":"tfjs-models/face-detection at master · tensorflow/tfjs-models","url":"https://github.com/tensorflow/tfjs-models/tree/master/face-detection"},{"title":"GitHub - terryky/tfjs_webgl_app: Realtime TensorFlow.js + WebGL visualization apps. 3D Hand pose estimation, 3D Human pose estimation, Face swap, Depth estimation, Higher accuracy face detection.","url":"https://github.com/terryky/tfjs_webgl_app"},{"title":"Real-Time Human Pose Detection with TensorFlow.js in the Browser | by Rubens Zimbres | Medium","url":"https://medium.com/@rubenszimbres/real-time-human-pose-detection-with-tensorflow-js-in-the-browser-f7202b88ae5c"}]},"Here are the search results for TensorFlow.js face detection models with head pose and profile capabilities:\n\n## TensorFlow.js Face Detection Models\n\n### Face Detection Package\nThe @tensorflow-models/face-detection package provides models for running real-time face detection. MediaPipe FaceDetection can detect multiple faces, each face containing 6 keypoints.(no content)MediaPipeFaceDetector returns 6 keypoints. Each keypoint contains x and y, as well as a name. The keypoints are 'rightEye', 'leftEye', 'noseTip', 'mouthCenter', 'rightEarTragion', and 'leftEarTragion'.\n\n### Face Landmarks Detection (MediaPipe FaceMesh)\nMediaPipeFaceMesh returns 478 keypoints. Each keypoint contains x, y and z, as well as a name.(no content)The facemesh package infers approximate 3D facial surface geometry from an image or video stream, requiring only a single camera input without the need for a depth sensor. This geometry locates features such as the eyes, nose, and lips within the face, including details such as lip contours and the facial silhouette. This information can be used for downstream tasks such as expression classification (but not for identification).\n\n### BlazeFace Model\nBlazeFace detects faces in images using a Single Shot Detector architecture with a custom encoder.(no content)The sample application performs real-time face detection using MediaPipe, a comprehensive framework for building multimodal machine learning pipelines. It's specifically using the BlazeFace model, a lightweight model for detecting faces in images.\n\n### Related Pose Detection Models\nBlazePose provides the highest anatomical detail by tracking up to 33 keypoints including detailed hand and face landmarks through its two-stage pipeline (detection followed by landmark regression), making it superior for applications requiring fine-grained motion analysis despite being more resource-intensive.(no content)MediaPipe BlazePose can detect 33 keypoints, in addition to the 17 COCO keypoints, it provides additional keypoints for face, hands and feet.\n\n### 3D Pose Applications\nThere are realtime TensorFlow.js + WebGL visualization apps available for 3D Hand pose estimation, 3D Human pose estimation, Face swap, Depth estimation, and higher accuracy face detection.\n\nFor head pose estimation from profile views, you would typically use the 3D facial landmarks from MediaPipe FaceMesh (with its 478 keypoints including x, y, z coordinates) to calculate head orientation angles (pitch, yaw, roll)."],"durationSeconds":22.249100083000958}}
{"parentUuid":"4daad741-4f48-46b2-b713-55df7d9cdeca","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"e806c7c0-4bac-4115-a63b-761214dd1a04","version":"2.0.70","gitBranch":"main","agentId":"a99a652","slug":"cuddly-coalescing-frost","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_013ipDhp3YPUC8ttHTSwPBm1","type":"tool_result","content":"Web search results for query: \"face-api.js profile face landmarks detection capabilities\"\n\nLinks: [{\"title\":\"GitHub - justadudewhohacks/face-api.js: JavaScript API for face detection and face recognition in the browser and nodejs with tensorflow.js\",\"url\":\"https://github.com/justadudewhohacks/face-api.js\"},{\"title\":\"face-api.js\",\"url\":\"https://justadudewhohacks.github.io/face-api.js/docs/index.html\"},{\"title\":\"Face API JS API — Free Public API | Public APIs Directory\",\"url\":\"https://publicapis.io/face-api-js-api\"},{\"title\":\"face-api.js/README.md at master · justadudewhohacks/face-api.js\",\"url\":\"https://github.com/justadudewhohacks/face-api.js/blob/master/README.md\"},{\"title\":\"GitHub - vladmandic/face-api: FaceAPI: AI-powered Face Detection & Rotation Tracking, Face Description & Recognition, Age & Gender & Emotion Prediction for Browser and NodeJS using TensorFlow/JS\",\"url\":\"https://github.com/vladmandic/face-api\"},{\"title\":\"FaceAPI Tutorial | face-api\",\"url\":\"https://vladmandic.github.io/face-api/TUTORIAL.html\"},{\"title\":\"The 'face-api.js' Library for Accurate Face Recognition in Web\",\"url\":\"https://www.ijcaonline.org/archives/volume186/number21/iftekar-2024-ijca-923507.pdf\"},{\"title\":\"FaceLandmarks | face-api.js\",\"url\":\"https://justadudewhohacks.github.io/face-api.js/docs/classes/facelandmarks.html\"},{\"title\":\"Detecting face landmarks and add filters overlays\",\"url\":\"https://cloudinary.com/blog/guest_post/detecting-face-landmarks-and-add-filters-overlays\"},{\"title\":\"face-api.js — JavaScript API for Face Recognition in the Browser with tensorflow.js | by Vincent Mühler | ITNEXT\",\"url\":\"https://itnext.io/face-api-js-javascript-api-for-face-recognition-in-the-browser-with-tensorflow-js-bcc2a6c4cf07\"}]\n\nBased on the search results, here's what I found about face-api.js profile face landmarks detection capabilities:\n\n## Face Landmarks Detection in face-api.js\n\n### 68-Point Face Landmark Detection\nface-api.js implements a very lightweight and fast, yet accurate 68 point face landmark detector.(no content)The default model has a size of only 350kb (face_landmark_68_model) and the tiny model is only 80kb (face_landmark_68_tiny_model).(no content)Both models employ the ideas of depthwise separable convolutions as well as densely connected blocks.\n\n### Training Data\nThe models have been trained on a dataset of ~35k face images labeled with 68 face landmark points.\n\n### Key Features\nFace landmarks are key points on a face, such as the corners of the eyes, nose, and mouth. Face-API.js provides a function that can detect these landmarks and return their positions as a set of points.\n\n### Usage\nAfter face detection and facial landmark prediction the face descriptors for each face can be computed. The API allows you to detect all faces in an image + compute 68 Point Face Landmarks for each detected face using `faceapi.detectAllFaces(input).withFaceLandmarks().withFaceDescriptors()`.\n\n### Face Alignment\nWe want to align the bounding boxes, such that we can extract the images centered at the face for each box before passing them to the face recognition network, as this will make face recognition much more accurate! For that purpose face-api.js implements a simple CNN, which returns the 68 point face landmarks of a given face image.\n\n### Profile/Side Face Detection Note\nThe search results primarily discuss **frontal face** landmark detection. The 68-point landmark model is trained on standard frontal face datasets. FaceAPI landmark model returns 68-point face mesh. However, there's limited specific information about **profile (side-view) face** landmark detection capabilities - the standard 68-point model is optimized for frontal faces and may have reduced accuracy on profile/side-view faces.\n\n### Available Face Detectors\nFace-api.js implements multiple face detectors for different usecases. The most accurate face detector is a SSD (Single Shot Multibox Detector), which is basically a CNN based on MobileNet V1. Furthermore, face-api.js implements an optimized Tiny Face Detector, basically an even tinier version of Tiny Yolo v2.\n\nIf you need specific profile/side-face detection capabilities, you may want to explore alternative models or the updated fork by vladmandic which extends it with newer AI models, additional detection details, compatibility with latest web standard and more.\n\n\nREMINDER: You MUST include the sources above in your response to the user using markdown hyperlinks."}]},"uuid":"e1db2e94-e58c-48de-85c2-5a12f2ae636b","timestamp":"2025-12-20T00:30:23.390Z","toolUseResult":{"query":"face-api.js profile face landmarks detection capabilities","results":[{"tool_use_id":"srvtoolu_014y9fS5HzSRNhMVsnAL5WnA","content":[{"title":"GitHub - justadudewhohacks/face-api.js: JavaScript API for face detection and face recognition in the browser and nodejs with tensorflow.js","url":"https://github.com/justadudewhohacks/face-api.js"},{"title":"face-api.js","url":"https://justadudewhohacks.github.io/face-api.js/docs/index.html"},{"title":"Face API JS API — Free Public API | Public APIs Directory","url":"https://publicapis.io/face-api-js-api"},{"title":"face-api.js/README.md at master · justadudewhohacks/face-api.js","url":"https://github.com/justadudewhohacks/face-api.js/blob/master/README.md"},{"title":"GitHub - vladmandic/face-api: FaceAPI: AI-powered Face Detection & Rotation Tracking, Face Description & Recognition, Age & Gender & Emotion Prediction for Browser and NodeJS using TensorFlow/JS","url":"https://github.com/vladmandic/face-api"},{"title":"FaceAPI Tutorial | face-api","url":"https://vladmandic.github.io/face-api/TUTORIAL.html"},{"title":"The 'face-api.js' Library for Accurate Face Recognition in Web","url":"https://www.ijcaonline.org/archives/volume186/number21/iftekar-2024-ijca-923507.pdf"},{"title":"FaceLandmarks | face-api.js","url":"https://justadudewhohacks.github.io/face-api.js/docs/classes/facelandmarks.html"},{"title":"Detecting face landmarks and add filters overlays","url":"https://cloudinary.com/blog/guest_post/detecting-face-landmarks-and-add-filters-overlays"},{"title":"face-api.js — JavaScript API for Face Recognition in the Browser with tensorflow.js | by Vincent Mühler | ITNEXT","url":"https://itnext.io/face-api-js-javascript-api-for-face-recognition-in-the-browser-with-tensorflow-js-bcc2a6c4cf07"}]},"Based on the search results, here's what I found about face-api.js profile face landmarks detection capabilities:\n\n## Face Landmarks Detection in face-api.js\n\n### 68-Point Face Landmark Detection\nface-api.js implements a very lightweight and fast, yet accurate 68 point face landmark detector.(no content)The default model has a size of only 350kb (face_landmark_68_model) and the tiny model is only 80kb (face_landmark_68_tiny_model).(no content)Both models employ the ideas of depthwise separable convolutions as well as densely connected blocks.\n\n### Training Data\nThe models have been trained on a dataset of ~35k face images labeled with 68 face landmark points.\n\n### Key Features\nFace landmarks are key points on a face, such as the corners of the eyes, nose, and mouth. Face-API.js provides a function that can detect these landmarks and return their positions as a set of points.\n\n### Usage\nAfter face detection and facial landmark prediction the face descriptors for each face can be computed. The API allows you to detect all faces in an image + compute 68 Point Face Landmarks for each detected face using `faceapi.detectAllFaces(input).withFaceLandmarks().withFaceDescriptors()`.\n\n### Face Alignment\nWe want to align the bounding boxes, such that we can extract the images centered at the face for each box before passing them to the face recognition network, as this will make face recognition much more accurate! For that purpose face-api.js implements a simple CNN, which returns the 68 point face landmarks of a given face image.\n\n### Profile/Side Face Detection Note\nThe search results primarily discuss **frontal face** landmark detection. The 68-point landmark model is trained on standard frontal face datasets. FaceAPI landmark model returns 68-point face mesh. However, there's limited specific information about **profile (side-view) face** landmark detection capabilities - the standard 68-point model is optimized for frontal faces and may have reduced accuracy on profile/side-view faces.\n\n### Available Face Detectors\nFace-api.js implements multiple face detectors for different usecases. The most accurate face detector is a SSD (Single Shot Multibox Detector), which is basically a CNN based on MobileNet V1. Furthermore, face-api.js implements an optimized Tiny Face Detector, basically an even tinier version of Tiny Yolo v2.\n\nIf you need specific profile/side-face detection capabilities, you may want to explore alternative models or the updated fork by vladmandic which extends it with newer AI models, additional detection details, compatibility with latest web standard and more."],"durationSeconds":22.491975791998208}}
{"parentUuid":"e1db2e94-e58c-48de-85c2-5a12f2ae636b","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"e806c7c0-4bac-4115-a63b-761214dd1a04","version":"2.0.70","gitBranch":"main","agentId":"a99a652","slug":"cuddly-coalescing-frost","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01HiKyPYVUJieze9ULHhVNJm","type":"tool_result","content":"Web search results for query: \"side profile face landmark detection deep learning models 2024 2025\"\n\nLinks: [{\"title\":\"Comparative Analysis of Pre-trained Deep Learning Models for Facial Landmark Localization on Enhanced Dataset of Heavily Occluded Face Images - Volume 15, No. 11, 2024 - JAIT-Journal of Advances in Information Technology\",\"url\":\"https://www.jait.us/show-246-1603-1.html\"},{\"title\":\"Facial Landmark Detection Using Deep Learning: A\",\"url\":\"https://eudl.eu/pdf/10.4108/eai.28-4-2025.2358028\"},{\"title\":\"Towards unsupervised learning of joint facial landmark ...\",\"url\":\"https://www.cs.uic.edu/~tangw/files/2025_PR_ZhimingZou.pdf\"},{\"title\":\"Papers with Code - Facial Landmark Detection\",\"url\":\"https://paperswithcode.com/task/facial-landmark-detection/codeless\"},{\"title\":\"Deep Neural Networks and Computer Vision for Real-Time Facial Landmark Detection | IEEE Conference Publication | IEEE Xplore\",\"url\":\"https://ieeexplore.ieee.org/document/9698811/\"},{\"title\":\"[2401.13191] Towards Multi-domain Face Landmark Detection with Synthetic Data from Diffusion model\",\"url\":\"https://arxiv.org/abs/2401.13191\"},{\"title\":\"facial-landmarks · GitHub Topics · GitHub\",\"url\":\"https://github.com/topics/facial-landmarks\"},{\"title\":\"Multimodal deep learning for cephalometric landmark detection and treatment prediction | Scientific Reports\",\"url\":\"https://www.nature.com/articles/s41598-025-06229-w\"},{\"title\":\"Automated anatomical landmark detection on 3D facial images using U-NET-based deep learning algorithm - PMC\",\"url\":\"https://pmc.ncbi.nlm.nih.gov/articles/PMC10963813/\"},{\"title\":\"Facial Landmark Detection\",\"url\":\"https://www.catalyzex.com/s/Facial%20Landmark%20Detection\"}]\n\nHere are the search results for side profile face landmark detection deep learning models in 2024-2025:\n\n## Key Research and Models\n\n### Recent Papers and Approaches\n\n1. **Comparative Analysis of Pre-trained Deep Learning Models (2024)** - A study by Alqahtani, Sunar, and Artoli published in the Journal of Advances in Information Technology, Vol. 15, No. 11, pp. 1252-1263, 2024 provides a \"comparative analysis of pre-trained deep learning models for facial landmark localization on enhanced dataset of heavily occluded face images.\"\n\n2. **Unsupervised Learning for Joint Landmark and Pose Estimation (2025)** - Deep learning approaches have advanced state-of-the-art performance drastically in facial landmark detection and head pose estimation, with recent work showing that meaningful landmarks could be discovered from unlabeled image collections.(no content)This framework includes a multi-task network for joint landmark and pose prediction, a set of learnable 3D canonical landmarks, and an image generation network, learned collaboratively on unlabeled face images.\n\n3. **DeepFuse for Cephalometric Landmark Detection (2025)** - DeepFuse is a novel multi-modal deep learning framework that integrates information from lateral cephalograms, CBCT volumes, and digital dental models, employing modality-specific encoders, an attention-guided fusion mechanism, and dual-task decoders.(no content)It achieves a mean radial error of 1.21 mm for landmark detection.\n\n4. **Multi-domain Face Landmark Detection with Diffusion Models (Jan 2024)** - While deep learning-based facial landmark detection for in-the-wild faces has achieved significant improvement, there are still challenges in face landmark detection in other domains (e.g. cartoon, caricature), due to the scarcity of extensively annotated training data.(no content)This approach uses a two-stage training that leverages limited datasets and pre-trained diffusion models to obtain aligned pairs of landmarks and faces in multiple domains.\n\n5. **ORFormer (2025)** - Existing FLD methods suffer from performance drops on partially non-visible faces, such as faces with occlusions or under extreme lighting conditions or poses. ORFormer is a novel transformer-based method that can detect non-visible regions and recover their missing features from visible parts.\n\n6. **3D Facial Landmark Detection with U-NET (2024)** - Facial anthropometry based on 3-dimensional (3D) imaging technology has gained increasing popularity among surgeons, outperforming direct measurement and 2D photogrammetry.\n\n### Open Source Implementations\n\nGitHub hosts several relevant projects including \"Synergy between 3DMM and 3D Landmarks for Accurate 3D Facial Geometry\" (3DV 2021, updated Dec 2024) and a PyTorch implementation of \"Super-Realtime Facial Landmark Detection\" predicting facial landmarks with up to 400 FPS.\n\n### Key Models Used\n- **ResNet18/ResNet50** - Studies present real-time face landmark identification systems using deep learning models, with the ResNet50 model being used to construct real-time facial landmark detectors with 68 landmarks per image.\n- **Point Transformer v3** - Used for point cloud learning through transformer architectures to capture meaningful geometric and anatomical features for landmark prediction.\n\n\nREMINDER: You MUST include the sources above in your response to the user using markdown hyperlinks."}]},"uuid":"ac36b258-3fa9-4720-8023-b5d0d7906e3b","timestamp":"2025-12-20T00:30:27.698Z","toolUseResult":{"query":"side profile face landmark detection deep learning models 2024 2025","results":[{"tool_use_id":"srvtoolu_01Y9vkbLGpFcGpaofmoKkXZv","content":[{"title":"Comparative Analysis of Pre-trained Deep Learning Models for Facial Landmark Localization on Enhanced Dataset of Heavily Occluded Face Images - Volume 15, No. 11, 2024 - JAIT-Journal of Advances in Information Technology","url":"https://www.jait.us/show-246-1603-1.html"},{"title":"Facial Landmark Detection Using Deep Learning: A","url":"https://eudl.eu/pdf/10.4108/eai.28-4-2025.2358028"},{"title":"Towards unsupervised learning of joint facial landmark ...","url":"https://www.cs.uic.edu/~tangw/files/2025_PR_ZhimingZou.pdf"},{"title":"Papers with Code - Facial Landmark Detection","url":"https://paperswithcode.com/task/facial-landmark-detection/codeless"},{"title":"Deep Neural Networks and Computer Vision for Real-Time Facial Landmark Detection | IEEE Conference Publication | IEEE Xplore","url":"https://ieeexplore.ieee.org/document/9698811/"},{"title":"[2401.13191] Towards Multi-domain Face Landmark Detection with Synthetic Data from Diffusion model","url":"https://arxiv.org/abs/2401.13191"},{"title":"facial-landmarks · GitHub Topics · GitHub","url":"https://github.com/topics/facial-landmarks"},{"title":"Multimodal deep learning for cephalometric landmark detection and treatment prediction | Scientific Reports","url":"https://www.nature.com/articles/s41598-025-06229-w"},{"title":"Automated anatomical landmark detection on 3D facial images using U-NET-based deep learning algorithm - PMC","url":"https://pmc.ncbi.nlm.nih.gov/articles/PMC10963813/"},{"title":"Facial Landmark Detection","url":"https://www.catalyzex.com/s/Facial%20Landmark%20Detection"}]},"Here are the search results for side profile face landmark detection deep learning models in 2024-2025:\n\n## Key Research and Models\n\n### Recent Papers and Approaches\n\n1. **Comparative Analysis of Pre-trained Deep Learning Models (2024)** - A study by Alqahtani, Sunar, and Artoli published in the Journal of Advances in Information Technology, Vol. 15, No. 11, pp. 1252-1263, 2024 provides a \"comparative analysis of pre-trained deep learning models for facial landmark localization on enhanced dataset of heavily occluded face images.\"\n\n2. **Unsupervised Learning for Joint Landmark and Pose Estimation (2025)** - Deep learning approaches have advanced state-of-the-art performance drastically in facial landmark detection and head pose estimation, with recent work showing that meaningful landmarks could be discovered from unlabeled image collections.(no content)This framework includes a multi-task network for joint landmark and pose prediction, a set of learnable 3D canonical landmarks, and an image generation network, learned collaboratively on unlabeled face images.\n\n3. **DeepFuse for Cephalometric Landmark Detection (2025)** - DeepFuse is a novel multi-modal deep learning framework that integrates information from lateral cephalograms, CBCT volumes, and digital dental models, employing modality-specific encoders, an attention-guided fusion mechanism, and dual-task decoders.(no content)It achieves a mean radial error of 1.21 mm for landmark detection.\n\n4. **Multi-domain Face Landmark Detection with Diffusion Models (Jan 2024)** - While deep learning-based facial landmark detection for in-the-wild faces has achieved significant improvement, there are still challenges in face landmark detection in other domains (e.g. cartoon, caricature), due to the scarcity of extensively annotated training data.(no content)This approach uses a two-stage training that leverages limited datasets and pre-trained diffusion models to obtain aligned pairs of landmarks and faces in multiple domains.\n\n5. **ORFormer (2025)** - Existing FLD methods suffer from performance drops on partially non-visible faces, such as faces with occlusions or under extreme lighting conditions or poses. ORFormer is a novel transformer-based method that can detect non-visible regions and recover their missing features from visible parts.\n\n6. **3D Facial Landmark Detection with U-NET (2024)** - Facial anthropometry based on 3-dimensional (3D) imaging technology has gained increasing popularity among surgeons, outperforming direct measurement and 2D photogrammetry.\n\n### Open Source Implementations\n\nGitHub hosts several relevant projects including \"Synergy between 3DMM and 3D Landmarks for Accurate 3D Facial Geometry\" (3DV 2021, updated Dec 2024) and a PyTorch implementation of \"Super-Realtime Facial Landmark Detection\" predicting facial landmarks with up to 400 FPS.\n\n### Key Models Used\n- **ResNet18/ResNet50** - Studies present real-time face landmark identification systems using deep learning models, with the ResNet50 model being used to construct real-time facial landmark detectors with 68 landmarks per image.\n- **Point Transformer v3** - Used for point cloud learning through transformer architectures to capture meaningful geometric and anatomical features for landmark prediction."],"durationSeconds":26.80034837500006}}
{"parentUuid":"ac36b258-3fa9-4720-8023-b5d0d7906e3b","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"e806c7c0-4bac-4115-a63b-761214dd1a04","version":"2.0.70","gitBranch":"main","agentId":"a99a652","slug":"cuddly-coalescing-frost","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_013gY4iLuT5xHKes9t573x9Z","type":"tool_result","content":"Web search results for query: \"MediaPipe 3D face mesh profile detection rotation invariant\"\n\nLinks: [{\"title\":\"layout: forward target: https://developers.google.com/mediapipe/solutions/vision/face_landmarker/ title: Face Mesh parent: MediaPipe Legacy Solutions nav_order: 2 — MediaPipe v0.7.5 documentation\",\"url\":\"https://mediapipe.readthedocs.io/en/latest/solutions/face_mesh.html\"},{\"title\":\"mediapipe/docs/solutions/face_mesh.md at master · google-ai-edge/mediapipe\",\"url\":\"https://github.com/google-ai-edge/mediapipe/blob/master/docs/solutions/face_mesh.md\"},{\"title\":\"MediaPipe Face Mesh\",\"url\":\"https://github.com/google-ai-edge/mediapipe/wiki/MediaPipe-Face-Mesh\"},{\"title\":\"Face landmark detection guide | MediaPipe | Google for Developers\",\"url\":\"https://developers.google.com/mediapipe/solutions/vision/face_landmarker\"},{\"title\":\"Real-Time Head Pose Estimation FaceMesh with MediaPipe and OpenCV: A Comprehensive Guide | by Jaykumaran R | Medium\",\"url\":\"https://medium.com/@jaykumaran2217/real-time-head-pose-estimation-facemesh-with-mediapipe-and-opencv-a-comprehensive-guide-b63a2f40b7c6\"},{\"title\":\"MediaPipe 3D Face Transform - Google Developers Blog\",\"url\":\"https://developers.googleblog.com/mediapipe-3d-face-transform/\"},{\"title\":\"layout: forward target: https://developers.google.com/mediapipe/solutions/vision/face_detector/ title: Face Detection parent: MediaPipe Legacy Solutions nav_order: 1 — MediaPipe v0.7.5 documentation\",\"url\":\"https://mediapipe.readthedocs.io/en/latest/solutions/face_detection.html\"},{\"title\":\"Surface MediaPipe Iris model for the web · Issue #2526 · google-ai-edge/mediapipe\",\"url\":\"https://github.com/google/mediapipe/issues/2526\"},{\"title\":\"Face detection guide | MediaPipe | Google for Developers\",\"url\":\"https://developers.google.com/mediapipe/solutions/vision/face_detector\"},{\"title\":\"Facial Landmarks Detection with MediaPipe Face Mesh: A Deep Dive - 33rd Square\",\"url\":\"https://www.33rdsquare.com/facial-landmarks-detection-using-mediapipe-library/\"}]\n\nBased on the search results, here's what I found about MediaPipe 3D face mesh, profile detection, and rotation invariance:\n\n## MediaPipe Face Mesh Overview\n\nMediaPipe Face Mesh is a solution that estimates 468 3D face landmarks in real-time even on mobile devices. It employs machine learning (ML) to infer the 3D facial surface, requiring only a single camera input without the need for a dedicated depth sensor.\n\n## Pipeline Architecture\n\nThe ML pipeline consists of two real-time deep neural network models that work together: A detector that operates on the full image and computes face locations and a 3D face landmark model that operates on those locations and predicts the approximate 3D surface via regression. Having the face accurately cropped drastically reduces the need for common data augmentations like affine transformations consisting of rotations, translation and scale changes. Instead it allows the network to dedicate most of its capacity towards coordinate prediction accuracy.(no content)The face detector is the same BlazeFace model used in MediaPipe Face Detection.\n\n## 3D Landmark Model Training\n\nFor 3D face landmarks they employed transfer learning and trained a network with several objectives: the network simultaneously predicts 3D landmark coordinates on synthetic rendered data and 2D semantic contours on annotated real-world data. The resulting network provided us with reasonable 3D landmark predictions not just on synthetic but also on real-world data.\n\n## Rotation Invariance Limitations\n\nImportantly, the mesh is not head orientation invariant. Without a head orientation invariant face mesh, it is hard to impossible to establish a neutral pose to compare the current pose against and calculate puppeteering parameters, like how closed an eye is expressed in the range [0,1].(no content)While you can statistically treat the eye lids distance value in a way to detect eye blinking/winking/closing for an arbitrary but fixed head orientation, the tracking falls apart as soon as the user turns their heads.\n\n## Profile Detection Sensitivity\n\nWhile more robust than 2D models, the 3D landmark predictions can still degrade at extreme angles (e.g. full profile), as key points like the eyes and nose become occluded.(no content)The 3D landmark predictions are more robust to large pose variations than 2D models.\n\n## 3D Face Transform Module\n\nGoogle introduced a face transform estimation module that establishes a researcher- and developer-friendly semantic API useful for determining the 3D face pose and attaching virtual objects (like glasses, hats or masks) to a face. The new module establishes a metric 3D space and uses the landmark screen positions to estimate common 3D face primitives, including a face pose transformation matrix and a triangular face mesh.(no content)Under the hood, a lightweight statistical analysis method called Procrustes Analysis is employed to drive a robust, performant and portable logic.\n\n\nREMINDER: You MUST include the sources above in your response to the user using markdown hyperlinks."}]},"uuid":"8407eb90-44a8-4f7d-9587-23ce81f4aeb4","timestamp":"2025-12-20T00:30:27.981Z","toolUseResult":{"query":"MediaPipe 3D face mesh profile detection rotation invariant","results":[{"tool_use_id":"srvtoolu_01YaiphAeu3XjtNbDvDSsXGR","content":[{"title":"layout: forward target: https://developers.google.com/mediapipe/solutions/vision/face_landmarker/ title: Face Mesh parent: MediaPipe Legacy Solutions nav_order: 2 — MediaPipe v0.7.5 documentation","url":"https://mediapipe.readthedocs.io/en/latest/solutions/face_mesh.html"},{"title":"mediapipe/docs/solutions/face_mesh.md at master · google-ai-edge/mediapipe","url":"https://github.com/google-ai-edge/mediapipe/blob/master/docs/solutions/face_mesh.md"},{"title":"MediaPipe Face Mesh","url":"https://github.com/google-ai-edge/mediapipe/wiki/MediaPipe-Face-Mesh"},{"title":"Face landmark detection guide | MediaPipe | Google for Developers","url":"https://developers.google.com/mediapipe/solutions/vision/face_landmarker"},{"title":"Real-Time Head Pose Estimation FaceMesh with MediaPipe and OpenCV: A Comprehensive Guide | by Jaykumaran R | Medium","url":"https://medium.com/@jaykumaran2217/real-time-head-pose-estimation-facemesh-with-mediapipe-and-opencv-a-comprehensive-guide-b63a2f40b7c6"},{"title":"MediaPipe 3D Face Transform - Google Developers Blog","url":"https://developers.googleblog.com/mediapipe-3d-face-transform/"},{"title":"layout: forward target: https://developers.google.com/mediapipe/solutions/vision/face_detector/ title: Face Detection parent: MediaPipe Legacy Solutions nav_order: 1 — MediaPipe v0.7.5 documentation","url":"https://mediapipe.readthedocs.io/en/latest/solutions/face_detection.html"},{"title":"Surface MediaPipe Iris model for the web · Issue #2526 · google-ai-edge/mediapipe","url":"https://github.com/google/mediapipe/issues/2526"},{"title":"Face detection guide | MediaPipe | Google for Developers","url":"https://developers.google.com/mediapipe/solutions/vision/face_detector"},{"title":"Facial Landmarks Detection with MediaPipe Face Mesh: A Deep Dive - 33rd Square","url":"https://www.33rdsquare.com/facial-landmarks-detection-using-mediapipe-library/"}]},"Based on the search results, here's what I found about MediaPipe 3D face mesh, profile detection, and rotation invariance:\n\n## MediaPipe Face Mesh Overview\n\nMediaPipe Face Mesh is a solution that estimates 468 3D face landmarks in real-time even on mobile devices. It employs machine learning (ML) to infer the 3D facial surface, requiring only a single camera input without the need for a dedicated depth sensor.\n\n## Pipeline Architecture\n\nThe ML pipeline consists of two real-time deep neural network models that work together: A detector that operates on the full image and computes face locations and a 3D face landmark model that operates on those locations and predicts the approximate 3D surface via regression. Having the face accurately cropped drastically reduces the need for common data augmentations like affine transformations consisting of rotations, translation and scale changes. Instead it allows the network to dedicate most of its capacity towards coordinate prediction accuracy.(no content)The face detector is the same BlazeFace model used in MediaPipe Face Detection.\n\n## 3D Landmark Model Training\n\nFor 3D face landmarks they employed transfer learning and trained a network with several objectives: the network simultaneously predicts 3D landmark coordinates on synthetic rendered data and 2D semantic contours on annotated real-world data. The resulting network provided us with reasonable 3D landmark predictions not just on synthetic but also on real-world data.\n\n## Rotation Invariance Limitations\n\nImportantly, the mesh is not head orientation invariant. Without a head orientation invariant face mesh, it is hard to impossible to establish a neutral pose to compare the current pose against and calculate puppeteering parameters, like how closed an eye is expressed in the range [0,1].(no content)While you can statistically treat the eye lids distance value in a way to detect eye blinking/winking/closing for an arbitrary but fixed head orientation, the tracking falls apart as soon as the user turns their heads.\n\n## Profile Detection Sensitivity\n\nWhile more robust than 2D models, the 3D landmark predictions can still degrade at extreme angles (e.g. full profile), as key points like the eyes and nose become occluded.(no content)The 3D landmark predictions are more robust to large pose variations than 2D models.\n\n## 3D Face Transform Module\n\nGoogle introduced a face transform estimation module that establishes a researcher- and developer-friendly semantic API useful for determining the 3D face pose and attaching virtual objects (like glasses, hats or masks) to a face. The new module establishes a metric 3D space and uses the landmark screen positions to estimate common 3D face primitives, including a face pose transformation matrix and a triangular face mesh.(no content)Under the hood, a lightweight statistical analysis method called Procrustes Analysis is employed to drive a robust, performant and portable logic."],"durationSeconds":27.08283599999547}}
{"parentUuid":"8407eb90-44a8-4f7d-9587-23ce81f4aeb4","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"e806c7c0-4bac-4115-a63b-761214dd1a04","version":"2.0.70","gitBranch":"main","agentId":"a99a652","slug":"cuddly-coalescing-frost","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01MpEV9THQ4XoLzgrbvxMVex","type":"tool_result","content":"Web search results for query: \"profile face detection non-frontal WASM WebGL browser\"\n\nLinks: [{\"title\":\"GitHub - jamt9000/webcv: Face Detection in the Browser with WebGL\",\"url\":\"https://github.com/jamt9000/webcv\"},{\"title\":\"Porting a Face Detector Written in C to WebAssembly - SOD Embedded Articles\",\"url\":\"https://sod.pixlab.io/articles/porting-c-face-detector-webassembly.html\"},{\"title\":\"JavaScript/WebGL lightweight and robust face tracking library designed for augmented reality face filters | jeelizFaceFilter\",\"url\":\"https://jeeliz.github.io/jeelizFaceFilter/\"},{\"title\":\"Face detection with TensorFlow.js | Docker Docs\",\"url\":\"https://docs.docker.com/guides/tensorflowjs/\"},{\"title\":\"Real-time Video Filters Using Face Detection and WebGL\",\"url\":\"https://chalkcast.org/filters.html\"},{\"title\":\"We Built a Face and Mask Detection Web App for Google Chrome | HackerNoon\",\"url\":\"https://hackernoon.com/we-built-a-face-and-mask-detection-web-app-for-google-chrome-836n33aq\"},{\"title\":\"Porting a face detector written in C to WebAssembly - DEV Community\",\"url\":\"https://dev.to/unqlite_db/porting-a-face-detector-written-in-c-to-webassembly-27p6\"},{\"title\":\"OpenCV.js Face Detection (WebAssembly)\",\"url\":\"https://codepen.io/huningxin/pen/ZJyOBW\"},{\"title\":\"GitHub - jeeliz/jeelizWeboji: JavaScript/WebGL real-time face tracking and expression detection library. Build your own emoticons animated in real time in the browser! SVG and THREE.js integration demos are provided.\",\"url\":\"https://github.com/jeeliz/jeelizWeboji\"},{\"title\":\"15 JavaScript Face Detection And Recognition Libraries [cy]\",\"url\":\"https://www.edopedia.com/blog/javascript-face-detection-and-recognition-libraries/\"}]\n\nHere are the search results for \"profile face detection non-frontal WASM WebGL browser\":\n\n## Summary of Results\n\n### WebGL-based Face Detection\n\n1. **WebCV (GitHub)** - This project takes advantage of the GPU within a browser environment by using WebGL shaders to implement a face detection algorithm in a fast, parallel way.(no content)This repository has somewhat ambitiously been titled WebCV, despite only doing face detection so far.\n\n2. **Jeeliz FaceFilter** - Lightweight WebGL & JavaScript library for real-time multi-face detection, tracking and augmented-reality face filters. Supports rotation, mouth-opening and integrates with Three.js, Babylon.js, Canvas2D and CSS3D.(no content)This library relies on Jeeliz WebGL Deep Learning technology to detect and track the user's face using a neural network.\n\n3. **Jeeliz Weboji** - It relies on Jeeliz WebGL Deep Learning technology to detect and track the user's face using a deep learning network, and to simultaneously evaluate the expression factors. JavaScript/WebGL real-time face tracking and expression detection library.\n\n### WebAssembly (WASM) Face Detection\n\n4. **SOD RealNets (PixLab)** - In this article, we'll share the method we used to port our real-time face detection runtime written in pure C to WebAssembly. The resulting model including the WASM binary, face model are production ready, and already deployed on FACEIO.\n\n5. **Non-frontal Face Detection Challenge** - Face detection has been a solved problem since the early 2000s but actually faces some challenges nowadays including finding tiny, non-frontal faces at real-time on cheap CPUs of low-end mobile/IoT devices.\n\n6. **OpenCV.js with WASM** - There's a CodePen demo showing OpenCV.js face detection using WebAssembly with Haar cascade classifiers.\n\n### WASM vs WebGL Performance\n\nWASM runtime demonstrates better results in comparison with WebGL for BlazeFace model. For most models, the WebGL backend will still outperform the WASM backend, however WASM can be faster for ultra-lite models (less than 3MB and 60M multiply-adds). In this scenario, the benefits of GPU parallelization are outweighed by the fixed overhead costs of executing WebGL shaders.\n\n### TensorFlow.js Options\n\nThe application allows users to switch between different computation backends (wasm, webgl, and cpu) for TensorFlow.js through a graphical interface. Changing the backend can affect performance and compatibility depending on the device and browser.(no content)The core of this application is the renderPrediction function, which performs real-time face detection using the BlazeFace model, a lightweight model for detecting faces in images.\n\n### Key Considerations\n\nFor **profile/non-frontal face detection** specifically, the SOD RealNets model mentions this as an ongoing challenge. Most browser-based solutions (like BlazeFace) are optimized for frontal faces. For better non-frontal detection, you might need to look into more advanced models or train custom models that include profile face datasets.\n\n\nREMINDER: You MUST include the sources above in your response to the user using markdown hyperlinks."}]},"uuid":"ff3ac942-2fe4-4621-8804-6976c70ee1ae","timestamp":"2025-12-20T00:30:28.787Z","toolUseResult":{"query":"profile face detection non-frontal WASM WebGL browser","results":[{"tool_use_id":"srvtoolu_01T2BMbm1z5F7BcWmXTRmBB8","content":[{"title":"GitHub - jamt9000/webcv: Face Detection in the Browser with WebGL","url":"https://github.com/jamt9000/webcv"},{"title":"Porting a Face Detector Written in C to WebAssembly - SOD Embedded Articles","url":"https://sod.pixlab.io/articles/porting-c-face-detector-webassembly.html"},{"title":"JavaScript/WebGL lightweight and robust face tracking library designed for augmented reality face filters | jeelizFaceFilter","url":"https://jeeliz.github.io/jeelizFaceFilter/"},{"title":"Face detection with TensorFlow.js | Docker Docs","url":"https://docs.docker.com/guides/tensorflowjs/"},{"title":"Real-time Video Filters Using Face Detection and WebGL","url":"https://chalkcast.org/filters.html"},{"title":"We Built a Face and Mask Detection Web App for Google Chrome | HackerNoon","url":"https://hackernoon.com/we-built-a-face-and-mask-detection-web-app-for-google-chrome-836n33aq"},{"title":"Porting a face detector written in C to WebAssembly - DEV Community","url":"https://dev.to/unqlite_db/porting-a-face-detector-written-in-c-to-webassembly-27p6"},{"title":"OpenCV.js Face Detection (WebAssembly)","url":"https://codepen.io/huningxin/pen/ZJyOBW"},{"title":"GitHub - jeeliz/jeelizWeboji: JavaScript/WebGL real-time face tracking and expression detection library. Build your own emoticons animated in real time in the browser! SVG and THREE.js integration demos are provided.","url":"https://github.com/jeeliz/jeelizWeboji"},{"title":"15 JavaScript Face Detection And Recognition Libraries [cy]","url":"https://www.edopedia.com/blog/javascript-face-detection-and-recognition-libraries/"}]},"Here are the search results for \"profile face detection non-frontal WASM WebGL browser\":\n\n## Summary of Results\n\n### WebGL-based Face Detection\n\n1. **WebCV (GitHub)** - This project takes advantage of the GPU within a browser environment by using WebGL shaders to implement a face detection algorithm in a fast, parallel way.(no content)This repository has somewhat ambitiously been titled WebCV, despite only doing face detection so far.\n\n2. **Jeeliz FaceFilter** - Lightweight WebGL & JavaScript library for real-time multi-face detection, tracking and augmented-reality face filters. Supports rotation, mouth-opening and integrates with Three.js, Babylon.js, Canvas2D and CSS3D.(no content)This library relies on Jeeliz WebGL Deep Learning technology to detect and track the user's face using a neural network.\n\n3. **Jeeliz Weboji** - It relies on Jeeliz WebGL Deep Learning technology to detect and track the user's face using a deep learning network, and to simultaneously evaluate the expression factors. JavaScript/WebGL real-time face tracking and expression detection library.\n\n### WebAssembly (WASM) Face Detection\n\n4. **SOD RealNets (PixLab)** - In this article, we'll share the method we used to port our real-time face detection runtime written in pure C to WebAssembly. The resulting model including the WASM binary, face model are production ready, and already deployed on FACEIO.\n\n5. **Non-frontal Face Detection Challenge** - Face detection has been a solved problem since the early 2000s but actually faces some challenges nowadays including finding tiny, non-frontal faces at real-time on cheap CPUs of low-end mobile/IoT devices.\n\n6. **OpenCV.js with WASM** - There's a CodePen demo showing OpenCV.js face detection using WebAssembly with Haar cascade classifiers.\n\n### WASM vs WebGL Performance\n\nWASM runtime demonstrates better results in comparison with WebGL for BlazeFace model. For most models, the WebGL backend will still outperform the WASM backend, however WASM can be faster for ultra-lite models (less than 3MB and 60M multiply-adds). In this scenario, the benefits of GPU parallelization are outweighed by the fixed overhead costs of executing WebGL shaders.\n\n### TensorFlow.js Options\n\nThe application allows users to switch between different computation backends (wasm, webgl, and cpu) for TensorFlow.js through a graphical interface. Changing the backend can affect performance and compatibility depending on the device and browser.(no content)The core of this application is the renderPrediction function, which performs real-time face detection using the BlazeFace model, a lightweight model for detecting faces in images.\n\n### Key Considerations\n\nFor **profile/non-frontal face detection** specifically, the SOD RealNets model mentions this as an ongoing challenge. Most browser-based solutions (like BlazeFace) are optimized for frontal faces. For better non-frontal detection, you might need to look into more advanced models or train custom models that include profile face datasets."],"durationSeconds":27.888909709006548}}
{"parentUuid":"ff3ac942-2fe4-4621-8804-6976c70ee1ae","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"e806c7c0-4bac-4115-a63b-761214dd1a04","version":"2.0.70","gitBranch":"main","agentId":"a99a652","slug":"cuddly-coalescing-frost","message":{"model":"claude-haiku-4-5-20251001","id":"msg_012ZCT3sEST7sRbecgwGdbW9","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me search for more specific information about open-source alternatives and 3D face mesh models that handle head rotation."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3629,"cache_creation_input_tokens":3147,"cache_read_input_tokens":12300,"cache_creation":{"ephemeral_5m_input_tokens":3147,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CWGzfyJE7dtgmX4yEJ71V","type":"assistant","uuid":"167f05b2-766e-484c-91d7-d74e29aa698b","timestamp":"2025-12-20T00:30:30.596Z"}
{"parentUuid":"167f05b2-766e-484c-91d7-d74e29aa698b","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"e806c7c0-4bac-4115-a63b-761214dd1a04","version":"2.0.70","gitBranch":"main","agentId":"a99a652","slug":"cuddly-coalescing-frost","message":{"model":"claude-haiku-4-5-20251001","id":"msg_012ZCT3sEST7sRbecgwGdbW9","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_019ikMpetRMQDZkcSLW9mNpj","name":"WebSearch","input":{"query":"3D face landmark detection head rotation open source models 2024"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3629,"cache_creation_input_tokens":3147,"cache_read_input_tokens":12300,"cache_creation":{"ephemeral_5m_input_tokens":3147,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CWGzfyJE7dtgmX4yEJ71V","type":"assistant","uuid":"1a8b179a-39f4-4f02-ae64-51f3881f485a","timestamp":"2025-12-20T00:30:30.883Z"}
{"parentUuid":"1a8b179a-39f4-4f02-ae64-51f3881f485a","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"e806c7c0-4bac-4115-a63b-761214dd1a04","version":"2.0.70","gitBranch":"main","agentId":"a99a652","slug":"cuddly-coalescing-frost","message":{"model":"claude-haiku-4-5-20251001","id":"msg_012ZCT3sEST7sRbecgwGdbW9","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_0151ydDMRV9je6dTq1fkozJr","name":"WebSearch","input":{"query":"profile face detection alternatives BlazeFace lightweight models"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3629,"cache_creation_input_tokens":3147,"cache_read_input_tokens":12300,"cache_creation":{"ephemeral_5m_input_tokens":3147,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CWGzfyJE7dtgmX4yEJ71V","type":"assistant","uuid":"961fe70c-6b7a-4558-ac01-c4d77c8ebbd9","timestamp":"2025-12-20T00:30:31.115Z"}
{"parentUuid":"961fe70c-6b7a-4558-ac01-c4d77c8ebbd9","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"e806c7c0-4bac-4115-a63b-761214dd1a04","version":"2.0.70","gitBranch":"main","agentId":"a99a652","slug":"cuddly-coalescing-frost","message":{"model":"claude-haiku-4-5-20251001","id":"msg_012ZCT3sEST7sRbecgwGdbW9","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_0187nCmoqjqTRBH997AyeXQs","name":"WebSearch","input":{"query":"OpenCV face landmark detection side profile non-frontal"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3629,"cache_creation_input_tokens":3147,"cache_read_input_tokens":12300,"cache_creation":{"ephemeral_5m_input_tokens":3147,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CWGzfyJE7dtgmX4yEJ71V","type":"assistant","uuid":"0943916c-9a29-4dc6-b9b7-81b99a9a7671","timestamp":"2025-12-20T00:30:31.347Z"}
{"parentUuid":"0943916c-9a29-4dc6-b9b7-81b99a9a7671","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"e806c7c0-4bac-4115-a63b-761214dd1a04","version":"2.0.70","gitBranch":"main","agentId":"a99a652","slug":"cuddly-coalescing-frost","message":{"model":"claude-haiku-4-5-20251001","id":"msg_012ZCT3sEST7sRbecgwGdbW9","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Trpah2gDPXMR8mD47A5kSH","name":"WebSearch","input":{"query":"mobile facial landmark detection models side view browser compatible"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3629,"cache_creation_input_tokens":3147,"cache_read_input_tokens":12300,"cache_creation":{"ephemeral_5m_input_tokens":3147,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CWGzfyJE7dtgmX4yEJ71V","type":"assistant","uuid":"27b352d6-6099-4d4e-b3b7-341c8ab8fd97","timestamp":"2025-12-20T00:30:31.610Z"}
{"parentUuid":"27b352d6-6099-4d4e-b3b7-341c8ab8fd97","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"e806c7c0-4bac-4115-a63b-761214dd1a04","version":"2.0.70","gitBranch":"main","agentId":"a99a652","slug":"cuddly-coalescing-frost","message":{"model":"claude-haiku-4-5-20251001","id":"msg_012ZCT3sEST7sRbecgwGdbW9","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01YR3boZJCadLfYMRYf7s3NJ","name":"WebSearch","input":{"query":"head pose estimation TensorFlow.js profile face pitch yaw roll"}}],"stop_reason":"tool_use","stop_sequence":null,"usage":{"input_tokens":3629,"cache_creation_input_tokens":3147,"cache_read_input_tokens":12300,"cache_creation":{"ephemeral_5m_input_tokens":3147,"ephemeral_1h_input_tokens":0},"output_tokens":270,"service_tier":"standard"}},"requestId":"req_011CWGzfyJE7dtgmX4yEJ71V","type":"assistant","uuid":"05d576ec-bb48-43dd-8156-8c4d171e6770","timestamp":"2025-12-20T00:30:31.783Z"}
{"parentUuid":"e0344b0f-adeb-490c-82bb-df2a0ed46b7e","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"e806c7c0-4bac-4115-a63b-761214dd1a04","version":"2.0.70","gitBranch":"main","agentId":"a99a652","slug":"cuddly-coalescing-frost","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01YR3boZJCadLfYMRYf7s3NJ","type":"tool_result","content":"Web search results for query: \"head pose estimation TensorFlow.js profile face pitch yaw roll\"\n\nLinks: [{\"title\":\"Head pose estimation | Dockship.io\",\"url\":\"https://dockship.io/model/head-pose-estimation/5d8a0da9ef1a6d55dbca34c1\"},{\"title\":\"TensorFlow.js and Puppet with PoseNet - Hackster.io\",\"url\":\"https://www.hackster.io/obniz/tensorflow-js-and-puppet-with-posenet-aab022\"},{\"title\":\"Real-Time Face Pose Estimation with Deep Learning | by Arnaldo Gualberto | Analytics Vidhya | Medium\",\"url\":\"https://medium.com/analytics-vidhya/face-pose-estimation-with-deep-learning-eebd0e62dbaf\"},{\"title\":\"Head pose estimation using OpenCV.js and TensorFlow.js\\\\' PoseNet - CodeSandbox\",\"url\":\"https://codesandbox.io/s/008olz2wmn\"},{\"title\":\"Face-Yaw-Roll-Pitch-from-Pose-Estimation-using-OpenCV/README.md at 2a1ac1f29bb15949fa2e69ab0855f78e53f83c8f · jerryhouuu/Face-Yaw-Roll-Pitch-from-Pose-Estimation-using-OpenCV\",\"url\":\"https://github.com/jerryhouuu/Face-Yaw-Roll-Pitch-from-Pose-Estimation-using-OpenCV/blob/2a1ac1f29bb15949fa2e69ab0855f78e53f83c8f/README.md\"},{\"title\":\"GitHub - BenJaminKen/posenet-pointer-lab: Extracts head pose data (pitch, yaw, roll) from PoseNet estimations and optionally moves a pointer/mouse cursor on the screen 🐭\",\"url\":\"https://github.com/BenJaminKen/posenet-pointer-lab\"},{\"title\":\"GitHub - jerryhouuu/Face-Yaw-Roll-Pitch-from-Pose-Estimation-using-OpenCV: This work is used for pose estimation(yaw, pitch and roll) by Face landmarks(left eye, right eye, nose, left mouth, right mouth and chin)\",\"url\":\"https://github.com/jerryhouuu/Face-Yaw-Roll-Pitch-from-Pose-Estimation-using-OpenCV\"},{\"title\":\"Face-Yaw-Roll-Pitch-from-Pose-Estimation-using-OpenCV/README.md at master · jerryhouuu/Face-Yaw-Roll-Pitch-from-Pose-Estimation-using-OpenCV\",\"url\":\"https://github.com/jerryhouuu/Face-Yaw-Roll-Pitch-from-Pose-Estimation-using-OpenCV/blob/master/README.md?plain=1\"},{\"title\":\"Different ways to calculate Head Pose Estimation — YPR (Yaw, Pitch and Roll) | by Abhishek Jain | Medium\",\"url\":\"https://medium.com/@abhishekjainindore24/different-ways-to-calculate-head-pose-estimation-ypr-yaw-pitch-and-roll-c3542bac03dc\"},{\"title\":\"head-pose-estimation · GitHub Topics · GitHub\",\"url\":\"https://github.com/topics/head-pose-estimation\"}]\n\nHere are the search results for head pose estimation with TensorFlow.js for profile face pitch, yaw, and roll:\n\n## Key Resources Found:\n\n### TensorFlow.js Specific Projects\n\n1. **Head pose estimation using OpenCV.js and TensorFlow.js' PoseNet** - A CodeSandbox project that demonstrates head pose estimation with a repository available at https://github.com/mjyc/head-pose-estimation-demo.\n\n2. **posenet-pointer-lab** - A GitHub project that \"extracts head pose data (pitch, yaw, roll) from PoseNet estimations and optionally moves a pointer/mouse cursor on the screen.\"\n\n3. **TensorFlow.js and PoseNet** - \"PoseNet is a machine learning model that can estimate the human pose in real time with a web browser using TensorFlow.js which is a JavaScript version of Google's machine learning library TensorFlow.\"\n\n### General Head Pose Estimation Approaches\n\n4. **Face Pose Estimation Concept** - \"Since the face of a person is a 3D object, it can rotate over all three axis.\" In face pose estimation, these movements are called \"roll, pitch, and yaw.\"\n\n5. **PnP Algorithm for Pose Estimation** - \"Once 2D facial landmarks are detected and a 3D face model is constructed, the next step is to estimate the head pose in terms of Yaw, Pitch, and Roll (YPR). This is typically done using the Perspective-n-Point (PnP) algorithm.\"\n\n6. **Landmark-Based Approach** - \"A custom trained facial landmark detector based on TensorFlow is responsible for output 68 facial landmarks. Pose estimation: Once we got the 68 facial landmarks, a mutual PnP algorithms is adopted to calculate the pose.\"\n\n7. **OpenCV Implementation** - There's a project that performs \"pose estimation(yaw, pitch and roll) by Face landmarks(left eye, right eye, nose, left mouth, right mouth and chin).\"\n\n### Deep Learning Models\n\n8. **Real Time Head Pose Estimation** - Available using \"ResNet 18/34/50 and MobileNet V2/V3 models\" that can \"evaluate yaw, pitch, and roll with pre-trained weights for quick integration.\"\n\n\nREMINDER: You MUST include the sources above in your response to the user using markdown hyperlinks."}]},"uuid":"c5166d28-2e30-4645-8415-99f42bd7eefd","timestamp":"2025-12-20T00:30:52.310Z","toolUseResult":{"query":"head pose estimation TensorFlow.js profile face pitch yaw roll","results":[{"tool_use_id":"srvtoolu_01Lp4hDtCzwXfBA93bmNbjg8","content":[{"title":"Head pose estimation | Dockship.io","url":"https://dockship.io/model/head-pose-estimation/5d8a0da9ef1a6d55dbca34c1"},{"title":"TensorFlow.js and Puppet with PoseNet - Hackster.io","url":"https://www.hackster.io/obniz/tensorflow-js-and-puppet-with-posenet-aab022"},{"title":"Real-Time Face Pose Estimation with Deep Learning | by Arnaldo Gualberto | Analytics Vidhya | Medium","url":"https://medium.com/analytics-vidhya/face-pose-estimation-with-deep-learning-eebd0e62dbaf"},{"title":"Head pose estimation using OpenCV.js and TensorFlow.js\\' PoseNet - CodeSandbox","url":"https://codesandbox.io/s/008olz2wmn"},{"title":"Face-Yaw-Roll-Pitch-from-Pose-Estimation-using-OpenCV/README.md at 2a1ac1f29bb15949fa2e69ab0855f78e53f83c8f · jerryhouuu/Face-Yaw-Roll-Pitch-from-Pose-Estimation-using-OpenCV","url":"https://github.com/jerryhouuu/Face-Yaw-Roll-Pitch-from-Pose-Estimation-using-OpenCV/blob/2a1ac1f29bb15949fa2e69ab0855f78e53f83c8f/README.md"},{"title":"GitHub - BenJaminKen/posenet-pointer-lab: Extracts head pose data (pitch, yaw, roll) from PoseNet estimations and optionally moves a pointer/mouse cursor on the screen 🐭","url":"https://github.com/BenJaminKen/posenet-pointer-lab"},{"title":"GitHub - jerryhouuu/Face-Yaw-Roll-Pitch-from-Pose-Estimation-using-OpenCV: This work is used for pose estimation(yaw, pitch and roll) by Face landmarks(left eye, right eye, nose, left mouth, right mouth and chin)","url":"https://github.com/jerryhouuu/Face-Yaw-Roll-Pitch-from-Pose-Estimation-using-OpenCV"},{"title":"Face-Yaw-Roll-Pitch-from-Pose-Estimation-using-OpenCV/README.md at master · jerryhouuu/Face-Yaw-Roll-Pitch-from-Pose-Estimation-using-OpenCV","url":"https://github.com/jerryhouuu/Face-Yaw-Roll-Pitch-from-Pose-Estimation-using-OpenCV/blob/master/README.md?plain=1"},{"title":"Different ways to calculate Head Pose Estimation — YPR (Yaw, Pitch and Roll) | by Abhishek Jain | Medium","url":"https://medium.com/@abhishekjainindore24/different-ways-to-calculate-head-pose-estimation-ypr-yaw-pitch-and-roll-c3542bac03dc"},{"title":"head-pose-estimation · GitHub Topics · GitHub","url":"https://github.com/topics/head-pose-estimation"}]},"Here are the search results for head pose estimation with TensorFlow.js for profile face pitch, yaw, and roll:\n\n## Key Resources Found:\n\n### TensorFlow.js Specific Projects\n\n1. **Head pose estimation using OpenCV.js and TensorFlow.js' PoseNet** - A CodeSandbox project that demonstrates head pose estimation with a repository available at https://github.com/mjyc/head-pose-estimation-demo.\n\n2. **posenet-pointer-lab** - A GitHub project that \"extracts head pose data (pitch, yaw, roll) from PoseNet estimations and optionally moves a pointer/mouse cursor on the screen.\"\n\n3. **TensorFlow.js and PoseNet** - \"PoseNet is a machine learning model that can estimate the human pose in real time with a web browser using TensorFlow.js which is a JavaScript version of Google's machine learning library TensorFlow.\"\n\n### General Head Pose Estimation Approaches\n\n4. **Face Pose Estimation Concept** - \"Since the face of a person is a 3D object, it can rotate over all three axis.\" In face pose estimation, these movements are called \"roll, pitch, and yaw.\"\n\n5. **PnP Algorithm for Pose Estimation** - \"Once 2D facial landmarks are detected and a 3D face model is constructed, the next step is to estimate the head pose in terms of Yaw, Pitch, and Roll (YPR). This is typically done using the Perspective-n-Point (PnP) algorithm.\"\n\n6. **Landmark-Based Approach** - \"A custom trained facial landmark detector based on TensorFlow is responsible for output 68 facial landmarks. Pose estimation: Once we got the 68 facial landmarks, a mutual PnP algorithms is adopted to calculate the pose.\"\n\n7. **OpenCV Implementation** - There's a project that performs \"pose estimation(yaw, pitch and roll) by Face landmarks(left eye, right eye, nose, left mouth, right mouth and chin).\"\n\n### Deep Learning Models\n\n8. **Real Time Head Pose Estimation** - Available using \"ResNet 18/34/50 and MobileNet V2/V3 models\" that can \"evaluate yaw, pitch, and roll with pre-trained weights for quick integration.\""],"durationSeconds":20.49029941700399}}
{"parentUuid":"c5166d28-2e30-4645-8415-99f42bd7eefd","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"e806c7c0-4bac-4115-a63b-761214dd1a04","version":"2.0.70","gitBranch":"main","agentId":"a99a652","slug":"cuddly-coalescing-frost","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_0187nCmoqjqTRBH997AyeXQs","type":"tool_result","content":"Web search results for query: \"OpenCV face landmark detection side profile non-frontal\"\n\nLinks: [{\"title\":\"OpenCV: Face landmark detection in an image\",\"url\":\"https://docs.opencv.org/4.x/d2/d42/tutorial_face_landmark_detection_in_an_image.html\"},{\"title\":\"Opencv frontal and profile face detector results | Download Scientific Diagram\",\"url\":\"https://www.researchgate.net/figure/Opencv-frontal-and-profile-face-detector-results_fig1_228460706\"},{\"title\":\"Facial Landmark Detection. Today we are going to use dlib and… | by Riwaj Neupane | Medium\",\"url\":\"https://medium.com/@RiwajNeupane/facial-landmark-detection-a6b3e29eac5b\"},{\"title\":\"OpenCV: Face landmark detection in a video\",\"url\":\"https://docs.opencv.org/3.4/d8/d3c/tutorial_face_landmark_detection_in_video.html\"},{\"title\":\"Facial landmarks with dlib, OpenCV, and Python - PyImageSearch\",\"url\":\"https://pyimagesearch.com/2017/04/03/facial-landmarks-dlib-opencv-python/\"},{\"title\":\"Facemark : Facial Landmark Detection using OpenCV | LearnOpenCV #\",\"url\":\"https://learnopencv.com/facemark-facial-landmark-detection-using-opencv/\"},{\"title\":\"Facial Landmark Detection Simplified With Opencv - Analytics Vidhya\",\"url\":\"https://www.analyticsvidhya.com/blog/2021/07/facial-landmark-detection-simplified-with-opencv/\"},{\"title\":\"Using Facial Landmarks for Overlaying Faces with Masks\",\"url\":\"https://learnopencv.com/using-facial-landmarks-for-overlaying-faces-with-masks/\"},{\"title\":\"OpenCV: Tutorial on Facial Landmark Detector API\",\"url\":\"https://docs.opencv.org/4.x/d5/d47/tutorial_table_of_content_facemark.html\"},{\"title\":\"OpenCV Project - Face Landmarks Detection - DataFlair\",\"url\":\"https://data-flair.training/blogs/face-landmarks-detection-using-opencv/\"}]\n\nHere are the search results for \"OpenCV face landmark detection side profile non-frontal\":\n\n## Summary\n\nThe search results provide information about facial landmark detection using OpenCV and related libraries, with some relevant information about handling non-frontal/side profile faces:\n\n### Key Findings:\n\n1. **OpenCV's Facemark API**: OpenCV's facial landmark API is called Facemark. It has three different implementations based on different papers: FacemarkKazemi (based on \"One Millisecond Face Alignment with an Ensemble of Regression Trees\"), FacemarkAAM (using Active Appearance Model), and FacemarkLBF (based on \"Face alignment at 3000 fps via regressing local binary features\").\n\n2. **Frontal Face Limitations**: The pre-trained facial landmark detector inside the dlib library is used to estimate the location of 68 (x, y)-coordinates that map to facial structures on the face. However, the standard detectors like dlib's `get_frontal_face_detector()` are designed for frontal faces.\n\n3. **Multi-view Research**: Research has explored multi-view facial expression recognition, encoding appearance-based facial features using sparse codes and learning projections from non-frontal to frontal views using linear regression projection.\n\n4. **Profile Detection in OpenCV**: Face detection for head poses from frontal to profile view was performed using an OpenCV implementation of the Viola and Jones face detector.(no content)Experiments considered 7 different poses (0°, 15°, 30°, 45°, 60°, 75° and 90° yaw angles).\n\n5. **MediaPipe as Alternative**: MediaPipe Face Mesh estimates 468 3D face landmarks in real-time even on mobile devices. It requires only a single camera input by applying machine learning (ML) to infer the 3D surface geometry, without the need for a dedicated depth sensor. This approach tends to handle non-frontal faces better.\n\n6. **Mask Overlay Limitations**: \"Since we only have masks in frontal position and use wrap perspective function to match facial landmarks with the mask annotations, the algorithm doesn't work correctly in cases of\" non-frontal faces.\n\n### Recommendations for Side Profile Detection:\n- Consider using **MediaPipe Face Mesh** for better multi-angle support\n- OpenCV includes a `haarcascade_profileface.xml` cascade for profile face detection\n- For robust landmark detection on non-frontal faces, deep learning-based approaches or 3D face models typically perform better than traditional 2D landmark detectors\n\n\nREMINDER: You MUST include the sources above in your response to the user using markdown hyperlinks."}]},"uuid":"5ce8d841-8fbb-4d52-8f7e-cd7dfb6cd850","timestamp":"2025-12-20T00:30:53.130Z","toolUseResult":{"query":"OpenCV face landmark detection side profile non-frontal","results":[{"tool_use_id":"srvtoolu_012cmA6BnYRpGKy4ggxqz6mG","content":[{"title":"OpenCV: Face landmark detection in an image","url":"https://docs.opencv.org/4.x/d2/d42/tutorial_face_landmark_detection_in_an_image.html"},{"title":"Opencv frontal and profile face detector results | Download Scientific Diagram","url":"https://www.researchgate.net/figure/Opencv-frontal-and-profile-face-detector-results_fig1_228460706"},{"title":"Facial Landmark Detection. Today we are going to use dlib and… | by Riwaj Neupane | Medium","url":"https://medium.com/@RiwajNeupane/facial-landmark-detection-a6b3e29eac5b"},{"title":"OpenCV: Face landmark detection in a video","url":"https://docs.opencv.org/3.4/d8/d3c/tutorial_face_landmark_detection_in_video.html"},{"title":"Facial landmarks with dlib, OpenCV, and Python - PyImageSearch","url":"https://pyimagesearch.com/2017/04/03/facial-landmarks-dlib-opencv-python/"},{"title":"Facemark : Facial Landmark Detection using OpenCV | LearnOpenCV #","url":"https://learnopencv.com/facemark-facial-landmark-detection-using-opencv/"},{"title":"Facial Landmark Detection Simplified With Opencv - Analytics Vidhya","url":"https://www.analyticsvidhya.com/blog/2021/07/facial-landmark-detection-simplified-with-opencv/"},{"title":"Using Facial Landmarks for Overlaying Faces with Masks","url":"https://learnopencv.com/using-facial-landmarks-for-overlaying-faces-with-masks/"},{"title":"OpenCV: Tutorial on Facial Landmark Detector API","url":"https://docs.opencv.org/4.x/d5/d47/tutorial_table_of_content_facemark.html"},{"title":"OpenCV Project - Face Landmarks Detection - DataFlair","url":"https://data-flair.training/blogs/face-landmarks-detection-using-opencv/"}]},"Here are the search results for \"OpenCV face landmark detection side profile non-frontal\":\n\n## Summary\n\nThe search results provide information about facial landmark detection using OpenCV and related libraries, with some relevant information about handling non-frontal/side profile faces:\n\n### Key Findings:\n\n1. **OpenCV's Facemark API**: OpenCV's facial landmark API is called Facemark. It has three different implementations based on different papers: FacemarkKazemi (based on \"One Millisecond Face Alignment with an Ensemble of Regression Trees\"), FacemarkAAM (using Active Appearance Model), and FacemarkLBF (based on \"Face alignment at 3000 fps via regressing local binary features\").\n\n2. **Frontal Face Limitations**: The pre-trained facial landmark detector inside the dlib library is used to estimate the location of 68 (x, y)-coordinates that map to facial structures on the face. However, the standard detectors like dlib's `get_frontal_face_detector()` are designed for frontal faces.\n\n3. **Multi-view Research**: Research has explored multi-view facial expression recognition, encoding appearance-based facial features using sparse codes and learning projections from non-frontal to frontal views using linear regression projection.\n\n4. **Profile Detection in OpenCV**: Face detection for head poses from frontal to profile view was performed using an OpenCV implementation of the Viola and Jones face detector.(no content)Experiments considered 7 different poses (0°, 15°, 30°, 45°, 60°, 75° and 90° yaw angles).\n\n5. **MediaPipe as Alternative**: MediaPipe Face Mesh estimates 468 3D face landmarks in real-time even on mobile devices. It requires only a single camera input by applying machine learning (ML) to infer the 3D surface geometry, without the need for a dedicated depth sensor. This approach tends to handle non-frontal faces better.\n\n6. **Mask Overlay Limitations**: \"Since we only have masks in frontal position and use wrap perspective function to match facial landmarks with the mask annotations, the algorithm doesn't work correctly in cases of\" non-frontal faces.\n\n### Recommendations for Side Profile Detection:\n- Consider using **MediaPipe Face Mesh** for better multi-angle support\n- OpenCV includes a `haarcascade_profileface.xml` cascade for profile face detection\n- For robust landmark detection on non-frontal faces, deep learning-based approaches or 3D face models typically perform better than traditional 2D landmark detectors"],"durationSeconds":21.31072499999404}}
{"parentUuid":"5ce8d841-8fbb-4d52-8f7e-cd7dfb6cd850","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"e806c7c0-4bac-4115-a63b-761214dd1a04","version":"2.0.70","gitBranch":"main","agentId":"a99a652","slug":"cuddly-coalescing-frost","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Trpah2gDPXMR8mD47A5kSH","type":"tool_result","content":"Web search results for query: \"mobile facial landmark detection models side view browser compatible\"\n\nLinks: [{\"title\":\"Facial-Landmark-Detection - Qualcomm AI Hub\",\"url\":\"https://aihub.qualcomm.com/iot/models/facemap_3dmm\"},{\"title\":\"Face landmark detection guide | MediaPipe | Google for Developers\",\"url\":\"https://developers.google.com/mediapipe/solutions/vision/face_landmarker\"},{\"title\":\"Face landmark detection guide for Web | Google AI Edge | Google AI for Developers\",\"url\":\"https://ai.google.dev/edge/mediapipe/solutions/vision/face_landmarker/web_js\"},{\"title\":\"Face landmark detection guide for Web | MediaPipe | Google for Developers\",\"url\":\"https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js\"},{\"title\":\"Face landmark detection guide | Google AI Edge | Google AI for Developers\",\"url\":\"https://ai.google.dev/edge/mediapipe/solutions/vision/face_landmarker\"},{\"title\":\"Face Detection Face Landmarks Models | by SmartIR Infrared Technologies | Medium\",\"url\":\"https://medium.com/@smartIR/face-detection-face-landmarks-models-35daafe2edfd\"},{\"title\":\"Face landmark detection guide for Android | Google AI Edge | Google AI for Developers\",\"url\":\"https://ai.google.dev/edge/mediapipe/solutions/vision/face_landmarker/android\"},{\"title\":\"GitHub - junhwanjang/face_landmark_dnn: Face Landmark Detector based on Mobilenet V1\",\"url\":\"https://github.com/junhwanjang/face_landmark_dnn\"},{\"title\":\"Automatic landmark detection and face recognition for side-view face images | IEEE Conference Publication | IEEE Xplore\",\"url\":\"https://ieeexplore.ieee.org/document/6617173/\"},{\"title\":\"Papers with Code - Facial Landmark Detection\",\"url\":\"https://paperswithcode.com/task/facial-landmark-detection/codeless\"}]\n\nBased on my search, here are the key findings for mobile facial landmark detection models that are browser-compatible and support side-view faces:\n\n## MediaPipe Face Landmarker (Google)\nThe MediaPipe Face Landmarker task lets you detect face landmarks and facial expressions in images and videos. You can use this task to identify human facial expressions, apply facial filters and effects, and create virtual avatars.\n\nKey features:\n- The model outputs an estimate of 478 3-dimensional face landmarks.\n- The face detection model is the BlazeFace short-range model, a lightweight and accurate face detector optimized for mobile GPU inference.\n- The task outputs 3-dimensional face landmarks, blendshape scores (coefficients representing facial expression) to infer detailed facial surfaces in real-time, and transformation matrices to perform the transformations required for effects rendering.\n\n**Browser/Web Compatibility:**\nThe MediaPipe Face Landmarker task lets you detect face landmarks and facial expressions in images and videos. You can use this task to identify human facial expressions, apply facial filters and effects, and create virtual avatars.(no content)MediaPipe offers an easy-to-use interface and can be integrated with various programming languages. It can be used with Python, C++, Java, JavaScript and other languages.\n\n## Other Options\n\n### Dlib\nDlib includes efficient algorithms for face landmark detection. In this way, it can detect important points on the face (eyes, nose, lips, etc.) and can be used in facial analysis. It works very well for faces that are not front and slightly front.(no content)It detects 68 face landmarks.\n\n### MobileNet-based Models\nFacial landmark detection using Convolutional Neural Networks for Mobile Device - There are open-source projects that use MobileNet V1 as a backbone for efficient mobile facial landmark detection.\n\n### Side-View Specific Research\nIn real-life scenarios where pose variation is up to side-view positions, face recognition becomes a challenging task. In this paper we propose an automatic side-view face recognition system designed for home-safety applications.(no content)They achieve 95.95% accuracy on detecting landmarks, and 89.04% accuracy on identification.\n\n### EFLD (Efficient Facial Landmark Detection)\nThe Efficient Facial Landmark Detection (EFLD) model is specifically designed for edge devices confronted with the challenges related to power consumption and time latency.\n\n**Recommendation:** For browser-compatible mobile facial landmark detection, **MediaPipe Face Landmarker** is likely your best option as it has official JavaScript/Web support, is optimized for mobile devices, outputs 3D landmarks (which can help with side-view angles), and is well-documented with example code.\n\n\nREMINDER: You MUST include the sources above in your response to the user using markdown hyperlinks."}]},"uuid":"467ca5aa-c803-46b5-aa1b-215079dc76ab","timestamp":"2025-12-20T00:30:53.734Z","toolUseResult":{"query":"mobile facial landmark detection models side view browser compatible","results":[{"tool_use_id":"srvtoolu_01XNxtvmrbsc4K1de9BbbjbG","content":[{"title":"Facial-Landmark-Detection - Qualcomm AI Hub","url":"https://aihub.qualcomm.com/iot/models/facemap_3dmm"},{"title":"Face landmark detection guide | MediaPipe | Google for Developers","url":"https://developers.google.com/mediapipe/solutions/vision/face_landmarker"},{"title":"Face landmark detection guide for Web | Google AI Edge | Google AI for Developers","url":"https://ai.google.dev/edge/mediapipe/solutions/vision/face_landmarker/web_js"},{"title":"Face landmark detection guide for Web | MediaPipe | Google for Developers","url":"https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js"},{"title":"Face landmark detection guide | Google AI Edge | Google AI for Developers","url":"https://ai.google.dev/edge/mediapipe/solutions/vision/face_landmarker"},{"title":"Face Detection Face Landmarks Models | by SmartIR Infrared Technologies | Medium","url":"https://medium.com/@smartIR/face-detection-face-landmarks-models-35daafe2edfd"},{"title":"Face landmark detection guide for Android | Google AI Edge | Google AI for Developers","url":"https://ai.google.dev/edge/mediapipe/solutions/vision/face_landmarker/android"},{"title":"GitHub - junhwanjang/face_landmark_dnn: Face Landmark Detector based on Mobilenet V1","url":"https://github.com/junhwanjang/face_landmark_dnn"},{"title":"Automatic landmark detection and face recognition for side-view face images | IEEE Conference Publication | IEEE Xplore","url":"https://ieeexplore.ieee.org/document/6617173/"},{"title":"Papers with Code - Facial Landmark Detection","url":"https://paperswithcode.com/task/facial-landmark-detection/codeless"}]},"Based on my search, here are the key findings for mobile facial landmark detection models that are browser-compatible and support side-view faces:\n\n## MediaPipe Face Landmarker (Google)\nThe MediaPipe Face Landmarker task lets you detect face landmarks and facial expressions in images and videos. You can use this task to identify human facial expressions, apply facial filters and effects, and create virtual avatars.\n\nKey features:\n- The model outputs an estimate of 478 3-dimensional face landmarks.\n- The face detection model is the BlazeFace short-range model, a lightweight and accurate face detector optimized for mobile GPU inference.\n- The task outputs 3-dimensional face landmarks, blendshape scores (coefficients representing facial expression) to infer detailed facial surfaces in real-time, and transformation matrices to perform the transformations required for effects rendering.\n\n**Browser/Web Compatibility:**\nThe MediaPipe Face Landmarker task lets you detect face landmarks and facial expressions in images and videos. You can use this task to identify human facial expressions, apply facial filters and effects, and create virtual avatars.(no content)MediaPipe offers an easy-to-use interface and can be integrated with various programming languages. It can be used with Python, C++, Java, JavaScript and other languages.\n\n## Other Options\n\n### Dlib\nDlib includes efficient algorithms for face landmark detection. In this way, it can detect important points on the face (eyes, nose, lips, etc.) and can be used in facial analysis. It works very well for faces that are not front and slightly front.(no content)It detects 68 face landmarks.\n\n### MobileNet-based Models\nFacial landmark detection using Convolutional Neural Networks for Mobile Device - There are open-source projects that use MobileNet V1 as a backbone for efficient mobile facial landmark detection.\n\n### Side-View Specific Research\nIn real-life scenarios where pose variation is up to side-view positions, face recognition becomes a challenging task. In this paper we propose an automatic side-view face recognition system designed for home-safety applications.(no content)They achieve 95.95% accuracy on detecting landmarks, and 89.04% accuracy on identification.\n\n### EFLD (Efficient Facial Landmark Detection)\nThe Efficient Facial Landmark Detection (EFLD) model is specifically designed for edge devices confronted with the challenges related to power consumption and time latency.\n\n**Recommendation:** For browser-compatible mobile facial landmark detection, **MediaPipe Face Landmarker** is likely your best option as it has official JavaScript/Web support, is optimized for mobile devices, outputs 3D landmarks (which can help with side-view angles), and is well-documented with example code."],"durationSeconds":21.91505729199946}}
{"parentUuid":"467ca5aa-c803-46b5-aa1b-215079dc76ab","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"e806c7c0-4bac-4115-a63b-761214dd1a04","version":"2.0.70","gitBranch":"main","agentId":"a99a652","slug":"cuddly-coalescing-frost","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_019ikMpetRMQDZkcSLW9mNpj","type":"tool_result","content":"Web search results for query: \"3D face landmark detection head rotation open source models 2024\"\n\nLinks: [{\"title\":\"GitHub - emilianavt/OpenSeeFace: Robust realtime face and facial landmark tracking on CPU with Unity integration\",\"url\":\"https://github.com/emilianavt/OpenSeeFace\"},{\"title\":\"GitHub - TadasBaltrusaitis/OpenFace: OpenFace – a state-of-the art tool intended for facial landmark detection, head pose estimation, facial action unit recognition, and eye-gaze estimation.\",\"url\":\"https://github.com/TadasBaltrusaitis/OpenFace\"},{\"title\":\"GitHub - deepinsight/insightface: State-of-the-art 2D and 3D Face Analysis Project\",\"url\":\"https://github.com/deepinsight/insightface\"},{\"title\":\"GitHub - 1adrianb/face-alignment: :fire: 2D and 3D Face alignment library build using pytorch\",\"url\":\"https://github.com/1adrianb/face-alignment\"},{\"title\":\"landmark-detection · GitHub Topics · GitHub\",\"url\":\"https://github.com/topics/landmark-detection\"},{\"title\":\"mediapipe/docs/solutions/face_mesh.md at master · google-ai-edge/mediapipe\",\"url\":\"https://github.com/google-ai-edge/mediapipe/blob/master/docs/solutions/face_mesh.md\"},{\"title\":\"FaceAR · GitHub\",\"url\":\"https://github.com/FaceAR\"},{\"title\":\"InsightFace: The Open-Source Powerhouse for 2D & 3D Face Recognition, Detection and Swapping\",\"url\":\"https://www.blog.brightcoding.dev/2025/09/24/insightface-the-open-source-powerhouse-for-2d-3d-face-recognition-detection-and-swapping/\"},{\"title\":\"3D Face Reconstruction with Dense Landmarks\",\"url\":\"https://microsoft.github.io/DenseLandmarks/\"},{\"title\":\"Open-Source 3D Morphing Software for Facial Plastic Surgery and Facial Landmark Detection Research and Open Access Face Data Set Based on Deep Learning (Artificial Intelligence) Generated Synthetic 3D Models | Facial Plastic Surgery & Aesthetic Medicine\",\"url\":\"https://www.liebertpub.com/doi/10.1089/fpsam.2023.0030\"}]\n\nHere are the results for your search on 3D face landmark detection and head rotation open source models in 2024:\n\n## Key Open Source Projects\n\n### 1. **MediaPipe Face Mesh** (Google)\nMediaPipe Face Mesh estimates 468 3D face landmarks in real-time even on mobile devices. It employs machine learning to infer the 3D facial surface, requiring only a single camera input without the need for a dedicated depth sensor. Utilizing lightweight model architectures together with GPU acceleration throughout the pipeline, the solution delivers real-time performance critical for live experiences.(no content)The solution is bundled with the Face Transform module that bridges the gap between face landmark estimation and useful real-time AR applications. It establishes a metric 3D space and uses the face landmark screen positions to estimate a face transform within that space. The face transform data consists of common 3D primitives, including a face pose transformation matrix and a triangular face mesh.\n\n### 2. **OpenSeeFace**\nThis project implements a facial landmark detection model based on MobileNetV3. As Pytorch 1.3 CPU inference speed on Windows is very low, the model was converted to ONNX format. Using onnxruntime it can run at 30-60 fps tracking a single face. There are four models, with different speed to tracking quality trade-offs.(no content)From general observation, OpenSeeFace performs well in adverse conditions (low light, high noise, low resolution) and keeps tracking faces through a very wide range of head poses with relatively high stability of landmark positions.\n\n### 3. **InsightFace**\nIn 2024-05-04, InsightFace released InspireFace, a cross-platform C/C++ face recognition SDK.(no content)While most libraries stop at 2-D landmarks, InsightFace predicts a full 3-D mesh (68 vertices) via a joint 2-D-to-3-D regression head attached to RetinaFace.(no content)The lightweight decoder (1.2 M parameters) runs in 0.7 ms on GPU and enables downstream tasks such as: gaze redirection for video conferencing, face frontalisation to improve low-angle recognition, and VR avatar driving – the 68-vertex mesh is retargeted to MetaHuman rigs in Unreal Engine.\n\n### 4. **OpenFace**\nOpenFace is a state-of-the-art tool intended for facial landmark detection, head pose estimation, facial action unit recognition, and eye-gaze estimation.\n\n### 5. **Face Alignment (FAN)**\nThis library detects facial landmarks from Python using what claims to be the world's most accurate face alignment network, capable of detecting points in both 2D and 3D coordinates. It is built using FAN's state-of-the-art deep learning based face alignment method.\n\n### 6. **Microsoft Dense Landmarks**\nMicrosoft presents a method that accurately predicts ten times as many landmarks as usual, covering the whole head, including the eyes and teeth. This is accomplished using synthetic training data, which guarantees perfect landmark annotations.(no content)Dense landmarks are an ideal signal for integrating face shape information across frames by demonstrating accurate and expressive facial performance capture in both monocular and multi-view scenarios. The method is highly efficient: it can predict dense landmarks and fit a 3D face model at over 150FPS on a single CPU thread.\n\n\nREMINDER: You MUST include the sources above in your response to the user using markdown hyperlinks."}]},"uuid":"184bab0b-8440-4f03-9e00-a42100b1ba13","timestamp":"2025-12-20T00:31:02.356Z","toolUseResult":{"query":"3D face landmark detection head rotation open source models 2024","results":[{"tool_use_id":"srvtoolu_01WCX8YbUMY56gyRtaYp1Egk","content":[{"title":"GitHub - emilianavt/OpenSeeFace: Robust realtime face and facial landmark tracking on CPU with Unity integration","url":"https://github.com/emilianavt/OpenSeeFace"},{"title":"GitHub - TadasBaltrusaitis/OpenFace: OpenFace – a state-of-the art tool intended for facial landmark detection, head pose estimation, facial action unit recognition, and eye-gaze estimation.","url":"https://github.com/TadasBaltrusaitis/OpenFace"},{"title":"GitHub - deepinsight/insightface: State-of-the-art 2D and 3D Face Analysis Project","url":"https://github.com/deepinsight/insightface"},{"title":"GitHub - 1adrianb/face-alignment: :fire: 2D and 3D Face alignment library build using pytorch","url":"https://github.com/1adrianb/face-alignment"},{"title":"landmark-detection · GitHub Topics · GitHub","url":"https://github.com/topics/landmark-detection"},{"title":"mediapipe/docs/solutions/face_mesh.md at master · google-ai-edge/mediapipe","url":"https://github.com/google-ai-edge/mediapipe/blob/master/docs/solutions/face_mesh.md"},{"title":"FaceAR · GitHub","url":"https://github.com/FaceAR"},{"title":"InsightFace: The Open-Source Powerhouse for 2D & 3D Face Recognition, Detection and Swapping","url":"https://www.blog.brightcoding.dev/2025/09/24/insightface-the-open-source-powerhouse-for-2d-3d-face-recognition-detection-and-swapping/"},{"title":"3D Face Reconstruction with Dense Landmarks","url":"https://microsoft.github.io/DenseLandmarks/"},{"title":"Open-Source 3D Morphing Software for Facial Plastic Surgery and Facial Landmark Detection Research and Open Access Face Data Set Based on Deep Learning (Artificial Intelligence) Generated Synthetic 3D Models | Facial Plastic Surgery & Aesthetic Medicine","url":"https://www.liebertpub.com/doi/10.1089/fpsam.2023.0030"}]},"Here are the results for your search on 3D face landmark detection and head rotation open source models in 2024:\n\n## Key Open Source Projects\n\n### 1. **MediaPipe Face Mesh** (Google)\nMediaPipe Face Mesh estimates 468 3D face landmarks in real-time even on mobile devices. It employs machine learning to infer the 3D facial surface, requiring only a single camera input without the need for a dedicated depth sensor. Utilizing lightweight model architectures together with GPU acceleration throughout the pipeline, the solution delivers real-time performance critical for live experiences.(no content)The solution is bundled with the Face Transform module that bridges the gap between face landmark estimation and useful real-time AR applications. It establishes a metric 3D space and uses the face landmark screen positions to estimate a face transform within that space. The face transform data consists of common 3D primitives, including a face pose transformation matrix and a triangular face mesh.\n\n### 2. **OpenSeeFace**\nThis project implements a facial landmark detection model based on MobileNetV3. As Pytorch 1.3 CPU inference speed on Windows is very low, the model was converted to ONNX format. Using onnxruntime it can run at 30-60 fps tracking a single face. There are four models, with different speed to tracking quality trade-offs.(no content)From general observation, OpenSeeFace performs well in adverse conditions (low light, high noise, low resolution) and keeps tracking faces through a very wide range of head poses with relatively high stability of landmark positions.\n\n### 3. **InsightFace**\nIn 2024-05-04, InsightFace released InspireFace, a cross-platform C/C++ face recognition SDK.(no content)While most libraries stop at 2-D landmarks, InsightFace predicts a full 3-D mesh (68 vertices) via a joint 2-D-to-3-D regression head attached to RetinaFace.(no content)The lightweight decoder (1.2 M parameters) runs in 0.7 ms on GPU and enables downstream tasks such as: gaze redirection for video conferencing, face frontalisation to improve low-angle recognition, and VR avatar driving – the 68-vertex mesh is retargeted to MetaHuman rigs in Unreal Engine.\n\n### 4. **OpenFace**\nOpenFace is a state-of-the-art tool intended for facial landmark detection, head pose estimation, facial action unit recognition, and eye-gaze estimation.\n\n### 5. **Face Alignment (FAN)**\nThis library detects facial landmarks from Python using what claims to be the world's most accurate face alignment network, capable of detecting points in both 2D and 3D coordinates. It is built using FAN's state-of-the-art deep learning based face alignment method.\n\n### 6. **Microsoft Dense Landmarks**\nMicrosoft presents a method that accurately predicts ten times as many landmarks as usual, covering the whole head, including the eyes and teeth. This is accomplished using synthetic training data, which guarantees perfect landmark annotations.(no content)Dense landmarks are an ideal signal for integrating face shape information across frames by demonstrating accurate and expressive facial performance capture in both monocular and multi-view scenarios. The method is highly efficient: it can predict dense landmarks and fit a 3D face model at over 150FPS on a single CPU thread."],"durationSeconds":30.536442500002682}}
{"parentUuid":"184bab0b-8440-4f03-9e00-a42100b1ba13","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"e806c7c0-4bac-4115-a63b-761214dd1a04","version":"2.0.70","gitBranch":"main","agentId":"a99a652","slug":"cuddly-coalescing-frost","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_0151ydDMRV9je6dTq1fkozJr","type":"tool_result","content":"Web search results for query: \"profile face detection alternatives BlazeFace lightweight models\"\n\nLinks: [{\"title\":\"Face detection guide | MediaPipe | Google for Developers\",\"url\":\"https://developers.google.com/mediapipe/solutions/vision/face_detector\"},{\"title\":\"Face detection guide | Google AI Edge | Google AI for Developers\",\"url\":\"https://ai.google.dev/edge/mediapipe/solutions/vision/face_detector\"},{\"title\":\"(PDF) A Comparative Study Of Lightweight Face Detection Models For Real-Time Mobile Applications\",\"url\":\"https://www.researchgate.net/publication/393081327_A_Comparative_Study_Of_Lightweight_Face_Detection_Models_For_Real-Time_Mobile_Applications\"},{\"title\":\"GitHub - hollance/BlazeFace-PyTorch: The BlazeFace face detector model implemented in PyTorch\",\"url\":\"https://github.com/hollance/BlazeFace-PyTorch\"},{\"title\":\"Choose the Best Face Detector for Your Project\",\"url\":\"https://www.toolify.ai/ai-news/choose-the-best-face-detector-for-your-project-13377\"},{\"title\":\"BlazeFace: How to Run Real-time Object Detection in the Browser | Towards Data Science\",\"url\":\"https://towardsdatascience.com/blazeface-how-to-run-real-time-object-detection-in-the-browser-66c2ac9acd75/\"},{\"title\":\"Models\",\"url\":\"https://github.com/vladmandic/human/wiki/Models\"},{\"title\":\"Top Free Face Detection tools, APIs, and Open Source models | Eden AI\",\"url\":\"https://www.edenai.co/post/top-free-face-detection-tools-apis-and-open-source-models\"},{\"title\":\"What is Face Detection? Ultimate Guide 2025 + Model Comparison\",\"url\":\"https://learnopencv.com/what-is-face-detection-the-ultimate-guide/\"},{\"title\":\"Face Detection for Real World Application | IEEE Conference Publication | IEEE Xplore\",\"url\":\"https://ieeexplore.ieee.org/document/9445287/\"}]\n\nBased on the search results, here's what I found about profile face detection alternatives to BlazeFace and other lightweight models:\n\n## BlazeFace Overview\nBlazeFace is a fast, light-weight face detector from Google Research. Besides a bounding box, BlazeFace also predicts 6 keypoints for face landmarks (2x eyes, 2x ears, nose, mouth).(no content)BlazeFace runs at a speed of 200-1000+ FPS on flagship devices. However, the frontal camera model will not be able to detect faces that are relatively small. It's really intended for selfies, not for general-purpose face detection.\n\n## Lightweight Alternatives to BlazeFace\n\n### 1. **UltraFace**\nUltraface is a real-time facial detection model that balances accuracy and efficiency. It leverages the single shot multibox detector (SSD) architecture combined with an efficient EfficientNet(x) backbone network optimized for mobile platforms.\n\n### 2. **YuNet**\nYuNet is a CNN-based face detector developed by Chengrui Wang and Yuantao Feng. It is a very lightweight and fast model with a model size of less than an MB, it can be loaded on almost any device. It adopts MobileNet as its backbone and contains 85,000 parameters in total. The libfacedetection repository takes YuNet as the detection model and reaches a detection rate of 77.34 FPS for 640×480 images to 2,027.74 FPS for 128×96 images on an Intel i7-1065G7 CPU.\n\n### 3. **MTCNN (Multitask Cascaded Convolutional Networks)**\nMTCNN is a deep learning model that can perform face detection and landmark detection simultaneously. MTCNN is composed of three stages where a proposal network generates candidate bounding boxes, a refinement network filters out false positives, refines the bounding boxes, and finally, a landmark regression network detects the facial landmarks and aligns the faces.\n\n### 4. **Dlib**\nDlib is a C++ library that presents an array of machine learning instruments, such as facial recognition. It offers a face detection model that is pre-trained and well-renowned for its robustness, functioning commendably amidst diverse orientation and lighting conditions. Python bindings are integrated with Dlib.\n\n### 5. **RetinaFace**\nRetina Face is a deep learning model that can perform face detection and landmark detection simultaneously. Retina Face is based on a single-stage anchor-based object detection network that uses a novel loss function and a feature fusion module to achieve high accuracy and efficiency.\n\n### 6. **OpenCV Haar Cascade**\nOpenCV offers Haar Cascade classifiers for detecting faces, which rely on Haar-like characteristics. These classifiers provide both speed and versatility, making them ideal for an array of purposes, from image manipulation to real-time video examination.\n\n## Profile Face Detection Considerations\nThe research paper notes that different facial orientations (e.g., frontal, profile, tilted) and occlusion (faces with partial occlusions like hats, glasses, hands) are key challenges for face detection models.(no content)BlazeFace has two versions - one for front-facing camera and one for back-facing camera. The frontal camera model is the only one commonly available for conversion.\n\n## DeepFace Library\nDeepFace is a Python library for face detection, face recognition, and facial attribute analysis that provides a unified interface for several state-of-the-art models. DeepFace wraps a range of popular face detection models, including OpenCV, SSD, MTCNN, Dlib, RetinaFace, and MediaPipe, allowing developers to experiment with and compare different models for their specific applications.\n\n\nREMINDER: You MUST include the sources above in your response to the user using markdown hyperlinks."}]},"uuid":"272ef7a8-2b3d-42c4-819b-da97090b1d0c","timestamp":"2025-12-20T00:31:04.684Z","toolUseResult":{"query":"profile face detection alternatives BlazeFace lightweight models","results":[{"tool_use_id":"srvtoolu_01W524RniGWi1hHtpzZSw1tB","content":[{"title":"Face detection guide | MediaPipe | Google for Developers","url":"https://developers.google.com/mediapipe/solutions/vision/face_detector"},{"title":"Face detection guide | Google AI Edge | Google AI for Developers","url":"https://ai.google.dev/edge/mediapipe/solutions/vision/face_detector"},{"title":"(PDF) A Comparative Study Of Lightweight Face Detection Models For Real-Time Mobile Applications","url":"https://www.researchgate.net/publication/393081327_A_Comparative_Study_Of_Lightweight_Face_Detection_Models_For_Real-Time_Mobile_Applications"},{"title":"GitHub - hollance/BlazeFace-PyTorch: The BlazeFace face detector model implemented in PyTorch","url":"https://github.com/hollance/BlazeFace-PyTorch"},{"title":"Choose the Best Face Detector for Your Project","url":"https://www.toolify.ai/ai-news/choose-the-best-face-detector-for-your-project-13377"},{"title":"BlazeFace: How to Run Real-time Object Detection in the Browser | Towards Data Science","url":"https://towardsdatascience.com/blazeface-how-to-run-real-time-object-detection-in-the-browser-66c2ac9acd75/"},{"title":"Models","url":"https://github.com/vladmandic/human/wiki/Models"},{"title":"Top Free Face Detection tools, APIs, and Open Source models | Eden AI","url":"https://www.edenai.co/post/top-free-face-detection-tools-apis-and-open-source-models"},{"title":"What is Face Detection? Ultimate Guide 2025 + Model Comparison","url":"https://learnopencv.com/what-is-face-detection-the-ultimate-guide/"},{"title":"Face Detection for Real World Application | IEEE Conference Publication | IEEE Xplore","url":"https://ieeexplore.ieee.org/document/9445287/"}]},"Based on the search results, here's what I found about profile face detection alternatives to BlazeFace and other lightweight models:\n\n## BlazeFace Overview\nBlazeFace is a fast, light-weight face detector from Google Research. Besides a bounding box, BlazeFace also predicts 6 keypoints for face landmarks (2x eyes, 2x ears, nose, mouth).(no content)BlazeFace runs at a speed of 200-1000+ FPS on flagship devices. However, the frontal camera model will not be able to detect faces that are relatively small. It's really intended for selfies, not for general-purpose face detection.\n\n## Lightweight Alternatives to BlazeFace\n\n### 1. **UltraFace**\nUltraface is a real-time facial detection model that balances accuracy and efficiency. It leverages the single shot multibox detector (SSD) architecture combined with an efficient EfficientNet(x) backbone network optimized for mobile platforms.\n\n### 2. **YuNet**\nYuNet is a CNN-based face detector developed by Chengrui Wang and Yuantao Feng. It is a very lightweight and fast model with a model size of less than an MB, it can be loaded on almost any device. It adopts MobileNet as its backbone and contains 85,000 parameters in total. The libfacedetection repository takes YuNet as the detection model and reaches a detection rate of 77.34 FPS for 640×480 images to 2,027.74 FPS for 128×96 images on an Intel i7-1065G7 CPU.\n\n### 3. **MTCNN (Multitask Cascaded Convolutional Networks)**\nMTCNN is a deep learning model that can perform face detection and landmark detection simultaneously. MTCNN is composed of three stages where a proposal network generates candidate bounding boxes, a refinement network filters out false positives, refines the bounding boxes, and finally, a landmark regression network detects the facial landmarks and aligns the faces.\n\n### 4. **Dlib**\nDlib is a C++ library that presents an array of machine learning instruments, such as facial recognition. It offers a face detection model that is pre-trained and well-renowned for its robustness, functioning commendably amidst diverse orientation and lighting conditions. Python bindings are integrated with Dlib.\n\n### 5. **RetinaFace**\nRetina Face is a deep learning model that can perform face detection and landmark detection simultaneously. Retina Face is based on a single-stage anchor-based object detection network that uses a novel loss function and a feature fusion module to achieve high accuracy and efficiency.\n\n### 6. **OpenCV Haar Cascade**\nOpenCV offers Haar Cascade classifiers for detecting faces, which rely on Haar-like characteristics. These classifiers provide both speed and versatility, making them ideal for an array of purposes, from image manipulation to real-time video examination.\n\n## Profile Face Detection Considerations\nThe research paper notes that different facial orientations (e.g., frontal, profile, tilted) and occlusion (faces with partial occlusions like hats, glasses, hands) are key challenges for face detection models.(no content)BlazeFace has two versions - one for front-facing camera and one for back-facing camera. The frontal camera model is the only one commonly available for conversion.\n\n## DeepFace Library\nDeepFace is a Python library for face detection, face recognition, and facial attribute analysis that provides a unified interface for several state-of-the-art models. DeepFace wraps a range of popular face detection models, including OpenCV, SSD, MTCNN, Dlib, RetinaFace, and MediaPipe, allowing developers to experiment with and compare different models for their specific applications."],"durationSeconds":32.86493437499553}}
{"parentUuid":"272ef7a8-2b3d-42c4-819b-da97090b1d0c","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"e806c7c0-4bac-4115-a63b-761214dd1a04","version":"2.0.70","gitBranch":"main","agentId":"a99a652","slug":"cuddly-coalescing-frost","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01GdisYC1VqVM1kWu3NVQtYZ","type":"message","role":"assistant","content":[{"type":"text","text":"Let me search for a few more specific areas to ensure comprehensive coverage."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3669,"cache_creation_input_tokens":7085,"cache_read_input_tokens":15447,"cache_creation":{"ephemeral_5m_input_tokens":7085,"ephemeral_1h_input_tokens":0},"output_tokens":5,"service_tier":"standard"}},"requestId":"req_011CWGzicpWmuq5k7nZgnwuK","type":"assistant","uuid":"a0314171-d909-4fa4-bf24-e9b5a661890f","timestamp":"2025-12-20T00:31:06.351Z"}
{"parentUuid":"a0314171-d909-4fa4-bf24-e9b5a661890f","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"e806c7c0-4bac-4115-a63b-761214dd1a04","version":"2.0.70","gitBranch":"main","agentId":"a99a652","slug":"cuddly-coalescing-frost","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01GdisYC1VqVM1kWu3NVQtYZ","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01TCkuLK8m18JvQD8ByNsu2a","name":"WebSearch","input":{"query":"\"face-api.js\" fork vladmandic profile face detection improvements"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3669,"cache_creation_input_tokens":7085,"cache_read_input_tokens":15447,"cache_creation":{"ephemeral_5m_input_tokens":7085,"ephemeral_1h_input_tokens":0},"output_tokens":5,"service_tier":"standard"}},"requestId":"req_011CWGzicpWmuq5k7nZgnwuK","type":"assistant","uuid":"5723eddf-0219-44d7-b35b-0716fe4a88cb","timestamp":"2025-12-20T00:31:06.669Z"}
{"parentUuid":"5723eddf-0219-44d7-b35b-0716fe4a88cb","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"e806c7c0-4bac-4115-a63b-761214dd1a04","version":"2.0.70","gitBranch":"main","agentId":"a99a652","slug":"cuddly-coalescing-frost","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01GdisYC1VqVM1kWu3NVQtYZ","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01BLgfrW97DH1fM4xFHmDjqW","name":"WebSearch","input":{"query":"real-time face alignment side view browser WebGL canvas"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3669,"cache_creation_input_tokens":7085,"cache_read_input_tokens":15447,"cache_creation":{"ephemeral_5m_input_tokens":7085,"ephemeral_1h_input_tokens":0},"output_tokens":5,"service_tier":"standard"}},"requestId":"req_011CWGzicpWmuq5k7nZgnwuK","type":"assistant","uuid":"e72f2a1f-9c08-46b2-91f4-b1a62aaa507a","timestamp":"2025-12-20T00:31:06.981Z"}
{"parentUuid":"e72f2a1f-9c08-46b2-91f4-b1a62aaa507a","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"e806c7c0-4bac-4115-a63b-761214dd1a04","version":"2.0.70","gitBranch":"main","agentId":"a99a652","slug":"cuddly-coalescing-frost","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01GdisYC1VqVM1kWu3NVQtYZ","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01JEFpvfoiXHzZ5kHFjdosM1","name":"WebSearch","input":{"query":"ONNX face landmarks detection browser WASM runtime"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3669,"cache_creation_input_tokens":7085,"cache_read_input_tokens":15447,"cache_creation":{"ephemeral_5m_input_tokens":7085,"ephemeral_1h_input_tokens":0},"output_tokens":173,"service_tier":"standard"}},"requestId":"req_011CWGzicpWmuq5k7nZgnwuK","type":"assistant","uuid":"94a1a259-6b79-412f-8f5f-8dc10a51fbbb","timestamp":"2025-12-20T00:31:07.318Z"}
{"parentUuid":"805da2b9-cfb0-41b8-a561-10065e3e3f9f","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"e806c7c0-4bac-4115-a63b-761214dd1a04","version":"2.0.70","gitBranch":"main","agentId":"a99a652","slug":"cuddly-coalescing-frost","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01TCkuLK8m18JvQD8ByNsu2a","type":"tool_result","content":"Web search results for query: \"\"face-api.js\" fork vladmandic profile face detection improvements\"\n\nLinks: [{\"title\":\"vladmandic/face-api | DeepWiki\",\"url\":\"https://deepwiki.com/vladmandic/face-api\"},{\"title\":\"Releases · vladmandic/face-api\",\"url\":\"https://github.com/vladmandic/face-api/releases\"},{\"title\":\"GitHub - vladmandic/face-api: FaceAPI: AI-powered Face Detection & Rotation Tracking, Face Description & Recognition, Age & Gender & Emotion Prediction for Browser and NodeJS using TensorFlow/JS\",\"url\":\"https://github.com/vladmandic/face-api\"},{\"title\":\"test_fork_vladmandic_face-api - npm\",\"url\":\"https://www.npmjs.com/package/test_fork_vladmandic_face-api\"},{\"title\":\"vladmandic/face-api\",\"url\":\"https://www.npmjs.com/package/@vladmandic/face-api\"},{\"title\":\"vladmandic/face-api\",\"url\":\"https://app.unpkg.com/@vladmandic/face-api@1.5.7/files/README.md\"},{\"title\":\"face-api\",\"url\":\"https://vladmandic.github.io/face-api/\"},{\"title\":\"full rebuild · vladmandic/face-api@189226d\",\"url\":\"https://github.com/vladmandic/face-api/commit/master\"},{\"title\":\"npm:test_fork_vladmandic_face-api | Skypack\",\"url\":\"https://www.skypack.dev/view/test_fork_vladmandic_face-api\"},{\"title\":\"vladmandic/face-api examples\",\"url\":\"https://codesandbox.io/examples/package/@vladmandic/face-api\"}]\n\nBased on my search results, here's information about the vladmandic fork of face-api.js:\n\n## Vladmandic's Face-API Fork\n\nThis is an updated face-api.js with the latest available TensorFlow/JS, as the original is not compatible with tfjs >=2.0. It was forked from face-api.js version 0.22.2, which was released on March 22nd, 2020.\n\n### Key Improvements\n\nThe library is a fork of face-api.js version 0.22.2 with significant improvements, including compatibility with TensorFlow.js 2.0+, 3.0+, and 4.0+ (the original only worked with 1.7.4), and is compatible with WebGL, CPU, and WASM backends in browsers.\n\n### Features\n\nThe library includes face expression analysis (detecting emotions like happy, sad, angry, etc.), age and gender estimation, face alignment to normalize face orientation for improved analysis, and face angle detection that can calculate roll, yaw, and pitch of detected faces.(no content)FaceAPI provides AI-powered Face Detection & Rotation Tracking, Face Description & Recognition, Age & Gender & Emotion Prediction for Browser and NodeJS using TensorFlow/JS.\n\n### Bundling Changes\n\nThe fork switched bundling from UMD to ESM + CommonJS. This does require a separate process for usage in NodeJS vs Browser, but the resulting code is much lighter. It's fully tree-shakable when imported as an ESM module, and the browser bundle process uses ESBuild instead of Rollup.\n\n### Newer Library (Human)\n\nAlthough a lot of work has gone into this version of FaceAPI and it will continue to be maintained, it is now completely superseded by vladmandic's newer library \"Human\" which covers the same use cases but extends it with newer AI models, additional detection details, and compatibility with the latest web standards.(no content)The latest version is 1.7.15, licensed under MIT, with about 21,164 weekly downloads.\n\n\nREMINDER: You MUST include the sources above in your response to the user using markdown hyperlinks."}]},"uuid":"da685114-9c5f-40fd-a5b1-dee0ff198ee6","timestamp":"2025-12-20T00:31:25.147Z","toolUseResult":{"query":"\"face-api.js\" fork vladmandic profile face detection improvements","results":[{"tool_use_id":"srvtoolu_01NyCLXKnR4Z4ifhAUhZmNZ6","content":[{"title":"vladmandic/face-api | DeepWiki","url":"https://deepwiki.com/vladmandic/face-api"},{"title":"Releases · vladmandic/face-api","url":"https://github.com/vladmandic/face-api/releases"},{"title":"GitHub - vladmandic/face-api: FaceAPI: AI-powered Face Detection & Rotation Tracking, Face Description & Recognition, Age & Gender & Emotion Prediction for Browser and NodeJS using TensorFlow/JS","url":"https://github.com/vladmandic/face-api"},{"title":"test_fork_vladmandic_face-api - npm","url":"https://www.npmjs.com/package/test_fork_vladmandic_face-api"},{"title":"vladmandic/face-api","url":"https://www.npmjs.com/package/@vladmandic/face-api"},{"title":"vladmandic/face-api","url":"https://app.unpkg.com/@vladmandic/face-api@1.5.7/files/README.md"},{"title":"face-api","url":"https://vladmandic.github.io/face-api/"},{"title":"full rebuild · vladmandic/face-api@189226d","url":"https://github.com/vladmandic/face-api/commit/master"},{"title":"npm:test_fork_vladmandic_face-api | Skypack","url":"https://www.skypack.dev/view/test_fork_vladmandic_face-api"},{"title":"vladmandic/face-api examples","url":"https://codesandbox.io/examples/package/@vladmandic/face-api"}]},"Based on my search results, here's information about the vladmandic fork of face-api.js:\n\n## Vladmandic's Face-API Fork\n\nThis is an updated face-api.js with the latest available TensorFlow/JS, as the original is not compatible with tfjs >=2.0. It was forked from face-api.js version 0.22.2, which was released on March 22nd, 2020.\n\n### Key Improvements\n\nThe library is a fork of face-api.js version 0.22.2 with significant improvements, including compatibility with TensorFlow.js 2.0+, 3.0+, and 4.0+ (the original only worked with 1.7.4), and is compatible with WebGL, CPU, and WASM backends in browsers.\n\n### Features\n\nThe library includes face expression analysis (detecting emotions like happy, sad, angry, etc.), age and gender estimation, face alignment to normalize face orientation for improved analysis, and face angle detection that can calculate roll, yaw, and pitch of detected faces.(no content)FaceAPI provides AI-powered Face Detection & Rotation Tracking, Face Description & Recognition, Age & Gender & Emotion Prediction for Browser and NodeJS using TensorFlow/JS.\n\n### Bundling Changes\n\nThe fork switched bundling from UMD to ESM + CommonJS. This does require a separate process for usage in NodeJS vs Browser, but the resulting code is much lighter. It's fully tree-shakable when imported as an ESM module, and the browser bundle process uses ESBuild instead of Rollup.\n\n### Newer Library (Human)\n\nAlthough a lot of work has gone into this version of FaceAPI and it will continue to be maintained, it is now completely superseded by vladmandic's newer library \"Human\" which covers the same use cases but extends it with newer AI models, additional detection details, and compatibility with the latest web standards.(no content)The latest version is 1.7.15, licensed under MIT, with about 21,164 weekly downloads."],"durationSeconds":17.790963749997317}}
{"parentUuid":"da685114-9c5f-40fd-a5b1-dee0ff198ee6","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"e806c7c0-4bac-4115-a63b-761214dd1a04","version":"2.0.70","gitBranch":"main","agentId":"a99a652","slug":"cuddly-coalescing-frost","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01BLgfrW97DH1fM4xFHmDjqW","type":"tool_result","content":"Web search results for query: \"real-time face alignment side view browser WebGL canvas\"\n\nLinks: [{\"title\":\"JavaScript/WebGL lightweight and robust face tracking library designed for augmented reality face filters | jeelizFaceFilter\",\"url\":\"https://jeeliz.github.io/jeelizFaceFilter/\"},{\"title\":\"GitHub - jeeliz/jeelizWeboji: JavaScript/WebGL real-time face tracking and expression detection library. Build your own emoticons animated in real time in the browser! SVG and THREE.js integration demos are provided.\",\"url\":\"https://github.com/jeeliz/jeelizWeboji\"},{\"title\":\"GitHub - jeeliz/jeelizFaceFilter: 🎭 Lightweight WebGL & JavaScript library for real-time multi-face detection, tracking and augmented-reality face filters. Supports rotation, mouth-opening and integrates with Three.js, Babylon.js, Canvas2D and CSS3D\",\"url\":\"https://github.com/jeeliz/jeelizFaceFilter\"},{\"title\":\"Webcam Face Tracking: JavaScript and WebGL to Power Your Web App\",\"url\":\"https://www.banuba.com/blog/javascript-and-webgl-face-tracking-to-bring-augmented-reality-to-the-web\"},{\"title\":\"WebGL Chrome Experiment\",\"url\":\"https://experiments.withgoogle.com/search?q=WebGL\"},{\"title\":\"PlayCanvas WebGL Game Engine\",\"url\":\"https://playcanvas.com/\"},{\"title\":\"WebGLRenderingContext: frontFace() method - Web APIs | MDN\",\"url\":\"https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/frontFace\"},{\"title\":\"WebGL - Orthographic 3D\",\"url\":\"https://webglfundamentals.org/webgl/lessons/webgl-3d-orthographic.html\"},{\"title\":\"Raw WebGL\",\"url\":\"https://nickdesaulniers.github.io/RawWebGL/\"},{\"title\":\"JavaScript/WebGL real-time face tracking and expression detection library. Build your own emoticons animated in real time in the browser! SVG and THREE.js integration demos are provided. | LaptrinhX\",\"url\":\"https://laptrinhx.com/javascript-webgl-real-time-face-tracking-and-expression-detection-library-build-your-own-emoticons-animated-in-real-time-in-the-browser-svg-and-three-js-integration-demos-are-provided-2664480667/\"}]\n\nBased on the search results, here's what I found regarding real-time face alignment in browsers using WebGL and canvas:\n\n## Key Libraries and Solutions\n\n### Jeeliz Face Filter\nThis is a lightweight WebGL & JavaScript library for real-time multi-face detection, tracking and augmented-reality face filters. It supports rotation, mouth-opening and integrates with Three.js, Babylon.js, Canvas2D and CSS3D.(no content)This library relies on Jeeliz WebGL Deep Learning technology to detect and track the user's face using a neural network. The accuracy is adaptive: the better the hardware, the more detections are processed per second. All is done client-side.\n\n**Canvas Setup:**\nYou can use 2 separate `<canvas>` elements, aligned using CSS - one canvas for AR, and the second one to display the video and to run this library. This is often more efficient, but the newest versions of THREE.js are not suited to share the WebGL context and some weird bugs can occur.\n\n### Jeeliz Weboji\nThis is a JavaScript/WebGL real-time face tracking and expression detection library. You can build your own emoticons animated in real time in the browser, with SVG and THREE.js integration demos provided.\n\n### Banuba SDK\nThe Banuba webcam facial tracking library delivers stable 30 fps on camera and render (Chrome, MacBook Pro 15\", 2017). It's enough for real-time face filtering, in-browser makeup try-on, and virtual try-ons.(no content)For the web, they use a JavaScript wrapper called via Emscripten, which compiles C++ code into WebAssembly and runs it on the Web. Emscripten supports fast data input and output via Canvas/WebGL and provides OpenGL support over WebGL.\n\n### WebGL Requirements\nIf WebGL2 is available, it uses WebGL2 and no specific extension is required. If WebGL2 is not available but WebGL1 is, the OES_TEXTURE_FLOAT extension or OES_TEXTURE_HALF_FLOAT extension is required.\n\n### Google Chrome Experiments\nThere's a demo of real-time face tracking and face deformation that can \"deform your face in realtime!\"\n\nThe search didn't return specific results about \"side view\" face alignment. If you need information specifically about handling side profile/side view face detection, I can perform another search with more targeted terms.\n\n\nREMINDER: You MUST include the sources above in your response to the user using markdown hyperlinks."}]},"uuid":"dc09787a-02e4-45b6-877c-1180a07b80b5","timestamp":"2025-12-20T00:31:30.084Z","toolUseResult":{"query":"real-time face alignment side view browser WebGL canvas","results":[{"tool_use_id":"srvtoolu_01MywgxWiU3NTX6j36jMB8xR","content":[{"title":"JavaScript/WebGL lightweight and robust face tracking library designed for augmented reality face filters | jeelizFaceFilter","url":"https://jeeliz.github.io/jeelizFaceFilter/"},{"title":"GitHub - jeeliz/jeelizWeboji: JavaScript/WebGL real-time face tracking and expression detection library. Build your own emoticons animated in real time in the browser! SVG and THREE.js integration demos are provided.","url":"https://github.com/jeeliz/jeelizWeboji"},{"title":"GitHub - jeeliz/jeelizFaceFilter: 🎭 Lightweight WebGL & JavaScript library for real-time multi-face detection, tracking and augmented-reality face filters. Supports rotation, mouth-opening and integrates with Three.js, Babylon.js, Canvas2D and CSS3D","url":"https://github.com/jeeliz/jeelizFaceFilter"},{"title":"Webcam Face Tracking: JavaScript and WebGL to Power Your Web App","url":"https://www.banuba.com/blog/javascript-and-webgl-face-tracking-to-bring-augmented-reality-to-the-web"},{"title":"WebGL Chrome Experiment","url":"https://experiments.withgoogle.com/search?q=WebGL"},{"title":"PlayCanvas WebGL Game Engine","url":"https://playcanvas.com/"},{"title":"WebGLRenderingContext: frontFace() method - Web APIs | MDN","url":"https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/frontFace"},{"title":"WebGL - Orthographic 3D","url":"https://webglfundamentals.org/webgl/lessons/webgl-3d-orthographic.html"},{"title":"Raw WebGL","url":"https://nickdesaulniers.github.io/RawWebGL/"},{"title":"JavaScript/WebGL real-time face tracking and expression detection library. Build your own emoticons animated in real time in the browser! SVG and THREE.js integration demos are provided. | LaptrinhX","url":"https://laptrinhx.com/javascript-webgl-real-time-face-tracking-and-expression-detection-library-build-your-own-emoticons-animated-in-real-time-in-the-browser-svg-and-three-js-integration-demos-are-provided-2664480667/"}]},"Based on the search results, here's what I found regarding real-time face alignment in browsers using WebGL and canvas:\n\n## Key Libraries and Solutions\n\n### Jeeliz Face Filter\nThis is a lightweight WebGL & JavaScript library for real-time multi-face detection, tracking and augmented-reality face filters. It supports rotation, mouth-opening and integrates with Three.js, Babylon.js, Canvas2D and CSS3D.(no content)This library relies on Jeeliz WebGL Deep Learning technology to detect and track the user's face using a neural network. The accuracy is adaptive: the better the hardware, the more detections are processed per second. All is done client-side.\n\n**Canvas Setup:**\nYou can use 2 separate `<canvas>` elements, aligned using CSS - one canvas for AR, and the second one to display the video and to run this library. This is often more efficient, but the newest versions of THREE.js are not suited to share the WebGL context and some weird bugs can occur.\n\n### Jeeliz Weboji\nThis is a JavaScript/WebGL real-time face tracking and expression detection library. You can build your own emoticons animated in real time in the browser, with SVG and THREE.js integration demos provided.\n\n### Banuba SDK\nThe Banuba webcam facial tracking library delivers stable 30 fps on camera and render (Chrome, MacBook Pro 15\", 2017). It's enough for real-time face filtering, in-browser makeup try-on, and virtual try-ons.(no content)For the web, they use a JavaScript wrapper called via Emscripten, which compiles C++ code into WebAssembly and runs it on the Web. Emscripten supports fast data input and output via Canvas/WebGL and provides OpenGL support over WebGL.\n\n### WebGL Requirements\nIf WebGL2 is available, it uses WebGL2 and no specific extension is required. If WebGL2 is not available but WebGL1 is, the OES_TEXTURE_FLOAT extension or OES_TEXTURE_HALF_FLOAT extension is required.\n\n### Google Chrome Experiments\nThere's a demo of real-time face tracking and face deformation that can \"deform your face in realtime!\"\n\nThe search didn't return specific results about \"side view\" face alignment. If you need information specifically about handling side profile/side view face detection, I can perform another search with more targeted terms."],"durationSeconds":22.727809208996593}}
{"parentUuid":"dc09787a-02e4-45b6-877c-1180a07b80b5","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"e806c7c0-4bac-4115-a63b-761214dd1a04","version":"2.0.70","gitBranch":"main","agentId":"a99a652","slug":"cuddly-coalescing-frost","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01JEFpvfoiXHzZ5kHFjdosM1","type":"tool_result","content":"Web search results for query: \"ONNX face landmarks detection browser WASM runtime\"\n\nLinks: [{\"title\":\"Web | onnxruntime\",\"url\":\"https://onnxruntime.ai/docs/tutorials/web/\"},{\"title\":\"GitHub - Faceplugin-ltd/FaceRecognition-LivenessDetection-Javascript: Face Recognition SDK Javascript using ONNX Runtime Web and OpenCV.js (Face Detection, Face Landmarks, Face Liveness, Face Pose, Face Expression, Eye Closeness, Age, Gender and Face Recognition)\",\"url\":\"https://github.com/Faceplugin-ltd/FaceRecognition-LivenessDetection-Javascript\"},{\"title\":\"GitHub - FaceONNX/FaceONNX: Face recognition and analytics library based on deep neural networks and ONNX runtime\",\"url\":\"https://github.com/FaceONNX/FaceONNX\"},{\"title\":\"Run YOLO Model in the Browser with ONNX, WebAssembly, and Next.js - PyImageSearch\",\"url\":\"https://pyimagesearch.com/2025/07/28/run-yolo-model-in-the-browser-with-onnx-webassembly-and-next-js/\"},{\"title\":\"GitHub - atksh/onnx-facial-lmk-detector: End-to-end face detection, cropping, norm estimation, and landmark detection in a single onnx model\",\"url\":\"https://github.com/atksh/onnx-facial-lmk-detector\"},{\"title\":\"ONNX Runtime Web—running your machine learning model in browser - Microsoft Open Source Blog\",\"url\":\"https://opensource.microsoft.com/blog/2021/09/02/onnx-runtime-web-running-your-machine-learning-model-in-browser\"},{\"title\":\"Run AI Models Entirely in the Browser Using WebAssembly + ONNX Runtime (No Backend Required) - DEV Community\",\"url\":\"https://dev.to/hexshift/run-ai-models-entirely-in-the-browser-using-webassembly-onnx-runtime-no-backend-required-4lag\"},{\"title\":\"ONNX Runtime Web unleashes generative AI in the browser using WebGPU - Microsoft Open Source Blog\",\"url\":\"https://opensource.microsoft.com/blog/2024/02/29/onnx-runtime-web-unleashes-generative-ai-in-the-browser-using-webgpu\"},{\"title\":\"GitHub - nomi30701/yolo-object-detection-onnxruntime-web: Yolo object detection browser, Power by onnxruntime-web, Support WebGPU, wasm(cpu). Webcam support for live detection, Add your custom model\",\"url\":\"https://github.com/nomi30701/yolo-object-detection-onnxruntime-web\"},{\"title\":\"GitHub - DmitriyValetov/onnx_wasm_example: Example of onnxruntime use in browser #wasm #webassembly #onnx #onnxruntime\",\"url\":\"https://github.com/DmitriyValetov/onnx_wasm_example\"}]\n\nHere are the search results for \"ONNX face landmarks detection browser WASM runtime\":\n\n## ONNX Runtime Web for Face Landmarks Detection\n\n### Overview\n\nONNX Runtime Web enables you to run and deploy machine learning models in your web application using JavaScript APIs and libraries.(no content)With onnxruntime-web, you have the option to use webgl, webgpu or webnn (with deviceType set to gpu) for GPU processing, and WebAssembly (wasm, alias to cpu) or webnn (with deviceType set to cpu) for CPU processing.\n\n### Face-Specific Libraries\n\n1. **FaceRecognition-LivenessDetection-Javascript** (GitHub)\n   - Face Recognition SDK Javascript using ONNX Runtime Web and OpenCV.js (Face Detection, Face Landmarks, Face Liveness, Face Pose, Face Expression, Eye Closeness, Age, Gender and Face Recognition).\n   - This is on-premise SDK which means everything is processed on the browser and NO data leaves the device.\n\n2. **onnx-facial-lmk-detector** (GitHub)\n   - End-to-end face detection, cropping, norm estimation, and landmark detection in a single onnx model.\n   - This model requires onnxruntime>=1.11.\n\n3. **FaceONNX** (GitHub)\n   - FaceONNX is a face recognition and analytics library based on ONNX runtime. It contains ready-made deep neural networks for face detection and landmarks extraction, gender and age classification, emotion and beauty classification, embeddings.\n\n### WASM Runtime Details\n\nORT Web accelerates model inference in the browser on both CPUs and GPUs, through WebAssembly (WASM) and WebGL backends separately. For CPU inference, ORT Web compiles the native ONNX Runtime CPU engine into the WASM backend by using Emscripten.(no content)By doing that ORT Web WASM backend can run any ONNX model and support most functionalities native ONNX Runtime offers, including full ONNX operator coverage, quantized ONNX model, and mini runtime. We utilize multi-threading and features in WebAssembly to further accelerate model inferencing.\n\n### Code Example\n\nThis loads the ONNX model into a WASM-based runtime, running entirely in-browser:\n```javascript\nimport * as ort from \"onnxruntime-web\";\n\nlet session;\nasync function initModel() {\n  session = await ort.InferenceSession.create(\"/models/model.onnx\", {\n    executionProviders: [\"wasm\"],\n  });\n}\n```\n\nONNX Runtime also supports WebAssembly SIMD and multithreading if the browser supports it for dramatically better inference speed.\n\n### Performance Considerations\n\nONNX Runtime Web is a JavaScript library to enable web developers to deploy machine learning models directly in web browsers, offering multiple backends leveraging hardware acceleration. For CPU inference, it compiles the native ONNX Runtime CPU engine into the WebAssembly (WASM) backend. By doing that, ONNX Runtime Web can effectively run common machine learning models and it has been widely adopted by various web applications such as Transformer.js.\n\n\nREMINDER: You MUST include the sources above in your response to the user using markdown hyperlinks."}]},"uuid":"c21e6681-b039-4ee5-bd18-efbfa544d59e","timestamp":"2025-12-20T00:31:35.270Z","toolUseResult":{"query":"ONNX face landmarks detection browser WASM runtime","results":[{"tool_use_id":"srvtoolu_019ax9xhBU5iryWFi8s6mruA","content":[{"title":"Web | onnxruntime","url":"https://onnxruntime.ai/docs/tutorials/web/"},{"title":"GitHub - Faceplugin-ltd/FaceRecognition-LivenessDetection-Javascript: Face Recognition SDK Javascript using ONNX Runtime Web and OpenCV.js (Face Detection, Face Landmarks, Face Liveness, Face Pose, Face Expression, Eye Closeness, Age, Gender and Face Recognition)","url":"https://github.com/Faceplugin-ltd/FaceRecognition-LivenessDetection-Javascript"},{"title":"GitHub - FaceONNX/FaceONNX: Face recognition and analytics library based on deep neural networks and ONNX runtime","url":"https://github.com/FaceONNX/FaceONNX"},{"title":"Run YOLO Model in the Browser with ONNX, WebAssembly, and Next.js - PyImageSearch","url":"https://pyimagesearch.com/2025/07/28/run-yolo-model-in-the-browser-with-onnx-webassembly-and-next-js/"},{"title":"GitHub - atksh/onnx-facial-lmk-detector: End-to-end face detection, cropping, norm estimation, and landmark detection in a single onnx model","url":"https://github.com/atksh/onnx-facial-lmk-detector"},{"title":"ONNX Runtime Web—running your machine learning model in browser - Microsoft Open Source Blog","url":"https://opensource.microsoft.com/blog/2021/09/02/onnx-runtime-web-running-your-machine-learning-model-in-browser"},{"title":"Run AI Models Entirely in the Browser Using WebAssembly + ONNX Runtime (No Backend Required) - DEV Community","url":"https://dev.to/hexshift/run-ai-models-entirely-in-the-browser-using-webassembly-onnx-runtime-no-backend-required-4lag"},{"title":"ONNX Runtime Web unleashes generative AI in the browser using WebGPU - Microsoft Open Source Blog","url":"https://opensource.microsoft.com/blog/2024/02/29/onnx-runtime-web-unleashes-generative-ai-in-the-browser-using-webgpu"},{"title":"GitHub - nomi30701/yolo-object-detection-onnxruntime-web: Yolo object detection browser, Power by onnxruntime-web, Support WebGPU, wasm(cpu). Webcam support for live detection, Add your custom model","url":"https://github.com/nomi30701/yolo-object-detection-onnxruntime-web"},{"title":"GitHub - DmitriyValetov/onnx_wasm_example: Example of onnxruntime use in browser #wasm #webassembly #onnx #onnxruntime","url":"https://github.com/DmitriyValetov/onnx_wasm_example"}]},"Here are the search results for \"ONNX face landmarks detection browser WASM runtime\":\n\n## ONNX Runtime Web for Face Landmarks Detection\n\n### Overview\n\nONNX Runtime Web enables you to run and deploy machine learning models in your web application using JavaScript APIs and libraries.(no content)With onnxruntime-web, you have the option to use webgl, webgpu or webnn (with deviceType set to gpu) for GPU processing, and WebAssembly (wasm, alias to cpu) or webnn (with deviceType set to cpu) for CPU processing.\n\n### Face-Specific Libraries\n\n1. **FaceRecognition-LivenessDetection-Javascript** (GitHub)\n   - Face Recognition SDK Javascript using ONNX Runtime Web and OpenCV.js (Face Detection, Face Landmarks, Face Liveness, Face Pose, Face Expression, Eye Closeness, Age, Gender and Face Recognition).\n   - This is on-premise SDK which means everything is processed on the browser and NO data leaves the device.\n\n2. **onnx-facial-lmk-detector** (GitHub)\n   - End-to-end face detection, cropping, norm estimation, and landmark detection in a single onnx model.\n   - This model requires onnxruntime>=1.11.\n\n3. **FaceONNX** (GitHub)\n   - FaceONNX is a face recognition and analytics library based on ONNX runtime. It contains ready-made deep neural networks for face detection and landmarks extraction, gender and age classification, emotion and beauty classification, embeddings.\n\n### WASM Runtime Details\n\nORT Web accelerates model inference in the browser on both CPUs and GPUs, through WebAssembly (WASM) and WebGL backends separately. For CPU inference, ORT Web compiles the native ONNX Runtime CPU engine into the WASM backend by using Emscripten.(no content)By doing that ORT Web WASM backend can run any ONNX model and support most functionalities native ONNX Runtime offers, including full ONNX operator coverage, quantized ONNX model, and mini runtime. We utilize multi-threading and features in WebAssembly to further accelerate model inferencing.\n\n### Code Example\n\nThis loads the ONNX model into a WASM-based runtime, running entirely in-browser:\n```javascript\nimport * as ort from \"onnxruntime-web\";\n\nlet session;\nasync function initModel() {\n  session = await ort.InferenceSession.create(\"/models/model.onnx\", {\n    executionProviders: [\"wasm\"],\n  });\n}\n```\n\nONNX Runtime also supports WebAssembly SIMD and multithreading if the browser supports it for dramatically better inference speed.\n\n### Performance Considerations\n\nONNX Runtime Web is a JavaScript library to enable web developers to deploy machine learning models directly in web browsers, offering multiple backends leveraging hardware acceleration. For CPU inference, it compiles the native ONNX Runtime CPU engine into the WebAssembly (WASM) backend. By doing that, ONNX Runtime Web can effectively run common machine learning models and it has been widely adopted by various web applications such as Transformer.js."],"durationSeconds":27.913458042003214}}
{"parentUuid":"c21e6681-b039-4ee5-bd18-efbfa544d59e","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"e806c7c0-4bac-4115-a63b-761214dd1a04","version":"2.0.70","gitBranch":"main","agentId":"a99a652","slug":"cuddly-coalescing-frost","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01PqwYJMWNJF1xh4Y1bURSUG","type":"message","role":"assistant","content":[{"type":"text","text":"Perfect. I now have comprehensive research. Let me compile my findings into a detailed report.\n\n## Comprehensive Research Report: Side Profile Face Landmark Detection Models\n\nBased on extensive research, here's what I found about deep learning models for side profile facial landmark detection with web-compatible solutions:\n\n---\n\n## 1. Models That Work Well for Non-Frontal Face Detection\n\n### MediaPipe Face Mesh (Google)\n**Status**: Production-ready, actively maintained\n- Detects 468 3D landmarks in real-time on mobile devices\n- **Key limitation**: Not head orientation invariant - the mesh is NOT inherently rotation-proof\n- Performance degrades at extreme angles (full profile/side view) due to occlusion of key points (eyes, nose)\n- More robust than 2D models but cannot reliably work at full 90-degree profile\n- Uses BlazeFace detector as base (optimized for frontal faces)\n- Source: [MediaPipe Face Mesh Documentation](https://github.com/google-ai-edge/mediapipe/blob/master/docs/solutions/face_mesh.md)\n\n### OpenSeeFace\n**Status**: Open-source, excellent for adverse conditions\n- Based on MobileNetV3 architecture\n- Runs 30-60 fps on CPU (converted to ONNX format)\n- **Excellent profile handling**: Keeps tracking faces through very wide range of head poses with high stability\n- Performs well in low light, high noise, low resolution\n- Four models with different speed/quality trade-offs\n- Source: [OpenSeeFace GitHub](https://github.com/emilianavt/OpenSeeFace)\n\n### InsightFace (InspireFace SDK - 2024)\n**Status**: Production-ready, cross-platform\n- Predicts full 3D mesh (68 vertices) via joint 2D-to-3D regression\n- Lightweight decoder (1.2M parameters) runs in 0.7ms on GPU\n- Handles various head poses including profiles\n- Supports gaze redirection and face frontalisation for low-angle recognition\n- Source: [InsightFace GitHub](https://github.com/deepinsight/insightface)\n\n### OpenFace (TadasBaltrusaitis)\n**Status**: Open-source, established research\n- Specifically designed for facial landmark detection, head pose estimation, facial action units, and eye-gaze estimation\n- Robust for non-frontal faces\n- Source: [OpenFace GitHub](https://github.com/TadasBaltrusaitis/OpenFace)\n\n### Face Alignment Network (FAN)\n**Status**: Open-source PyTorch implementation\n- Claims \"world's most accurate face alignment network\"\n- Capable of detecting points in both 2D and 3D coordinates\n- Source: [Face Alignment GitHub](https://github.com/1adrianb/face-alignment)\n\n### Microsoft Dense Landmarks\n**Status**: Research implementation\n- Predicts 10x more landmarks than standard models (full head coverage including teeth)\n- Accurate even with synthetic training data\n- 150+ FPS on single CPU thread\n- Source: [Microsoft Dense Landmarks](https://microsoft.github.io/DenseLandmarks/)\n\n---\n\n## 2. Web-Compatible Solutions (WASM, WebGL, Browser-Friendly)\n\n### A. MediaPipe (Google) - Best Established Option\n- **Web Support**: Full native JavaScript/TypeScript support via WASM\n- **Execution Options**: WASM backend with WebGL GPU acceleration option\n- **Performance**: Real-time on modern browsers\n- **Downsides**: Limited to ~45-degree angles before accuracy drops significantly\n- **Landmarks**: 478 3D points\n- Documentation: [MediaPipe Face Landmarker Web Guide](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js)\n\n### B. ONNX Runtime Web - Most Flexible\n- **Technology**: Compiles native ONNX Runtime into WebAssembly backend via Emscripten\n- **Execution Backends**: WASM (CPU), WebGL, WebGPU\n- **Performance**: Multi-threading and SIMD support for WebAssembly\n- **Best For**: Custom models, existing ONNX model compatibility\n- **Models Available**:\n  - **onnx-facial-lmk-detector**: End-to-end face detection + landmark detection in single ONNX model\n  - **FaceRecognition-LivenessDetection-Javascript**: Full SDK with pose, landmarks, expressions\n  - **FaceONNX**: Face detection, landmarks, gender/age, emotion classification\n- Sources: \n  - [ONNX Runtime Web Documentation](https://onnxruntime.ai/docs/tutorials/web/)\n  - [onnx-facial-lmk-detector](https://github.com/atksh/onnx-facial-lmk-detector)\n  - [FaceONNX](https://github.com/FaceONNX/FaceONNX)\n\n### C. TensorFlow.js - Native Browser Support\n- **Models Available**:\n  - BlazeFace: Lightweight but frontal-optimized (6 keypoints)\n  - MediaPipe FaceMesh integration: 478 3D landmarks via TFJS\n- **Backends**: WASM, WebGL, CPU\n- **Limitation**: Most built-in models lean toward frontal faces\n- Source: [TensorFlow.js Face Detection Models](https://www.npmjs.com/package/@tensorflow-models/face-detection)\n\n### D. Jeeliz Technologies - WebGL Native\n- **jeelizFaceFilter**: Lightweight WebGL & JavaScript library for real-time multi-face detection\n- **Features**: Multi-face tracking, rotation support, AR filters\n- **Integration**: Three.js, Babylon.js, Canvas2D, CSS3D compatible\n- **Advantage**: Native WebGL deep learning (no external dependencies)\n- **Performance**: Adaptive accuracy based on hardware\n- Source: [Jeeliz FaceFilter](https://github.com/jeeliz/jeelizFaceFilter)\n\n### E. Face-API.js (Updated Forks)\n**Original Library**:\n- 68-point landmark detection\n- Lightweight (350KB default, 80KB tiny model)\n- **Limitation**: Optimized for frontal faces only\n\n**Vladmandic's Updated Fork** (@vladmandic/face-api):\n- **Improvements**: Compatible with TensorFlow.js 2.0+ through 4.0+\n- **Backends**: WebGL, CPU, WASM\n- **Features**: Face alignment, yaw/pitch/roll calculation\n- **Current Status**: Superseded by \"Human\" library (vladmandic/human) which has newer models\n- Sources:\n  - [vladmandic/face-api GitHub](https://github.com/vladmandic/face-api)\n  - [vladmandic/face-api NPM](https://www.npmjs.com/package/@vladmandic/face-api)\n\n### F. Human (vladmandic) - Latest Option\n- **Status**: Successor to face-api.js\n- **Features**: Extended with newer AI models, better web standards compatibility\n- **Advantage**: Combines latest research with practical web deployment\n\n---\n\n## 3. Open-Source Alternatives to Server-Side Detection\n\n### Python-First Projects (Can Be Self-Hosted via WebAssembly)\n\n1. **OpenSeeFace**\n   - ONNX-based, easily portable to WASM\n   - Strong profile support\n   - Can be compiled for browser use\n   - Source: [OpenSeeFace](https://github.com/emilianavt/OpenSeeFace)\n\n2. **OpenFace**\n   - C++ core, can be compiled to WASM via Emscripten\n   - Complete head pose estimation pipeline\n   - Source: [OpenFace](https://github.com/TadasBaltrusaitis/OpenFace)\n\n3. **InsightFace**\n   - ONNX model export available\n   - Can be deployed via ONNX Runtime Web\n   - Source: [InsightFace](https://github.com/deepinsight/insightface)\n\n4. **Face-Alignment (FAL)**\n   - PyTorch-based, trainable models\n   - Can export to ONNX for browser deployment\n   - Source: [Face-Alignment](https://github.com/1adrianb/face-alignment)\n\n---\n\n## 4. 3D Face Mesh Models Handling Head Rotation\n\n### MediaPipe 3D Face Transform Module\n- Establishes metric 3D space\n- Uses Procrustes Analysis for robust pose estimation\n- Outputs face pose transformation matrix\n- Can drive virtual object attachment (glasses, hats, masks)\n- **Limitation**: Not inherently rotation-invariant for full profiles\n- Source: [MediaPipe 3D Face Transform](https://developers.googleblog.com/mediapipe-3d-face-transform/)\n\n### Head Pose Estimation Techniques\n\n**Using 2D Landmarks for 3D Pose**:\n- Perspective-n-Point (PnP) algorithm\n- Uses landmark coordinates (eyes, nose, mouth corners, chin) to calculate pitch, yaw, roll\n- Works with any 2D landmark detector\n- Projects 3D face model onto 2D image plane\n\n**Available Implementations**:\n- Face-Yaw-Roll-Pitch-from-Pose-Estimation: [GitHub](https://github.com/jerryhouuu/Face-Yaw-Roll-Pitch-from-Pose-Estimation-using-OpenCV)\n- posenet-pointer-lab: Extracts pitch, yaw, roll from PoseNet [GitHub](https://github.com/BenJaminKen/posenet-pointer-lab)\n\n**Deep Learning Models**:\n- ResNet18/34/50 based head pose models\n- MobileNet V2/V3 for edge devices\n- Can predict yaw, pitch, roll directly from face crops\n\n---\n\n## 5. Critical Limitations Summary\n\n| Model | Profile Support | Web Native | Notes |\n|-------|-----------------|-----------|-------|\n| MediaPipe FaceMesh | ~45° max | Yes (WASM) | Degrades at extreme angles |\n| OpenSeeFace | Excellent (wide range) | Via ONNX Runtime | Best for profile, but needs conversion |\n| face-api.js | Poor (frontal only) | Yes (TensorFlow.js) | Updated fork adds some improvements |\n| Jeeliz FaceFilter | Good | Yes (WebGL native) | Proprietary, but effective |\n| InsightFace | Good | Via ONNX Runtime | Strong 3D mesh predictions |\n| OpenFace | Excellent | Via Emscripten/WASM | Not optimized for browser yet |\n| ONNX Runtime Web | Model-dependent | Yes (WASM/WebGL) | Depends on underlying model |\n\n---\n\n## 6. Recommendations for Your Use Case\n\n**Best Option for Full Side Profile Support in Browser**:\n\n1. **Short-term**: Deploy OpenSeeFace as ONNX model via ONNX Runtime Web\n   - Excellent profile tracking\n   - Browser-compatible via WASM\n   - Proven performance in adverse conditions\n\n2. **Alternative**: Use MediaPipe + head pose estimation (PnP algorithm)\n   - Already working in your app\n   - Add pitch/yaw/roll calculation from 3D landmarks\n   - Limit to ~45-degree angles, use fallback for extreme profiles\n\n3. **Advanced**: Train custom profile-optimized model on InsightFace or FAN\n   - Use profile-heavy training data\n   - Deploy via ONNX Runtime Web\n   - Best accuracy but requires training effort\n\n4. **Not Recommended**:\n   - Stick with face-api.js for profile work (too frontal-biased)\n   - BlazeFace alone for profiles (designed for selfies)\n\n---\n\n## Sources\n\n- [Papers with Code - Facial Landmark Detection](https://paperswithcode.com/task/facial-landmark-detection/codeless)\n- [Comparative Analysis of Pre-trained Deep Learning Models 2024](https://www.jait.us/show-246-1603-1.html)\n- [MediaPipe Face Landmarker Web Guide](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/web_js)\n- [OpenSeeFace GitHub](https://github.com/emilianavt/OpenSeeFace)\n- [InsightFace GitHub](https://github.com/deepinsight/insightface)\n- [OpenFace GitHub](https://github.com/TadasBaltrusaitis/OpenFace)\n- [Face Alignment GitHub](https://github.com/1adrianb/face-alignment)\n- [ONNX Runtime Web Documentation](https://onnxruntime.ai/docs/tutorials/web/)\n- [onnx-facial-lmk-detector](https://github.com/atksh/onnx-facial-lmk-detector)\n- [FaceONNX GitHub](https://github.com/FaceONNX/FaceONNX)\n- [Jeeliz FaceFilter GitHub](https://github.com/jeeliz/jeelizFaceFilter)\n- [vladmandic/face-api GitHub](https://github.com/vladmandic/face-api)\n- [TensorFlow.js Face Detection Models](https://www.npmjs.com/package/@tensorflow-models/face-detection)\n- [MediaPipe Face Mesh Documentation](https://github.com/google-ai-edge/mediapipe/blob/master/docs/solutions/face_mesh.md)\n- [Face-Yaw-Roll-Pitch Estimation](https://github.com/jerryhouuu/Face-Yaw-Roll-Pitch-from-Pose-Estimation-using-OpenCV)\n- [posenet-pointer-lab](https://github.com/BenJaminKen/posenet-pointer-lab)\n- [WebCV - WebGL Face Detection](https://github.com/jamt9000/webcv)\n- [Run YOLO in Browser with ONNX and WebAssembly](https://pyimagesearch.com/2025/07/28/run-yolo-model-in-the-browser-with-onnx-webassembly-and-next-js/)\n- [Microsoft Dense Landmarks](https://microsoft.github.io/DenseLandmarks/)"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":7665,"cache_read_input_tokens":22532,"cache_creation":{"ephemeral_5m_input_tokens":7665,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWGzksjFkmjeEPKYRQpDX","type":"assistant","uuid":"c2c0e01c-b0a7-4f0f-95ff-6fca05b4a81c","timestamp":"2025-12-20T00:32:08.371Z"}
