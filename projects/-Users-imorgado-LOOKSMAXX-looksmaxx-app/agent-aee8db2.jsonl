{"parentUuid":null,"isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"988cde7a-9586-4ca8-910d-50a828b2fa2d","version":"2.0.76","gitBranch":"main","agentId":"aee8db2","type":"user","message":{"role":"user","content":"Explore the LOOKSMAXX side profile landmark implementation. Find and analyze:\n1. All files related to side profile landmark detection and placement\n2. The list of side profile landmarks used (names, coordinates, mappings)\n3. How landmarks are calculated/detected (InsightFace, manual placement, offsets, etc.)\n4. Any normalization or transformation applied to side landmarks\n5. The Frankfort plane calculation and how it affects landmark placement\n6. Documentation of the side profile landmarking system\n\nFocus on:\n- src/lib/serverSideDetection.ts\n- src/lib/sideProfileDetection.ts\n- src/lib/sideProfileNormalization.ts\n- src/components/LandmarkAnalysisTool.tsx\n- Any type definitions for side landmarks\n\nProvide a complete inventory of all 28 side landmarks with their detection methods."},"uuid":"63b13745-e6be-4aa7-ae97-77ac4c30ebf7","timestamp":"2025-12-30T14:57:10.475Z"}
{"parentUuid":"63b13745-e6be-4aa7-ae97-77ac4c30ebf7","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"988cde7a-9586-4ca8-910d-50a828b2fa2d","version":"2.0.76","gitBranch":"main","agentId":"aee8db2","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01RVFwNuAWfQcqhnU3knDg3X","type":"message","role":"assistant","content":[{"type":"text","text":"I'll explore the LOOKSMAXX side profile landmark implementation systematically."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":39730,"cache_read_input_tokens":0,"cache_creation":{"ephemeral_5m_input_tokens":39730,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWd4rQw9w6ky4U9fMTmEx","type":"assistant","uuid":"597a2974-bf76-4827-bba1-66b75e97e4c5","timestamp":"2025-12-30T14:57:14.615Z"}
{"parentUuid":"597a2974-bf76-4827-bba1-66b75e97e4c5","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"988cde7a-9586-4ca8-910d-50a828b2fa2d","version":"2.0.76","gitBranch":"main","agentId":"aee8db2","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01RVFwNuAWfQcqhnU3knDg3X","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01XXvB4rUDoB4joY312FuuNL","name":"Read","input":{"file_path":"/Users/imorgado/LOOKSMAXX/looksmaxx-app/src/lib/serverSideDetection.ts"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":39730,"cache_read_input_tokens":0,"cache_creation":{"ephemeral_5m_input_tokens":39730,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWd4rQw9w6ky4U9fMTmEx","type":"assistant","uuid":"52b2670e-8f02-4e71-a7a2-9a2cdfaded85","timestamp":"2025-12-30T14:57:15.025Z"}
{"parentUuid":"52b2670e-8f02-4e71-a7a2-9a2cdfaded85","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"988cde7a-9586-4ca8-910d-50a828b2fa2d","version":"2.0.76","gitBranch":"main","agentId":"aee8db2","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01RVFwNuAWfQcqhnU3knDg3X","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01UbtiNg4U8AEwaE2phbpv4X","name":"Read","input":{"file_path":"/Users/imorgado/LOOKSMAXX/looksmaxx-app/src/lib/sideProfileDetection.ts"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":39730,"cache_read_input_tokens":0,"cache_creation":{"ephemeral_5m_input_tokens":39730,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWd4rQw9w6ky4U9fMTmEx","type":"assistant","uuid":"1a0a3a66-8a3d-4a52-bf97-e2051d0f40f5","timestamp":"2025-12-30T14:57:15.525Z"}
{"parentUuid":"1a0a3a66-8a3d-4a52-bf97-e2051d0f40f5","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"988cde7a-9586-4ca8-910d-50a828b2fa2d","version":"2.0.76","gitBranch":"main","agentId":"aee8db2","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01RVFwNuAWfQcqhnU3knDg3X","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Lgk7csoVJzEpzJAf3vDWur","name":"Read","input":{"file_path":"/Users/imorgado/LOOKSMAXX/looksmaxx-app/src/lib/sideProfileNormalization.ts"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":39730,"cache_read_input_tokens":0,"cache_creation":{"ephemeral_5m_input_tokens":39730,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWd4rQw9w6ky4U9fMTmEx","type":"assistant","uuid":"e32b78b9-7dc3-429b-bb2b-b3476e0a5390","timestamp":"2025-12-30T14:57:15.994Z"}
{"parentUuid":"e32b78b9-7dc3-429b-bb2b-b3476e0a5390","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"988cde7a-9586-4ca8-910d-50a828b2fa2d","version":"2.0.76","gitBranch":"main","agentId":"aee8db2","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01RVFwNuAWfQcqhnU3knDg3X","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01BwVXbJfa5ezRzYXnJdvBH5","name":"Read","input":{"file_path":"/Users/imorgado/LOOKSMAXX/looksmaxx-app/src/components/LandmarkAnalysisTool.tsx"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":39730,"cache_read_input_tokens":0,"cache_creation":{"ephemeral_5m_input_tokens":39730,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWd4rQw9w6ky4U9fMTmEx","type":"assistant","uuid":"6ec8ae93-826d-4ed3-8014-2319aaf540df","timestamp":"2025-12-30T14:57:16.629Z"}
{"parentUuid":"6ec8ae93-826d-4ed3-8014-2319aaf540df","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"988cde7a-9586-4ca8-910d-50a828b2fa2d","version":"2.0.76","gitBranch":"main","agentId":"aee8db2","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01RVFwNuAWfQcqhnU3knDg3X","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01AAKWnVskBVQWibMCcT8CcW","name":"Glob","input":{"pattern":"**/*side*landmark*.ts"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":39730,"cache_read_input_tokens":0,"cache_creation":{"ephemeral_5m_input_tokens":39730,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWd4rQw9w6ky4U9fMTmEx","type":"assistant","uuid":"7bd83fe1-7b6f-4d65-ba7f-09db7adc968e","timestamp":"2025-12-30T14:57:17.049Z"}
{"parentUuid":"7bd83fe1-7b6f-4d65-ba7f-09db7adc968e","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"988cde7a-9586-4ca8-910d-50a828b2fa2d","version":"2.0.76","gitBranch":"main","agentId":"aee8db2","slug":"fizzy-singing-bird","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01XXvB4rUDoB4joY312FuuNL","type":"tool_result","content":"     1→/**\n     2→ * Server-Side Detection Service for Side Profiles\n     3→ *\n     4→ * Calls the Railway-hosted InsightFace API for accurate side profile detection.\n     5→ * Returns 106 raw landmarks mapped to our 28 cephalometric landmarks.\n     6→ *\n     7→ * Supports manual overrides for estimated landmarks (porion, tragus, intertragicNotch)\n     8→ * to achieve FaceIQ-level Frankfort plane accuracy.\n     9→ */\n    10→\n    11→import { SideLandmarkResponse } from '@/app/api/side-landmarks/route';\n    12→\n    13→/**\n    14→ * Landmarks that are geometrically estimated and benefit from manual adjustment\n    15→ */\n    16→export const ESTIMATED_LANDMARK_IDS = ['porion', 'tragus', 'intertragicNotch'] as const;\n    17→export type EstimatedLandmarkId = typeof ESTIMATED_LANDMARK_IDS[number];\n    18→\n    19→export interface ServerDetectionResult {\n    20→  landmarks: Array<{ id: string; x: number; y: number }>;\n    21→  rawLandmarks?: Array<{ x: number; y: number }>;  // Raw 106 landmarks for FaceIQ-style normalization\n    22→  confidence: number;\n    23→  faceBox: { x: number; y: number; width: number; height: number };\n    24→  direction?: 'left' | 'right';\n    25→  rotationAngle?: number;\n    26→  frankfortPlane?: {\n    27→    angle: number;\n    28→    orbitale: { x: number; y: number };\n    29→    porion: { x: number; y: number };\n    30→  };\n    31→  /** Tracks which landmarks were manually adjusted */\n    32→  manuallyAdjusted?: string[];\n    33→}\n    34→\n    35→/**\n    36→ * Manual landmark override for estimated ear landmarks\n    37→ */\n    38→export interface LandmarkOverride {\n    39→  id: string;\n    40→  x: number;\n    41→  y: number;\n    42→}\n    43→\n    44→/**\n    45→ * Convert image URL to base64\n    46→ */\n    47→async function imageUrlToBase64(imageUrl: string): Promise<string> {\n    48→  // If it's already a data URL, extract the base64 part\n    49→  if (imageUrl.startsWith('data:')) {\n    50→    return imageUrl;\n    51→  }\n    52→\n    53→  // If it's a blob URL or regular URL, fetch and convert\n    54→  const response = await fetch(imageUrl);\n    55→  const blob = await response.blob();\n    56→\n    57→  return new Promise((resolve, reject) => {\n    58→    const reader = new FileReader();\n    59→    reader.onloadend = () => {\n    60→      if (typeof reader.result === 'string') {\n    61→        resolve(reader.result);\n    62→      } else {\n    63→        reject(new Error('Failed to convert to base64'));\n    64→      }\n    65→    };\n    66→    reader.onerror = reject;\n    67→    reader.readAsDataURL(blob);\n    68→  });\n    69→}\n    70→\n    71→\n    72→/**\n    73→ * Get image dimensions\n    74→ */\n    75→function getImageDimensions(imageUrl: string): Promise<{ width: number; height: number }> {\n    76→  return new Promise((resolve, reject) => {\n    77→    const img = new Image();\n    78→    img.onload = () => resolve({ width: img.naturalWidth, height: img.naturalHeight });\n    79→    img.onerror = reject;\n    80→    img.src = imageUrl;\n    81→  });\n    82→}\n    83→\n    84→/**\n    85→ * Calculate Frankfort Horizontal Plane from orbitale and porion landmarks\n    86→ */\n    87→function calculateFrankfortPlane(\n    88→  orbitale: { x: number; y: number },\n    89→  porion: { x: number; y: number }\n    90→): { angle: number; orbitale: { x: number; y: number }; porion: { x: number; y: number } } {\n    91→  // Calculate angle from horizontal (in degrees)\n    92→  const dx = porion.x - orbitale.x;\n    93→  const dy = porion.y - orbitale.y;\n    94→  const angle = Math.atan2(dy, dx) * (180 / Math.PI);\n    95→\n    96→  return {\n    97→    angle,\n    98→    orbitale,\n    99→    porion,\n   100→  };\n   101→}\n   102→\n   103→/**\n   104→ * Detect side profile landmarks using server-side InsightFace API\n   105→ */\n   106→export async function detectSideProfileServer(\n   107→  imageUrl: string\n   108→): Promise<ServerDetectionResult | null> {\n   109→  try {\n   110→    console.log('[ServerDetection] Starting server-side detection...');\n   111→\n   112→    // Convert image to base64\n   113→    const base64Image = await imageUrlToBase64(imageUrl);\n   114→\n   115→    // Call our API proxy\n   116→    const response = await fetch('/api/side-landmarks', {\n   117→      method: 'POST',\n   118→      headers: {\n   119→        'Content-Type': 'application/json',\n   120→      },\n   121→      body: JSON.stringify({ image: base64Image }),\n   122→    });\n   123→\n   124→    if (!response.ok) {\n   125→      console.error('[ServerDetection] API error:', response.status);\n   126→      return null;\n   127→    }\n   128→\n   129→    const data: SideLandmarkResponse = await response.json();\n   130→\n   131→    if (!data.success || !data.data?.namedLandmarks) {\n   132→      console.log('[ServerDetection] Detection failed:', data.error || 'No landmarks found');\n   133→      return null;\n   134→    }\n   135→\n   136→    const resultData = data.data;\n   137→    console.log('[ServerDetection] Detection successful, count:', resultData.landmarkCount);\n   138→\n   139→    // Get image dimensions for normalization\n   140→    const { width, height } = await getImageDimensions(imageUrl);\n   141→    console.log('[ServerDetection] Normalizing landmarks with dimensions:', width, 'x', height);\n   142→\n   143→    // Convert namedLandmarks object to array format matching our system AND NORMALIZE (0-1)\n   144→    const landmarks = Object.entries(resultData.namedLandmarks).map(([id, point]) => ({\n   145→      id,\n   146→      x: Math.max(0, Math.min(1, point.x / width)),\n   147→      y: Math.max(0, Math.min(1, point.y / height)),\n   148→    }));\n   149→\n   150→    // Convert raw landmarks array for FaceIQ-style normalization (indices 10, 26, 75)\n   151→    const rawLandmarks = resultData.landmarks?.map(pt => ({\n   152→      x: Math.max(0, Math.min(1, pt.x / width)),\n   153→      y: Math.max(0, Math.min(1, pt.y / height)),\n   154→    })) || [];\n   155→\n   156→    // Use Frankfort Plane from server if available (future proof), otherwise calculate locally\n   157→    let frankfortPlane: ServerDetectionResult['frankfortPlane'];\n   158→    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n   159→    const serverFrankfort = (resultData as any).frankfort_plane;\n   160→\n   161→    if (serverFrankfort) {\n   162→      frankfortPlane = serverFrankfort;\n   163→      console.log('[ServerDetection] Frankfort Plane angle (from server):', serverFrankfort.angle.toFixed(2), 'degrees');\n   164→    } else {\n   165→      // Find normalized orbitale and porion from our processed list\n   166→      const normOrbitale = landmarks.find(l => l.id === 'orbitale');\n   167→      const normPorion = landmarks.find(l => l.id === 'porion');\n   168→\n   169→      if (normOrbitale && normPorion) {\n   170→        frankfortPlane = calculateFrankfortPlane(normOrbitale, normPorion);\n   171→        console.log('[ServerDetection] Frankfort Plane angle (calculated):', frankfortPlane.angle.toFixed(2), 'degrees');\n   172→      }\n   173→    }\n   174→\n   175→    return {\n   176→      landmarks,\n   177→      rawLandmarks,  // For FaceIQ-style normalization using indices 10, 26, 75\n   178→      confidence: 0.95, // InsightFace is generally high confidence\n   179→      faceBox: resultData.crop || { x: 0, y: 0, width: 1, height: 1 },\n   180→      direction: resultData.direction,\n   181→      rotationAngle: resultData.rotationAngle,\n   182→      frankfortPlane,\n   183→    };\n   184→  } catch (error) {\n   185→    console.error('[ServerDetection] Error:', error);\n   186→    return null;\n   187→  }\n   188→}\n   189→\n   190→/**\n   191→ * Merge manual landmark overrides with detected landmarks\n   192→ *\n   193→ * Used for applying user adjustments to estimated ear landmarks\n   194→ * (porion, tragus, intertragicNotch) for FaceIQ-level accuracy.\n   195→ *\n   196→ * @param detectedLandmarks - Landmarks from server detection\n   197→ * @param overrides - Manual adjustments from user\n   198→ * @returns Merged landmarks with manual overrides applied\n   199→ */\n   200→export function mergeWithOverrides(\n   201→  detectedLandmarks: Array<{ id: string; x: number; y: number }>,\n   202→  overrides: LandmarkOverride[]\n   203→): Array<{ id: string; x: number; y: number }> {\n   204→  if (!overrides.length) return detectedLandmarks;\n   205→\n   206→  const overrideMap = new Map(overrides.map(o => [o.id, o]));\n   207→\n   208→  return detectedLandmarks.map(landmark => {\n   209→    const override = overrideMap.get(landmark.id);\n   210→    if (override) {\n   211→      console.log(`[ServerDetection] Applied override for ${landmark.id}:`, {\n   212→        original: { x: landmark.x.toFixed(4), y: landmark.y.toFixed(4) },\n   213→        adjusted: { x: override.x.toFixed(4), y: override.y.toFixed(4) },\n   214→      });\n   215→      return { ...landmark, x: override.x, y: override.y };\n   216→    }\n   217→    return landmark;\n   218→  });\n   219→}\n   220→\n   221→/**\n   222→ * Recalculate Frankfort Horizontal Plane after manual adjustments\n   223→ *\n   224→ * Call this after applying overrides to porion or orbitale to update\n   225→ * the Frankfort plane angle used in side profile analysis.\n   226→ *\n   227→ * @param landmarks - Merged landmarks with overrides applied\n   228→ * @returns Updated Frankfort plane calculation or null if landmarks not found\n   229→ */\n   230→export function recalculateFrankfortPlane(\n   231→  landmarks: Array<{ id: string; x: number; y: number }>\n   232→): ServerDetectionResult['frankfortPlane'] | null {\n   233→  const orbitale = landmarks.find(l => l.id === 'orbitale');\n   234→  const porion = landmarks.find(l => l.id === 'porion');\n   235→\n   236→  if (!orbitale || !porion) {\n   237→    console.warn('[ServerDetection] Cannot calculate Frankfort plane: missing orbitale or porion');\n   238→    return null;\n   239→  }\n   240→\n   241→  const plane = calculateFrankfortPlane(orbitale, porion);\n   242→  console.log('[ServerDetection] Recalculated Frankfort Plane angle:', plane.angle.toFixed(2), 'degrees');\n   243→\n   244→  return plane;\n   245→}\n   246→\n   247→/**\n   248→ * Apply manual overrides to a detection result and recalculate Frankfort plane\n   249→ *\n   250→ * Convenience function that combines merging and recalculation.\n   251→ *\n   252→ * @param result - Original detection result\n   253→ * @param overrides - Manual landmark adjustments\n   254→ * @returns Updated result with overrides applied\n   255→ */\n   256→export function applyManualOverrides(\n   257→  result: ServerDetectionResult,\n   258→  overrides: LandmarkOverride[]\n   259→): ServerDetectionResult {\n   260→  if (!overrides.length) return result;\n   261→\n   262→  const mergedLandmarks = mergeWithOverrides(result.landmarks, overrides);\n   263→  const updatedFrankfort = recalculateFrankfortPlane(mergedLandmarks);\n   264→  const adjustedIds = overrides.map(o => o.id);\n   265→\n   266→  return {\n   267→    ...result,\n   268→    landmarks: mergedLandmarks,\n   269→    frankfortPlane: updatedFrankfort || result.frankfortPlane,\n   270→    manuallyAdjusted: adjustedIds,\n   271→  };\n   272→}\n   273→\n   274→/**\n   275→ * Check if a landmark is estimated (vs directly detected)\n   276→ */\n   277→export function isEstimatedLandmark(landmarkId: string): boolean {\n   278→  return ESTIMATED_LANDMARK_IDS.includes(landmarkId as EstimatedLandmarkId);\n   279→}\n   280→\n\n</system-reminder>\n"}]},"uuid":"1e3c74df-8d36-4894-9f9d-53b126dff8b0","timestamp":"2025-12-30T14:57:17.121Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/imorgado/LOOKSMAXX/looksmaxx-app/src/lib/serverSideDetection.ts","content":"/**\n * Server-Side Detection Service for Side Profiles\n *\n * Calls the Railway-hosted InsightFace API for accurate side profile detection.\n * Returns 106 raw landmarks mapped to our 28 cephalometric landmarks.\n *\n * Supports manual overrides for estimated landmarks (porion, tragus, intertragicNotch)\n * to achieve FaceIQ-level Frankfort plane accuracy.\n */\n\nimport { SideLandmarkResponse } from '@/app/api/side-landmarks/route';\n\n/**\n * Landmarks that are geometrically estimated and benefit from manual adjustment\n */\nexport const ESTIMATED_LANDMARK_IDS = ['porion', 'tragus', 'intertragicNotch'] as const;\nexport type EstimatedLandmarkId = typeof ESTIMATED_LANDMARK_IDS[number];\n\nexport interface ServerDetectionResult {\n  landmarks: Array<{ id: string; x: number; y: number }>;\n  rawLandmarks?: Array<{ x: number; y: number }>;  // Raw 106 landmarks for FaceIQ-style normalization\n  confidence: number;\n  faceBox: { x: number; y: number; width: number; height: number };\n  direction?: 'left' | 'right';\n  rotationAngle?: number;\n  frankfortPlane?: {\n    angle: number;\n    orbitale: { x: number; y: number };\n    porion: { x: number; y: number };\n  };\n  /** Tracks which landmarks were manually adjusted */\n  manuallyAdjusted?: string[];\n}\n\n/**\n * Manual landmark override for estimated ear landmarks\n */\nexport interface LandmarkOverride {\n  id: string;\n  x: number;\n  y: number;\n}\n\n/**\n * Convert image URL to base64\n */\nasync function imageUrlToBase64(imageUrl: string): Promise<string> {\n  // If it's already a data URL, extract the base64 part\n  if (imageUrl.startsWith('data:')) {\n    return imageUrl;\n  }\n\n  // If it's a blob URL or regular URL, fetch and convert\n  const response = await fetch(imageUrl);\n  const blob = await response.blob();\n\n  return new Promise((resolve, reject) => {\n    const reader = new FileReader();\n    reader.onloadend = () => {\n      if (typeof reader.result === 'string') {\n        resolve(reader.result);\n      } else {\n        reject(new Error('Failed to convert to base64'));\n      }\n    };\n    reader.onerror = reject;\n    reader.readAsDataURL(blob);\n  });\n}\n\n\n/**\n * Get image dimensions\n */\nfunction getImageDimensions(imageUrl: string): Promise<{ width: number; height: number }> {\n  return new Promise((resolve, reject) => {\n    const img = new Image();\n    img.onload = () => resolve({ width: img.naturalWidth, height: img.naturalHeight });\n    img.onerror = reject;\n    img.src = imageUrl;\n  });\n}\n\n/**\n * Calculate Frankfort Horizontal Plane from orbitale and porion landmarks\n */\nfunction calculateFrankfortPlane(\n  orbitale: { x: number; y: number },\n  porion: { x: number; y: number }\n): { angle: number; orbitale: { x: number; y: number }; porion: { x: number; y: number } } {\n  // Calculate angle from horizontal (in degrees)\n  const dx = porion.x - orbitale.x;\n  const dy = porion.y - orbitale.y;\n  const angle = Math.atan2(dy, dx) * (180 / Math.PI);\n\n  return {\n    angle,\n    orbitale,\n    porion,\n  };\n}\n\n/**\n * Detect side profile landmarks using server-side InsightFace API\n */\nexport async function detectSideProfileServer(\n  imageUrl: string\n): Promise<ServerDetectionResult | null> {\n  try {\n    console.log('[ServerDetection] Starting server-side detection...');\n\n    // Convert image to base64\n    const base64Image = await imageUrlToBase64(imageUrl);\n\n    // Call our API proxy\n    const response = await fetch('/api/side-landmarks', {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json',\n      },\n      body: JSON.stringify({ image: base64Image }),\n    });\n\n    if (!response.ok) {\n      console.error('[ServerDetection] API error:', response.status);\n      return null;\n    }\n\n    const data: SideLandmarkResponse = await response.json();\n\n    if (!data.success || !data.data?.namedLandmarks) {\n      console.log('[ServerDetection] Detection failed:', data.error || 'No landmarks found');\n      return null;\n    }\n\n    const resultData = data.data;\n    console.log('[ServerDetection] Detection successful, count:', resultData.landmarkCount);\n\n    // Get image dimensions for normalization\n    const { width, height } = await getImageDimensions(imageUrl);\n    console.log('[ServerDetection] Normalizing landmarks with dimensions:', width, 'x', height);\n\n    // Convert namedLandmarks object to array format matching our system AND NORMALIZE (0-1)\n    const landmarks = Object.entries(resultData.namedLandmarks).map(([id, point]) => ({\n      id,\n      x: Math.max(0, Math.min(1, point.x / width)),\n      y: Math.max(0, Math.min(1, point.y / height)),\n    }));\n\n    // Convert raw landmarks array for FaceIQ-style normalization (indices 10, 26, 75)\n    const rawLandmarks = resultData.landmarks?.map(pt => ({\n      x: Math.max(0, Math.min(1, pt.x / width)),\n      y: Math.max(0, Math.min(1, pt.y / height)),\n    })) || [];\n\n    // Use Frankfort Plane from server if available (future proof), otherwise calculate locally\n    let frankfortPlane: ServerDetectionResult['frankfortPlane'];\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    const serverFrankfort = (resultData as any).frankfort_plane;\n\n    if (serverFrankfort) {\n      frankfortPlane = serverFrankfort;\n      console.log('[ServerDetection] Frankfort Plane angle (from server):', serverFrankfort.angle.toFixed(2), 'degrees');\n    } else {\n      // Find normalized orbitale and porion from our processed list\n      const normOrbitale = landmarks.find(l => l.id === 'orbitale');\n      const normPorion = landmarks.find(l => l.id === 'porion');\n\n      if (normOrbitale && normPorion) {\n        frankfortPlane = calculateFrankfortPlane(normOrbitale, normPorion);\n        console.log('[ServerDetection] Frankfort Plane angle (calculated):', frankfortPlane.angle.toFixed(2), 'degrees');\n      }\n    }\n\n    return {\n      landmarks,\n      rawLandmarks,  // For FaceIQ-style normalization using indices 10, 26, 75\n      confidence: 0.95, // InsightFace is generally high confidence\n      faceBox: resultData.crop || { x: 0, y: 0, width: 1, height: 1 },\n      direction: resultData.direction,\n      rotationAngle: resultData.rotationAngle,\n      frankfortPlane,\n    };\n  } catch (error) {\n    console.error('[ServerDetection] Error:', error);\n    return null;\n  }\n}\n\n/**\n * Merge manual landmark overrides with detected landmarks\n *\n * Used for applying user adjustments to estimated ear landmarks\n * (porion, tragus, intertragicNotch) for FaceIQ-level accuracy.\n *\n * @param detectedLandmarks - Landmarks from server detection\n * @param overrides - Manual adjustments from user\n * @returns Merged landmarks with manual overrides applied\n */\nexport function mergeWithOverrides(\n  detectedLandmarks: Array<{ id: string; x: number; y: number }>,\n  overrides: LandmarkOverride[]\n): Array<{ id: string; x: number; y: number }> {\n  if (!overrides.length) return detectedLandmarks;\n\n  const overrideMap = new Map(overrides.map(o => [o.id, o]));\n\n  return detectedLandmarks.map(landmark => {\n    const override = overrideMap.get(landmark.id);\n    if (override) {\n      console.log(`[ServerDetection] Applied override for ${landmark.id}:`, {\n        original: { x: landmark.x.toFixed(4), y: landmark.y.toFixed(4) },\n        adjusted: { x: override.x.toFixed(4), y: override.y.toFixed(4) },\n      });\n      return { ...landmark, x: override.x, y: override.y };\n    }\n    return landmark;\n  });\n}\n\n/**\n * Recalculate Frankfort Horizontal Plane after manual adjustments\n *\n * Call this after applying overrides to porion or orbitale to update\n * the Frankfort plane angle used in side profile analysis.\n *\n * @param landmarks - Merged landmarks with overrides applied\n * @returns Updated Frankfort plane calculation or null if landmarks not found\n */\nexport function recalculateFrankfortPlane(\n  landmarks: Array<{ id: string; x: number; y: number }>\n): ServerDetectionResult['frankfortPlane'] | null {\n  const orbitale = landmarks.find(l => l.id === 'orbitale');\n  const porion = landmarks.find(l => l.id === 'porion');\n\n  if (!orbitale || !porion) {\n    console.warn('[ServerDetection] Cannot calculate Frankfort plane: missing orbitale or porion');\n    return null;\n  }\n\n  const plane = calculateFrankfortPlane(orbitale, porion);\n  console.log('[ServerDetection] Recalculated Frankfort Plane angle:', plane.angle.toFixed(2), 'degrees');\n\n  return plane;\n}\n\n/**\n * Apply manual overrides to a detection result and recalculate Frankfort plane\n *\n * Convenience function that combines merging and recalculation.\n *\n * @param result - Original detection result\n * @param overrides - Manual landmark adjustments\n * @returns Updated result with overrides applied\n */\nexport function applyManualOverrides(\n  result: ServerDetectionResult,\n  overrides: LandmarkOverride[]\n): ServerDetectionResult {\n  if (!overrides.length) return result;\n\n  const mergedLandmarks = mergeWithOverrides(result.landmarks, overrides);\n  const updatedFrankfort = recalculateFrankfortPlane(mergedLandmarks);\n  const adjustedIds = overrides.map(o => o.id);\n\n  return {\n    ...result,\n    landmarks: mergedLandmarks,\n    frankfortPlane: updatedFrankfort || result.frankfortPlane,\n    manuallyAdjusted: adjustedIds,\n  };\n}\n\n/**\n * Check if a landmark is estimated (vs directly detected)\n */\nexport function isEstimatedLandmark(landmarkId: string): boolean {\n  return ESTIMATED_LANDMARK_IDS.includes(landmarkId as EstimatedLandmarkId);\n}\n","numLines":280,"startLine":1,"totalLines":280}}}
{"parentUuid":"1e3c74df-8d36-4894-9f9d-53b126dff8b0","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"988cde7a-9586-4ca8-910d-50a828b2fa2d","version":"2.0.76","gitBranch":"main","agentId":"aee8db2","slug":"fizzy-singing-bird","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01UbtiNg4U8AEwaE2phbpv4X","type":"tool_result","content":"     1→/**\n     2→ * Side Profile Detection using Image Processing\n     3→ *\n     4→ * Since MediaPipe doesn't work well with side profiles, this module uses\n     5→ * edge detection and contour analysis to find the profile silhouette\n     6→ * and estimate landmark positions.\n     7→ *\n     8→ * Performance optimizations:\n     9→ * - Image downsampling before edge detection (reduces computation 4-9x)\n    10→ */\n    11→\n    12→import { SIDE_PROFILE_LANDMARKS } from './landmarks';\n    13→\n    14→// Maximum dimension for edge detection processing\n    15→const MAX_PROCESSING_SIZE = 480;\n    16→\n    17→interface Point {\n    18→  x: number;\n    19→  y: number;\n    20→}\n    21→\n    22→interface ProfileContour {\n    23→  points: Point[];\n    24→  boundingBox: { x: number; y: number; width: number; height: number };\n    25→  orientation: 'left' | 'right'; // Which direction the face is pointing\n    26→}\n    27→\n    28→interface SideProfileResult {\n    29→  landmarks: Array<{ id: string; x: number; y: number }>;\n    30→  confidence: number;\n    31→  contour: Point[];\n    32→  orientation: 'left' | 'right';\n    33→}\n    34→\n    35→/**\n    36→ * Detect side profile landmarks from an image\n    37→ */\n    38→export async function detectSideProfile(\n    39→  imageUrl: string\n    40→): Promise<SideProfileResult | null> {\n    41→  try {\n    42→    const img = await loadImage(imageUrl);\n    43→    const canvas = document.createElement('canvas');\n    44→    const ctx = canvas.getContext('2d');\n    45→    if (!ctx) return null;\n    46→\n    47→    // Downsample large images for faster edge detection\n    48→    const { width, height } = downsampleDimensions(img.width, img.height, MAX_PROCESSING_SIZE);\n    49→    canvas.width = width;\n    50→    canvas.height = height;\n    51→    ctx.imageSmoothingEnabled = true;\n    52→    ctx.imageSmoothingQuality = 'high';\n    53→    ctx.drawImage(img, 0, 0, width, height);\n    54→\n    55→    // Get image data (landmarks use normalized 0-1 coordinates, so no rescaling needed)\n    56→    const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);\n    57→\n    58→    // Step 1: Convert to grayscale\n    59→    const grayscale = toGrayscale(imageData);\n    60→\n    61→    // Step 2: Apply Gaussian blur to reduce noise\n    62→    const blurred = gaussianBlur(grayscale, canvas.width, canvas.height);\n    63→\n    64→    // Step 3: Edge detection (Sobel operator)\n    65→    const edges = sobelEdgeDetection(blurred, canvas.width, canvas.height);\n    66→\n    67→    // Step 4: Find the profile contour\n    68→    const contour = extractProfileContour(edges, canvas.width, canvas.height);\n    69→\n    70→    if (!contour || contour.points.length < 10) {\n    71→      console.log('[SideProfile] Could not extract sufficient contour points');\n    72→      return null;\n    73→    }\n    74→\n    75→    // Step 5: Analyze contour to find key anchor points\n    76→    const anchors = findAnchorPoints(contour);\n    77→\n    78→    // Step 6: Map anchors to our 28 landmarks\n    79→    const landmarks = mapToLandmarks(anchors, contour);\n    80→\n    81→    return {\n    82→      landmarks,\n    83→      confidence: 0.7, // Lower confidence than MediaPipe frontal\n    84→      contour: contour.points,\n    85→      orientation: contour.orientation,\n    86→    };\n    87→  } catch (error) {\n    88→    console.error('[SideProfile] Detection error:', error);\n    89→    return null;\n    90→  }\n    91→}\n    92→\n    93→/**\n    94→ * Load an image from URL\n    95→ */\n    96→function loadImage(url: string): Promise<HTMLImageElement> {\n    97→  return new Promise((resolve, reject) => {\n    98→    const img = new Image();\n    99→    img.crossOrigin = 'anonymous';\n   100→    img.onload = () => resolve(img);\n   101→    img.onerror = reject;\n   102→    img.src = url;\n   103→  });\n   104→}\n   105→\n   106→/**\n   107→ * Calculate downsampled dimensions while maintaining aspect ratio\n   108→ */\n   109→function downsampleDimensions(\n   110→  width: number,\n   111→  height: number,\n   112→  maxSize: number\n   113→): { width: number; height: number } {\n   114→  const maxDim = Math.max(width, height);\n   115→  if (maxDim <= maxSize) {\n   116→    return { width, height };\n   117→  }\n   118→\n   119→  const scale = maxSize / maxDim;\n   120→  return {\n   121→    width: Math.round(width * scale),\n   122→    height: Math.round(height * scale),\n   123→  };\n   124→}\n   125→\n   126→/**\n   127→ * Convert image data to grayscale array\n   128→ */\n   129→function toGrayscale(imageData: ImageData): Uint8Array {\n   130→  const data = imageData.data;\n   131→  const gray = new Uint8Array(data.length / 4);\n   132→\n   133→  for (let i = 0; i < gray.length; i++) {\n   134→    const idx = i * 4;\n   135→    // Luminosity method for grayscale\n   136→    gray[i] = Math.round(0.299 * data[idx] + 0.587 * data[idx + 1] + 0.114 * data[idx + 2]);\n   137→  }\n   138→\n   139→  return gray;\n   140→}\n   141→\n   142→/**\n   143→ * Apply 3x3 Gaussian blur\n   144→ */\n   145→function gaussianBlur(gray: Uint8Array, width: number, height: number): Uint8Array {\n   146→  const kernel = [\n   147→    1/16, 2/16, 1/16,\n   148→    2/16, 4/16, 2/16,\n   149→    1/16, 2/16, 1/16\n   150→  ];\n   151→\n   152→  const result = new Uint8Array(gray.length);\n   153→\n   154→  for (let y = 1; y < height - 1; y++) {\n   155→    for (let x = 1; x < width - 1; x++) {\n   156→      let sum = 0;\n   157→      let k = 0;\n   158→      for (let ky = -1; ky <= 1; ky++) {\n   159→        for (let kx = -1; kx <= 1; kx++) {\n   160→          sum += gray[(y + ky) * width + (x + kx)] * kernel[k++];\n   161→        }\n   162→      }\n   163→      result[y * width + x] = sum;\n   164→    }\n   165→  }\n   166→\n   167→  return result;\n   168→}\n   169→\n   170→/**\n   171→ * Sobel edge detection\n   172→ */\n   173→function sobelEdgeDetection(gray: Uint8Array, width: number, height: number): Uint8Array {\n   174→  const sobelX = [-1, 0, 1, -2, 0, 2, -1, 0, 1];\n   175→  const sobelY = [-1, -2, -1, 0, 0, 0, 1, 2, 1];\n   176→\n   177→  const edges = new Uint8Array(gray.length);\n   178→\n   179→  for (let y = 1; y < height - 1; y++) {\n   180→    for (let x = 1; x < width - 1; x++) {\n   181→      let gx = 0, gy = 0;\n   182→      let k = 0;\n   183→\n   184→      for (let ky = -1; ky <= 1; ky++) {\n   185→        for (let kx = -1; kx <= 1; kx++) {\n   186→          const pixel = gray[(y + ky) * width + (x + kx)];\n   187→          gx += pixel * sobelX[k];\n   188→          gy += pixel * sobelY[k];\n   189→          k++;\n   190→        }\n   191→      }\n   192→\n   193→      // Magnitude\n   194→      edges[y * width + x] = Math.min(255, Math.sqrt(gx * gx + gy * gy));\n   195→    }\n   196→  }\n   197→\n   198→  return edges;\n   199→}\n   200→\n   201→/**\n   202→ * Extract the profile contour from edge image\n   203→ * Looks for the strongest vertical edge on each side\n   204→ */\n   205→function extractProfileContour(\n   206→  edges: Uint8Array,\n   207→  width: number,\n   208→  height: number\n   209→): ProfileContour | null {\n   210→  // Determine if face is on left or right side of image\n   211→  let leftEdgeSum = 0;\n   212→  let rightEdgeSum = 0;\n   213→\n   214→  const midX = width / 2;\n   215→\n   216→  for (let y = 0; y < height; y++) {\n   217→    for (let x = 0; x < width; x++) {\n   218→      const val = edges[y * width + x];\n   219→      if (x < midX) {\n   220→        leftEdgeSum += val;\n   221→      } else {\n   222→        rightEdgeSum += val;\n   223→      }\n   224→    }\n   225→  }\n   226→\n   227→  // Face is likely on the side with more edge activity\n   228→  const faceOnLeft = leftEdgeSum > rightEdgeSum;\n   229→  const orientation: 'left' | 'right' = faceOnLeft ? 'left' : 'right'; // profile edge direction\n   230→\n   231→  // Find the profile edge - scan from the face side inward\n   232→  const contourPoints: Point[] = [];\n   233→  const threshold = 30; // Edge threshold\n   234→\n   235→  // Scan each row to find the profile edge\n   236→  for (let y = Math.floor(height * 0.1); y < Math.floor(height * 0.95); y++) {\n   237→    let edgeX = -1;\n   238→    let maxEdge = threshold;\n   239→\n   240→    if (faceOnLeft) {\n   241→      // Scan from left, find rightmost strong edge in left half\n   242→      for (let x = 0; x < midX; x++) {\n   243→        if (edges[y * width + x] > maxEdge) {\n   244→          maxEdge = edges[y * width + x];\n   245→          edgeX = x;\n   246→        }\n   247→      }\n   248→    } else {\n   249→      // Scan from right, find leftmost strong edge in right half\n   250→      for (let x = width - 1; x >= midX; x--) {\n   251→        if (edges[y * width + x] > maxEdge) {\n   252→          maxEdge = edges[y * width + x];\n   253→          edgeX = x;\n   254→        }\n   255→      }\n   256→    }\n   257→\n   258→    if (edgeX !== -1) {\n   259→      contourPoints.push({ x: edgeX / width, y: y / height });\n   260→    }\n   261→  }\n   262→\n   263→  if (contourPoints.length < 10) return null;\n   264→\n   265→  // Smooth the contour using moving average\n   266→  const smoothedPoints = smoothContour(contourPoints, 5);\n   267→\n   268→  // Calculate bounding box\n   269→  let minX = 1, minY = 1, maxX = 0, maxY = 0;\n   270→  smoothedPoints.forEach(p => {\n   271→    minX = Math.min(minX, p.x);\n   272→    minY = Math.min(minY, p.y);\n   273→    maxX = Math.max(maxX, p.x);\n   274→    maxY = Math.max(maxY, p.y);\n   275→  });\n   276→\n   277→  return {\n   278→    points: smoothedPoints,\n   279→    boundingBox: { x: minX, y: minY, width: maxX - minX, height: maxY - minY },\n   280→    orientation,\n   281→  };\n   282→}\n   283→\n   284→/**\n   285→ * Smooth contour points using moving average\n   286→ */\n   287→function smoothContour(points: Point[], windowSize: number): Point[] {\n   288→  const smoothed: Point[] = [];\n   289→  const half = Math.floor(windowSize / 2);\n   290→\n   291→  for (let i = 0; i < points.length; i++) {\n   292→    let sumX = 0, sumY = 0, count = 0;\n   293→\n   294→    for (let j = -half; j <= half; j++) {\n   295→      const idx = i + j;\n   296→      if (idx >= 0 && idx < points.length) {\n   297→        sumX += points[idx].x;\n   298→        sumY += points[idx].y;\n   299→        count++;\n   300→      }\n   301→    }\n   302→\n   303→    smoothed.push({ x: sumX / count, y: sumY / count });\n   304→  }\n   305→\n   306→  return smoothed;\n   307→}\n   308→\n   309→interface AnchorPoints {\n   310→  vertex: Point;      // Top of head\n   311→  forehead: Point;    // Forehead profile\n   312→  glabella: Point;    // Between brows\n   313→  nasion: Point;      // Nasal root\n   314→  noseTip: Point;     // Pronasale\n   315→  subnasale: Point;   // Base of nose\n   316→  upperLip: Point;    // Labrale superius\n   317→  lowerLip: Point;    // Labrale inferius\n   318→  chin: Point;        // Pogonion\n   319→  menton: Point;      // Bottom of chin\n   320→  neckPoint: Point;   // Neck\n   321→  jawAngle: Point;    // Gonion\n   322→}\n   323→\n   324→/**\n   325→ * Find anchor points along the profile contour\n   326→ */\n   327→function findAnchorPoints(\n   328→  contour: ProfileContour\n   329→): AnchorPoints {\n   330→  const points = contour.points;\n   331→\n   332→  // Helper to find point at approximate Y position\n   333→  const findPointAtY = (targetY: number): Point => {\n   334→    let closest = points[0];\n   335→    let minDist = Math.abs(points[0].y - targetY);\n   336→\n   337→    for (const p of points) {\n   338→      const dist = Math.abs(p.y - targetY);\n   339→      if (dist < minDist) {\n   340→        minDist = dist;\n   341→        closest = p;\n   342→      }\n   343→    }\n   344→    return closest;\n   345→  };\n   346→\n   347→  // Helper to find the most protruding point in a Y range\n   348→  const findProtrudingPoint = (yStart: number, yEnd: number, direction: 'left' | 'right'): Point => {\n   349→    let best = points[0];\n   350→\n   351→    for (const p of points) {\n   352→      if (p.y >= yStart && p.y <= yEnd) {\n   353→        if (direction === 'left' && p.x < best.x) best = p;\n   354→        if (direction === 'right' && p.x > best.x) best = p;\n   355→      }\n   356→    }\n   357→    return best;\n   358→  };\n   359→\n   360→  // Find key inflection points based on profile geometry\n   361→  const isLeftFacing = contour.orientation === 'left';\n   362→  const protrusion = isLeftFacing ? 'left' : 'right';\n   363→\n   364→  // Divide face into regions based on typical proportions\n   365→  const vertex = findPointAtY(0.05);\n   366→  const forehead = findPointAtY(0.15);\n   367→  const glabella = findPointAtY(0.28);\n   368→  const nasion = findPointAtY(0.32);\n   369→\n   370→  // Nose tip is usually the most protruding point between y=0.35 and y=0.55\n   371→  const noseTip = findProtrudingPoint(0.35, 0.55, protrusion);\n   372→\n   373→  const subnasale = findPointAtY(0.58);\n   374→  const upperLip = findPointAtY(0.62);\n   375→  const lowerLip = findPointAtY(0.68);\n   376→\n   377→  // Chin (pogonion) is often protruding\n   378→  const chin = findProtrudingPoint(0.75, 0.85, protrusion);\n   379→\n   380→  const menton = findPointAtY(0.88);\n   381→  const neckPoint = findPointAtY(0.95);\n   382→\n   383→  // Jaw angle - find where contour curves from vertical to horizontal\n   384→  // This is typically around y=0.7-0.8, and set back from the chin\n   385→  const jawAngle = findPointAtY(0.75);\n   386→\n   387→  return {\n   388→    vertex,\n   389→    forehead,\n   390→    glabella,\n   391→    nasion,\n   392→    noseTip,\n   393→    subnasale,\n   394→    upperLip,\n   395→    lowerLip,\n   396→    chin,\n   397→    menton,\n   398→    neckPoint,\n   399→    jawAngle,\n   400→  };\n   401→}\n   402→\n   403→/**\n   404→ * Map anchor points to our 28 side profile landmarks\n   405→ */\n   406→function mapToLandmarks(\n   407→  anchors: AnchorPoints,\n   408→  contour: ProfileContour\n   409→): Array<{ id: string; x: number; y: number }> {\n   410→  const isLeft = contour.orientation === 'left';\n   411→\n   412→  // Helper to interpolate between two points\n   413→  const lerp = (p1: Point, p2: Point, t: number): Point => ({\n   414→    x: p1.x + (p2.x - p1.x) * t,\n   415→    y: p1.y + (p2.y - p1.y) * t,\n   416→  });\n   417→\n   418→  // Helper to offset a point horizontally (for ear/back of head estimation)\n   419→  const offsetX = (p: Point, offset: number): Point => ({\n   420→    x: p.x + (isLeft ? offset : -offset),\n   421→    y: p.y,\n   422→  });\n   423→\n   424→  // Map each of our 28 landmarks\n   425→  // Standard cephalometric order: vertex, occiput, pronasale, neckPoint, porion, orbitale,\n   426→  // tragus, intertragicNotch, cornealApex, cheekbone, trichion, glabella, nasion,\n   427→  // rhinion, supratip, infratip, columella, subnasale, subalare, labraleSuperius,\n   428→  // cheilion, labraleInferius, sublabiale, pogonion, menton, cervicalPoint, gonionTop, gonionBottom\n   429→\n   430→  const landmarkPositions: Record<string, Point> = {\n   431→    // 1. vertex - top of head\n   432→    vertex: anchors.vertex,\n   433→\n   434→    // 2. occiput - back of head (estimate based on vertex, offset back)\n   435→    occiput: offsetX(anchors.vertex, 0.15),\n   436→\n   437→    // 3. pronasale - nose tip\n   438→    pronasale: anchors.noseTip,\n   439→\n   440→    // 4. neckPoint - lower neck\n   441→    neckPoint: anchors.neckPoint,\n   442→\n   443→    // 5. porion - ear canal (estimate based on jaw angle, offset back)\n   444→    porion: offsetX({ x: anchors.jawAngle.x, y: anchors.nasion.y }, 0.08),\n   445→\n   446→    // 6. orbitale - lowest orbital rim (between glabella and nasion level)\n   447→    orbitale: { x: lerp(anchors.glabella, anchors.nasion, 0.5).x, y: anchors.nasion.y - 0.02 },\n   448→\n   449→    // 7. tragus - ear cartilage\n   450→    tragus: offsetX({ x: anchors.jawAngle.x, y: lerp(anchors.nasion, anchors.jawAngle, 0.3).y }, 0.06),\n   451→\n   452→    // 8. intertragicNotch - notch in ear\n   453→    intertragicNotch: offsetX({ x: anchors.jawAngle.x, y: lerp(anchors.nasion, anchors.jawAngle, 0.5).y }, 0.07),\n   454→\n   455→    // 9. cornealApex - forward point of cornea\n   456→    cornealApex: { x: anchors.glabella.x + (isLeft ? -0.02 : 0.02), y: anchors.glabella.y + 0.02 },\n   457→\n   458→    // 10. cheekbone - zygomatic prominence\n   459→    cheekbone: lerp(anchors.nasion, anchors.jawAngle, 0.4),\n   460→\n   461→    // 11. trichion - hairline\n   462→    trichion: anchors.forehead,\n   463→\n   464→    // 12. glabella - between brows\n   465→    glabella: anchors.glabella,\n   466→\n   467→    // 13. nasion - nasal root\n   468→    nasion: anchors.nasion,\n   469→\n   470→    // 14. rhinion - mid-dorsum of nose\n   471→    rhinion: lerp(anchors.nasion, anchors.noseTip, 0.4),\n   472→\n   473→    // 15. supratip - above nose tip\n   474→    supratip: lerp(anchors.nasion, anchors.noseTip, 0.75),\n   475→\n   476→    // 16. infratip - below nose tip\n   477→    infratip: lerp(anchors.noseTip, anchors.subnasale, 0.3),\n   478→\n   479→    // 17. columella - nasal septum\n   480→    columella: lerp(anchors.noseTip, anchors.subnasale, 0.5),\n   481→\n   482→    // 18. subnasale - base of nose\n   483→    subnasale: anchors.subnasale,\n   484→\n   485→    // 19. subalare - nostril wing\n   486→    subalare: { x: anchors.subnasale.x + (isLeft ? -0.02 : 0.02), y: anchors.subnasale.y - 0.01 },\n   487→\n   488→    // 20. labraleSuperius - upper lip\n   489→    labraleSuperius: anchors.upperLip,\n   490→\n   491→    // 21. cheilion - mouth corner\n   492→    cheilion: { x: lerp(anchors.upperLip, anchors.jawAngle, 0.3).x, y: lerp(anchors.upperLip, anchors.lowerLip, 0.5).y },\n   493→\n   494→    // 22. labraleInferius - lower lip\n   495→    labraleInferius: anchors.lowerLip,\n   496→\n   497→    // 23. sublabiale - below lower lip\n   498→    sublabiale: lerp(anchors.lowerLip, anchors.chin, 0.3),\n   499→\n   500→    // 24. pogonion - chin prominence\n   501→    pogonion: anchors.chin,\n   502→\n   503→    // 25. menton - bottom of chin\n   504→    menton: anchors.menton,\n   505→\n   506→    // 26. cervicalPoint - high neck point\n   507→    cervicalPoint: lerp(anchors.menton, anchors.neckPoint, 0.5),\n   508→\n   509→    // 27. gonionTop - upper jaw angle\n   510→    gonionTop: { x: anchors.jawAngle.x, y: anchors.jawAngle.y - 0.03 },\n   511→\n   512→    // 28. gonionBottom - lower jaw angle\n   513→    gonionBottom: anchors.jawAngle,\n   514→  };\n   515→\n   516→  // Convert to array matching SIDE_PROFILE_LANDMARKS order\n   517→  return SIDE_PROFILE_LANDMARKS.map(lm => {\n   518→    const pos = landmarkPositions[lm.id] || { x: 0.5, y: 0.5 };\n   519→    return {\n   520→      id: lm.id,\n   521→      x: Math.max(0, Math.min(1, pos.x)),\n   522→      y: Math.max(0, Math.min(1, pos.y)),\n   523→    };\n   524→  });\n   525→}\n   526→\n   527→/**\n   528→ * Debug: Draw the detected contour on a canvas\n   529→ */\n   530→export function debugDrawContour(\n   531→  canvas: HTMLCanvasElement,\n   532→  contour: Point[],\n   533→  landmarks: Array<{ id: string; x: number; y: number }>\n   534→): void {\n   535→  const ctx = canvas.getContext('2d');\n   536→  if (!ctx) return;\n   537→\n   538→  const width = canvas.width;\n   539→  const height = canvas.height;\n   540→\n   541→  // Draw contour\n   542→  ctx.strokeStyle = '#00ff00';\n   543→  ctx.lineWidth = 2;\n   544→  ctx.beginPath();\n   545→  contour.forEach((p, i) => {\n   546→    const x = p.x * width;\n   547→    const y = p.y * height;\n   548→    if (i === 0) ctx.moveTo(x, y);\n   549→    else ctx.lineTo(x, y);\n   550→  });\n   551→  ctx.stroke();\n   552→\n   553→  // Draw landmarks\n   554→  landmarks.forEach(lm => {\n   555→    ctx.fillStyle = '#ff0000';\n   556→    ctx.beginPath();\n   557→    ctx.arc(lm.x * width, lm.y * height, 4, 0, Math.PI * 2);\n   558→    ctx.fill();\n   559→\n   560→    ctx.fillStyle = '#ffffff';\n   561→    ctx.font = '10px sans-serif';\n   562→    ctx.fillText(lm.id, lm.x * width + 6, lm.y * height);\n   563→  });\n   564→}\n   565→\n\n</system-reminder>\n"}]},"uuid":"955962b3-7002-4f04-88a1-3326b3c4bfca","timestamp":"2025-12-30T14:57:17.121Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/imorgado/LOOKSMAXX/looksmaxx-app/src/lib/sideProfileDetection.ts","content":"/**\n * Side Profile Detection using Image Processing\n *\n * Since MediaPipe doesn't work well with side profiles, this module uses\n * edge detection and contour analysis to find the profile silhouette\n * and estimate landmark positions.\n *\n * Performance optimizations:\n * - Image downsampling before edge detection (reduces computation 4-9x)\n */\n\nimport { SIDE_PROFILE_LANDMARKS } from './landmarks';\n\n// Maximum dimension for edge detection processing\nconst MAX_PROCESSING_SIZE = 480;\n\ninterface Point {\n  x: number;\n  y: number;\n}\n\ninterface ProfileContour {\n  points: Point[];\n  boundingBox: { x: number; y: number; width: number; height: number };\n  orientation: 'left' | 'right'; // Which direction the face is pointing\n}\n\ninterface SideProfileResult {\n  landmarks: Array<{ id: string; x: number; y: number }>;\n  confidence: number;\n  contour: Point[];\n  orientation: 'left' | 'right';\n}\n\n/**\n * Detect side profile landmarks from an image\n */\nexport async function detectSideProfile(\n  imageUrl: string\n): Promise<SideProfileResult | null> {\n  try {\n    const img = await loadImage(imageUrl);\n    const canvas = document.createElement('canvas');\n    const ctx = canvas.getContext('2d');\n    if (!ctx) return null;\n\n    // Downsample large images for faster edge detection\n    const { width, height } = downsampleDimensions(img.width, img.height, MAX_PROCESSING_SIZE);\n    canvas.width = width;\n    canvas.height = height;\n    ctx.imageSmoothingEnabled = true;\n    ctx.imageSmoothingQuality = 'high';\n    ctx.drawImage(img, 0, 0, width, height);\n\n    // Get image data (landmarks use normalized 0-1 coordinates, so no rescaling needed)\n    const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);\n\n    // Step 1: Convert to grayscale\n    const grayscale = toGrayscale(imageData);\n\n    // Step 2: Apply Gaussian blur to reduce noise\n    const blurred = gaussianBlur(grayscale, canvas.width, canvas.height);\n\n    // Step 3: Edge detection (Sobel operator)\n    const edges = sobelEdgeDetection(blurred, canvas.width, canvas.height);\n\n    // Step 4: Find the profile contour\n    const contour = extractProfileContour(edges, canvas.width, canvas.height);\n\n    if (!contour || contour.points.length < 10) {\n      console.log('[SideProfile] Could not extract sufficient contour points');\n      return null;\n    }\n\n    // Step 5: Analyze contour to find key anchor points\n    const anchors = findAnchorPoints(contour);\n\n    // Step 6: Map anchors to our 28 landmarks\n    const landmarks = mapToLandmarks(anchors, contour);\n\n    return {\n      landmarks,\n      confidence: 0.7, // Lower confidence than MediaPipe frontal\n      contour: contour.points,\n      orientation: contour.orientation,\n    };\n  } catch (error) {\n    console.error('[SideProfile] Detection error:', error);\n    return null;\n  }\n}\n\n/**\n * Load an image from URL\n */\nfunction loadImage(url: string): Promise<HTMLImageElement> {\n  return new Promise((resolve, reject) => {\n    const img = new Image();\n    img.crossOrigin = 'anonymous';\n    img.onload = () => resolve(img);\n    img.onerror = reject;\n    img.src = url;\n  });\n}\n\n/**\n * Calculate downsampled dimensions while maintaining aspect ratio\n */\nfunction downsampleDimensions(\n  width: number,\n  height: number,\n  maxSize: number\n): { width: number; height: number } {\n  const maxDim = Math.max(width, height);\n  if (maxDim <= maxSize) {\n    return { width, height };\n  }\n\n  const scale = maxSize / maxDim;\n  return {\n    width: Math.round(width * scale),\n    height: Math.round(height * scale),\n  };\n}\n\n/**\n * Convert image data to grayscale array\n */\nfunction toGrayscale(imageData: ImageData): Uint8Array {\n  const data = imageData.data;\n  const gray = new Uint8Array(data.length / 4);\n\n  for (let i = 0; i < gray.length; i++) {\n    const idx = i * 4;\n    // Luminosity method for grayscale\n    gray[i] = Math.round(0.299 * data[idx] + 0.587 * data[idx + 1] + 0.114 * data[idx + 2]);\n  }\n\n  return gray;\n}\n\n/**\n * Apply 3x3 Gaussian blur\n */\nfunction gaussianBlur(gray: Uint8Array, width: number, height: number): Uint8Array {\n  const kernel = [\n    1/16, 2/16, 1/16,\n    2/16, 4/16, 2/16,\n    1/16, 2/16, 1/16\n  ];\n\n  const result = new Uint8Array(gray.length);\n\n  for (let y = 1; y < height - 1; y++) {\n    for (let x = 1; x < width - 1; x++) {\n      let sum = 0;\n      let k = 0;\n      for (let ky = -1; ky <= 1; ky++) {\n        for (let kx = -1; kx <= 1; kx++) {\n          sum += gray[(y + ky) * width + (x + kx)] * kernel[k++];\n        }\n      }\n      result[y * width + x] = sum;\n    }\n  }\n\n  return result;\n}\n\n/**\n * Sobel edge detection\n */\nfunction sobelEdgeDetection(gray: Uint8Array, width: number, height: number): Uint8Array {\n  const sobelX = [-1, 0, 1, -2, 0, 2, -1, 0, 1];\n  const sobelY = [-1, -2, -1, 0, 0, 0, 1, 2, 1];\n\n  const edges = new Uint8Array(gray.length);\n\n  for (let y = 1; y < height - 1; y++) {\n    for (let x = 1; x < width - 1; x++) {\n      let gx = 0, gy = 0;\n      let k = 0;\n\n      for (let ky = -1; ky <= 1; ky++) {\n        for (let kx = -1; kx <= 1; kx++) {\n          const pixel = gray[(y + ky) * width + (x + kx)];\n          gx += pixel * sobelX[k];\n          gy += pixel * sobelY[k];\n          k++;\n        }\n      }\n\n      // Magnitude\n      edges[y * width + x] = Math.min(255, Math.sqrt(gx * gx + gy * gy));\n    }\n  }\n\n  return edges;\n}\n\n/**\n * Extract the profile contour from edge image\n * Looks for the strongest vertical edge on each side\n */\nfunction extractProfileContour(\n  edges: Uint8Array,\n  width: number,\n  height: number\n): ProfileContour | null {\n  // Determine if face is on left or right side of image\n  let leftEdgeSum = 0;\n  let rightEdgeSum = 0;\n\n  const midX = width / 2;\n\n  for (let y = 0; y < height; y++) {\n    for (let x = 0; x < width; x++) {\n      const val = edges[y * width + x];\n      if (x < midX) {\n        leftEdgeSum += val;\n      } else {\n        rightEdgeSum += val;\n      }\n    }\n  }\n\n  // Face is likely on the side with more edge activity\n  const faceOnLeft = leftEdgeSum > rightEdgeSum;\n  const orientation: 'left' | 'right' = faceOnLeft ? 'left' : 'right'; // profile edge direction\n\n  // Find the profile edge - scan from the face side inward\n  const contourPoints: Point[] = [];\n  const threshold = 30; // Edge threshold\n\n  // Scan each row to find the profile edge\n  for (let y = Math.floor(height * 0.1); y < Math.floor(height * 0.95); y++) {\n    let edgeX = -1;\n    let maxEdge = threshold;\n\n    if (faceOnLeft) {\n      // Scan from left, find rightmost strong edge in left half\n      for (let x = 0; x < midX; x++) {\n        if (edges[y * width + x] > maxEdge) {\n          maxEdge = edges[y * width + x];\n          edgeX = x;\n        }\n      }\n    } else {\n      // Scan from right, find leftmost strong edge in right half\n      for (let x = width - 1; x >= midX; x--) {\n        if (edges[y * width + x] > maxEdge) {\n          maxEdge = edges[y * width + x];\n          edgeX = x;\n        }\n      }\n    }\n\n    if (edgeX !== -1) {\n      contourPoints.push({ x: edgeX / width, y: y / height });\n    }\n  }\n\n  if (contourPoints.length < 10) return null;\n\n  // Smooth the contour using moving average\n  const smoothedPoints = smoothContour(contourPoints, 5);\n\n  // Calculate bounding box\n  let minX = 1, minY = 1, maxX = 0, maxY = 0;\n  smoothedPoints.forEach(p => {\n    minX = Math.min(minX, p.x);\n    minY = Math.min(minY, p.y);\n    maxX = Math.max(maxX, p.x);\n    maxY = Math.max(maxY, p.y);\n  });\n\n  return {\n    points: smoothedPoints,\n    boundingBox: { x: minX, y: minY, width: maxX - minX, height: maxY - minY },\n    orientation,\n  };\n}\n\n/**\n * Smooth contour points using moving average\n */\nfunction smoothContour(points: Point[], windowSize: number): Point[] {\n  const smoothed: Point[] = [];\n  const half = Math.floor(windowSize / 2);\n\n  for (let i = 0; i < points.length; i++) {\n    let sumX = 0, sumY = 0, count = 0;\n\n    for (let j = -half; j <= half; j++) {\n      const idx = i + j;\n      if (idx >= 0 && idx < points.length) {\n        sumX += points[idx].x;\n        sumY += points[idx].y;\n        count++;\n      }\n    }\n\n    smoothed.push({ x: sumX / count, y: sumY / count });\n  }\n\n  return smoothed;\n}\n\ninterface AnchorPoints {\n  vertex: Point;      // Top of head\n  forehead: Point;    // Forehead profile\n  glabella: Point;    // Between brows\n  nasion: Point;      // Nasal root\n  noseTip: Point;     // Pronasale\n  subnasale: Point;   // Base of nose\n  upperLip: Point;    // Labrale superius\n  lowerLip: Point;    // Labrale inferius\n  chin: Point;        // Pogonion\n  menton: Point;      // Bottom of chin\n  neckPoint: Point;   // Neck\n  jawAngle: Point;    // Gonion\n}\n\n/**\n * Find anchor points along the profile contour\n */\nfunction findAnchorPoints(\n  contour: ProfileContour\n): AnchorPoints {\n  const points = contour.points;\n\n  // Helper to find point at approximate Y position\n  const findPointAtY = (targetY: number): Point => {\n    let closest = points[0];\n    let minDist = Math.abs(points[0].y - targetY);\n\n    for (const p of points) {\n      const dist = Math.abs(p.y - targetY);\n      if (dist < minDist) {\n        minDist = dist;\n        closest = p;\n      }\n    }\n    return closest;\n  };\n\n  // Helper to find the most protruding point in a Y range\n  const findProtrudingPoint = (yStart: number, yEnd: number, direction: 'left' | 'right'): Point => {\n    let best = points[0];\n\n    for (const p of points) {\n      if (p.y >= yStart && p.y <= yEnd) {\n        if (direction === 'left' && p.x < best.x) best = p;\n        if (direction === 'right' && p.x > best.x) best = p;\n      }\n    }\n    return best;\n  };\n\n  // Find key inflection points based on profile geometry\n  const isLeftFacing = contour.orientation === 'left';\n  const protrusion = isLeftFacing ? 'left' : 'right';\n\n  // Divide face into regions based on typical proportions\n  const vertex = findPointAtY(0.05);\n  const forehead = findPointAtY(0.15);\n  const glabella = findPointAtY(0.28);\n  const nasion = findPointAtY(0.32);\n\n  // Nose tip is usually the most protruding point between y=0.35 and y=0.55\n  const noseTip = findProtrudingPoint(0.35, 0.55, protrusion);\n\n  const subnasale = findPointAtY(0.58);\n  const upperLip = findPointAtY(0.62);\n  const lowerLip = findPointAtY(0.68);\n\n  // Chin (pogonion) is often protruding\n  const chin = findProtrudingPoint(0.75, 0.85, protrusion);\n\n  const menton = findPointAtY(0.88);\n  const neckPoint = findPointAtY(0.95);\n\n  // Jaw angle - find where contour curves from vertical to horizontal\n  // This is typically around y=0.7-0.8, and set back from the chin\n  const jawAngle = findPointAtY(0.75);\n\n  return {\n    vertex,\n    forehead,\n    glabella,\n    nasion,\n    noseTip,\n    subnasale,\n    upperLip,\n    lowerLip,\n    chin,\n    menton,\n    neckPoint,\n    jawAngle,\n  };\n}\n\n/**\n * Map anchor points to our 28 side profile landmarks\n */\nfunction mapToLandmarks(\n  anchors: AnchorPoints,\n  contour: ProfileContour\n): Array<{ id: string; x: number; y: number }> {\n  const isLeft = contour.orientation === 'left';\n\n  // Helper to interpolate between two points\n  const lerp = (p1: Point, p2: Point, t: number): Point => ({\n    x: p1.x + (p2.x - p1.x) * t,\n    y: p1.y + (p2.y - p1.y) * t,\n  });\n\n  // Helper to offset a point horizontally (for ear/back of head estimation)\n  const offsetX = (p: Point, offset: number): Point => ({\n    x: p.x + (isLeft ? offset : -offset),\n    y: p.y,\n  });\n\n  // Map each of our 28 landmarks\n  // Standard cephalometric order: vertex, occiput, pronasale, neckPoint, porion, orbitale,\n  // tragus, intertragicNotch, cornealApex, cheekbone, trichion, glabella, nasion,\n  // rhinion, supratip, infratip, columella, subnasale, subalare, labraleSuperius,\n  // cheilion, labraleInferius, sublabiale, pogonion, menton, cervicalPoint, gonionTop, gonionBottom\n\n  const landmarkPositions: Record<string, Point> = {\n    // 1. vertex - top of head\n    vertex: anchors.vertex,\n\n    // 2. occiput - back of head (estimate based on vertex, offset back)\n    occiput: offsetX(anchors.vertex, 0.15),\n\n    // 3. pronasale - nose tip\n    pronasale: anchors.noseTip,\n\n    // 4. neckPoint - lower neck\n    neckPoint: anchors.neckPoint,\n\n    // 5. porion - ear canal (estimate based on jaw angle, offset back)\n    porion: offsetX({ x: anchors.jawAngle.x, y: anchors.nasion.y }, 0.08),\n\n    // 6. orbitale - lowest orbital rim (between glabella and nasion level)\n    orbitale: { x: lerp(anchors.glabella, anchors.nasion, 0.5).x, y: anchors.nasion.y - 0.02 },\n\n    // 7. tragus - ear cartilage\n    tragus: offsetX({ x: anchors.jawAngle.x, y: lerp(anchors.nasion, anchors.jawAngle, 0.3).y }, 0.06),\n\n    // 8. intertragicNotch - notch in ear\n    intertragicNotch: offsetX({ x: anchors.jawAngle.x, y: lerp(anchors.nasion, anchors.jawAngle, 0.5).y }, 0.07),\n\n    // 9. cornealApex - forward point of cornea\n    cornealApex: { x: anchors.glabella.x + (isLeft ? -0.02 : 0.02), y: anchors.glabella.y + 0.02 },\n\n    // 10. cheekbone - zygomatic prominence\n    cheekbone: lerp(anchors.nasion, anchors.jawAngle, 0.4),\n\n    // 11. trichion - hairline\n    trichion: anchors.forehead,\n\n    // 12. glabella - between brows\n    glabella: anchors.glabella,\n\n    // 13. nasion - nasal root\n    nasion: anchors.nasion,\n\n    // 14. rhinion - mid-dorsum of nose\n    rhinion: lerp(anchors.nasion, anchors.noseTip, 0.4),\n\n    // 15. supratip - above nose tip\n    supratip: lerp(anchors.nasion, anchors.noseTip, 0.75),\n\n    // 16. infratip - below nose tip\n    infratip: lerp(anchors.noseTip, anchors.subnasale, 0.3),\n\n    // 17. columella - nasal septum\n    columella: lerp(anchors.noseTip, anchors.subnasale, 0.5),\n\n    // 18. subnasale - base of nose\n    subnasale: anchors.subnasale,\n\n    // 19. subalare - nostril wing\n    subalare: { x: anchors.subnasale.x + (isLeft ? -0.02 : 0.02), y: anchors.subnasale.y - 0.01 },\n\n    // 20. labraleSuperius - upper lip\n    labraleSuperius: anchors.upperLip,\n\n    // 21. cheilion - mouth corner\n    cheilion: { x: lerp(anchors.upperLip, anchors.jawAngle, 0.3).x, y: lerp(anchors.upperLip, anchors.lowerLip, 0.5).y },\n\n    // 22. labraleInferius - lower lip\n    labraleInferius: anchors.lowerLip,\n\n    // 23. sublabiale - below lower lip\n    sublabiale: lerp(anchors.lowerLip, anchors.chin, 0.3),\n\n    // 24. pogonion - chin prominence\n    pogonion: anchors.chin,\n\n    // 25. menton - bottom of chin\n    menton: anchors.menton,\n\n    // 26. cervicalPoint - high neck point\n    cervicalPoint: lerp(anchors.menton, anchors.neckPoint, 0.5),\n\n    // 27. gonionTop - upper jaw angle\n    gonionTop: { x: anchors.jawAngle.x, y: anchors.jawAngle.y - 0.03 },\n\n    // 28. gonionBottom - lower jaw angle\n    gonionBottom: anchors.jawAngle,\n  };\n\n  // Convert to array matching SIDE_PROFILE_LANDMARKS order\n  return SIDE_PROFILE_LANDMARKS.map(lm => {\n    const pos = landmarkPositions[lm.id] || { x: 0.5, y: 0.5 };\n    return {\n      id: lm.id,\n      x: Math.max(0, Math.min(1, pos.x)),\n      y: Math.max(0, Math.min(1, pos.y)),\n    };\n  });\n}\n\n/**\n * Debug: Draw the detected contour on a canvas\n */\nexport function debugDrawContour(\n  canvas: HTMLCanvasElement,\n  contour: Point[],\n  landmarks: Array<{ id: string; x: number; y: number }>\n): void {\n  const ctx = canvas.getContext('2d');\n  if (!ctx) return;\n\n  const width = canvas.width;\n  const height = canvas.height;\n\n  // Draw contour\n  ctx.strokeStyle = '#00ff00';\n  ctx.lineWidth = 2;\n  ctx.beginPath();\n  contour.forEach((p, i) => {\n    const x = p.x * width;\n    const y = p.y * height;\n    if (i === 0) ctx.moveTo(x, y);\n    else ctx.lineTo(x, y);\n  });\n  ctx.stroke();\n\n  // Draw landmarks\n  landmarks.forEach(lm => {\n    ctx.fillStyle = '#ff0000';\n    ctx.beginPath();\n    ctx.arc(lm.x * width, lm.y * height, 4, 0, Math.PI * 2);\n    ctx.fill();\n\n    ctx.fillStyle = '#ffffff';\n    ctx.font = '10px sans-serif';\n    ctx.fillText(lm.id, lm.x * width + 6, lm.y * height);\n  });\n}\n","numLines":565,"startLine":1,"totalLines":565}}}
{"parentUuid":"955962b3-7002-4f04-88a1-3326b3c4bfca","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"988cde7a-9586-4ca8-910d-50a828b2fa2d","version":"2.0.76","gitBranch":"main","agentId":"aee8db2","slug":"fizzy-singing-bird","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Lgk7csoVJzEpzJAf3vDWur","type":"tool_result","content":"     1→/**\n     2→ * Side Profile Normalization Utilities - FaceIQ Parity Implementation\n     3→ * \n     4→ * This module replicates FaceIQ's exact side profile normalization algorithm\n     5→ * for 100% parity with their landmark detection and visualization.\n     6→ * \n     7→ * FaceIQ Algorithm (reverse-engineered):\n     8→ * - Uses landmark indices 10, 26, 75 for rotation calculation\n     9→ * - Left profile: rotate based on landmarks[75] → landmarks[26]\n    10→ * - Right profile: rotate based on landmarks[10] → landmarks[26]\n    11→ * - Pivot point: landmarks[10] for right, landmarks[26] for left\n    12→ * - Crops to 1024×1024 with 1.12 scale factor and 0.65 height ratio\n    13→ */\n    14→\n    15→export interface Point2D {\n    16→    x: number;\n    17→    y: number;\n    18→}\n    19→\n    20→export interface FaceIQNormalizationResult {\n    21→    /** Rotation angle applied (in radians) */\n    22→    rotationAngle: number;\n    23→    /** Rotation angle in degrees */\n    24→    rotationAngleDeg: number;\n    25→    /** Direction the face is pointing */\n    26→    direction: 'left' | 'right';\n    27→    /** Pivot point used for rotation */\n    28→    pivot: Point2D;\n    29→    /** Rotated landmarks */\n    30→    rotatedLandmarks: Array<{ id: string; x: number; y: number }>;\n    31→    /** Rotated image as data URL (if image provided) */\n    32→    rotatedImageUrl?: string;\n    33→    /** Crop info */\n    34→    cropInfo: {\n    35→        x: number;\n    36→        y: number;\n    37→        size: number;\n    38→        scale: number;\n    39→    };\n    40→}\n    41→\n    42→/**\n    43→ * FaceIQ's landmark indices for rotation calculation\n    44→ * \n    45→ * These correspond to face contour positions in their model:\n    46→ * - Index 10: Upper face contour (forehead/temple area) - right anchor\n    47→ * - Index 26: Mid-face contour (jaw level) - common reference\n    48→ * - Index 75: Upper face contour (mirrored) - left anchor\n    49→ * \n    50→ * Our InsightFace 106 mapping:\n    51→ * - Index 10 → InsightFace contour point ~9-10 (right side)\n    52→ * - Index 26 → InsightFace contour point ~25-26 (mid contour)\n    53→ * - Index 75 → InsightFace right eye area ~71-75\n    54→ */\n    55→\n    56→/**\n    57→ * FaceIQ to our raw landmark array index mapping (documentation only)\n    58→ * These indices map to the raw landmarks array returned by the API\n    59→ *\n    60→ * @internal Used for reference - actual implementation uses direct indices\n    61→ */\n    62→// eslint-disable-next-line @typescript-eslint/no-unused-vars\n    63→const _FACEIQ_INDEX_REFERENCE = {\n    64→    10: 'faceContour_10',  // Right anchor for rotation\n    65→    26: 'faceContour_26',  // Common reference point\n    66→    75: 'rightEyeLowerInner',  // Left anchor (near eye for left-facing)\n    67→} as const;\n    68→\n    69→/**\n    70→ * Calculate rotation angle using FaceIQ's exact algorithm\n    71→ * \n    72→ * @param landmarks - Raw landmarks array from API\n    73→ * @param direction - Face direction (\"left\" or \"right\")\n    74→ * @returns Rotation angle in radians\n    75→ */\n    76→export function calculateFaceIQRotationAngle(\n    77→    landmarks: Array<{ x: number; y: number }>,\n    78→    direction: 'left' | 'right'\n    79→): number {\n    80→    // FaceIQ algorithm:\n    81→    // anchor = (direction === \"left\") ? landmarks[75] : landmarks[10];\n    82→    // reference = landmarks[26];\n    83→    // angle = Math.atan2(reference.y - anchor.y, reference.x - anchor.x);\n    84→\n    85→    const anchor = direction === 'left' ? landmarks[75] : landmarks[10];\n    86→    const reference = landmarks[26];\n    87→\n    88→    if (!anchor || !reference) {\n    89→        console.warn('[FaceIQ Normalization] Missing landmark indices 10, 26, or 75');\n    90→        return 0;\n    91→    }\n    92→\n    93→    const angle = Math.atan2(reference.y - anchor.y, reference.x - anchor.x);\n    94→    return angle;\n    95→}\n    96→\n    97→/**\n    98→ * Get the rotation pivot point using FaceIQ's logic\n    99→ * \n   100→ * @param landmarks - Raw landmarks array\n   101→ * @param direction - Face direction\n   102→ * @returns Pivot point coordinates\n   103→ */\n   104→export function getFaceIQPivot(\n   105→    landmarks: Array<{ x: number; y: number }>,\n   106→    direction: 'left' | 'right'\n   107→): Point2D {\n   108→    // FaceIQ: pivot = (direction === \"right\") ? landmarks[10] : landmarks[26]\n   109→    const pivotLandmark = direction === 'right' ? landmarks[10] : landmarks[26];\n   110→\n   111→    if (!pivotLandmark) {\n   112→        return { x: 0.5, y: 0.5 };\n   113→    }\n   114→\n   115→    return { x: pivotLandmark.x, y: pivotLandmark.y };\n   116→}\n   117→\n   118→/**\n   119→ * Rotate a point around a pivot using FaceIQ's formula\n   120→ * \n   121→ * FaceIQ's rotation function:\n   122→ * ```\n   123→ * let j = e => {\n   124→ *   let t = Math.sin(-g), i = Math.cos(-g), a = e.x - f, s = e.y - b;\n   125→ *   return { x: f + a * i - s * t, y: b + a * t + s * i };\n   126→ * };\n   127→ * ```\n   128→ */\n   129→export function rotatePointFaceIQ(\n   130→    point: Point2D,\n   131→    pivot: Point2D,\n   132→    angleRad: number\n   133→): Point2D {\n   134→    // FaceIQ rotates by NEGATIVE angle\n   135→    const negAngle = -angleRad;\n   136→    const sin = Math.sin(negAngle);\n   137→    const cos = Math.cos(negAngle);\n   138→\n   139→    const dx = point.x - pivot.x;\n   140→    const dy = point.y - pivot.y;\n   141→\n   142→    return {\n   143→        x: pivot.x + dx * cos - dy * sin,\n   144→        y: pivot.y + dx * sin + dy * cos,\n   145→    };\n   146→}\n   147→\n   148→/**\n   149→ * Calculate crop dimensions using FaceIQ's formula\n   150→ * \n   151→ * FaceIQ algorithm:\n   152→ * - croppedHeight = bboxHeight * 1.12\n   153→ * - cropSize = croppedHeight / 0.65\n   154→ * - Constrained between 32 and 2 * max(width, height)\n   155→ */\n   156→export function calculateFaceIQCropSize(\n   157→    bboxHeight: number,\n   158→    imageWidth: number,\n   159→    imageHeight: number\n   160→): number {\n   161→    const scaledHeight = bboxHeight * 1.12;\n   162→    const cropSize = scaledHeight / 0.65;\n   163→\n   164→    // FaceIQ constraints\n   165→    const minSize = 32;\n   166→    const maxSize = 2 * Math.max(imageWidth, imageHeight);\n   167→\n   168→    return Math.min(Math.max(minSize, cropSize), maxSize);\n   169→}\n   170→\n   171→/**\n   172→ * Apply FaceIQ-exact normalization to named landmarks\n   173→ * \n   174→ * This function works with our named landmark format and applies\n   175→ * the FaceIQ rotation algorithm.\n   176→ * \n   177→ * @param namedLandmarks - Landmarks as { id: string; x: number; y: number }[]\n   178→ * @param rawLandmarks - Raw landmark array (for indices 10, 26, 75)\n   179→ * @param direction - Face direction\n   180→ * @param bbox - Bounding box for crop calculation\n   181→ */\n   182→export function applyFaceIQNormalization(\n   183→    namedLandmarks: Array<{ id: string; x: number; y: number }>,\n   184→    rawLandmarks: Array<{ x: number; y: number }>,\n   185→    direction: 'left' | 'right',\n   186→    bbox?: { x: number; y: number; width: number; height: number }\n   187→): FaceIQNormalizationResult {\n   188→    // Calculate rotation angle using FaceIQ's algorithm\n   189→    const rotationAngle = calculateFaceIQRotationAngle(rawLandmarks, direction);\n   190→    const rotationAngleDeg = rotationAngle * (180 / Math.PI);\n   191→\n   192→    // Get pivot point\n   193→    const pivot = getFaceIQPivot(rawLandmarks, direction);\n   194→\n   195→    // Skip rotation if angle is very small (< 2 degrees)\n   196→    if (Math.abs(rotationAngleDeg) < 2) {\n   197→        return {\n   198→            rotationAngle: 0,\n   199→            rotationAngleDeg: 0,\n   200→            direction,\n   201→            pivot,\n   202→            rotatedLandmarks: namedLandmarks,\n   203→            cropInfo: {\n   204→                x: 0,\n   205→                y: 0,\n   206→                size: 1024,\n   207→                scale: 1,\n   208→            },\n   209→        };\n   210→    }\n   211→\n   212→    // Rotate all named landmarks\n   213→    const rotatedLandmarks = namedLandmarks.map(landmark => {\n   214→        const rotated = rotatePointFaceIQ(\n   215→            { x: landmark.x, y: landmark.y },\n   216→            pivot,\n   217→            rotationAngle\n   218→        );\n   219→        return {\n   220→            id: landmark.id,\n   221→            x: rotated.x,\n   222→            y: rotated.y,\n   223→        };\n   224→    });\n   225→\n   226→    // Calculate crop info\n   227→    const cropSize = bbox\n   228→        ? calculateFaceIQCropSize(bbox.height, 1, 1)  // Normalized\n   229→        : 1024;\n   230→\n   231→    console.log(`[FaceIQ Normalization] Direction: ${direction}, Rotation: ${rotationAngleDeg.toFixed(1)}°`);\n   232→\n   233→    return {\n   234→        rotationAngle,\n   235→        rotationAngleDeg,\n   236→        direction,\n   237→        pivot,\n   238→        rotatedLandmarks,\n   239→        cropInfo: {\n   240→            x: pivot.x - cropSize / 2,\n   241→            y: pivot.y - cropSize / 2,\n   242→            size: cropSize,\n   243→            scale: 1024 / cropSize,\n   244→        },\n   245→    };\n   246→}\n   247→\n   248→/**\n   249→ * Simplified wrapper for the detection flow\n   250→ * \n   251→ * This is a drop-in replacement for applyFrankfortCorrection that uses\n   252→ * FaceIQ's algorithm instead.\n   253→ * \n   254→ * @param landmarks - Named landmarks from detection\n   255→ * @param rawLandmarks - Raw landmark array (if available)\n   256→ * @param direction - Face direction\n   257→ * @returns Normalized landmarks\n   258→ */\n   259→export function applyFaceIQCorrection(\n   260→    landmarks: Array<{ id: string; x: number; y: number }>,\n   261→    rawLandmarks?: Array<{ x: number; y: number }>,\n   262→    direction?: 'left' | 'right'\n   263→): Array<{ id: string; x: number; y: number }> {\n   264→    // If we don't have raw landmarks or direction, fall back to Frankfort-based\n   265→    if (!rawLandmarks || rawLandmarks.length < 76 || !direction) {\n   266→        console.log('[FaceIQ Normalization] Missing raw landmarks, using Frankfort fallback');\n   267→        return applyFrankfortCorrectionFallback(landmarks);\n   268→    }\n   269→\n   270→    const result = applyFaceIQNormalization(landmarks, rawLandmarks, direction);\n   271→    return result.rotatedLandmarks;\n   272→}\n   273→\n   274→/**\n   275→ * Fallback to our original Frankfort-based correction\n   276→ * when FaceIQ indices are not available\n   277→ */\n   278→function applyFrankfortCorrectionFallback(\n   279→    landmarks: Array<{ id: string; x: number; y: number }>\n   280→): Array<{ id: string; x: number; y: number }> {\n   281→    const orbitale = landmarks.find(l => l.id === 'orbitale');\n   282→    const porion = landmarks.find(l => l.id === 'porion');\n   283→\n   284→    if (!orbitale || !porion) {\n   285→        return landmarks;\n   286→    }\n   287→\n   288→    // Calculate Frankfort angle\n   289→    const dx = porion.x - orbitale.x;\n   290→    const dy = porion.y - orbitale.y;\n   291→    const angle = Math.atan2(dy, dx);\n   292→\n   293→    if (Math.abs(angle) < 0.035) { // ~2 degrees\n   294→        return landmarks;\n   295→    }\n   296→\n   297→    const pivot: Point2D = {\n   298→        x: (orbitale.x + porion.x) / 2,\n   299→        y: (orbitale.y + porion.y) / 2,\n   300→    };\n   301→\n   302→    return landmarks.map(landmark => {\n   303→        const cos = Math.cos(-angle);\n   304→        const sin = Math.sin(-angle);\n   305→        const dx = landmark.x - pivot.x;\n   306→        const dy = landmark.y - pivot.y;\n   307→\n   308→        return {\n   309→            id: landmark.id,\n   310→            x: pivot.x + dx * cos - dy * sin,\n   311→            y: pivot.y + dx * sin + dy * cos,\n   312→        };\n   313→    });\n   314→}\n   315→\n   316→/**\n   317→ * Rotate image to match FaceIQ's 1024×1024 standardized output\n   318→ */\n   319→export async function rotateImageFaceIQ(\n   320→    imageUrl: string,\n   321→    rawLandmarks: Array<{ x: number; y: number }>,\n   322→    direction: 'left' | 'right',\n   323→    bbox: { x: number; y: number; width: number; height: number }\n   324→): Promise<string> {\n   325→    return new Promise((resolve, reject) => {\n   326→        const img = new Image();\n   327→        img.crossOrigin = 'anonymous';\n   328→\n   329→        img.onload = () => {\n   330→            const canvas = document.createElement('canvas');\n   331→            const ctx = canvas.getContext('2d');\n   332→\n   333→            if (!ctx) {\n   334→                reject(new Error('Canvas context unavailable'));\n   335→                return;\n   336→            }\n   337→\n   338→            // FaceIQ uses 1024×1024 output\n   339→            const OUTPUT_SIZE = 1024;\n   340→            canvas.width = OUTPUT_SIZE;\n   341→            canvas.height = OUTPUT_SIZE;\n   342→\n   343→            // Calculate rotation\n   344→            const rotationAngle = calculateFaceIQRotationAngle(rawLandmarks, direction);\n   345→            const pivot = getFaceIQPivot(rawLandmarks, direction);\n   346→\n   347→            // Calculate crop size using FaceIQ formula\n   348→            const cropSize = calculateFaceIQCropSize(\n   349→                bbox.height * img.height,\n   350→                img.width,\n   351→                img.height\n   352→            );\n   353→\n   354→            const scale = OUTPUT_SIZE / cropSize;\n   355→\n   356→            // Transform canvas\n   357→            ctx.translate(OUTPUT_SIZE / 2, OUTPUT_SIZE / 2);\n   358→            ctx.rotate(-rotationAngle);\n   359→            ctx.scale(scale, scale);\n   360→            ctx.translate(\n   361→                -pivot.x * img.width,\n   362→                -pivot.y * img.height\n   363→            );\n   364→\n   365→            // Draw image\n   366→            ctx.drawImage(img, 0, 0);\n   367→\n   368→            resolve(canvas.toDataURL('image/jpeg', 0.9));\n   369→        };\n   370→\n   371→        img.onerror = () => reject(new Error('Failed to load image'));\n   372→        img.src = imageUrl;\n   373→    });\n   374→}\n   375→\n   376→// ============================================\n   377→// LEGACY EXPORTS FOR BACKWARD COMPATIBILITY\n   378→// ============================================\n   379→\n   380→// Keep the old function name as an alias\n   381→export { applyFrankfortCorrectionFallback as applyFrankfortCorrection };\n   382→\n   383→// Re-export with old names for compatibility\n   384→export function normalizeLandmarksToFrankfort(\n   385→    landmarks: Array<{ id: string; x: number; y: number }>\n   386→) {\n   387→    return {\n   388→        rotationAngle: 0,\n   389→        originalFrankfortAngle: 0,\n   390→        rotatedLandmarks: applyFrankfortCorrectionFallback(landmarks),\n   391→        rotationCenter: { x: 0.5, y: 0.5 },\n   392→    };\n   393→}\n   394→\n\n</system-reminder>\n"}]},"uuid":"bb13c96e-d678-4031-9895-12afb68472d9","timestamp":"2025-12-30T14:57:17.121Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/imorgado/LOOKSMAXX/looksmaxx-app/src/lib/sideProfileNormalization.ts","content":"/**\n * Side Profile Normalization Utilities - FaceIQ Parity Implementation\n * \n * This module replicates FaceIQ's exact side profile normalization algorithm\n * for 100% parity with their landmark detection and visualization.\n * \n * FaceIQ Algorithm (reverse-engineered):\n * - Uses landmark indices 10, 26, 75 for rotation calculation\n * - Left profile: rotate based on landmarks[75] → landmarks[26]\n * - Right profile: rotate based on landmarks[10] → landmarks[26]\n * - Pivot point: landmarks[10] for right, landmarks[26] for left\n * - Crops to 1024×1024 with 1.12 scale factor and 0.65 height ratio\n */\n\nexport interface Point2D {\n    x: number;\n    y: number;\n}\n\nexport interface FaceIQNormalizationResult {\n    /** Rotation angle applied (in radians) */\n    rotationAngle: number;\n    /** Rotation angle in degrees */\n    rotationAngleDeg: number;\n    /** Direction the face is pointing */\n    direction: 'left' | 'right';\n    /** Pivot point used for rotation */\n    pivot: Point2D;\n    /** Rotated landmarks */\n    rotatedLandmarks: Array<{ id: string; x: number; y: number }>;\n    /** Rotated image as data URL (if image provided) */\n    rotatedImageUrl?: string;\n    /** Crop info */\n    cropInfo: {\n        x: number;\n        y: number;\n        size: number;\n        scale: number;\n    };\n}\n\n/**\n * FaceIQ's landmark indices for rotation calculation\n * \n * These correspond to face contour positions in their model:\n * - Index 10: Upper face contour (forehead/temple area) - right anchor\n * - Index 26: Mid-face contour (jaw level) - common reference\n * - Index 75: Upper face contour (mirrored) - left anchor\n * \n * Our InsightFace 106 mapping:\n * - Index 10 → InsightFace contour point ~9-10 (right side)\n * - Index 26 → InsightFace contour point ~25-26 (mid contour)\n * - Index 75 → InsightFace right eye area ~71-75\n */\n\n/**\n * FaceIQ to our raw landmark array index mapping (documentation only)\n * These indices map to the raw landmarks array returned by the API\n *\n * @internal Used for reference - actual implementation uses direct indices\n */\n// eslint-disable-next-line @typescript-eslint/no-unused-vars\nconst _FACEIQ_INDEX_REFERENCE = {\n    10: 'faceContour_10',  // Right anchor for rotation\n    26: 'faceContour_26',  // Common reference point\n    75: 'rightEyeLowerInner',  // Left anchor (near eye for left-facing)\n} as const;\n\n/**\n * Calculate rotation angle using FaceIQ's exact algorithm\n * \n * @param landmarks - Raw landmarks array from API\n * @param direction - Face direction (\"left\" or \"right\")\n * @returns Rotation angle in radians\n */\nexport function calculateFaceIQRotationAngle(\n    landmarks: Array<{ x: number; y: number }>,\n    direction: 'left' | 'right'\n): number {\n    // FaceIQ algorithm:\n    // anchor = (direction === \"left\") ? landmarks[75] : landmarks[10];\n    // reference = landmarks[26];\n    // angle = Math.atan2(reference.y - anchor.y, reference.x - anchor.x);\n\n    const anchor = direction === 'left' ? landmarks[75] : landmarks[10];\n    const reference = landmarks[26];\n\n    if (!anchor || !reference) {\n        console.warn('[FaceIQ Normalization] Missing landmark indices 10, 26, or 75');\n        return 0;\n    }\n\n    const angle = Math.atan2(reference.y - anchor.y, reference.x - anchor.x);\n    return angle;\n}\n\n/**\n * Get the rotation pivot point using FaceIQ's logic\n * \n * @param landmarks - Raw landmarks array\n * @param direction - Face direction\n * @returns Pivot point coordinates\n */\nexport function getFaceIQPivot(\n    landmarks: Array<{ x: number; y: number }>,\n    direction: 'left' | 'right'\n): Point2D {\n    // FaceIQ: pivot = (direction === \"right\") ? landmarks[10] : landmarks[26]\n    const pivotLandmark = direction === 'right' ? landmarks[10] : landmarks[26];\n\n    if (!pivotLandmark) {\n        return { x: 0.5, y: 0.5 };\n    }\n\n    return { x: pivotLandmark.x, y: pivotLandmark.y };\n}\n\n/**\n * Rotate a point around a pivot using FaceIQ's formula\n * \n * FaceIQ's rotation function:\n * ```\n * let j = e => {\n *   let t = Math.sin(-g), i = Math.cos(-g), a = e.x - f, s = e.y - b;\n *   return { x: f + a * i - s * t, y: b + a * t + s * i };\n * };\n * ```\n */\nexport function rotatePointFaceIQ(\n    point: Point2D,\n    pivot: Point2D,\n    angleRad: number\n): Point2D {\n    // FaceIQ rotates by NEGATIVE angle\n    const negAngle = -angleRad;\n    const sin = Math.sin(negAngle);\n    const cos = Math.cos(negAngle);\n\n    const dx = point.x - pivot.x;\n    const dy = point.y - pivot.y;\n\n    return {\n        x: pivot.x + dx * cos - dy * sin,\n        y: pivot.y + dx * sin + dy * cos,\n    };\n}\n\n/**\n * Calculate crop dimensions using FaceIQ's formula\n * \n * FaceIQ algorithm:\n * - croppedHeight = bboxHeight * 1.12\n * - cropSize = croppedHeight / 0.65\n * - Constrained between 32 and 2 * max(width, height)\n */\nexport function calculateFaceIQCropSize(\n    bboxHeight: number,\n    imageWidth: number,\n    imageHeight: number\n): number {\n    const scaledHeight = bboxHeight * 1.12;\n    const cropSize = scaledHeight / 0.65;\n\n    // FaceIQ constraints\n    const minSize = 32;\n    const maxSize = 2 * Math.max(imageWidth, imageHeight);\n\n    return Math.min(Math.max(minSize, cropSize), maxSize);\n}\n\n/**\n * Apply FaceIQ-exact normalization to named landmarks\n * \n * This function works with our named landmark format and applies\n * the FaceIQ rotation algorithm.\n * \n * @param namedLandmarks - Landmarks as { id: string; x: number; y: number }[]\n * @param rawLandmarks - Raw landmark array (for indices 10, 26, 75)\n * @param direction - Face direction\n * @param bbox - Bounding box for crop calculation\n */\nexport function applyFaceIQNormalization(\n    namedLandmarks: Array<{ id: string; x: number; y: number }>,\n    rawLandmarks: Array<{ x: number; y: number }>,\n    direction: 'left' | 'right',\n    bbox?: { x: number; y: number; width: number; height: number }\n): FaceIQNormalizationResult {\n    // Calculate rotation angle using FaceIQ's algorithm\n    const rotationAngle = calculateFaceIQRotationAngle(rawLandmarks, direction);\n    const rotationAngleDeg = rotationAngle * (180 / Math.PI);\n\n    // Get pivot point\n    const pivot = getFaceIQPivot(rawLandmarks, direction);\n\n    // Skip rotation if angle is very small (< 2 degrees)\n    if (Math.abs(rotationAngleDeg) < 2) {\n        return {\n            rotationAngle: 0,\n            rotationAngleDeg: 0,\n            direction,\n            pivot,\n            rotatedLandmarks: namedLandmarks,\n            cropInfo: {\n                x: 0,\n                y: 0,\n                size: 1024,\n                scale: 1,\n            },\n        };\n    }\n\n    // Rotate all named landmarks\n    const rotatedLandmarks = namedLandmarks.map(landmark => {\n        const rotated = rotatePointFaceIQ(\n            { x: landmark.x, y: landmark.y },\n            pivot,\n            rotationAngle\n        );\n        return {\n            id: landmark.id,\n            x: rotated.x,\n            y: rotated.y,\n        };\n    });\n\n    // Calculate crop info\n    const cropSize = bbox\n        ? calculateFaceIQCropSize(bbox.height, 1, 1)  // Normalized\n        : 1024;\n\n    console.log(`[FaceIQ Normalization] Direction: ${direction}, Rotation: ${rotationAngleDeg.toFixed(1)}°`);\n\n    return {\n        rotationAngle,\n        rotationAngleDeg,\n        direction,\n        pivot,\n        rotatedLandmarks,\n        cropInfo: {\n            x: pivot.x - cropSize / 2,\n            y: pivot.y - cropSize / 2,\n            size: cropSize,\n            scale: 1024 / cropSize,\n        },\n    };\n}\n\n/**\n * Simplified wrapper for the detection flow\n * \n * This is a drop-in replacement for applyFrankfortCorrection that uses\n * FaceIQ's algorithm instead.\n * \n * @param landmarks - Named landmarks from detection\n * @param rawLandmarks - Raw landmark array (if available)\n * @param direction - Face direction\n * @returns Normalized landmarks\n */\nexport function applyFaceIQCorrection(\n    landmarks: Array<{ id: string; x: number; y: number }>,\n    rawLandmarks?: Array<{ x: number; y: number }>,\n    direction?: 'left' | 'right'\n): Array<{ id: string; x: number; y: number }> {\n    // If we don't have raw landmarks or direction, fall back to Frankfort-based\n    if (!rawLandmarks || rawLandmarks.length < 76 || !direction) {\n        console.log('[FaceIQ Normalization] Missing raw landmarks, using Frankfort fallback');\n        return applyFrankfortCorrectionFallback(landmarks);\n    }\n\n    const result = applyFaceIQNormalization(landmarks, rawLandmarks, direction);\n    return result.rotatedLandmarks;\n}\n\n/**\n * Fallback to our original Frankfort-based correction\n * when FaceIQ indices are not available\n */\nfunction applyFrankfortCorrectionFallback(\n    landmarks: Array<{ id: string; x: number; y: number }>\n): Array<{ id: string; x: number; y: number }> {\n    const orbitale = landmarks.find(l => l.id === 'orbitale');\n    const porion = landmarks.find(l => l.id === 'porion');\n\n    if (!orbitale || !porion) {\n        return landmarks;\n    }\n\n    // Calculate Frankfort angle\n    const dx = porion.x - orbitale.x;\n    const dy = porion.y - orbitale.y;\n    const angle = Math.atan2(dy, dx);\n\n    if (Math.abs(angle) < 0.035) { // ~2 degrees\n        return landmarks;\n    }\n\n    const pivot: Point2D = {\n        x: (orbitale.x + porion.x) / 2,\n        y: (orbitale.y + porion.y) / 2,\n    };\n\n    return landmarks.map(landmark => {\n        const cos = Math.cos(-angle);\n        const sin = Math.sin(-angle);\n        const dx = landmark.x - pivot.x;\n        const dy = landmark.y - pivot.y;\n\n        return {\n            id: landmark.id,\n            x: pivot.x + dx * cos - dy * sin,\n            y: pivot.y + dx * sin + dy * cos,\n        };\n    });\n}\n\n/**\n * Rotate image to match FaceIQ's 1024×1024 standardized output\n */\nexport async function rotateImageFaceIQ(\n    imageUrl: string,\n    rawLandmarks: Array<{ x: number; y: number }>,\n    direction: 'left' | 'right',\n    bbox: { x: number; y: number; width: number; height: number }\n): Promise<string> {\n    return new Promise((resolve, reject) => {\n        const img = new Image();\n        img.crossOrigin = 'anonymous';\n\n        img.onload = () => {\n            const canvas = document.createElement('canvas');\n            const ctx = canvas.getContext('2d');\n\n            if (!ctx) {\n                reject(new Error('Canvas context unavailable'));\n                return;\n            }\n\n            // FaceIQ uses 1024×1024 output\n            const OUTPUT_SIZE = 1024;\n            canvas.width = OUTPUT_SIZE;\n            canvas.height = OUTPUT_SIZE;\n\n            // Calculate rotation\n            const rotationAngle = calculateFaceIQRotationAngle(rawLandmarks, direction);\n            const pivot = getFaceIQPivot(rawLandmarks, direction);\n\n            // Calculate crop size using FaceIQ formula\n            const cropSize = calculateFaceIQCropSize(\n                bbox.height * img.height,\n                img.width,\n                img.height\n            );\n\n            const scale = OUTPUT_SIZE / cropSize;\n\n            // Transform canvas\n            ctx.translate(OUTPUT_SIZE / 2, OUTPUT_SIZE / 2);\n            ctx.rotate(-rotationAngle);\n            ctx.scale(scale, scale);\n            ctx.translate(\n                -pivot.x * img.width,\n                -pivot.y * img.height\n            );\n\n            // Draw image\n            ctx.drawImage(img, 0, 0);\n\n            resolve(canvas.toDataURL('image/jpeg', 0.9));\n        };\n\n        img.onerror = () => reject(new Error('Failed to load image'));\n        img.src = imageUrl;\n    });\n}\n\n// ============================================\n// LEGACY EXPORTS FOR BACKWARD COMPATIBILITY\n// ============================================\n\n// Keep the old function name as an alias\nexport { applyFrankfortCorrectionFallback as applyFrankfortCorrection };\n\n// Re-export with old names for compatibility\nexport function normalizeLandmarksToFrankfort(\n    landmarks: Array<{ id: string; x: number; y: number }>\n) {\n    return {\n        rotationAngle: 0,\n        originalFrankfortAngle: 0,\n        rotatedLandmarks: applyFrankfortCorrectionFallback(landmarks),\n        rotationCenter: { x: 0.5, y: 0.5 },\n    };\n}\n","numLines":394,"startLine":1,"totalLines":394}}}
{"parentUuid":"bb13c96e-d678-4031-9895-12afb68472d9","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"988cde7a-9586-4ca8-910d-50a828b2fa2d","version":"2.0.76","gitBranch":"main","agentId":"aee8db2","slug":"fizzy-singing-bird","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01BwVXbJfa5ezRzYXnJdvBH5","type":"tool_result","content":"     1→'use client';\n     2→\n     3→import { useState, useRef, useCallback, useEffect } from 'react';\n     4→import Image from 'next/image';\n     5→import { motion } from 'framer-motion';\n     6→import {\n     7→  ChevronLeft,\n     8→  ChevronRight,\n     9→  ChevronUp,\n    10→  ChevronDown,\n    11→  Check,\n    12→  Info,\n    13→  Scan,\n    14→  Loader2,\n    15→  Move,\n    16→  Focus,\n    17→  AlertTriangle,\n    18→  X,\n    19→  Settings2,\n    20→} from 'lucide-react';\n    21→\n    22→\n    23→import {\n    24→  LandmarkPoint,\n    25→  FRONT_PROFILE_LANDMARKS,\n    26→  SIDE_PROFILE_LANDMARKS,\n    27→  getLandmarkColor,\n    28→  FRONT_LANDMARK_CATEGORIES,\n    29→  SIDE_LANDMARK_CATEGORIES,\n    30→} from '@/lib/landmarks';\n    31→import { getLandmarkImagePath, getLandmarkPlacementGuide } from '@/lib/landmarkImages';\n    32→import { detectFromImageUrl } from '@/lib/mediapipeDetection';\n    33→import { LandmarkEditor } from '@/components/analysis';\n    34→import { ESTIMATED_LANDMARKS } from '@/hooks/useLandmarkAdjustment';\n    35→\n    36→interface LandmarkAnalysisToolProps {\n    37→  imageUrl: string;\n    38→  mode: 'front' | 'side';\n    39→  initialLandmarks?: LandmarkPoint[];\n    40→  onLandmarksChange?: (landmarks: LandmarkPoint[]) => void;\n    41→  onComplete?: (landmarks: LandmarkPoint[]) => void;\n    42→  onBack?: () => void;\n    43→}\n    44→\n    45→function getOrderedLandmarks(mode: 'front' | 'side'): string[] {\n    46→  const landmarks = mode === 'front' ? FRONT_PROFILE_LANDMARKS : SIDE_PROFILE_LANDMARKS;\n    47→  return landmarks.map(lm => lm.id);\n    48→}\n    49→\n    50→export function LandmarkAnalysisTool({\n    51→  imageUrl,\n    52→  mode,\n    53→  initialLandmarks,\n    54→  onLandmarksChange,\n    55→  onComplete,\n    56→  onBack,\n    57→}: LandmarkAnalysisToolProps) {\n    58→  const containerRef = useRef<HTMLDivElement>(null);\n    59→  const [imageDimensions, setImageDimensions] = useState<{ width: number; height: number } | null>(null);\n    60→  const [containerSize, setContainerSize] = useState<{ width: number; height: number } | null>(null);\n    61→  const defaultLandmarks = mode === 'front' ? FRONT_PROFILE_LANDMARKS : SIDE_PROFILE_LANDMARKS;\n    62→  const categories = mode === 'front' ? FRONT_LANDMARK_CATEGORIES : SIDE_LANDMARK_CATEGORIES;\n    63→  const orderedIds = getOrderedLandmarks(mode);\n    64→\n    65→  const [landmarks, setLandmarks] = useState<LandmarkPoint[]>(\n    66→    initialLandmarks || defaultLandmarks\n    67→  );\n    68→  const [currentStepIndex, setCurrentStepIndex] = useState(0);\n    69→  const [zoomLevel, setZoomLevel] = useState(2); // 2x/4x/8x discrete levels\n    70→\n    71→  // Reset state when mode changes (fixes side profile starting at step 52)\n    72→  useEffect(() => {\n    73→    const newLandmarks = mode === 'front' ? FRONT_PROFILE_LANDMARKS : SIDE_PROFILE_LANDMARKS;\n    74→    setCurrentStepIndex(0);\n    75→    setPlacedLandmarks(new Set());\n    76→    setHasAutoDetected(false);\n    77→    setDetectionFailed(false);\n    78→    setLandmarks(newLandmarks);\n    79→    setPan({ x: 0, y: 0 });\n    80→    setZoomLevel(2); // Reset to 2x\n    81→    setShowAdjustmentMode(false);\n    82→    setEarLandmarksAdjusted(false);\n    83→  }, [mode]);\n    84→\n    85→  // Check if estimated ear landmarks exist in current landmarks\n    86→  const hasEstimatedEarLandmarks = mode === 'side' && landmarks.some(\n    87→    lm => ESTIMATED_LANDMARKS.includes(lm.id as typeof ESTIMATED_LANDMARKS[number])\n    88→  );\n    89→\n    90→  // Handle ear landmark adjustment confirmation\n    91→  const handleAdjustmentConfirm = useCallback((adjustedLandmarks: Array<{ id: string; x: number; y: number }>) => {\n    92→    // Merge adjusted landmarks with existing\n    93→    setLandmarks(prev => prev.map(lm => {\n    94→      const adjusted = adjustedLandmarks.find(a => a.id === lm.id);\n    95→      if (adjusted) {\n    96→        return { ...lm, x: adjusted.x, y: adjusted.y };\n    97→      }\n    98→      return lm;\n    99→    }));\n   100→\n   101→    // Recalculate Frankfort plane with adjusted landmarks\n   102→    const porion = adjustedLandmarks.find(l => l.id === 'porion');\n   103→    const orbitale = adjustedLandmarks.find(l => l.id === 'orbitale');\n   104→    if (porion && orbitale) {\n   105→      const dx = porion.x - orbitale.x;\n   106→      const dy = porion.y - orbitale.y;\n   107→      const angle = Math.atan2(dy, dx) * (180 / Math.PI);\n   108→      setFrankfortPlane({\n   109→        angle,\n   110→        orbitale: { x: orbitale.x, y: orbitale.y },\n   111→        porion: { x: porion.x, y: porion.y },\n   112→      });\n   113→    }\n   114→\n   115→    setEarLandmarksAdjusted(true);\n   116→    setShowAdjustmentMode(false);\n   117→  }, []);\n   118→  const [pan, setPan] = useState({ x: 0, y: 0 });\n   119→  const [isDragging, setIsDragging] = useState(false);\n   120→  const [dragStart, setDragStart] = useState({ x: 0, y: 0 });\n   121→  const [pressedKeys, setPressedKeys] = useState<Set<string>>(new Set());\n   122→  const [activeTab, setActiveTab] = useState<'info' | 'reference'>('info');\n   123→  const [isDetecting, setIsDetecting] = useState(true);\n   124→  const [hasAutoDetected, setHasAutoDetected] = useState(false);\n   125→  const [autoZoomEnabled, setAutoZoomEnabled] = useState(true);\n   126→  const [detectionFailed, setDetectionFailed] = useState(false);\n   127→  const [placedLandmarks, setPlacedLandmarks] = useState<Set<string>>(new Set());\n   128→  // Frankfort Plane for side profile visualization (from server detection)\n   129→  const [frankfortPlane, setFrankfortPlane] = useState<{\n   130→    angle: number;\n   131→    orbitale: { x: number; y: number };\n   132→    porion: { x: number; y: number };\n   133→  } | null>(null);\n   134→  // Show ear landmark adjustment mode (for side profile only)\n   135→  const [showAdjustmentMode, setShowAdjustmentMode] = useState(false);\n   136→  // Track if ear landmarks have been adjusted\n   137→  const [earLandmarksAdjusted, setEarLandmarksAdjusted] = useState(false);\n   138→\n   139→  const currentLandmarkId = orderedIds[currentStepIndex];\n   140→  const currentLandmark = landmarks.find((lm) => lm.id === currentLandmarkId);\n   141→  const totalSteps = orderedIds.length;\n   142→  const progress = ((currentStepIndex + 1) / totalSteps) * 100;\n   143→\n   144→  const color = currentLandmark\n   145→    ? getLandmarkColor(currentLandmark.id, categories)\n   146→    : '#00f3ff';\n   147→\n   148→  // Load image dimensions on mount\n   149→  useEffect(() => {\n   150→    const img = new window.Image();\n   151→    img.onload = () => {\n   152→      setImageDimensions({ width: img.naturalWidth, height: img.naturalHeight });\n   153→    };\n   154→    img.src = imageUrl;\n   155→  }, [imageUrl]);\n   156→\n   157→  // Track container size changes with ResizeObserver\n   158→  useEffect(() => {\n   159→    if (!containerRef.current) return;\n   160→\n   161→    const observer = new ResizeObserver((entries) => {\n   162→      const { width, height } = entries[0].contentRect;\n   163→      setContainerSize({ width, height });\n   164→    });\n   165→\n   166→    observer.observe(containerRef.current);\n   167→    return () => observer.disconnect();\n   168→  }, []);\n   169→\n   170→  // Calculate the rendered image bounds within the container (accounting for object-contain)\n   171→  const getImageBounds = useCallback(() => {\n   172→    if (!containerRef.current || !imageDimensions || !containerSize) {\n   173→      return { offsetX: 0, offsetY: 0, renderedWidth: 1, renderedHeight: 1, containerWidth: 1, containerHeight: 1 };\n   174→    }\n   175→\n   176→    const containerWidth = containerSize.width;\n   177→    const containerHeight = containerSize.height;\n   178→    const imageAspect = imageDimensions.width / imageDimensions.height;\n   179→    const containerAspect = containerWidth / containerHeight;\n   180→\n   181→    let renderedWidth: number;\n   182→    let renderedHeight: number;\n   183→    let offsetX = 0;\n   184→    let offsetY = 0;\n   185→\n   186→    if (imageAspect > containerAspect) {\n   187→      renderedWidth = containerWidth;\n   188→      renderedHeight = containerWidth / imageAspect;\n   189→      offsetY = (containerHeight - renderedHeight) / 2;\n   190→    } else {\n   191→      renderedHeight = containerHeight;\n   192→      renderedWidth = containerHeight * imageAspect;\n   193→      offsetX = (containerWidth - renderedWidth) / 2;\n   194→    }\n   195→\n   196→    return { offsetX, offsetY, renderedWidth, renderedHeight, containerWidth, containerHeight };\n   197→  }, [imageDimensions, containerSize]);\n   198→\n   199→  // Get what normalized coordinates the center orb points to on the image\n   200→  const getCrosshairNormalizedPosition = useCallback(() => {\n   201→    const bounds = getImageBounds();\n   202→    if (!bounds.renderedWidth || !bounds.renderedHeight) {\n   203→      return { x: 0.5, y: 0.5 };\n   204→    }\n   205→\n   206→    // The container center (where the orb is) in screen coordinates\n   207→    const containerCenterX = bounds.containerWidth / 2;\n   208→    const containerCenterY = bounds.containerHeight / 2;\n   209→\n   210→    // The transform is: translate(pan.x, pan.y) scale(zoomLevel)\n   211→    // To find what image point is at container center, we reverse this:\n   212→    // 1. The point at container center after transform comes from:\n   213→    //    screenPos = imagePos * zoomLevel + pan\n   214→    // 2. Solving for imagePos:\n   215→    //    imagePos = (screenPos - pan) / zoomLevel\n   216→    const imageX = (containerCenterX - pan.x) / zoomLevel;\n   217→    const imageY = (containerCenterY - pan.y) / zoomLevel;\n   218→\n   219→    // Convert to normalized (0-1) coordinates within the image\n   220→    const normalizedX = (imageX - bounds.offsetX) / bounds.renderedWidth;\n   221→    const normalizedY = (imageY - bounds.offsetY) / bounds.renderedHeight;\n   222→\n   223→    return {\n   224→      x: Math.max(0, Math.min(1, normalizedX)),\n   225→      y: Math.max(0, Math.min(1, normalizedY)),\n   226→    };\n   227→  }, [getImageBounds, pan, zoomLevel]);\n   228→\n   229→  // Convert normalized image coordinates (0-1) to pixel position within the container\n   230→  // Note: This is used for landmarks INSIDE the transformed container, so no zoom/pan needed\n   231→  const getLandmarkPixelPosition = useCallback((x: number, y: number) => {\n   232→    const bounds = getImageBounds();\n   233→    // Position relative to container (the parent transform handles zoom/pan)\n   234→    const pixelX = bounds.offsetX + x * bounds.renderedWidth;\n   235→    const pixelY = bounds.offsetY + y * bounds.renderedHeight;\n   236→    return { left: pixelX, top: pixelY };\n   237→  }, [getImageBounds]);\n   238→\n   239→  useEffect(() => {\n   240→    onLandmarksChange?.(landmarks);\n   241→  }, [landmarks, onLandmarksChange]);\n   242→\n   243→  // Confirm placement: set current landmark to where crosshair points\n   244→  const confirmPlacement = useCallback(() => {\n   245→    const pos = getCrosshairNormalizedPosition();\n   246→    setLandmarks((prev) =>\n   247→      prev.map((lm) =>\n   248→        lm.id === currentLandmarkId ? { ...lm, x: pos.x, y: pos.y } : lm\n   249→      )\n   250→    );\n   251→    setPlacedLandmarks((prev) => new Set(prev).add(currentLandmarkId));\n   252→  }, [currentLandmarkId, getCrosshairNormalizedPosition]);\n   253→\n   254→  // Handle click - confirms placement at crosshair position\n   255→  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n   256→  const handleContainerClick = useCallback(() => {\n   257→    if (isDragging) return;\n   258→    confirmPlacement();\n   259→  }, [isDragging, confirmPlacement]);\n   260→\n   261→  // Mouse down - start dragging to pan\n   262→  const handleMouseDown = useCallback(\n   263→    (e: React.MouseEvent) => {\n   264→      if (e.button === 0) {\n   265→        setIsDragging(true);\n   266→        setDragStart({ x: e.clientX - pan.x, y: e.clientY - pan.y });\n   267→      }\n   268→    },\n   269→    [pan]\n   270→  );\n   271→\n   272→  // Mouse move - pan the image\n   273→  const handleMouseMove = useCallback(\n   274→    (e: React.MouseEvent) => {\n   275→      if (isDragging) {\n   276→        setPan({\n   277→          x: e.clientX - dragStart.x,\n   278→          y: e.clientY - dragStart.y,\n   279→        });\n   280→      }\n   281→    },\n   282→    [isDragging, dragStart]\n   283→  );\n   284→\n   285→  const handleMouseUp = useCallback(() => {\n   286→    setIsDragging(false);\n   287→  }, []);\n   288→\n   289→  const handleResetZoom = useCallback(() => {\n   290→    setZoomLevel(2); // Reset to 2x\n   291→    setPan({ x: 0, y: 0 });\n   292→  }, []);\n   293→\n   294→  // Pan the image using arrow keys (moves the crosshair target point on the image)\n   295→  const panImage = useCallback((direction: 'up' | 'down' | 'left' | 'right') => {\n   296→    const step = 20; // pixels to pan per keypress\n   297→    setPan((prev) => {\n   298→      switch (direction) {\n   299→        case 'up': return { ...prev, y: prev.y + step };\n   300→        case 'down': return { ...prev, y: prev.y - step };\n   301→        case 'left': return { ...prev, x: prev.x + step };\n   302→        case 'right': return { ...prev, x: prev.x - step };\n   303→        default: return prev;\n   304→      }\n   305→    });\n   306→  }, []);\n   307→\n   308→  const handleNext = useCallback(() => {\n   309→    // Confirm placement at current crosshair position before moving to next\n   310→    confirmPlacement();\n   311→\n   312→    if (currentStepIndex < totalSteps - 1) {\n   313→      setCurrentStepIndex((prev) => prev + 1);\n   314→      // Don't reset zoom - let zoomToLandmark handle it\n   315→    } else {\n   316→      onComplete?.(landmarks);\n   317→    }\n   318→  }, [currentStepIndex, totalSteps, landmarks, onComplete, confirmPlacement]);\n   319→\n   320→\n   321→  const handlePrevious = useCallback(() => {\n   322→    if (currentStepIndex > 0) {\n   323→      setCurrentStepIndex((prev) => prev - 1);\n   324→      handleResetZoom();\n   325→    } else {\n   326→      onBack?.();\n   327→    }\n   328→  }, [currentStepIndex, handleResetZoom, onBack]);\n   329→\n   330→  // Landmark-specific zoom levels for optimal precision\n   331→  // Fine detail landmarks (pupils, eyelids) get higher zoom, larger areas get lower zoom\n   332→  const LANDMARK_ZOOM_LEVELS: Record<string, number> = {\n   333→    // 2x zoom - larger landmarks\n   334→    trichion: 2,\n   335→    left_temporal: 2, right_temporal: 2,\n   336→    left_auricular_lateral: 2, right_auricular_lateral: 2,\n   337→\n   338→    // 4x zoom - medium detail landmarks\n   339→    left_pupila: 4, right_pupila: 4,\n   340→    left_canthus_medialis: 4, left_canthus_lateralis: 4,\n   341→    right_canthus_medialis: 4, right_canthus_lateralis: 4,\n   342→    left_sulcus_palpebralis_lateralis: 4, right_sulcus_palpebralis_lateralis: 4,\n   343→    left_supercilium_medialis: 4, left_supercilium_medial_corner: 4,\n   344→    left_supercilium_superior: 4, left_supercilium_apex: 4, left_supercilium_lateralis: 4,\n   345→    right_supercilium_medialis: 4, right_supercilium_medial_corner: 4,\n   346→    right_supercilium_superior: 4, right_supercilium_apex: 4, right_supercilium_lateralis: 4,\n   347→    left_ala_nasi: 4, right_ala_nasi: 4,\n   348→    nasal_base: 4, subnasale: 4,\n   349→    left_dorsum_nasi: 4, right_dorsum_nasi: 4,\n   350→    labrale_superius: 4, cupids_bow: 4, mouth_middle: 4,\n   351→    labrale_inferius: 4, left_cheilion: 4, right_cheilion: 4,\n   352→    left_gonion_superior: 4, left_gonion_inferior: 4,\n   353→    right_gonion_superior: 4, right_gonion_inferior: 4,\n   354→    left_mentum_lateralis: 4, right_mentum_lateralis: 4, menton: 4,\n   355→    left_zygion: 2, right_zygion: 2,\n   356→    left_cervical_lateralis: 4, right_cervical_lateralis: 4,\n   357→\n   358→    // 8x zoom - fine detail landmarks (eyelids)\n   359→    left_palpebra_superior: 8, left_palpebra_inferior: 8,\n   360→    right_palpebra_superior: 8, right_palpebra_inferior: 8,\n   361→    left_pretarsal_skin_crease: 8, right_pretarsal_skin_crease: 8,\n   362→\n   363→    // ========== SIDE PROFILE LANDMARKS ==========\n   364→    // Note: Some IDs shared with front profile (trichion, subnasale, menton) - zoom applies to both\n   365→    // 2x zoom - larger side landmarks\n   366→    vertex: 2,\n   367→    occiput: 2,\n   368→    neckPoint: 2,\n   369→    forehead: 2, // Separate from glabella\n   370→\n   371→    // 4x zoom - medium detail side landmarks\n   372→    porion: 4,\n   373→    orbitale: 4,\n   374→    tragus: 4,\n   375→    intertragicNotch: 4,\n   376→    cornealApex: 4,\n   377→    eyelidEnd: 4, // Lateral eyelid end in side profile\n   378→    lowerEyelid: 4, // Lower eyelid margin in side profile\n   379→    cheekbone: 4,\n   380→    glabella: 4,\n   381→    nasion: 4,\n   382→    pronasale: 4,\n   383→    rhinion: 4,\n   384→    supratip: 4,\n   385→    infratip: 4,\n   386→    columella: 4,\n   387→    subalare: 4,\n   388→    labraleSuperius: 4,\n   389→    cheilion: 4,\n   390→    labraleInferius: 4,\n   391→    sublabiale: 4,\n   392→    pogonion: 4,\n   393→    // menton: 4 already defined in front section (applies to both profiles)\n   394→    cervicalPoint: 4,\n   395→    gonionTop: 4,\n   396→    gonionBottom: 4,\n   397→  };\n   398→\n   399→  // Auto-zoom to the current landmark's region - centers the landmark under the fixed orb\n   400→  const zoomToLandmark = useCallback((landmarkId: string) => {\n   401→    if (!autoZoomEnabled || !containerRef.current || !containerSize || !imageDimensions) return;\n   402→\n   403→    const landmark = landmarks.find(lm => lm.id === landmarkId);\n   404→    if (!landmark) return;\n   405→\n   406→    const bounds = getImageBounds();\n   407→    if (bounds.renderedWidth <= 1 || bounds.renderedHeight <= 1) return; // Bounds not ready\n   408→\n   409→    // Use landmark-specific zoom level, default to 2x\n   410→    const newZoom = LANDMARK_ZOOM_LEVELS[landmarkId] || 2;\n   411→    setZoomLevel(newZoom);\n   412→\n   413→    // Calculate pan so the landmark appears at container center (under the fixed orb)\n   414→    const containerCenterX = bounds.containerWidth / 2;\n   415→    const containerCenterY = bounds.containerHeight / 2;\n   416→\n   417→    // Where the landmark is in unzoomed image space\n   418→    const landmarkX = bounds.offsetX + landmark.x * bounds.renderedWidth;\n   419→    const landmarkY = bounds.offsetY + landmark.y * bounds.renderedHeight;\n   420→\n   421→    // Pan needed: after zoom, landmark should be at container center\n   422→    // Transform is: translate(pan) scale(zoom) with origin at 0,0\n   423→    // A point at landmarkPos ends up at: landmarkPos * zoom + pan\n   424→    // We want it at containerCenter, so: pan = containerCenter - landmarkPos * zoom\n   425→    setPan({\n   426→      x: containerCenterX - landmarkX * newZoom,\n   427→      y: containerCenterY - landmarkY * newZoom,\n   428→    });\n   429→  }, [autoZoomEnabled, landmarks, getImageBounds, containerSize, imageDimensions]);\n   430→\n   431→  // Auto-detect landmarks using Human.js/MediaPipe\n   432→  const handleAutoDetect = useCallback(async () => {\n   433→    setIsDetecting(true);\n   434→    setDetectionFailed(false);\n   435→    setFrankfortPlane(null);\n   436→    try {\n   437→      const result = await detectFromImageUrl(imageUrl, mode);\n   438→      console.log('[DEBUG] Detection result:', result);\n   439→      console.log('[DEBUG] Sample landmarks:', result?.landmarks.slice(0, 5));\n   440→      if (result && result.landmarks.length > 0) {\n   441→        // Update landmarks with detected positions\n   442→        setLandmarks(prev =>\n   443→          prev.map(lm => {\n   444→            const detected = result.landmarks.find(d => d.id === lm.id);\n   445→            if (detected) {\n   446→              return { ...lm, x: detected.x, y: detected.y };\n   447→            }\n   448→            return lm;\n   449→          })\n   450→        );\n   451→        setHasAutoDetected(true);\n   452→        setDetectionFailed(false);\n   453→\n   454→        // Capture Frankfort Plane for side profile (from server-side detection)\n   455→        if (mode === 'side' && result.frankfortPlane) {\n   456→          console.log('[DEBUG] Frankfort Plane:', result.frankfortPlane);\n   457→          setFrankfortPlane(result.frankfortPlane);\n   458→        }\n   459→\n   460→        // Zoom to first landmark after detection\n   461→        zoomToLandmark(orderedIds[0]);\n   462→      } else {\n   463→        // Detection returned no results - common for side profile\n   464→        console.log('[DEBUG] No landmarks detected - manual placement required');\n   465→        setDetectionFailed(true);\n   466→        setHasAutoDetected(false);\n   467→      }\n   468→    } catch (error) {\n   469→      console.error('Auto-detection failed:', error);\n   470→      setDetectionFailed(true);\n   471→    } finally {\n   472→      setIsDetecting(false);\n   473→    }\n   474→  }, [imageUrl, mode, orderedIds, zoomToLandmark]);\n   475→\n   476→  // Auto-detect after image dimensions are loaded (prevents race condition)\n   477→  useEffect(() => {\n   478→    if (imageDimensions) {\n   479→      handleAutoDetect();\n   480→    }\n   481→    // eslint-disable-next-line react-hooks/exhaustive-deps\n   482→  }, [imageDimensions]); // Run after dimensions are loaded\n   483→\n   484→  // Auto-zoom when step changes or container size becomes available\n   485→  useEffect(() => {\n   486→    if (hasAutoDetected && autoZoomEnabled && currentLandmarkId && containerSize) {\n   487→      zoomToLandmark(currentLandmarkId);\n   488→    }\n   489→  }, [currentStepIndex, currentLandmarkId, hasAutoDetected, autoZoomEnabled, zoomToLandmark, containerSize]);\n   490→\n   491→  // Keyboard handlers with proper state tracking\n   492→  useEffect(() => {\n   493→    const handleKeyDown = (e: KeyboardEvent) => {\n   494→      if (['ArrowUp', 'ArrowDown', 'ArrowLeft', 'ArrowRight', 'Enter', 'Backspace', 'r', 'R'].includes(e.key)) {\n   495→        e.preventDefault();\n   496→      }\n   497→\n   498→      setPressedKeys((prev) => new Set(prev).add(e.key));\n   499→\n   500→      switch (e.key) {\n   501→        case 'ArrowUp': panImage('up'); break;\n   502→        case 'ArrowDown': panImage('down'); break;\n   503→        case 'ArrowLeft': panImage('left'); break;\n   504→        case 'ArrowRight': panImage('right'); break;\n   505→        case 'Enter': handleNext(); break;\n   506→        case 'Backspace': handlePrevious(); break;\n   507→        case 'r':\n   508→        case 'R': handleResetZoom(); break;\n   509→      }\n   510→    };\n   511→\n   512→    const handleKeyUp = (e: KeyboardEvent) => {\n   513→      setPressedKeys((prev) => {\n   514→        const next = new Set(prev);\n   515→        next.delete(e.key);\n   516→        return next;\n   517→      });\n   518→    };\n   519→\n   520→    window.addEventListener('keydown', handleKeyDown);\n   521→    window.addEventListener('keyup', handleKeyUp);\n   522→    return () => {\n   523→      window.removeEventListener('keydown', handleKeyDown);\n   524→      window.removeEventListener('keyup', handleKeyUp);\n   525→    };\n   526→  }, [panImage, handleNext, handlePrevious, handleResetZoom]);\n   527→\n   528→  const isKeyPressed = (key: string) => pressedKeys.has(key);\n   529→\n   530→  // Render LandmarkEditor for ear landmark adjustment (side profile only)\n   531→  if (showAdjustmentMode && mode === 'side') {\n   532→    return (\n   533→      <LandmarkEditor\n   534→        imageUrl={imageUrl}\n   535→        landmarks={landmarks.map(lm => ({ id: lm.id, x: lm.x, y: lm.y }))}\n   536→        onConfirm={handleAdjustmentConfirm}\n   537→        onSkip={() => setShowAdjustmentMode(false)}\n   538→      />\n   539→    );\n   540→  }\n   541→\n   542→  return (\n   543→    <div className=\"fixed inset-0 bg-black\">\n   544→      <div className=\"flex flex-col md:flex-row h-full gap-3 p-3 md:p-4\">\n   545→        {/* Sidebar - Right on desktop */}\n   546→        <div className=\"w-full md:w-80 flex-shrink-0 flex flex-col gap-3 md:order-2 overflow-hidden md:overflow-y-auto\">\n   547→          {/* Progress Card */}\n   548→          <div className=\"bg-neutral-900 rounded-xl border border-neutral-800 overflow-hidden flex-shrink-0\">\n   549→            <div className=\"p-4\">\n   550→              <div className=\"flex items-center justify-between text-xs text-neutral-400 mb-2\">\n   551→                <span>Step {currentStepIndex + 1} of {totalSteps}</span>\n   552→                <span>{Math.round(progress)}%</span>\n   553→              </div>\n   554→              <div className=\"h-1.5 bg-neutral-800 rounded-full overflow-hidden mb-3\">\n   555→                <motion.div\n   556→                  className=\"h-full rounded-full\"\n   557→                  style={{ width: `${progress}%`, backgroundColor: '#00f3ff' }}\n   558→                  transition={{ duration: 0.3 }}\n   559→                />\n   560→              </div>\n   561→              <div className=\"flex items-center gap-2\">\n   562→                <div className=\"w-6 h-6 bg-[#00f3ff] rounded-full flex items-center justify-center flex-shrink-0\">\n   563→                  <Check className=\"w-3.5 h-3.5 text-black\" />\n   564→                </div>\n   565→                <span className=\"text-sm font-medium text-white\">\n   566→                  {currentStepIndex} placed\n   567→                </span>\n   568→              </div>\n   569→            </div>\n   570→\n   571→            {/* View Tabs */}\n   572→            <div className=\"flex border-t border-neutral-800\">\n   573→              <button\n   574→                onClick={() => setActiveTab('info')}\n   575→                className={`flex-1 py-2.5 text-xs font-medium transition-colors ${activeTab === 'info'\n   576→                  ? 'text-[#00f3ff] border-b-2 border-[#00f3ff]'\n   577→                  : 'text-neutral-500 hover:text-neutral-300'\n   578→                  }`}\n   579→              >\n   580→                Current Point\n   581→              </button>\n   582→              <button\n   583→                onClick={() => setActiveTab('reference')}\n   584→                className={`flex-1 py-2.5 text-xs font-medium transition-colors ${activeTab === 'reference'\n   585→                  ? 'text-[#00f3ff] border-b-2 border-[#00f3ff]'\n   586→                  : 'text-neutral-500 hover:text-neutral-300'\n   587→                  }`}\n   588→              >\n   589→                Reference\n   590→              </button>\n   591→            </div>\n   592→\n   593→            {/* Info/Reference Content */}\n   594→            <div className=\"bg-neutral-900/50\">\n   595→              {activeTab === 'info' ? (\n   596→                <div>\n   597→                  {/* Photo Reference Image */}\n   598→                  {currentLandmark && getLandmarkImagePath(currentLandmark.id, mode, 'photo') ? (\n   599→                    <div className=\"relative w-full aspect-square bg-neutral-800\">\n   600→                      <Image\n   601→                        src={getLandmarkImagePath(currentLandmark.id, mode, 'photo')!}\n   602→                        alt={currentLandmark.label}\n   603→                        fill\n   604→                        className=\"object-contain\"\n   605→                        unoptimized\n   606→                      />\n   607→                    </div>\n   608→                  ) : (\n   609→                    <div className=\"w-full aspect-square bg-neutral-800 flex items-center justify-center\">\n   610→                      <div\n   611→                        className=\"w-14 h-14 rounded-full flex items-center justify-center\"\n   612→                        style={{ backgroundColor: `${color}20`, border: `2px solid ${color}` }}\n   613→                      >\n   614→                        <div className=\"w-4 h-4 rounded-full\" style={{ backgroundColor: color }} />\n   615→                      </div>\n   616→                    </div>\n   617→                  )}\n   618→                  <div className=\"p-3 text-center border-t border-neutral-800\">\n   619→                    <p className=\"text-sm font-semibold text-white\">{currentLandmark?.label}</p>\n   620→                    <p className=\"text-xs text-[#00f3ff] mt-0.5 font-mono\">{currentLandmark?.medicalTerm}</p>\n   621→                  </div>\n   622→                </div>\n   623→              ) : (\n   624→                <div>\n   625→                  {/* Infographic Reference Image */}\n   626→                  {currentLandmark && getLandmarkImagePath(currentLandmark.id, mode, 'infographic') ? (\n   627→                    <div className=\"relative w-full aspect-square bg-neutral-800\">\n   628→                      <Image\n   629→                        src={getLandmarkImagePath(currentLandmark.id, mode, 'infographic')!}\n   630→                        alt={`${currentLandmark.label} infographic`}\n   631→                        fill\n   632→                        className=\"object-contain\"\n   633→                        unoptimized\n   634→                      />\n   635→                    </div>\n   636→                  ) : (\n   637→                    <div className=\"w-full aspect-square bg-neutral-800 flex items-center justify-center\">\n   638→                      <Info className=\"w-12 h-12 text-neutral-600\" />\n   639→                    </div>\n   640→                  )}\n   641→                  <div className=\"p-3 text-center border-t border-neutral-800\">\n   642→                    <p className=\"text-sm text-neutral-300\">\n   643→                      {currentLandmark ? getLandmarkPlacementGuide(currentLandmark.id, mode) : ''}\n   644→                    </p>\n   645→                  </div>\n   646→                </div>\n   647→              )}\n   648→            </div>\n   649→          </div>\n   650→\n   651→          {/* Keyboard Shortcuts - Desktop only */}\n   652→          <div className=\"hidden md:flex flex-col gap-3\">\n   653→            <div className=\"bg-neutral-900 rounded-xl border border-neutral-800 p-4\">\n   654→              <p className=\"text-xs text-neutral-500 font-medium uppercase tracking-wide mb-3 text-center\">\n   655→                Keyboard Controls\n   656→              </p>\n   657→              <div className=\"flex justify-center mb-4\">\n   658→                <div className=\"flex flex-col gap-1 items-center\">\n   659→                  {/* Arrow Up */}\n   660→                  <div\n   661→                    className={`w-10 h-10 rounded-lg flex items-center justify-center transition-all duration-100 ${isKeyPressed('ArrowUp')\n   662→                      ? 'bg-[#00f3ff] text-black shadow-[0_0_15px_rgba(0,243,255,0.5)]'\n   663→                      : 'bg-neutral-800 text-neutral-400 border border-neutral-700'\n   664→                      }`}\n   665→                  >\n   666→                    <ChevronUp className=\"w-5 h-5\" />\n   667→                  </div>\n   668→                  {/* Arrow Row */}\n   669→                  <div className=\"flex gap-1\">\n   670→                    {[\n   671→                      { key: 'ArrowLeft', icon: ChevronLeft },\n   672→                      { key: 'ArrowDown', icon: ChevronDown },\n   673→                      { key: 'ArrowRight', icon: ChevronRight },\n   674→                    ].map(({ key, icon: Icon }) => (\n   675→                      <div\n   676→                        key={key}\n   677→                        className={`w-10 h-10 rounded-lg flex items-center justify-center transition-all duration-100 ${isKeyPressed(key)\n   678→                          ? 'bg-[#00f3ff] text-black shadow-[0_0_15px_rgba(0,243,255,0.5)]'\n   679→                          : 'bg-neutral-800 text-neutral-400 border border-neutral-700'\n   680→                          }`}\n   681→                      >\n   682→                        <Icon className=\"w-5 h-5\" />\n   683→                      </div>\n   684→                    ))}\n   685→                  </div>\n   686→                </div>\n   687→              </div>\n   688→\n   689→              <div className=\"space-y-2 text-sm\">\n   690→                <div className=\"flex items-center justify-between\">\n   691→                  <span\n   692→                    className={`px-2 py-1 rounded font-mono text-xs transition-all duration-100 ${isKeyPressed('Enter')\n   693→                      ? 'bg-[#00f3ff] text-black'\n   694→                      : 'bg-neutral-800 text-neutral-400'\n   695→                      }`}\n   696→                  >\n   697→                    Enter\n   698→                  </span>\n   699→                  <span className=\"text-neutral-500\">Next point</span>\n   700→                </div>\n   701→                <div className=\"flex items-center justify-between\">\n   702→                  <span\n   703→                    className={`px-2 py-1 rounded font-mono text-xs transition-all duration-100 ${isKeyPressed('Backspace')\n   704→                      ? 'bg-[#00f3ff] text-black'\n   705→                      : 'bg-neutral-800 text-neutral-400'\n   706→                      }`}\n   707→                  >\n   708→                    Backspace\n   709→                  </span>\n   710→                  <span className=\"text-neutral-500\">Previous</span>\n   711→                </div>\n   712→                <div className=\"flex items-center justify-between\">\n   713→                  <span\n   714→                    className={`px-2 py-1 rounded font-mono text-xs transition-all duration-100 ${isKeyPressed('r') || isKeyPressed('R')\n   715→                      ? 'bg-[#00f3ff] text-black'\n   716→                      : 'bg-neutral-800 text-neutral-400'\n   717→                      }`}\n   718→                  >\n   719→                    R\n   720→                  </span>\n   721→                  <span className=\"text-neutral-500\">Reset zoom</span>\n   722→                </div>\n   723→              </div>\n   724→            </div>\n   725→\n   726→            {/* Zoom Controls */}\n   727→            <div className=\"bg-neutral-900 rounded-xl border border-neutral-800 p-4\">\n   728→              <p className=\"text-xs text-neutral-500 font-medium uppercase tracking-wide mb-3\">\n   729→                Zoom Level\n   730→              </p>\n   731→              <div className=\"flex gap-2\">\n   732→                {/* 2x/4x/8x discrete zoom levels */}\n   733→                {[2, 4, 8].map((level) => (\n   734→                  <button\n   735→                    key={level}\n   736→                    onClick={() => {\n   737→                      if (containerSize) {\n   738→                        // Adjust pan to keep the same center point visible when zoom changes\n   739→                        // Current center in image space: imageCenter = (containerCenter - pan) / oldZoom\n   740→                        // New pan to show same center: newPan = containerCenter - imageCenter * newZoom\n   741→                        const containerCenterX = containerSize.width / 2;\n   742→                        const containerCenterY = containerSize.height / 2;\n   743→                        const imageCenterX = (containerCenterX - pan.x) / zoomLevel;\n   744→                        const imageCenterY = (containerCenterY - pan.y) / zoomLevel;\n   745→                        const newPanX = containerCenterX - imageCenterX * level;\n   746→                        const newPanY = containerCenterY - imageCenterY * level;\n   747→                        setZoomLevel(level);\n   748→                        setPan({ x: newPanX, y: newPanY });\n   749→                      } else {\n   750→                        setZoomLevel(level);\n   751→                      }\n   752→                    }}\n   753→                    className={`flex-1 py-2 rounded-lg text-sm font-medium transition-all ${zoomLevel === level\n   754→                      ? 'bg-[#00f3ff] text-black'\n   755→                      : 'bg-neutral-800 text-neutral-400 hover:bg-neutral-700'\n   756→                      }`}\n   757→                  >\n   758→                    {level}x\n   759→                  </button>\n   760→                ))}\n   761→              </div>\n   762→            </div>\n   763→\n   764→            {/* Auto-Detect Button */}\n   765→            <button\n   766→              onClick={handleAutoDetect}\n   767→              disabled={isDetecting}\n   768→              className={`w-full py-3 rounded-lg text-sm font-medium transition-all flex items-center justify-center gap-2 ${hasAutoDetected\n   769→                ? 'bg-green-500/20 text-green-400 border border-green-500/30'\n   770→                : 'bg-gradient-to-r from-[#00f3ff] to-[#00c4cc] text-black hover:shadow-[0_0_20px_rgba(0,243,255,0.3)]'\n   771→                } disabled:opacity-50 disabled:cursor-not-allowed`}\n   772→            >\n   773→              {isDetecting ? (\n   774→                <>\n   775→                  <Loader2 className=\"w-4 h-4 animate-spin\" />\n   776→                  Detecting...\n   777→                </>\n   778→              ) : hasAutoDetected ? (\n   779→                <>\n   780→                  <Check className=\"w-4 h-4\" />\n   781→                  Detected - Adjust if needed\n   782→                </>\n   783→              ) : (\n   784→                <>\n   785→                  <Scan className=\"w-4 h-4\" />\n   786→                  Auto-Detect Landmarks\n   787→                </>\n   788→              )}\n   789→            </button>\n   790→\n   791→            {/* Adjust Ear Landmarks Button - Side profile only */}\n   792→            {hasEstimatedEarLandmarks && hasAutoDetected && (\n   793→              <button\n   794→                onClick={() => setShowAdjustmentMode(true)}\n   795→                className={`w-full py-3 rounded-lg text-sm font-medium transition-all flex items-center justify-center gap-2 ${\n   796→                  earLandmarksAdjusted\n   797→                    ? 'bg-green-500/20 text-green-400 border border-green-500/30'\n   798→                    : 'bg-amber-500/20 text-amber-400 border border-amber-500/30 hover:bg-amber-500/30'\n   799→                }`}\n   800→              >\n   801→                <Settings2 className=\"w-4 h-4\" />\n   802→                {earLandmarksAdjusted ? 'Ear Landmarks Adjusted' : 'Adjust Ear Landmarks'}\n   803→              </button>\n   804→            )}\n   805→\n   806→            {/* Auto-Zoom Toggle */}\n   807→            <button\n   808→              onClick={() => setAutoZoomEnabled(!autoZoomEnabled)}\n   809→              className={`w-full py-2.5 rounded-lg text-xs font-medium transition-all flex items-center justify-center gap-2 ${autoZoomEnabled\n   810→                ? 'bg-[#00f3ff] text-black'\n   811→                : 'bg-neutral-800 text-neutral-400 hover:bg-neutral-700'\n   812→                }`}\n   813→            >\n   814→              <Focus className=\"w-4 h-4\" />\n   815→              {autoZoomEnabled ? 'Auto-Zoom: ON' : 'Auto-Zoom: OFF'}\n   816→            </button>\n   817→\n   818→          </div>\n   819→        </div>\n   820→\n   821→        {/* Main Image Area */}\n   822→        <div className=\"flex-1 min-h-0 relative md:order-1 flex flex-col\">\n   823→          <div\n   824→            ref={containerRef}\n   825→            className=\"relative flex-1 bg-neutral-900 overflow-hidden rounded-xl border border-neutral-800 select-none\"\n   826→            onMouseDown={handleMouseDown}\n   827→            onMouseMove={handleMouseMove}\n   828→            onMouseUp={handleMouseUp}\n   829→            onMouseLeave={handleMouseUp}\n   830→            style={{\n   831→              cursor: isDragging ? 'grabbing' : 'grab',\n   832→            }}\n   833→          >\n   834→            {/* Transformed Content - Image and placed landmarks move together */}\n   835→            <div\n   836→              className=\"absolute inset-0\"\n   837→              style={{\n   838→                transform: `translate(${pan.x}px, ${pan.y}px) scale(${zoomLevel})`,\n   839→                transformOrigin: '0 0',\n   840→              }}\n   841→            >\n   842→              {/* User's Image */}\n   843→              <Image\n   844→                src={imageUrl}\n   845→                alt=\"Your photo\"\n   846→                fill\n   847→                className=\"object-contain pointer-events-none select-none\"\n   848→                unoptimized\n   849→                draggable={false}\n   850→              />\n   851→\n   852→              {/* Placed landmarks - always visible as they're placed */}\n   853→              {landmarks.filter(lm => placedLandmarks.has(lm.id) && lm.id !== currentLandmarkId).map((landmark) => {\n   854→                const lmColor = getLandmarkColor(landmark.id, categories);\n   855→                const pos = getLandmarkPixelPosition(landmark.x, landmark.y);\n   856→\n   857→                return (\n   858→                  <div\n   859→                    key={landmark.id}\n   860→                    className=\"absolute pointer-events-none\"\n   861→                    style={{\n   862→                      left: pos.left,\n   863→                      top: pos.top,\n   864→                      transform: `translate(-50%, -50%) scale(${1 / zoomLevel})`,\n   865→                      transformOrigin: 'center center',\n   866→                    }}\n   867→                  >\n   868→                    {/* Small persistent dot - matches Harmony style */}\n   869→                    <div\n   870→                      className=\"absolute rounded-full\"\n   871→                      style={{\n   872→                        width: 8,\n   873→                        height: 8,\n   874→                        left: -4,\n   875→                        top: -4,\n   876→                        backgroundColor: lmColor,\n   877→                        boxShadow: `0 0 4px ${lmColor}, 0 0 8px ${lmColor}60`,\n   878→                        border: '1px solid rgba(255,255,255,0.5)',\n   879→                      }}\n   880→                    />\n   881→                  </div>\n   882→                );\n   883→              })}\n   884→\n   885→              {/* Frankfort Horizontal Plane - green reference line for side profiles */}\n   886→              {mode === 'side' && frankfortPlane && (\n   887→                <svg\n   888→                  className=\"absolute inset-0 pointer-events-none\"\n   889→                  style={{ width: '100%', height: '100%' }}\n   890→                >\n   891→                  {(() => {\n   892→                    const bounds = getImageBounds();\n   893→                    const orbitaleX = bounds.offsetX + frankfortPlane.orbitale.x * bounds.renderedWidth;\n   894→                    const orbitaleY = bounds.offsetY + frankfortPlane.orbitale.y * bounds.renderedHeight;\n   895→                    const porionX = bounds.offsetX + frankfortPlane.porion.x * bounds.renderedWidth;\n   896→                    const porionY = bounds.offsetY + frankfortPlane.porion.y * bounds.renderedHeight;\n   897→\n   898→                    // Extend the line beyond the points for visibility\n   899→                    const dx = porionX - orbitaleX;\n   900→                    const dy = porionY - orbitaleY;\n   901→                    const length = Math.sqrt(dx * dx + dy * dy);\n   902→                    const extendFactor = length > 0 ? 0.3 : 0;\n   903→                    const startX = orbitaleX - (dx / length) * bounds.renderedWidth * extendFactor;\n   904→                    const startY = orbitaleY - (dy / length) * bounds.renderedWidth * extendFactor;\n   905→                    const endX = porionX + (dx / length) * bounds.renderedWidth * extendFactor;\n   906→                    const endY = porionY + (dy / length) * bounds.renderedWidth * extendFactor;\n   907→\n   908→                    return (\n   909→                      <>\n   910→                        {/* Main Frankfort line */}\n   911→                        <line\n   912→                          x1={startX}\n   913→                          y1={startY}\n   914→                          x2={endX}\n   915→                          y2={endY}\n   916→                          stroke=\"#22c55e\"\n   917→                          strokeWidth={2 / zoomLevel}\n   918→                          strokeDasharray={`${6 / zoomLevel} ${4 / zoomLevel}`}\n   919→                          opacity={0.8}\n   920→                        />\n   921→                        {/* Orbitale point marker */}\n   922→                        <circle\n   923→                          cx={orbitaleX}\n   924→                          cy={orbitaleY}\n   925→                          r={4 / zoomLevel}\n   926→                          fill=\"#22c55e\"\n   927→                          stroke=\"white\"\n   928→                          strokeWidth={1 / zoomLevel}\n   929→                        />\n   930→                        {/* Porion point marker */}\n   931→                        <circle\n   932→                          cx={porionX}\n   933→                          cy={porionY}\n   934→                          r={4 / zoomLevel}\n   935→                          fill=\"#22c55e\"\n   936→                          stroke=\"white\"\n   937→                          strokeWidth={1 / zoomLevel}\n   938→                        />\n   939→                        {/* Angle indicator */}\n   940→                        <text\n   941→                          x={startX}\n   942→                          y={startY - 10 / zoomLevel}\n   943→                          fill=\"#22c55e\"\n   944→                          fontSize={12 / zoomLevel}\n   945→                          fontWeight=\"bold\"\n   946→                        >\n   947→                          FH: {frankfortPlane.angle.toFixed(1)}°\n   948→                        </text>\n   949→                      </>\n   950→                    );\n   951→                  })()}\n   952→                </svg>\n   953→              )}\n   954→            </div>\n   955→\n   956→            {/* FIXED CENTER TARGETING DOT - small precise point for accurate placement */}\n   957→            <div className=\"absolute inset-0 pointer-events-none flex items-center justify-center z-20\">\n   958→              {/* Crosshair lines for precision */}\n   959→              <div\n   960→                className=\"absolute\"\n   961→                style={{\n   962→                  width: 20,\n   963→                  height: 1,\n   964→                  backgroundColor: '#00f3ff',\n   965→                  opacity: 0.6,\n   966→                }}\n   967→              />\n   968→              <div\n   969→                className=\"absolute\"\n   970→                style={{\n   971→                  width: 1,\n   972→                  height: 20,\n   973→                  backgroundColor: '#00f3ff',\n   974→                  opacity: 0.6,\n   975→                }}\n   976→              />\n   977→              {/* Subtle glow ring */}\n   978→              <div\n   979→                className=\"absolute rounded-full\"\n   980→                style={{\n   981→                  width: 12,\n   982→                  height: 12,\n   983→                  background: 'radial-gradient(circle, #00f3ff33 0%, transparent 70%)',\n   984→                }}\n   985→              />\n   986→              {/* Center dot - small and precise */}\n   987→              <div\n   988→                className=\"relative rounded-full\"\n   989→                style={{\n   990→                  width: 4,\n   991→                  height: 4,\n   992→                  backgroundColor: '#00f3ff',\n   993→                  boxShadow: '0 0 6px #00f3ff, 0 0 12px #00f3ff80',\n   994→                }}\n   995→              />\n   996→            </div>\n   997→\n   998→            {/* Loading Overlay */}\n   999→            {isDetecting && (\n  1000→              <div className=\"absolute inset-0 bg-black/90 flex flex-col items-center justify-center z-50 backdrop-blur-sm\">\n  1001→                <div className=\"relative mb-8\">\n  1002→                  <motion.div\n  1003→                    animate={{ scale: [1, 1.2, 1], opacity: [0.5, 1, 0.5] }}\n  1004→                    transition={{ duration: 2, repeat: Infinity, ease: \"easeInOut\" }}\n  1005→                    className=\"absolute inset-0 bg-[#00f3ff]/20 blur-3xl rounded-full\"\n  1006→                  />\n  1007→                  <div className=\"relative w-20 h-20 rounded-2xl bg-neutral-900 border border-white/10 flex items-center justify-center shadow-[0_0_30px_rgba(0,243,255,0.15)]\">\n  1008→                    <Scan className=\"w-10 h-10 text-[#00f3ff]\" />\n  1009→                  </div>\n  1010→                </div>\n  1011→                <p className=\"text-white text-xl font-bold tracking-wide\">Mapping Biometrics...</p>\n  1012→                <div className=\"flex items-center gap-2 mt-3\">\n  1013→                  <Loader2 className=\"w-4 h-4 text-[#00f3ff] animate-spin\" />\n  1014→                  <p className=\"text-[#00f3ff] text-sm font-mono tracking-wider\">AI ANALYSIS IN PROGRESS</p>\n  1015→                </div>\n  1016→              </div>\n  1017→            )}\n  1018→\n  1019→            {/* Detection Failed Banner */}\n  1020→            {detectionFailed && !isDetecting && (\n  1021→              <motion.div\n  1022→                initial={{ opacity: 0, y: -20 }}\n  1023→                animate={{ opacity: 1, y: 0 }}\n  1024→                className=\"absolute top-12 left-3 right-3 z-30\"\n  1025→              >\n  1026→                <div className=\"bg-amber-500/20 border border-amber-500/50 rounded-lg px-3 py-2 flex items-center gap-2\">\n  1027→                  <AlertTriangle className=\"w-4 h-4 text-amber-400 flex-shrink-0\" />\n  1028→                  <p className=\"text-amber-200 text-xs flex-1\">\n  1029→                    {mode === 'side'\n  1030→                      ? 'Auto-detection could not find profile. Please place landmarks manually for best accuracy.'\n  1031→                      : 'Could not detect face. Please place landmarks manually.'}\n  1032→                  </p>\n  1033→                  <button\n  1034→                    onClick={() => setDetectionFailed(false)}\n  1035→                    className=\"text-amber-400 hover:text-amber-200 transition-colors\"\n  1036→                  >\n  1037→                    <X className=\"w-4 h-4\" />\n  1038→                  </button>\n  1039→                </div>\n  1040→              </motion.div>\n  1041→            )}\n  1042→\n  1043→            {/* Zoom indicator */}\n  1044→            <div className=\"absolute top-3 left-3 px-3 py-1.5 rounded-lg bg-black/80 border border-neutral-700 text-white text-xs flex items-center gap-2\">\n  1045→              <Move className=\"w-3 h-3\" />\n  1046→              {zoomLevel.toFixed(1)}x - Drag to align\n  1047→            </div>\n  1048→\n  1049→            {/* Current landmark label overlay */}\n  1050→            <div className=\"absolute bottom-0 left-0 right-0 bg-gradient-to-t from-black via-black/80 to-transparent p-4 pointer-events-none\">\n  1051→              <p className=\"text-center text-white text-sm font-medium\">\n  1052→                Drag image to align:{' '}\n  1053→                <span className=\"font-semibold\" style={{ color }}>{currentLandmark?.label}</span>\n  1054→              </p>\n  1055→              <p className=\"text-center text-neutral-400 text-xs mt-1\">\n  1056→                Press Enter or click Next to confirm\n  1057→              </p>\n  1058→            </div>\n  1059→          </div>\n  1060→\n  1061→          {/* Navigation Bar - Fixed at bottom of image area */}\n  1062→          <div className=\"mt-3 flex items-center justify-center gap-3\">\n  1063→            <button\n  1064→              onClick={handlePrevious}\n  1065→              className=\"p-2.5 rounded-xl bg-neutral-800 text-neutral-300 hover:bg-neutral-700 border border-neutral-700 transition-all\"\n  1066→            >\n  1067→              <ChevronLeft className=\"w-5 h-5\" />\n  1068→            </button>\n  1069→\n  1070→            {/* Step dots - show current position indicator */}\n  1071→            <div className=\"flex items-center gap-2 px-4 py-2 bg-neutral-900 rounded-xl border border-neutral-800\">\n  1072→              <span className=\"text-xs text-neutral-400 font-mono min-w-[4ch]\">\n  1073→                {currentStepIndex + 1}\n  1074→              </span>\n  1075→              <div className=\"w-32 h-1.5 bg-neutral-800 rounded-full overflow-hidden\">\n  1076→                <div\n  1077→                  className=\"h-full bg-[#00f3ff] rounded-full transition-all duration-200\"\n  1078→                  style={{ width: `${((currentStepIndex + 1) / totalSteps) * 100}%` }}\n  1079→                />\n  1080→              </div>\n  1081→              <span className=\"text-xs text-neutral-400 font-mono min-w-[4ch] text-right\">\n  1082→                {totalSteps}\n  1083→              </span>\n  1084→            </div>\n  1085→\n  1086→            <button\n  1087→              onClick={handleNext}\n  1088→              className={`flex items-center gap-2 px-5 py-2.5 rounded-xl font-medium text-sm transition-all ${currentStepIndex === totalSteps - 1\n  1089→                ? 'bg-green-500 text-white hover:bg-green-600'\n  1090→                : 'bg-[#00f3ff] text-black hover:shadow-[0_0_20px_rgba(0,243,255,0.4)]'\n  1091→                }`}\n  1092→            >\n  1093→              {currentStepIndex === totalSteps - 1 ? (\n  1094→                <>\n  1095→                  <Check className=\"w-4 h-4\" />\n  1096→                  Complete\n  1097→                </>\n  1098→              ) : (\n  1099→                <>\n  1100→                  Next\n  1101→                  <ChevronRight className=\"w-4 h-4\" />\n  1102→                </>\n  1103→              )}\n  1104→            </button>\n  1105→\n  1106→          </div>\n  1107→        </div>\n  1108→      </div>\n  1109→    </div>\n  1110→  );\n  1111→}\n  1112→\n\n</system-reminder>\n"}]},"uuid":"08b35847-5b82-4fcc-a926-727e57e9d050","timestamp":"2025-12-30T14:57:17.345Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/imorgado/LOOKSMAXX/looksmaxx-app/src/components/LandmarkAnalysisTool.tsx","content":"'use client';\n\nimport { useState, useRef, useCallback, useEffect } from 'react';\nimport Image from 'next/image';\nimport { motion } from 'framer-motion';\nimport {\n  ChevronLeft,\n  ChevronRight,\n  ChevronUp,\n  ChevronDown,\n  Check,\n  Info,\n  Scan,\n  Loader2,\n  Move,\n  Focus,\n  AlertTriangle,\n  X,\n  Settings2,\n} from 'lucide-react';\n\n\nimport {\n  LandmarkPoint,\n  FRONT_PROFILE_LANDMARKS,\n  SIDE_PROFILE_LANDMARKS,\n  getLandmarkColor,\n  FRONT_LANDMARK_CATEGORIES,\n  SIDE_LANDMARK_CATEGORIES,\n} from '@/lib/landmarks';\nimport { getLandmarkImagePath, getLandmarkPlacementGuide } from '@/lib/landmarkImages';\nimport { detectFromImageUrl } from '@/lib/mediapipeDetection';\nimport { LandmarkEditor } from '@/components/analysis';\nimport { ESTIMATED_LANDMARKS } from '@/hooks/useLandmarkAdjustment';\n\ninterface LandmarkAnalysisToolProps {\n  imageUrl: string;\n  mode: 'front' | 'side';\n  initialLandmarks?: LandmarkPoint[];\n  onLandmarksChange?: (landmarks: LandmarkPoint[]) => void;\n  onComplete?: (landmarks: LandmarkPoint[]) => void;\n  onBack?: () => void;\n}\n\nfunction getOrderedLandmarks(mode: 'front' | 'side'): string[] {\n  const landmarks = mode === 'front' ? FRONT_PROFILE_LANDMARKS : SIDE_PROFILE_LANDMARKS;\n  return landmarks.map(lm => lm.id);\n}\n\nexport function LandmarkAnalysisTool({\n  imageUrl,\n  mode,\n  initialLandmarks,\n  onLandmarksChange,\n  onComplete,\n  onBack,\n}: LandmarkAnalysisToolProps) {\n  const containerRef = useRef<HTMLDivElement>(null);\n  const [imageDimensions, setImageDimensions] = useState<{ width: number; height: number } | null>(null);\n  const [containerSize, setContainerSize] = useState<{ width: number; height: number } | null>(null);\n  const defaultLandmarks = mode === 'front' ? FRONT_PROFILE_LANDMARKS : SIDE_PROFILE_LANDMARKS;\n  const categories = mode === 'front' ? FRONT_LANDMARK_CATEGORIES : SIDE_LANDMARK_CATEGORIES;\n  const orderedIds = getOrderedLandmarks(mode);\n\n  const [landmarks, setLandmarks] = useState<LandmarkPoint[]>(\n    initialLandmarks || defaultLandmarks\n  );\n  const [currentStepIndex, setCurrentStepIndex] = useState(0);\n  const [zoomLevel, setZoomLevel] = useState(2); // 2x/4x/8x discrete levels\n\n  // Reset state when mode changes (fixes side profile starting at step 52)\n  useEffect(() => {\n    const newLandmarks = mode === 'front' ? FRONT_PROFILE_LANDMARKS : SIDE_PROFILE_LANDMARKS;\n    setCurrentStepIndex(0);\n    setPlacedLandmarks(new Set());\n    setHasAutoDetected(false);\n    setDetectionFailed(false);\n    setLandmarks(newLandmarks);\n    setPan({ x: 0, y: 0 });\n    setZoomLevel(2); // Reset to 2x\n    setShowAdjustmentMode(false);\n    setEarLandmarksAdjusted(false);\n  }, [mode]);\n\n  // Check if estimated ear landmarks exist in current landmarks\n  const hasEstimatedEarLandmarks = mode === 'side' && landmarks.some(\n    lm => ESTIMATED_LANDMARKS.includes(lm.id as typeof ESTIMATED_LANDMARKS[number])\n  );\n\n  // Handle ear landmark adjustment confirmation\n  const handleAdjustmentConfirm = useCallback((adjustedLandmarks: Array<{ id: string; x: number; y: number }>) => {\n    // Merge adjusted landmarks with existing\n    setLandmarks(prev => prev.map(lm => {\n      const adjusted = adjustedLandmarks.find(a => a.id === lm.id);\n      if (adjusted) {\n        return { ...lm, x: adjusted.x, y: adjusted.y };\n      }\n      return lm;\n    }));\n\n    // Recalculate Frankfort plane with adjusted landmarks\n    const porion = adjustedLandmarks.find(l => l.id === 'porion');\n    const orbitale = adjustedLandmarks.find(l => l.id === 'orbitale');\n    if (porion && orbitale) {\n      const dx = porion.x - orbitale.x;\n      const dy = porion.y - orbitale.y;\n      const angle = Math.atan2(dy, dx) * (180 / Math.PI);\n      setFrankfortPlane({\n        angle,\n        orbitale: { x: orbitale.x, y: orbitale.y },\n        porion: { x: porion.x, y: porion.y },\n      });\n    }\n\n    setEarLandmarksAdjusted(true);\n    setShowAdjustmentMode(false);\n  }, []);\n  const [pan, setPan] = useState({ x: 0, y: 0 });\n  const [isDragging, setIsDragging] = useState(false);\n  const [dragStart, setDragStart] = useState({ x: 0, y: 0 });\n  const [pressedKeys, setPressedKeys] = useState<Set<string>>(new Set());\n  const [activeTab, setActiveTab] = useState<'info' | 'reference'>('info');\n  const [isDetecting, setIsDetecting] = useState(true);\n  const [hasAutoDetected, setHasAutoDetected] = useState(false);\n  const [autoZoomEnabled, setAutoZoomEnabled] = useState(true);\n  const [detectionFailed, setDetectionFailed] = useState(false);\n  const [placedLandmarks, setPlacedLandmarks] = useState<Set<string>>(new Set());\n  // Frankfort Plane for side profile visualization (from server detection)\n  const [frankfortPlane, setFrankfortPlane] = useState<{\n    angle: number;\n    orbitale: { x: number; y: number };\n    porion: { x: number; y: number };\n  } | null>(null);\n  // Show ear landmark adjustment mode (for side profile only)\n  const [showAdjustmentMode, setShowAdjustmentMode] = useState(false);\n  // Track if ear landmarks have been adjusted\n  const [earLandmarksAdjusted, setEarLandmarksAdjusted] = useState(false);\n\n  const currentLandmarkId = orderedIds[currentStepIndex];\n  const currentLandmark = landmarks.find((lm) => lm.id === currentLandmarkId);\n  const totalSteps = orderedIds.length;\n  const progress = ((currentStepIndex + 1) / totalSteps) * 100;\n\n  const color = currentLandmark\n    ? getLandmarkColor(currentLandmark.id, categories)\n    : '#00f3ff';\n\n  // Load image dimensions on mount\n  useEffect(() => {\n    const img = new window.Image();\n    img.onload = () => {\n      setImageDimensions({ width: img.naturalWidth, height: img.naturalHeight });\n    };\n    img.src = imageUrl;\n  }, [imageUrl]);\n\n  // Track container size changes with ResizeObserver\n  useEffect(() => {\n    if (!containerRef.current) return;\n\n    const observer = new ResizeObserver((entries) => {\n      const { width, height } = entries[0].contentRect;\n      setContainerSize({ width, height });\n    });\n\n    observer.observe(containerRef.current);\n    return () => observer.disconnect();\n  }, []);\n\n  // Calculate the rendered image bounds within the container (accounting for object-contain)\n  const getImageBounds = useCallback(() => {\n    if (!containerRef.current || !imageDimensions || !containerSize) {\n      return { offsetX: 0, offsetY: 0, renderedWidth: 1, renderedHeight: 1, containerWidth: 1, containerHeight: 1 };\n    }\n\n    const containerWidth = containerSize.width;\n    const containerHeight = containerSize.height;\n    const imageAspect = imageDimensions.width / imageDimensions.height;\n    const containerAspect = containerWidth / containerHeight;\n\n    let renderedWidth: number;\n    let renderedHeight: number;\n    let offsetX = 0;\n    let offsetY = 0;\n\n    if (imageAspect > containerAspect) {\n      renderedWidth = containerWidth;\n      renderedHeight = containerWidth / imageAspect;\n      offsetY = (containerHeight - renderedHeight) / 2;\n    } else {\n      renderedHeight = containerHeight;\n      renderedWidth = containerHeight * imageAspect;\n      offsetX = (containerWidth - renderedWidth) / 2;\n    }\n\n    return { offsetX, offsetY, renderedWidth, renderedHeight, containerWidth, containerHeight };\n  }, [imageDimensions, containerSize]);\n\n  // Get what normalized coordinates the center orb points to on the image\n  const getCrosshairNormalizedPosition = useCallback(() => {\n    const bounds = getImageBounds();\n    if (!bounds.renderedWidth || !bounds.renderedHeight) {\n      return { x: 0.5, y: 0.5 };\n    }\n\n    // The container center (where the orb is) in screen coordinates\n    const containerCenterX = bounds.containerWidth / 2;\n    const containerCenterY = bounds.containerHeight / 2;\n\n    // The transform is: translate(pan.x, pan.y) scale(zoomLevel)\n    // To find what image point is at container center, we reverse this:\n    // 1. The point at container center after transform comes from:\n    //    screenPos = imagePos * zoomLevel + pan\n    // 2. Solving for imagePos:\n    //    imagePos = (screenPos - pan) / zoomLevel\n    const imageX = (containerCenterX - pan.x) / zoomLevel;\n    const imageY = (containerCenterY - pan.y) / zoomLevel;\n\n    // Convert to normalized (0-1) coordinates within the image\n    const normalizedX = (imageX - bounds.offsetX) / bounds.renderedWidth;\n    const normalizedY = (imageY - bounds.offsetY) / bounds.renderedHeight;\n\n    return {\n      x: Math.max(0, Math.min(1, normalizedX)),\n      y: Math.max(0, Math.min(1, normalizedY)),\n    };\n  }, [getImageBounds, pan, zoomLevel]);\n\n  // Convert normalized image coordinates (0-1) to pixel position within the container\n  // Note: This is used for landmarks INSIDE the transformed container, so no zoom/pan needed\n  const getLandmarkPixelPosition = useCallback((x: number, y: number) => {\n    const bounds = getImageBounds();\n    // Position relative to container (the parent transform handles zoom/pan)\n    const pixelX = bounds.offsetX + x * bounds.renderedWidth;\n    const pixelY = bounds.offsetY + y * bounds.renderedHeight;\n    return { left: pixelX, top: pixelY };\n  }, [getImageBounds]);\n\n  useEffect(() => {\n    onLandmarksChange?.(landmarks);\n  }, [landmarks, onLandmarksChange]);\n\n  // Confirm placement: set current landmark to where crosshair points\n  const confirmPlacement = useCallback(() => {\n    const pos = getCrosshairNormalizedPosition();\n    setLandmarks((prev) =>\n      prev.map((lm) =>\n        lm.id === currentLandmarkId ? { ...lm, x: pos.x, y: pos.y } : lm\n      )\n    );\n    setPlacedLandmarks((prev) => new Set(prev).add(currentLandmarkId));\n  }, [currentLandmarkId, getCrosshairNormalizedPosition]);\n\n  // Handle click - confirms placement at crosshair position\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  const handleContainerClick = useCallback(() => {\n    if (isDragging) return;\n    confirmPlacement();\n  }, [isDragging, confirmPlacement]);\n\n  // Mouse down - start dragging to pan\n  const handleMouseDown = useCallback(\n    (e: React.MouseEvent) => {\n      if (e.button === 0) {\n        setIsDragging(true);\n        setDragStart({ x: e.clientX - pan.x, y: e.clientY - pan.y });\n      }\n    },\n    [pan]\n  );\n\n  // Mouse move - pan the image\n  const handleMouseMove = useCallback(\n    (e: React.MouseEvent) => {\n      if (isDragging) {\n        setPan({\n          x: e.clientX - dragStart.x,\n          y: e.clientY - dragStart.y,\n        });\n      }\n    },\n    [isDragging, dragStart]\n  );\n\n  const handleMouseUp = useCallback(() => {\n    setIsDragging(false);\n  }, []);\n\n  const handleResetZoom = useCallback(() => {\n    setZoomLevel(2); // Reset to 2x\n    setPan({ x: 0, y: 0 });\n  }, []);\n\n  // Pan the image using arrow keys (moves the crosshair target point on the image)\n  const panImage = useCallback((direction: 'up' | 'down' | 'left' | 'right') => {\n    const step = 20; // pixels to pan per keypress\n    setPan((prev) => {\n      switch (direction) {\n        case 'up': return { ...prev, y: prev.y + step };\n        case 'down': return { ...prev, y: prev.y - step };\n        case 'left': return { ...prev, x: prev.x + step };\n        case 'right': return { ...prev, x: prev.x - step };\n        default: return prev;\n      }\n    });\n  }, []);\n\n  const handleNext = useCallback(() => {\n    // Confirm placement at current crosshair position before moving to next\n    confirmPlacement();\n\n    if (currentStepIndex < totalSteps - 1) {\n      setCurrentStepIndex((prev) => prev + 1);\n      // Don't reset zoom - let zoomToLandmark handle it\n    } else {\n      onComplete?.(landmarks);\n    }\n  }, [currentStepIndex, totalSteps, landmarks, onComplete, confirmPlacement]);\n\n\n  const handlePrevious = useCallback(() => {\n    if (currentStepIndex > 0) {\n      setCurrentStepIndex((prev) => prev - 1);\n      handleResetZoom();\n    } else {\n      onBack?.();\n    }\n  }, [currentStepIndex, handleResetZoom, onBack]);\n\n  // Landmark-specific zoom levels for optimal precision\n  // Fine detail landmarks (pupils, eyelids) get higher zoom, larger areas get lower zoom\n  const LANDMARK_ZOOM_LEVELS: Record<string, number> = {\n    // 2x zoom - larger landmarks\n    trichion: 2,\n    left_temporal: 2, right_temporal: 2,\n    left_auricular_lateral: 2, right_auricular_lateral: 2,\n\n    // 4x zoom - medium detail landmarks\n    left_pupila: 4, right_pupila: 4,\n    left_canthus_medialis: 4, left_canthus_lateralis: 4,\n    right_canthus_medialis: 4, right_canthus_lateralis: 4,\n    left_sulcus_palpebralis_lateralis: 4, right_sulcus_palpebralis_lateralis: 4,\n    left_supercilium_medialis: 4, left_supercilium_medial_corner: 4,\n    left_supercilium_superior: 4, left_supercilium_apex: 4, left_supercilium_lateralis: 4,\n    right_supercilium_medialis: 4, right_supercilium_medial_corner: 4,\n    right_supercilium_superior: 4, right_supercilium_apex: 4, right_supercilium_lateralis: 4,\n    left_ala_nasi: 4, right_ala_nasi: 4,\n    nasal_base: 4, subnasale: 4,\n    left_dorsum_nasi: 4, right_dorsum_nasi: 4,\n    labrale_superius: 4, cupids_bow: 4, mouth_middle: 4,\n    labrale_inferius: 4, left_cheilion: 4, right_cheilion: 4,\n    left_gonion_superior: 4, left_gonion_inferior: 4,\n    right_gonion_superior: 4, right_gonion_inferior: 4,\n    left_mentum_lateralis: 4, right_mentum_lateralis: 4, menton: 4,\n    left_zygion: 2, right_zygion: 2,\n    left_cervical_lateralis: 4, right_cervical_lateralis: 4,\n\n    // 8x zoom - fine detail landmarks (eyelids)\n    left_palpebra_superior: 8, left_palpebra_inferior: 8,\n    right_palpebra_superior: 8, right_palpebra_inferior: 8,\n    left_pretarsal_skin_crease: 8, right_pretarsal_skin_crease: 8,\n\n    // ========== SIDE PROFILE LANDMARKS ==========\n    // Note: Some IDs shared with front profile (trichion, subnasale, menton) - zoom applies to both\n    // 2x zoom - larger side landmarks\n    vertex: 2,\n    occiput: 2,\n    neckPoint: 2,\n    forehead: 2, // Separate from glabella\n\n    // 4x zoom - medium detail side landmarks\n    porion: 4,\n    orbitale: 4,\n    tragus: 4,\n    intertragicNotch: 4,\n    cornealApex: 4,\n    eyelidEnd: 4, // Lateral eyelid end in side profile\n    lowerEyelid: 4, // Lower eyelid margin in side profile\n    cheekbone: 4,\n    glabella: 4,\n    nasion: 4,\n    pronasale: 4,\n    rhinion: 4,\n    supratip: 4,\n    infratip: 4,\n    columella: 4,\n    subalare: 4,\n    labraleSuperius: 4,\n    cheilion: 4,\n    labraleInferius: 4,\n    sublabiale: 4,\n    pogonion: 4,\n    // menton: 4 already defined in front section (applies to both profiles)\n    cervicalPoint: 4,\n    gonionTop: 4,\n    gonionBottom: 4,\n  };\n\n  // Auto-zoom to the current landmark's region - centers the landmark under the fixed orb\n  const zoomToLandmark = useCallback((landmarkId: string) => {\n    if (!autoZoomEnabled || !containerRef.current || !containerSize || !imageDimensions) return;\n\n    const landmark = landmarks.find(lm => lm.id === landmarkId);\n    if (!landmark) return;\n\n    const bounds = getImageBounds();\n    if (bounds.renderedWidth <= 1 || bounds.renderedHeight <= 1) return; // Bounds not ready\n\n    // Use landmark-specific zoom level, default to 2x\n    const newZoom = LANDMARK_ZOOM_LEVELS[landmarkId] || 2;\n    setZoomLevel(newZoom);\n\n    // Calculate pan so the landmark appears at container center (under the fixed orb)\n    const containerCenterX = bounds.containerWidth / 2;\n    const containerCenterY = bounds.containerHeight / 2;\n\n    // Where the landmark is in unzoomed image space\n    const landmarkX = bounds.offsetX + landmark.x * bounds.renderedWidth;\n    const landmarkY = bounds.offsetY + landmark.y * bounds.renderedHeight;\n\n    // Pan needed: after zoom, landmark should be at container center\n    // Transform is: translate(pan) scale(zoom) with origin at 0,0\n    // A point at landmarkPos ends up at: landmarkPos * zoom + pan\n    // We want it at containerCenter, so: pan = containerCenter - landmarkPos * zoom\n    setPan({\n      x: containerCenterX - landmarkX * newZoom,\n      y: containerCenterY - landmarkY * newZoom,\n    });\n  }, [autoZoomEnabled, landmarks, getImageBounds, containerSize, imageDimensions]);\n\n  // Auto-detect landmarks using Human.js/MediaPipe\n  const handleAutoDetect = useCallback(async () => {\n    setIsDetecting(true);\n    setDetectionFailed(false);\n    setFrankfortPlane(null);\n    try {\n      const result = await detectFromImageUrl(imageUrl, mode);\n      console.log('[DEBUG] Detection result:', result);\n      console.log('[DEBUG] Sample landmarks:', result?.landmarks.slice(0, 5));\n      if (result && result.landmarks.length > 0) {\n        // Update landmarks with detected positions\n        setLandmarks(prev =>\n          prev.map(lm => {\n            const detected = result.landmarks.find(d => d.id === lm.id);\n            if (detected) {\n              return { ...lm, x: detected.x, y: detected.y };\n            }\n            return lm;\n          })\n        );\n        setHasAutoDetected(true);\n        setDetectionFailed(false);\n\n        // Capture Frankfort Plane for side profile (from server-side detection)\n        if (mode === 'side' && result.frankfortPlane) {\n          console.log('[DEBUG] Frankfort Plane:', result.frankfortPlane);\n          setFrankfortPlane(result.frankfortPlane);\n        }\n\n        // Zoom to first landmark after detection\n        zoomToLandmark(orderedIds[0]);\n      } else {\n        // Detection returned no results - common for side profile\n        console.log('[DEBUG] No landmarks detected - manual placement required');\n        setDetectionFailed(true);\n        setHasAutoDetected(false);\n      }\n    } catch (error) {\n      console.error('Auto-detection failed:', error);\n      setDetectionFailed(true);\n    } finally {\n      setIsDetecting(false);\n    }\n  }, [imageUrl, mode, orderedIds, zoomToLandmark]);\n\n  // Auto-detect after image dimensions are loaded (prevents race condition)\n  useEffect(() => {\n    if (imageDimensions) {\n      handleAutoDetect();\n    }\n    // eslint-disable-next-line react-hooks/exhaustive-deps\n  }, [imageDimensions]); // Run after dimensions are loaded\n\n  // Auto-zoom when step changes or container size becomes available\n  useEffect(() => {\n    if (hasAutoDetected && autoZoomEnabled && currentLandmarkId && containerSize) {\n      zoomToLandmark(currentLandmarkId);\n    }\n  }, [currentStepIndex, currentLandmarkId, hasAutoDetected, autoZoomEnabled, zoomToLandmark, containerSize]);\n\n  // Keyboard handlers with proper state tracking\n  useEffect(() => {\n    const handleKeyDown = (e: KeyboardEvent) => {\n      if (['ArrowUp', 'ArrowDown', 'ArrowLeft', 'ArrowRight', 'Enter', 'Backspace', 'r', 'R'].includes(e.key)) {\n        e.preventDefault();\n      }\n\n      setPressedKeys((prev) => new Set(prev).add(e.key));\n\n      switch (e.key) {\n        case 'ArrowUp': panImage('up'); break;\n        case 'ArrowDown': panImage('down'); break;\n        case 'ArrowLeft': panImage('left'); break;\n        case 'ArrowRight': panImage('right'); break;\n        case 'Enter': handleNext(); break;\n        case 'Backspace': handlePrevious(); break;\n        case 'r':\n        case 'R': handleResetZoom(); break;\n      }\n    };\n\n    const handleKeyUp = (e: KeyboardEvent) => {\n      setPressedKeys((prev) => {\n        const next = new Set(prev);\n        next.delete(e.key);\n        return next;\n      });\n    };\n\n    window.addEventListener('keydown', handleKeyDown);\n    window.addEventListener('keyup', handleKeyUp);\n    return () => {\n      window.removeEventListener('keydown', handleKeyDown);\n      window.removeEventListener('keyup', handleKeyUp);\n    };\n  }, [panImage, handleNext, handlePrevious, handleResetZoom]);\n\n  const isKeyPressed = (key: string) => pressedKeys.has(key);\n\n  // Render LandmarkEditor for ear landmark adjustment (side profile only)\n  if (showAdjustmentMode && mode === 'side') {\n    return (\n      <LandmarkEditor\n        imageUrl={imageUrl}\n        landmarks={landmarks.map(lm => ({ id: lm.id, x: lm.x, y: lm.y }))}\n        onConfirm={handleAdjustmentConfirm}\n        onSkip={() => setShowAdjustmentMode(false)}\n      />\n    );\n  }\n\n  return (\n    <div className=\"fixed inset-0 bg-black\">\n      <div className=\"flex flex-col md:flex-row h-full gap-3 p-3 md:p-4\">\n        {/* Sidebar - Right on desktop */}\n        <div className=\"w-full md:w-80 flex-shrink-0 flex flex-col gap-3 md:order-2 overflow-hidden md:overflow-y-auto\">\n          {/* Progress Card */}\n          <div className=\"bg-neutral-900 rounded-xl border border-neutral-800 overflow-hidden flex-shrink-0\">\n            <div className=\"p-4\">\n              <div className=\"flex items-center justify-between text-xs text-neutral-400 mb-2\">\n                <span>Step {currentStepIndex + 1} of {totalSteps}</span>\n                <span>{Math.round(progress)}%</span>\n              </div>\n              <div className=\"h-1.5 bg-neutral-800 rounded-full overflow-hidden mb-3\">\n                <motion.div\n                  className=\"h-full rounded-full\"\n                  style={{ width: `${progress}%`, backgroundColor: '#00f3ff' }}\n                  transition={{ duration: 0.3 }}\n                />\n              </div>\n              <div className=\"flex items-center gap-2\">\n                <div className=\"w-6 h-6 bg-[#00f3ff] rounded-full flex items-center justify-center flex-shrink-0\">\n                  <Check className=\"w-3.5 h-3.5 text-black\" />\n                </div>\n                <span className=\"text-sm font-medium text-white\">\n                  {currentStepIndex} placed\n                </span>\n              </div>\n            </div>\n\n            {/* View Tabs */}\n            <div className=\"flex border-t border-neutral-800\">\n              <button\n                onClick={() => setActiveTab('info')}\n                className={`flex-1 py-2.5 text-xs font-medium transition-colors ${activeTab === 'info'\n                  ? 'text-[#00f3ff] border-b-2 border-[#00f3ff]'\n                  : 'text-neutral-500 hover:text-neutral-300'\n                  }`}\n              >\n                Current Point\n              </button>\n              <button\n                onClick={() => setActiveTab('reference')}\n                className={`flex-1 py-2.5 text-xs font-medium transition-colors ${activeTab === 'reference'\n                  ? 'text-[#00f3ff] border-b-2 border-[#00f3ff]'\n                  : 'text-neutral-500 hover:text-neutral-300'\n                  }`}\n              >\n                Reference\n              </button>\n            </div>\n\n            {/* Info/Reference Content */}\n            <div className=\"bg-neutral-900/50\">\n              {activeTab === 'info' ? (\n                <div>\n                  {/* Photo Reference Image */}\n                  {currentLandmark && getLandmarkImagePath(currentLandmark.id, mode, 'photo') ? (\n                    <div className=\"relative w-full aspect-square bg-neutral-800\">\n                      <Image\n                        src={getLandmarkImagePath(currentLandmark.id, mode, 'photo')!}\n                        alt={currentLandmark.label}\n                        fill\n                        className=\"object-contain\"\n                        unoptimized\n                      />\n                    </div>\n                  ) : (\n                    <div className=\"w-full aspect-square bg-neutral-800 flex items-center justify-center\">\n                      <div\n                        className=\"w-14 h-14 rounded-full flex items-center justify-center\"\n                        style={{ backgroundColor: `${color}20`, border: `2px solid ${color}` }}\n                      >\n                        <div className=\"w-4 h-4 rounded-full\" style={{ backgroundColor: color }} />\n                      </div>\n                    </div>\n                  )}\n                  <div className=\"p-3 text-center border-t border-neutral-800\">\n                    <p className=\"text-sm font-semibold text-white\">{currentLandmark?.label}</p>\n                    <p className=\"text-xs text-[#00f3ff] mt-0.5 font-mono\">{currentLandmark?.medicalTerm}</p>\n                  </div>\n                </div>\n              ) : (\n                <div>\n                  {/* Infographic Reference Image */}\n                  {currentLandmark && getLandmarkImagePath(currentLandmark.id, mode, 'infographic') ? (\n                    <div className=\"relative w-full aspect-square bg-neutral-800\">\n                      <Image\n                        src={getLandmarkImagePath(currentLandmark.id, mode, 'infographic')!}\n                        alt={`${currentLandmark.label} infographic`}\n                        fill\n                        className=\"object-contain\"\n                        unoptimized\n                      />\n                    </div>\n                  ) : (\n                    <div className=\"w-full aspect-square bg-neutral-800 flex items-center justify-center\">\n                      <Info className=\"w-12 h-12 text-neutral-600\" />\n                    </div>\n                  )}\n                  <div className=\"p-3 text-center border-t border-neutral-800\">\n                    <p className=\"text-sm text-neutral-300\">\n                      {currentLandmark ? getLandmarkPlacementGuide(currentLandmark.id, mode) : ''}\n                    </p>\n                  </div>\n                </div>\n              )}\n            </div>\n          </div>\n\n          {/* Keyboard Shortcuts - Desktop only */}\n          <div className=\"hidden md:flex flex-col gap-3\">\n            <div className=\"bg-neutral-900 rounded-xl border border-neutral-800 p-4\">\n              <p className=\"text-xs text-neutral-500 font-medium uppercase tracking-wide mb-3 text-center\">\n                Keyboard Controls\n              </p>\n              <div className=\"flex justify-center mb-4\">\n                <div className=\"flex flex-col gap-1 items-center\">\n                  {/* Arrow Up */}\n                  <div\n                    className={`w-10 h-10 rounded-lg flex items-center justify-center transition-all duration-100 ${isKeyPressed('ArrowUp')\n                      ? 'bg-[#00f3ff] text-black shadow-[0_0_15px_rgba(0,243,255,0.5)]'\n                      : 'bg-neutral-800 text-neutral-400 border border-neutral-700'\n                      }`}\n                  >\n                    <ChevronUp className=\"w-5 h-5\" />\n                  </div>\n                  {/* Arrow Row */}\n                  <div className=\"flex gap-1\">\n                    {[\n                      { key: 'ArrowLeft', icon: ChevronLeft },\n                      { key: 'ArrowDown', icon: ChevronDown },\n                      { key: 'ArrowRight', icon: ChevronRight },\n                    ].map(({ key, icon: Icon }) => (\n                      <div\n                        key={key}\n                        className={`w-10 h-10 rounded-lg flex items-center justify-center transition-all duration-100 ${isKeyPressed(key)\n                          ? 'bg-[#00f3ff] text-black shadow-[0_0_15px_rgba(0,243,255,0.5)]'\n                          : 'bg-neutral-800 text-neutral-400 border border-neutral-700'\n                          }`}\n                      >\n                        <Icon className=\"w-5 h-5\" />\n                      </div>\n                    ))}\n                  </div>\n                </div>\n              </div>\n\n              <div className=\"space-y-2 text-sm\">\n                <div className=\"flex items-center justify-between\">\n                  <span\n                    className={`px-2 py-1 rounded font-mono text-xs transition-all duration-100 ${isKeyPressed('Enter')\n                      ? 'bg-[#00f3ff] text-black'\n                      : 'bg-neutral-800 text-neutral-400'\n                      }`}\n                  >\n                    Enter\n                  </span>\n                  <span className=\"text-neutral-500\">Next point</span>\n                </div>\n                <div className=\"flex items-center justify-between\">\n                  <span\n                    className={`px-2 py-1 rounded font-mono text-xs transition-all duration-100 ${isKeyPressed('Backspace')\n                      ? 'bg-[#00f3ff] text-black'\n                      : 'bg-neutral-800 text-neutral-400'\n                      }`}\n                  >\n                    Backspace\n                  </span>\n                  <span className=\"text-neutral-500\">Previous</span>\n                </div>\n                <div className=\"flex items-center justify-between\">\n                  <span\n                    className={`px-2 py-1 rounded font-mono text-xs transition-all duration-100 ${isKeyPressed('r') || isKeyPressed('R')\n                      ? 'bg-[#00f3ff] text-black'\n                      : 'bg-neutral-800 text-neutral-400'\n                      }`}\n                  >\n                    R\n                  </span>\n                  <span className=\"text-neutral-500\">Reset zoom</span>\n                </div>\n              </div>\n            </div>\n\n            {/* Zoom Controls */}\n            <div className=\"bg-neutral-900 rounded-xl border border-neutral-800 p-4\">\n              <p className=\"text-xs text-neutral-500 font-medium uppercase tracking-wide mb-3\">\n                Zoom Level\n              </p>\n              <div className=\"flex gap-2\">\n                {/* 2x/4x/8x discrete zoom levels */}\n                {[2, 4, 8].map((level) => (\n                  <button\n                    key={level}\n                    onClick={() => {\n                      if (containerSize) {\n                        // Adjust pan to keep the same center point visible when zoom changes\n                        // Current center in image space: imageCenter = (containerCenter - pan) / oldZoom\n                        // New pan to show same center: newPan = containerCenter - imageCenter * newZoom\n                        const containerCenterX = containerSize.width / 2;\n                        const containerCenterY = containerSize.height / 2;\n                        const imageCenterX = (containerCenterX - pan.x) / zoomLevel;\n                        const imageCenterY = (containerCenterY - pan.y) / zoomLevel;\n                        const newPanX = containerCenterX - imageCenterX * level;\n                        const newPanY = containerCenterY - imageCenterY * level;\n                        setZoomLevel(level);\n                        setPan({ x: newPanX, y: newPanY });\n                      } else {\n                        setZoomLevel(level);\n                      }\n                    }}\n                    className={`flex-1 py-2 rounded-lg text-sm font-medium transition-all ${zoomLevel === level\n                      ? 'bg-[#00f3ff] text-black'\n                      : 'bg-neutral-800 text-neutral-400 hover:bg-neutral-700'\n                      }`}\n                  >\n                    {level}x\n                  </button>\n                ))}\n              </div>\n            </div>\n\n            {/* Auto-Detect Button */}\n            <button\n              onClick={handleAutoDetect}\n              disabled={isDetecting}\n              className={`w-full py-3 rounded-lg text-sm font-medium transition-all flex items-center justify-center gap-2 ${hasAutoDetected\n                ? 'bg-green-500/20 text-green-400 border border-green-500/30'\n                : 'bg-gradient-to-r from-[#00f3ff] to-[#00c4cc] text-black hover:shadow-[0_0_20px_rgba(0,243,255,0.3)]'\n                } disabled:opacity-50 disabled:cursor-not-allowed`}\n            >\n              {isDetecting ? (\n                <>\n                  <Loader2 className=\"w-4 h-4 animate-spin\" />\n                  Detecting...\n                </>\n              ) : hasAutoDetected ? (\n                <>\n                  <Check className=\"w-4 h-4\" />\n                  Detected - Adjust if needed\n                </>\n              ) : (\n                <>\n                  <Scan className=\"w-4 h-4\" />\n                  Auto-Detect Landmarks\n                </>\n              )}\n            </button>\n\n            {/* Adjust Ear Landmarks Button - Side profile only */}\n            {hasEstimatedEarLandmarks && hasAutoDetected && (\n              <button\n                onClick={() => setShowAdjustmentMode(true)}\n                className={`w-full py-3 rounded-lg text-sm font-medium transition-all flex items-center justify-center gap-2 ${\n                  earLandmarksAdjusted\n                    ? 'bg-green-500/20 text-green-400 border border-green-500/30'\n                    : 'bg-amber-500/20 text-amber-400 border border-amber-500/30 hover:bg-amber-500/30'\n                }`}\n              >\n                <Settings2 className=\"w-4 h-4\" />\n                {earLandmarksAdjusted ? 'Ear Landmarks Adjusted' : 'Adjust Ear Landmarks'}\n              </button>\n            )}\n\n            {/* Auto-Zoom Toggle */}\n            <button\n              onClick={() => setAutoZoomEnabled(!autoZoomEnabled)}\n              className={`w-full py-2.5 rounded-lg text-xs font-medium transition-all flex items-center justify-center gap-2 ${autoZoomEnabled\n                ? 'bg-[#00f3ff] text-black'\n                : 'bg-neutral-800 text-neutral-400 hover:bg-neutral-700'\n                }`}\n            >\n              <Focus className=\"w-4 h-4\" />\n              {autoZoomEnabled ? 'Auto-Zoom: ON' : 'Auto-Zoom: OFF'}\n            </button>\n\n          </div>\n        </div>\n\n        {/* Main Image Area */}\n        <div className=\"flex-1 min-h-0 relative md:order-1 flex flex-col\">\n          <div\n            ref={containerRef}\n            className=\"relative flex-1 bg-neutral-900 overflow-hidden rounded-xl border border-neutral-800 select-none\"\n            onMouseDown={handleMouseDown}\n            onMouseMove={handleMouseMove}\n            onMouseUp={handleMouseUp}\n            onMouseLeave={handleMouseUp}\n            style={{\n              cursor: isDragging ? 'grabbing' : 'grab',\n            }}\n          >\n            {/* Transformed Content - Image and placed landmarks move together */}\n            <div\n              className=\"absolute inset-0\"\n              style={{\n                transform: `translate(${pan.x}px, ${pan.y}px) scale(${zoomLevel})`,\n                transformOrigin: '0 0',\n              }}\n            >\n              {/* User's Image */}\n              <Image\n                src={imageUrl}\n                alt=\"Your photo\"\n                fill\n                className=\"object-contain pointer-events-none select-none\"\n                unoptimized\n                draggable={false}\n              />\n\n              {/* Placed landmarks - always visible as they're placed */}\n              {landmarks.filter(lm => placedLandmarks.has(lm.id) && lm.id !== currentLandmarkId).map((landmark) => {\n                const lmColor = getLandmarkColor(landmark.id, categories);\n                const pos = getLandmarkPixelPosition(landmark.x, landmark.y);\n\n                return (\n                  <div\n                    key={landmark.id}\n                    className=\"absolute pointer-events-none\"\n                    style={{\n                      left: pos.left,\n                      top: pos.top,\n                      transform: `translate(-50%, -50%) scale(${1 / zoomLevel})`,\n                      transformOrigin: 'center center',\n                    }}\n                  >\n                    {/* Small persistent dot - matches Harmony style */}\n                    <div\n                      className=\"absolute rounded-full\"\n                      style={{\n                        width: 8,\n                        height: 8,\n                        left: -4,\n                        top: -4,\n                        backgroundColor: lmColor,\n                        boxShadow: `0 0 4px ${lmColor}, 0 0 8px ${lmColor}60`,\n                        border: '1px solid rgba(255,255,255,0.5)',\n                      }}\n                    />\n                  </div>\n                );\n              })}\n\n              {/* Frankfort Horizontal Plane - green reference line for side profiles */}\n              {mode === 'side' && frankfortPlane && (\n                <svg\n                  className=\"absolute inset-0 pointer-events-none\"\n                  style={{ width: '100%', height: '100%' }}\n                >\n                  {(() => {\n                    const bounds = getImageBounds();\n                    const orbitaleX = bounds.offsetX + frankfortPlane.orbitale.x * bounds.renderedWidth;\n                    const orbitaleY = bounds.offsetY + frankfortPlane.orbitale.y * bounds.renderedHeight;\n                    const porionX = bounds.offsetX + frankfortPlane.porion.x * bounds.renderedWidth;\n                    const porionY = bounds.offsetY + frankfortPlane.porion.y * bounds.renderedHeight;\n\n                    // Extend the line beyond the points for visibility\n                    const dx = porionX - orbitaleX;\n                    const dy = porionY - orbitaleY;\n                    const length = Math.sqrt(dx * dx + dy * dy);\n                    const extendFactor = length > 0 ? 0.3 : 0;\n                    const startX = orbitaleX - (dx / length) * bounds.renderedWidth * extendFactor;\n                    const startY = orbitaleY - (dy / length) * bounds.renderedWidth * extendFactor;\n                    const endX = porionX + (dx / length) * bounds.renderedWidth * extendFactor;\n                    const endY = porionY + (dy / length) * bounds.renderedWidth * extendFactor;\n\n                    return (\n                      <>\n                        {/* Main Frankfort line */}\n                        <line\n                          x1={startX}\n                          y1={startY}\n                          x2={endX}\n                          y2={endY}\n                          stroke=\"#22c55e\"\n                          strokeWidth={2 / zoomLevel}\n                          strokeDasharray={`${6 / zoomLevel} ${4 / zoomLevel}`}\n                          opacity={0.8}\n                        />\n                        {/* Orbitale point marker */}\n                        <circle\n                          cx={orbitaleX}\n                          cy={orbitaleY}\n                          r={4 / zoomLevel}\n                          fill=\"#22c55e\"\n                          stroke=\"white\"\n                          strokeWidth={1 / zoomLevel}\n                        />\n                        {/* Porion point marker */}\n                        <circle\n                          cx={porionX}\n                          cy={porionY}\n                          r={4 / zoomLevel}\n                          fill=\"#22c55e\"\n                          stroke=\"white\"\n                          strokeWidth={1 / zoomLevel}\n                        />\n                        {/* Angle indicator */}\n                        <text\n                          x={startX}\n                          y={startY - 10 / zoomLevel}\n                          fill=\"#22c55e\"\n                          fontSize={12 / zoomLevel}\n                          fontWeight=\"bold\"\n                        >\n                          FH: {frankfortPlane.angle.toFixed(1)}°\n                        </text>\n                      </>\n                    );\n                  })()}\n                </svg>\n              )}\n            </div>\n\n            {/* FIXED CENTER TARGETING DOT - small precise point for accurate placement */}\n            <div className=\"absolute inset-0 pointer-events-none flex items-center justify-center z-20\">\n              {/* Crosshair lines for precision */}\n              <div\n                className=\"absolute\"\n                style={{\n                  width: 20,\n                  height: 1,\n                  backgroundColor: '#00f3ff',\n                  opacity: 0.6,\n                }}\n              />\n              <div\n                className=\"absolute\"\n                style={{\n                  width: 1,\n                  height: 20,\n                  backgroundColor: '#00f3ff',\n                  opacity: 0.6,\n                }}\n              />\n              {/* Subtle glow ring */}\n              <div\n                className=\"absolute rounded-full\"\n                style={{\n                  width: 12,\n                  height: 12,\n                  background: 'radial-gradient(circle, #00f3ff33 0%, transparent 70%)',\n                }}\n              />\n              {/* Center dot - small and precise */}\n              <div\n                className=\"relative rounded-full\"\n                style={{\n                  width: 4,\n                  height: 4,\n                  backgroundColor: '#00f3ff',\n                  boxShadow: '0 0 6px #00f3ff, 0 0 12px #00f3ff80',\n                }}\n              />\n            </div>\n\n            {/* Loading Overlay */}\n            {isDetecting && (\n              <div className=\"absolute inset-0 bg-black/90 flex flex-col items-center justify-center z-50 backdrop-blur-sm\">\n                <div className=\"relative mb-8\">\n                  <motion.div\n                    animate={{ scale: [1, 1.2, 1], opacity: [0.5, 1, 0.5] }}\n                    transition={{ duration: 2, repeat: Infinity, ease: \"easeInOut\" }}\n                    className=\"absolute inset-0 bg-[#00f3ff]/20 blur-3xl rounded-full\"\n                  />\n                  <div className=\"relative w-20 h-20 rounded-2xl bg-neutral-900 border border-white/10 flex items-center justify-center shadow-[0_0_30px_rgba(0,243,255,0.15)]\">\n                    <Scan className=\"w-10 h-10 text-[#00f3ff]\" />\n                  </div>\n                </div>\n                <p className=\"text-white text-xl font-bold tracking-wide\">Mapping Biometrics...</p>\n                <div className=\"flex items-center gap-2 mt-3\">\n                  <Loader2 className=\"w-4 h-4 text-[#00f3ff] animate-spin\" />\n                  <p className=\"text-[#00f3ff] text-sm font-mono tracking-wider\">AI ANALYSIS IN PROGRESS</p>\n                </div>\n              </div>\n            )}\n\n            {/* Detection Failed Banner */}\n            {detectionFailed && !isDetecting && (\n              <motion.div\n                initial={{ opacity: 0, y: -20 }}\n                animate={{ opacity: 1, y: 0 }}\n                className=\"absolute top-12 left-3 right-3 z-30\"\n              >\n                <div className=\"bg-amber-500/20 border border-amber-500/50 rounded-lg px-3 py-2 flex items-center gap-2\">\n                  <AlertTriangle className=\"w-4 h-4 text-amber-400 flex-shrink-0\" />\n                  <p className=\"text-amber-200 text-xs flex-1\">\n                    {mode === 'side'\n                      ? 'Auto-detection could not find profile. Please place landmarks manually for best accuracy.'\n                      : 'Could not detect face. Please place landmarks manually.'}\n                  </p>\n                  <button\n                    onClick={() => setDetectionFailed(false)}\n                    className=\"text-amber-400 hover:text-amber-200 transition-colors\"\n                  >\n                    <X className=\"w-4 h-4\" />\n                  </button>\n                </div>\n              </motion.div>\n            )}\n\n            {/* Zoom indicator */}\n            <div className=\"absolute top-3 left-3 px-3 py-1.5 rounded-lg bg-black/80 border border-neutral-700 text-white text-xs flex items-center gap-2\">\n              <Move className=\"w-3 h-3\" />\n              {zoomLevel.toFixed(1)}x - Drag to align\n            </div>\n\n            {/* Current landmark label overlay */}\n            <div className=\"absolute bottom-0 left-0 right-0 bg-gradient-to-t from-black via-black/80 to-transparent p-4 pointer-events-none\">\n              <p className=\"text-center text-white text-sm font-medium\">\n                Drag image to align:{' '}\n                <span className=\"font-semibold\" style={{ color }}>{currentLandmark?.label}</span>\n              </p>\n              <p className=\"text-center text-neutral-400 text-xs mt-1\">\n                Press Enter or click Next to confirm\n              </p>\n            </div>\n          </div>\n\n          {/* Navigation Bar - Fixed at bottom of image area */}\n          <div className=\"mt-3 flex items-center justify-center gap-3\">\n            <button\n              onClick={handlePrevious}\n              className=\"p-2.5 rounded-xl bg-neutral-800 text-neutral-300 hover:bg-neutral-700 border border-neutral-700 transition-all\"\n            >\n              <ChevronLeft className=\"w-5 h-5\" />\n            </button>\n\n            {/* Step dots - show current position indicator */}\n            <div className=\"flex items-center gap-2 px-4 py-2 bg-neutral-900 rounded-xl border border-neutral-800\">\n              <span className=\"text-xs text-neutral-400 font-mono min-w-[4ch]\">\n                {currentStepIndex + 1}\n              </span>\n              <div className=\"w-32 h-1.5 bg-neutral-800 rounded-full overflow-hidden\">\n                <div\n                  className=\"h-full bg-[#00f3ff] rounded-full transition-all duration-200\"\n                  style={{ width: `${((currentStepIndex + 1) / totalSteps) * 100}%` }}\n                />\n              </div>\n              <span className=\"text-xs text-neutral-400 font-mono min-w-[4ch] text-right\">\n                {totalSteps}\n              </span>\n            </div>\n\n            <button\n              onClick={handleNext}\n              className={`flex items-center gap-2 px-5 py-2.5 rounded-xl font-medium text-sm transition-all ${currentStepIndex === totalSteps - 1\n                ? 'bg-green-500 text-white hover:bg-green-600'\n                : 'bg-[#00f3ff] text-black hover:shadow-[0_0_20px_rgba(0,243,255,0.4)]'\n                }`}\n            >\n              {currentStepIndex === totalSteps - 1 ? (\n                <>\n                  <Check className=\"w-4 h-4\" />\n                  Complete\n                </>\n              ) : (\n                <>\n                  Next\n                  <ChevronRight className=\"w-4 h-4\" />\n                </>\n              )}\n            </button>\n\n          </div>\n        </div>\n      </div>\n    </div>\n  );\n}\n","numLines":1112,"startLine":1,"totalLines":1112}}}
{"parentUuid":"08b35847-5b82-4fcc-a926-727e57e9d050","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"988cde7a-9586-4ca8-910d-50a828b2fa2d","version":"2.0.76","gitBranch":"main","agentId":"aee8db2","slug":"fizzy-singing-bird","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01AAKWnVskBVQWibMCcT8CcW","type":"tool_result","content":"No files found"}]},"uuid":"ceb37066-94da-4191-ab4f-abc579bc292b","timestamp":"2025-12-30T14:57:17.405Z","toolUseResult":{"filenames":[],"durationMs":292,"numFiles":0,"truncated":false}}
{"parentUuid":"ceb37066-94da-4191-ab4f-abc579bc292b","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"988cde7a-9586-4ca8-910d-50a828b2fa2d","version":"2.0.76","gitBranch":"main","agentId":"aee8db2","slug":"fizzy-singing-bird","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01VBC2faqXAo9856Pwd5egYC","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me search for type definitions and the landmark definitions:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":34091,"cache_read_input_tokens":39730,"cache_creation":{"ephemeral_5m_input_tokens":34091,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWd4rvQCQTRJHsDDw9vsc","type":"assistant","uuid":"d88c10d6-c3dd-4f95-a0a4-9aed94af29f6","timestamp":"2025-12-30T14:57:21.836Z"}
{"parentUuid":"d88c10d6-c3dd-4f95-a0a4-9aed94af29f6","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"988cde7a-9586-4ca8-910d-50a828b2fa2d","version":"2.0.76","gitBranch":"main","agentId":"aee8db2","slug":"fizzy-singing-bird","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01VBC2faqXAo9856Pwd5egYC","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_011uTkCDMemmBgTtY2aEtmq5","name":"Read","input":{"file_path":"/Users/imorgado/LOOKSMAXX/looksmaxx-app/src/lib/landmarks.ts"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":34091,"cache_read_input_tokens":39730,"cache_creation":{"ephemeral_5m_input_tokens":34091,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWd4rvQCQTRJHsDDw9vsc","type":"assistant","uuid":"31c92159-aff2-4fb7-806c-f2ecd1d45638","timestamp":"2025-12-30T14:57:23.103Z"}
{"parentUuid":"31c92159-aff2-4fb7-806c-f2ecd1d45638","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"988cde7a-9586-4ca8-910d-50a828b2fa2d","version":"2.0.76","gitBranch":"main","agentId":"aee8db2","slug":"fizzy-singing-bird","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01VBC2faqXAo9856Pwd5egYC","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Tuc8JiSnsNzoM2Z4hjMKgJ","name":"Grep","input":{"pattern":"SIDE_PROFILE_LANDMARKS","output_mode":"files_with_matches"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":34091,"cache_read_input_tokens":39730,"cache_creation":{"ephemeral_5m_input_tokens":34091,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWd4rvQCQTRJHsDDw9vsc","type":"assistant","uuid":"8bb5eb8b-8198-463f-8324-d966de741d5e","timestamp":"2025-12-30T14:57:24.083Z"}
{"parentUuid":"8bb5eb8b-8198-463f-8324-d966de741d5e","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"988cde7a-9586-4ca8-910d-50a828b2fa2d","version":"2.0.76","gitBranch":"main","agentId":"aee8db2","slug":"fizzy-singing-bird","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01VBC2faqXAo9856Pwd5egYC","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Gbb7tK9oaSRSctj56P5B6u","name":"Grep","input":{"pattern":"sideLandmarks|SideLandmarks","output_mode":"files_with_matches"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":34091,"cache_read_input_tokens":39730,"cache_creation":{"ephemeral_5m_input_tokens":34091,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWd4rvQCQTRJHsDDw9vsc","type":"assistant","uuid":"b23acc27-97a1-4f8a-8440-64ab816b4d37","timestamp":"2025-12-30T14:57:24.797Z"}
{"parentUuid":"b23acc27-97a1-4f8a-8440-64ab816b4d37","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"988cde7a-9586-4ca8-910d-50a828b2fa2d","version":"2.0.76","gitBranch":"main","agentId":"aee8db2","slug":"fizzy-singing-bird","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Tuc8JiSnsNzoM2Z4hjMKgJ","type":"tool_result","content":"Found 10 files\nsrc/components/LandmarkAnalysisTool.tsx\nsrc/lib/landmarks.ts\nsrc/lib/mediapipeDetection.ts\nsrc/app/results/page.tsx\nsrc/lib/landmarkImages.ts\nsrc/components/SideProfileManualTool.tsx\nsrc/lib/sideProfileDetection.ts\ntest-demographic-scoring.ts\ntest-full-simulation.ts\nsrc/hooks/useAutoDetection.ts"}]},"uuid":"8cc0b9d6-3ed8-4105-b5eb-ddd0f65251e9","timestamp":"2025-12-30T14:57:24.877Z","toolUseResult":{"mode":"files_with_matches","filenames":["src/components/LandmarkAnalysisTool.tsx","src/lib/landmarks.ts","src/lib/mediapipeDetection.ts","src/app/results/page.tsx","src/lib/landmarkImages.ts","src/components/SideProfileManualTool.tsx","src/lib/sideProfileDetection.ts","test-demographic-scoring.ts","test-full-simulation.ts","src/hooks/useAutoDetection.ts"],"numFiles":10}}
{"parentUuid":"8cc0b9d6-3ed8-4105-b5eb-ddd0f65251e9","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"988cde7a-9586-4ca8-910d-50a828b2fa2d","version":"2.0.76","gitBranch":"main","agentId":"aee8db2","slug":"fizzy-singing-bird","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Gbb7tK9oaSRSctj56P5B6u","type":"tool_result","content":"Found 18 files\nsrc/components/results/tabs/OverviewTab.tsx\nsrc/lib/faceiq-parity/index.ts\nsrc/lib/faceiq-parity/sideLandmarks.ts\nsrc/lib/sample-data.ts\nsrc/components/results/tabs/RatiosTab.tsx\nsrc/app/results/page.tsx\nsrc/contexts/ResultsContext.tsx\nsrc/app/analysis/page.tsx\nsrc/lib/scoring/analyzer.ts\nsrc/app/api/analyze-face/route.ts\nsrc/components/ResultsDashboard.tsx\nSPRINTS.md\ntest-demographic-scoring.ts\nFINAL_VERIFICATION_REPORT.md\nTECHNICAL_SPECS.md\ntest-full-simulation.ts\nsrc/lib/scoring.ts\nsrc/hooks/useAutoDetection.ts"}]},"uuid":"9600db23-3f67-46eb-8b00-81d072c46a27","timestamp":"2025-12-30T14:57:24.881Z","toolUseResult":{"mode":"files_with_matches","filenames":["src/components/results/tabs/OverviewTab.tsx","src/lib/faceiq-parity/index.ts","src/lib/faceiq-parity/sideLandmarks.ts","src/lib/sample-data.ts","src/components/results/tabs/RatiosTab.tsx","src/app/results/page.tsx","src/contexts/ResultsContext.tsx","src/app/analysis/page.tsx","src/lib/scoring/analyzer.ts","src/app/api/analyze-face/route.ts","src/components/ResultsDashboard.tsx","SPRINTS.md","test-demographic-scoring.ts","FINAL_VERIFICATION_REPORT.md","TECHNICAL_SPECS.md","test-full-simulation.ts","src/lib/scoring.ts","src/hooks/useAutoDetection.ts"],"numFiles":18}}
{"parentUuid":"9600db23-3f67-46eb-8b00-81d072c46a27","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"988cde7a-9586-4ca8-910d-50a828b2fa2d","version":"2.0.76","gitBranch":"main","agentId":"aee8db2","slug":"fizzy-singing-bird","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_011uTkCDMemmBgTtY2aEtmq5","type":"tool_result","content":"     1→/**\n     2→ * Facial Landmark Types and Default Data\n     3→ * Based on TECHNICAL_SPECS.md medical terminology\n     4→ */\n     5→\n     6→export interface LandmarkPoint {\n     7→  id: string;\n     8→  label: string;\n     9→  medicalTerm: string;\n    10→  description: string;\n    11→  x: number;\n    12→  y: number;\n    13→  category: string;\n    14→}\n    15→\n    16→export interface LandmarkCategory {\n    17→  name: string;\n    18→  color: string;\n    19→  landmarks: string[];\n    20→}\n    21→\n    22→// ============================================\n    23→// FRONT PROFILE LANDMARKS (52 Points)\n    24→// ============================================\n    25→\n    26→export const FRONT_LANDMARK_CATEGORIES: LandmarkCategory[] = [\n    27→  {\n    28→    name: 'Head',\n    29→    color: '#FF6B6B',\n    30→    landmarks: ['trichion'],\n    31→  },\n    32→  {\n    33→    name: 'Eyes - Left',\n    34→    color: '#4ECDC4',\n    35→    landmarks: [\n    36→      'left_pupila',\n    37→      'left_canthus_medialis',\n    38→      'left_canthus_lateralis',\n    39→      'left_palpebra_superior',\n    40→      'left_palpebra_inferior',\n    41→      'left_sulcus_palpebralis_lateralis',\n    42→      'left_pretarsal_skin_crease',\n    43→    ],\n    44→  },\n    45→  {\n    46→    name: 'Eyes - Right',\n    47→    color: '#45B7D1',\n    48→    landmarks: [\n    49→      'right_pupila',\n    50→      'right_canthus_medialis',\n    51→      'right_canthus_lateralis',\n    52→      'right_palpebra_superior',\n    53→      'right_palpebra_inferior',\n    54→      'right_sulcus_palpebralis_lateralis',\n    55→      'right_pretarsal_skin_crease',\n    56→    ],\n    57→  },\n    58→  {\n    59→    name: 'Eyebrows - Left',\n    60→    color: '#96CEB4',\n    61→    landmarks: [\n    62→      'left_supercilium_medialis',\n    63→      'left_supercilium_medial_corner',\n    64→      'left_supercilium_superior',\n    65→      'left_supercilium_apex',\n    66→      'left_supercilium_lateralis',\n    67→    ],\n    68→  },\n    69→  {\n    70→    name: 'Eyebrows - Right',\n    71→    color: '#88D8B0',\n    72→    landmarks: [\n    73→      'right_supercilium_medialis',\n    74→      'right_supercilium_medial_corner',\n    75→      'right_supercilium_superior',\n    76→      'right_supercilium_apex',\n    77→      'right_supercilium_lateralis',\n    78→    ],\n    79→  },\n    80→  {\n    81→    name: 'Nose',\n    82→    color: '#FFEAA7',\n    83→    landmarks: [\n    84→      'nasal_base',\n    85→      'left_dorsum_nasi',\n    86→      'right_dorsum_nasi',\n    87→      'left_ala_nasi',\n    88→      'right_ala_nasi',\n    89→      'subnasale',\n    90→    ],\n    91→  },\n    92→  {\n    93→    name: 'Mouth',\n    94→    color: '#DDA0DD',\n    95→    landmarks: [\n    96→      'labrale_superius',\n    97→      'cupids_bow',\n    98→      'mouth_middle',\n    99→      'labrale_inferius',\n   100→      'left_cheilion',\n   101→      'right_cheilion',\n   102→    ],\n   103→  },\n   104→  {\n   105→    name: 'Jaw',\n   106→    color: '#F39C12',\n   107→    landmarks: [\n   108→      'left_gonion_superior',\n   109→      'right_gonion_superior',\n   110→      'left_gonion_inferior',\n   111→      'right_gonion_inferior',\n   112→    ],\n   113→  },\n   114→  {\n   115→    name: 'Chin',\n   116→    color: '#E74C3C',\n   117→    landmarks: ['left_mentum_lateralis', 'right_mentum_lateralis', 'menton'],\n   118→  },\n   119→  {\n   120→    name: 'Face Width',\n   121→    color: '#9B59B6',\n   122→    landmarks: [\n   123→      'left_zygion',\n   124→      'right_zygion',\n   125→      'left_temporal',\n   126→      'right_temporal',\n   127→      'left_auricular_lateral',\n   128→      'right_auricular_lateral',\n   129→    ],\n   130→  },\n   131→  {\n   132→    name: 'Neck',\n   133→    color: '#1ABC9C',\n   134→    landmarks: ['left_cervical_lateralis', 'right_cervical_lateralis'],\n   135→  },\n   136→];\n   137→\n   138→export const FRONT_PROFILE_LANDMARKS: LandmarkPoint[] = [\n   139→  // Head/Hair\n   140→  {\n   141→    id: 'trichion',\n   142→    label: 'Hairline',\n   143→    medicalTerm: 'Trichion (frontal view)',\n   144→    description: 'Anterior hairline at midline',\n   145→    x: 0.5,\n   146→    y: 0.08,\n   147→    category: 'Head',\n   148→  },\n   149→\n   150→  // Eyes - Left\n   151→  {\n   152→    id: 'left_pupila',\n   153→    label: 'Left Pupil',\n   154→    medicalTerm: 'Left Pupila',\n   155→    description: 'Center of left pupil',\n   156→    x: 0.38,\n   157→    y: 0.35,\n   158→    category: 'Eyes - Left',\n   159→  },\n   160→  {\n   161→    id: 'left_canthus_medialis',\n   162→    label: 'Left Medial Canthus',\n   163→    medicalTerm: 'Left Canthus Medialis',\n   164→    description: 'Inner corner of left eye',\n   165→    x: 0.42,\n   166→    y: 0.35,\n   167→    category: 'Eyes - Left',\n   168→  },\n   169→  {\n   170→    id: 'left_canthus_lateralis',\n   171→    label: 'Left Lateral Canthus',\n   172→    medicalTerm: 'Left Canthus Lateralis',\n   173→    description: 'Outer corner of left eye',\n   174→    x: 0.32,\n   175→    y: 0.34,\n   176→    category: 'Eyes - Left',\n   177→  },\n   178→  {\n   179→    id: 'left_palpebra_superior',\n   180→    label: 'Left Upper Eyelid',\n   181→    medicalTerm: 'Left Palpebra Superior',\n   182→    description: 'Upper eyelid of left eye',\n   183→    x: 0.37,\n   184→    y: 0.33,\n   185→    category: 'Eyes - Left',\n   186→  },\n   187→  {\n   188→    id: 'left_palpebra_inferior',\n   189→    label: 'Left Lower Eyelid',\n   190→    medicalTerm: 'Left Palpebra Inferior',\n   191→    description: 'Lower eyelid of left eye',\n   192→    x: 0.37,\n   193→    y: 0.37,\n   194→    category: 'Eyes - Left',\n   195→  },\n   196→  {\n   197→    id: 'left_sulcus_palpebralis_lateralis',\n   198→    label: 'Left Eyelid Hood End',\n   199→    medicalTerm: 'Left Sulcus Palpebralis Lateralis',\n   200→    description: 'Lateral end of left upper eyelid crease',\n   201→    x: 0.31,\n   202→    y: 0.33,\n   203→    category: 'Eyes - Left',\n   204→  },\n   205→  {\n   206→    id: 'left_pretarsal_skin_crease',\n   207→    label: 'Left Upper Eyelid Crease',\n   208→    medicalTerm: 'Left Pretarsal Skin Crease',\n   209→    description: 'Left upper eyelid crease',\n   210→    x: 0.37,\n   211→    y: 0.32,\n   212→    category: 'Eyes - Left',\n   213→  },\n   214→\n   215→  // Eyes - Right\n   216→  {\n   217→    id: 'right_pupila',\n   218→    label: 'Right Pupil',\n   219→    medicalTerm: 'Right Pupila',\n   220→    description: 'Center of right pupil',\n   221→    x: 0.62,\n   222→    y: 0.35,\n   223→    category: 'Eyes - Right',\n   224→  },\n   225→  {\n   226→    id: 'right_canthus_medialis',\n   227→    label: 'Right Medial Canthus',\n   228→    medicalTerm: 'Right Canthus Medialis',\n   229→    description: 'Inner corner of right eye',\n   230→    x: 0.58,\n   231→    y: 0.35,\n   232→    category: 'Eyes - Right',\n   233→  },\n   234→  {\n   235→    id: 'right_canthus_lateralis',\n   236→    label: 'Right Lateral Canthus',\n   237→    medicalTerm: 'Right Canthus Lateralis',\n   238→    description: 'Outer corner of right eye',\n   239→    x: 0.68,\n   240→    y: 0.34,\n   241→    category: 'Eyes - Right',\n   242→  },\n   243→  {\n   244→    id: 'right_palpebra_superior',\n   245→    label: 'Right Upper Eyelid',\n   246→    medicalTerm: 'Right Palpebra Superior',\n   247→    description: 'Upper eyelid of right eye',\n   248→    x: 0.63,\n   249→    y: 0.33,\n   250→    category: 'Eyes - Right',\n   251→  },\n   252→  {\n   253→    id: 'right_palpebra_inferior',\n   254→    label: 'Right Lower Eyelid',\n   255→    medicalTerm: 'Right Palpebra Inferior',\n   256→    description: 'Lower eyelid of right eye',\n   257→    x: 0.63,\n   258→    y: 0.37,\n   259→    category: 'Eyes - Right',\n   260→  },\n   261→  {\n   262→    id: 'right_sulcus_palpebralis_lateralis',\n   263→    label: 'Right Eyelid Hood End',\n   264→    medicalTerm: 'Right Sulcus Palpebralis Lateralis',\n   265→    description: 'Lateral end of right upper eyelid crease',\n   266→    x: 0.69,\n   267→    y: 0.33,\n   268→    category: 'Eyes - Right',\n   269→  },\n   270→  {\n   271→    id: 'right_pretarsal_skin_crease',\n   272→    label: 'Right Upper Eyelid Crease',\n   273→    medicalTerm: 'Right Pretarsal Skin Crease',\n   274→    description: 'Right upper eyelid crease',\n   275→    x: 0.63,\n   276→    y: 0.32,\n   277→    category: 'Eyes - Right',\n   278→  },\n   279→\n   280→  // Eyebrows - Left\n   281→  {\n   282→    id: 'left_supercilium_medialis',\n   283→    label: 'Left Brow Head',\n   284→    medicalTerm: 'Left Supercilium Medialis',\n   285→    description: 'Medial start of left eyebrow',\n   286→    x: 0.43,\n   287→    y: 0.28,\n   288→    category: 'Eyebrows - Left',\n   289→  },\n   290→  {\n   291→    id: 'left_supercilium_medial_corner',\n   292→    label: 'Left Brow Inner Corner',\n   293→    medicalTerm: 'Left Supercilium Medial Corner',\n   294→    description: 'Inner corner of left eyebrow',\n   295→    x: 0.41,\n   296→    y: 0.27,\n   297→    category: 'Eyebrows - Left',\n   298→  },\n   299→  {\n   300→    id: 'left_supercilium_superior',\n   301→    label: 'Left Brow Arch',\n   302→    medicalTerm: 'Left Supercilium Superior',\n   303→    description: 'Superior arc of left eyebrow',\n   304→    x: 0.36,\n   305→    y: 0.26,\n   306→    category: 'Eyebrows - Left',\n   307→  },\n   308→  {\n   309→    id: 'left_supercilium_apex',\n   310→    label: 'Left Brow Peak',\n   311→    medicalTerm: 'Left Supercilium Apex',\n   312→    description: 'Highest point of left eyebrow',\n   313→    x: 0.34,\n   314→    y: 0.26,\n   315→    category: 'Eyebrows - Left',\n   316→  },\n   317→  {\n   318→    id: 'left_supercilium_lateralis',\n   319→    label: 'Left Brow Tail',\n   320→    medicalTerm: 'Left Supercilium Lateralis',\n   321→    description: 'Lateral end of left eyebrow',\n   322→    x: 0.29,\n   323→    y: 0.28,\n   324→    category: 'Eyebrows - Left',\n   325→  },\n   326→\n   327→  // Eyebrows - Right\n   328→  {\n   329→    id: 'right_supercilium_medialis',\n   330→    label: 'Right Brow Head',\n   331→    medicalTerm: 'Right Supercilium Medialis',\n   332→    description: 'Medial start of right eyebrow',\n   333→    x: 0.57,\n   334→    y: 0.28,\n   335→    category: 'Eyebrows - Right',\n   336→  },\n   337→  {\n   338→    id: 'right_supercilium_medial_corner',\n   339→    label: 'Right Brow Inner Corner',\n   340→    medicalTerm: 'Right Supercilium Medial Corner',\n   341→    description: 'Inner corner of right eyebrow',\n   342→    x: 0.59,\n   343→    y: 0.27,\n   344→    category: 'Eyebrows - Right',\n   345→  },\n   346→  {\n   347→    id: 'right_supercilium_superior',\n   348→    label: 'Right Brow Arch',\n   349→    medicalTerm: 'Right Supercilium Superior',\n   350→    description: 'Superior arc of right eyebrow',\n   351→    x: 0.64,\n   352→    y: 0.26,\n   353→    category: 'Eyebrows - Right',\n   354→  },\n   355→  {\n   356→    id: 'right_supercilium_apex',\n   357→    label: 'Right Brow Peak',\n   358→    medicalTerm: 'Right Supercilium Apex',\n   359→    description: 'Highest point of right eyebrow',\n   360→    x: 0.66,\n   361→    y: 0.26,\n   362→    category: 'Eyebrows - Right',\n   363→  },\n   364→  {\n   365→    id: 'right_supercilium_lateralis',\n   366→    label: 'Right Brow Tail',\n   367→    medicalTerm: 'Right Supercilium Lateralis',\n   368→    description: 'Lateral end of right eyebrow',\n   369→    x: 0.71,\n   370→    y: 0.28,\n   371→    category: 'Eyebrows - Right',\n   372→  },\n   373→\n   374→  // Nose\n   375→  {\n   376→    id: 'nasal_base',\n   377→    label: 'Nasal Base',\n   378→    medicalTerm: 'Nasal Base',\n   379→    description: 'Base of nasal dorsum',\n   380→    x: 0.5,\n   381→    y: 0.38,\n   382→    category: 'Nose',\n   383→  },\n   384→  {\n   385→    id: 'left_dorsum_nasi',\n   386→    label: 'Left Nose Bridge',\n   387→    medicalTerm: 'Left Dorsum Nasi',\n   388→    description: 'Left side of nasal bridge',\n   389→    x: 0.47,\n   390→    y: 0.42,\n   391→    category: 'Nose',\n   392→  },\n   393→  {\n   394→    id: 'right_dorsum_nasi',\n   395→    label: 'Right Nose Bridge',\n   396→    medicalTerm: 'Right Dorsum Nasi',\n   397→    description: 'Right side of nasal bridge',\n   398→    x: 0.53,\n   399→    y: 0.42,\n   400→    category: 'Nose',\n   401→  },\n   402→  {\n   403→    id: 'left_ala_nasi',\n   404→    label: 'Left Nose Side',\n   405→    medicalTerm: 'Left Ala Nasi',\n   406→    description: 'Lateral aspect of left nasal ala',\n   407→    x: 0.44,\n   408→    y: 0.5,\n   409→    category: 'Nose',\n   410→  },\n   411→  {\n   412→    id: 'right_ala_nasi',\n   413→    label: 'Right Nose Side',\n   414→    medicalTerm: 'Right Ala Nasi',\n   415→    description: 'Lateral aspect of right nasal ala',\n   416→    x: 0.56,\n   417→    y: 0.5,\n   418→    category: 'Nose',\n   419→  },\n   420→  {\n   421→    id: 'subnasale',\n   422→    label: 'Nose Bottom',\n   423→    medicalTerm: 'Subnasale',\n   424→    description: 'Junction of columella and upper lip',\n   425→    x: 0.5,\n   426→    y: 0.52,\n   427→    category: 'Nose',\n   428→  },\n   429→\n   430→  // Mouth\n   431→  {\n   432→    id: 'labrale_superius',\n   433→    label: \"Cupid's Bow\",\n   434→    medicalTerm: 'Labrale Superius',\n   435→    description: 'Midpoint of upper lip vermilion',\n   436→    x: 0.5,\n   437→    y: 0.58,\n   438→    category: 'Mouth',\n   439→  },\n   440→  {\n   441→    id: 'cupids_bow',\n   442→    label: \"Inner Cupid's Bow\",\n   443→    medicalTerm: \"Cupid's Bow\",\n   444→    description: 'Central peak of upper lip',\n   445→    x: 0.5,\n   446→    y: 0.57,\n   447→    category: 'Mouth',\n   448→  },\n   449→  {\n   450→    id: 'mouth_middle',\n   451→    label: 'Mouth Middle',\n   452→    medicalTerm: 'Mouth Middle',\n   453→    description: 'Center of mouth opening',\n   454→    x: 0.5,\n   455→    y: 0.62,\n   456→    category: 'Mouth',\n   457→  },\n   458→  {\n   459→    id: 'labrale_inferius',\n   460→    label: 'Lower Lip Center',\n   461→    medicalTerm: 'Labrale Inferius',\n   462→    description: 'Midpoint of lower lip vermilion border',\n   463→    x: 0.5,\n   464→    y: 0.66,\n   465→    category: 'Mouth',\n   466→  },\n   467→  {\n   468→    id: 'left_cheilion',\n   469→    label: 'Left Mouth Corner',\n   470→    medicalTerm: 'Left Cheilion',\n   471→    description: 'Left oral commissure',\n   472→    x: 0.42,\n   473→    y: 0.62,\n   474→    category: 'Mouth',\n   475→  },\n   476→  {\n   477→    id: 'right_cheilion',\n   478→    label: 'Right Mouth Corner',\n   479→    medicalTerm: 'Right Cheilion',\n   480→    description: 'Right oral commissure',\n   481→    x: 0.58,\n   482→    y: 0.62,\n   483→    category: 'Mouth',\n   484→  },\n   485→\n   486→  // Jaw\n   487→  {\n   488→    id: 'left_gonion_superior',\n   489→    label: 'Left Upper Jaw Angle',\n   490→    medicalTerm: 'Left Gonion Superior',\n   491→    description: 'Superior aspect of left mandibular angle',\n   492→    x: 0.22,\n   493→    y: 0.55,\n   494→    category: 'Jaw',\n   495→  },\n   496→  {\n   497→    id: 'right_gonion_superior',\n   498→    label: 'Right Upper Jaw Angle',\n   499→    medicalTerm: 'Right Gonion Superior',\n   500→    description: 'Superior aspect of right mandibular angle',\n   501→    x: 0.78,\n   502→    y: 0.55,\n   503→    category: 'Jaw',\n   504→  },\n   505→  {\n   506→    id: 'left_gonion_inferior',\n   507→    label: 'Left Lower Jaw Angle',\n   508→    medicalTerm: 'Left Gonion Inferior',\n   509→    description: 'Inferior aspect of left mandibular angle',\n   510→    x: 0.24,\n   511→    y: 0.7,\n   512→    category: 'Jaw',\n   513→  },\n   514→  {\n   515→    id: 'right_gonion_inferior',\n   516→    label: 'Right Lower Jaw Angle',\n   517→    medicalTerm: 'Right Gonion Inferior',\n   518→    description: 'Inferior aspect of right mandibular angle',\n   519→    x: 0.76,\n   520→    y: 0.7,\n   521→    category: 'Jaw',\n   522→  },\n   523→\n   524→  // Chin\n   525→  {\n   526→    id: 'left_mentum_lateralis',\n   527→    label: 'Left Chin',\n   528→    medicalTerm: 'Left Mentum Lateralis',\n   529→    description: 'Left lateral chin',\n   530→    x: 0.42,\n   531→    y: 0.8,\n   532→    category: 'Chin',\n   533→  },\n   534→  {\n   535→    id: 'right_mentum_lateralis',\n   536→    label: 'Right Chin',\n   537→    medicalTerm: 'Right Mentum Lateralis',\n   538→    description: 'Right lateral chin',\n   539→    x: 0.58,\n   540→    y: 0.8,\n   541→    category: 'Chin',\n   542→  },\n   543→  {\n   544→    id: 'menton',\n   545→    label: 'Chin Bottom',\n   546→    medicalTerm: 'Menton',\n   547→    description: 'Lowest point of chin in midline',\n   548→    x: 0.5,\n   549→    y: 0.88,\n   550→    category: 'Chin',\n   551→  },\n   552→\n   553→  // Face Width\n   554→  {\n   555→    id: 'left_zygion',\n   556→    label: 'Left Cheekbone',\n   557→    medicalTerm: 'Left Zygion',\n   558→    description: 'Most lateral point of left zygomatic arch',\n   559→    x: 0.18,\n   560→    y: 0.42,\n   561→    category: 'Face Width',\n   562→  },\n   563→  {\n   564→    id: 'right_zygion',\n   565→    label: 'Right Cheekbone',\n   566→    medicalTerm: 'Right Zygion',\n   567→    description: 'Most lateral point of right zygomatic arch',\n   568→    x: 0.82,\n   569→    y: 0.42,\n   570→    category: 'Face Width',\n   571→  },\n   572→  {\n   573→    id: 'left_temporal',\n   574→    label: 'Left Temple',\n   575→    medicalTerm: 'Left Temporal Point',\n   576→    description: 'Left temporal region',\n   577→    x: 0.2,\n   578→    y: 0.3,\n   579→    category: 'Face Width',\n   580→  },\n   581→  {\n   582→    id: 'right_temporal',\n   583→    label: 'Right Temple',\n   584→    medicalTerm: 'Right Temporal Point',\n   585→    description: 'Right temporal region',\n   586→    x: 0.8,\n   587→    y: 0.3,\n   588→    category: 'Face Width',\n   589→  },\n   590→  {\n   591→    id: 'left_auricular_lateral',\n   592→    label: 'Left Outer Ear',\n   593→    medicalTerm: 'Left Auricular Lateral Point',\n   594→    description: 'Lateral-most point of left ear',\n   595→    x: 0.12,\n   596→    y: 0.4,\n   597→    category: 'Face Width',\n   598→  },\n   599→  {\n   600→    id: 'right_auricular_lateral',\n   601→    label: 'Right Outer Ear',\n   602→    medicalTerm: 'Right Auricular Lateral Point',\n   603→    description: 'Lateral-most point of right ear',\n   604→    x: 0.88,\n   605→    y: 0.4,\n   606→    category: 'Face Width',\n   607→  },\n   608→\n   609→  // Neck\n   610→  {\n   611→    id: 'left_cervical_lateralis',\n   612→    label: 'Left Neck Point',\n   613→    medicalTerm: 'Left Cervical Lateralis',\n   614→    description: 'Left cervical point',\n   615→    x: 0.35,\n   616→    y: 0.95,\n   617→    category: 'Neck',\n   618→  },\n   619→  {\n   620→    id: 'right_cervical_lateralis',\n   621→    label: 'Right Neck Point',\n   622→    medicalTerm: 'Right Cervical Lateralis',\n   623→    description: 'Right cervical point',\n   624→    x: 0.65,\n   625→    y: 0.95,\n   626→    category: 'Neck',\n   627→  },\n   628→];\n   629→\n   630→// ============================================\n   631→// SIDE PROFILE LANDMARKS (31 Points)\n   632→// FaceIQ Parity - Matches FaceIQ's exact order and flow\n   633→// ============================================\n   634→\n   635→export const SIDE_LANDMARK_CATEGORIES: LandmarkCategory[] = [\n   636→  {\n   637→    name: 'Head',\n   638→    color: '#FF6B6B',\n   639→    landmarks: ['vertex', 'occiput'],\n   640→  },\n   641→  {\n   642→    name: 'Forehead',\n   643→    color: '#4ECDC4',\n   644→    landmarks: ['trichion', 'forehead', 'glabella'],\n   645→  },\n   646→  {\n   647→    name: 'Eye Region',\n   648→    color: '#45B7D1',\n   649→    landmarks: ['orbitale', 'cornealApex', 'eyelidEnd', 'lowerEyelid'],\n   650→  },\n   651→  {\n   652→    name: 'Ear',\n   653→    color: '#3498DB',\n   654→    landmarks: ['porion', 'tragus', 'intertragicNotch'],\n   655→  },\n   656→  {\n   657→    name: 'Cheek',\n   658→    color: '#9B59B6',\n   659→    landmarks: ['cheekbone'],\n   660→  },\n   661→  {\n   662→    name: 'Nose',\n   663→    color: '#FFEAA7',\n   664→    landmarks: [\n   665→      'nasion',\n   666→      'rhinion',\n   667→      'supratip',\n   668→      'pronasale',\n   669→      'infratip',\n   670→      'columella',\n   671→      'subnasale',\n   672→      'subalare',\n   673→    ],\n   674→  },\n   675→  {\n   676→    name: 'Lips',\n   677→    color: '#DDA0DD',\n   678→    landmarks: ['labraleSuperius', 'cheilion', 'labraleInferius', 'sublabiale'],\n   679→  },\n   680→  {\n   681→    name: 'Chin',\n   682→    color: '#E74C3C',\n   683→    landmarks: ['pogonion', 'menton'],\n   684→  },\n   685→  {\n   686→    name: 'Jaw',\n   687→    color: '#F39C12',\n   688→    landmarks: ['gonionTop', 'gonionBottom'],\n   689→  },\n   690→  {\n   691→    name: 'Neck',\n   692→    color: '#1ABC9C',\n   693→    landmarks: ['cervicalPoint', 'neckPoint'],\n   694→  },\n   695→];\n   696→\n   697→// FaceIQ Parity Order: Matches FaceIQ's exact flow (1 of 31 → 31 of 31)\n   698→// Head → Forehead → Eye → Ear → Cheek → Nose → Lips → Chin → Jaw → Neck\n   699→export const SIDE_PROFILE_LANDMARKS: LandmarkPoint[] = [\n   700→  // ========== HEAD (1-2) ==========\n   701→  {\n   702→    id: 'vertex',\n   703→    label: 'Top of Head',\n   704→    medicalTerm: 'Vertex',\n   705→    description: 'The highest point on the top of the head when looking from the side',\n   706→    x: 0.45,\n   707→    y: 0.02,\n   708→    category: 'Head',\n   709→  },\n   710→  {\n   711→    id: 'occiput',\n   712→    label: 'Back of Head',\n   713→    medicalTerm: 'Occiput',\n   714→    description: 'The most posterior point on the back of the head',\n   715→    x: 0.85,\n   716→    y: 0.15,\n   717→    category: 'Head',\n   718→  },\n   719→\n   720→  // ========== FOREHEAD (3-5) ==========\n   721→  {\n   722→    id: 'trichion',\n   723→    label: 'Hairline',\n   724→    medicalTerm: 'Trichion',\n   725→    description: 'The point where the hairline meets the forehead in the midline',\n   726→    x: 0.35,\n   727→    y: 0.1,\n   728→    category: 'Forehead',\n   729→  },\n   730→  {\n   731→    id: 'forehead',\n   732→    label: 'Forehead Point',\n   733→    medicalTerm: 'Forehead',\n   734→    description: 'The most prominent point on the forehead between hairline and glabella',\n   735→    x: 0.30,\n   736→    y: 0.20,\n   737→    category: 'Forehead',\n   738→  },\n   739→  {\n   740→    id: 'glabella',\n   741→    label: 'Glabella',\n   742→    medicalTerm: 'Glabella',\n   743→    description: 'The most prominent point between the eyebrows',\n   744→    x: 0.32,\n   745→    y: 0.28,\n   746→    category: 'Forehead',\n   747→  },\n   748→\n   749→  // ========== EYE REGION (6-9) ==========\n   750→  {\n   751→    id: 'orbitale',\n   752→    label: 'Orbitale',\n   753→    medicalTerm: 'Orbitale',\n   754→    description: 'The lowest point on the lower edge of the eye socket (orbital rim)',\n   755→    x: 0.35,\n   756→    y: 0.38,\n   757→    category: 'Eye Region',\n   758→  },\n   759→  {\n   760→    id: 'cornealApex',\n   761→    label: 'Corneal Apex',\n   762→    medicalTerm: 'Corneal Apex',\n   763→    description: 'The most anterior point of the cornea (eyeball)',\n   764→    x: 0.28,\n   765→    y: 0.34,\n   766→    category: 'Eye Region',\n   767→  },\n   768→  {\n   769→    id: 'eyelidEnd',\n   770→    label: 'Eyelid End',\n   771→    medicalTerm: 'Lateral Canthus',\n   772→    description: 'The outer corner of the eye where upper and lower eyelids meet',\n   773→    x: 0.38,\n   774→    y: 0.33,\n   775→    category: 'Eye Region',\n   776→  },\n   777→  {\n   778→    id: 'lowerEyelid',\n   779→    label: 'Lower Eyelid',\n   780→    medicalTerm: 'Lower Palpebra',\n   781→    description: 'The lowest point of the lower eyelid margin',\n   782→    x: 0.32,\n   783→    y: 0.36,\n   784→    category: 'Eye Region',\n   785→  },\n   786→\n   787→  // ========== EAR (10-12) - Critical for Frankfort Plane ==========\n   788→  {\n   789→    id: 'porion',\n   790→    label: 'Porion',\n   791→    medicalTerm: 'Porion',\n   792→    description: 'The highest point on the upper margin of the external auditory meatus (ear canal opening). Forms the Frankfort Horizontal Plane with Orbitale.',\n   793→    x: 0.75,\n   794→    y: 0.35,\n   795→    category: 'Ear',\n   796→  },\n   797→  {\n   798→    id: 'tragus',\n   799→    label: 'Tragus',\n   800→    medicalTerm: 'Tragus',\n   801→    description: 'The small pointed cartilage projection in front of the ear canal',\n   802→    x: 0.72,\n   803→    y: 0.42,\n   804→    category: 'Ear',\n   805→  },\n   806→  {\n   807→    id: 'intertragicNotch',\n   808→    label: 'Intertragic Notch',\n   809→    medicalTerm: 'Intertragic Notch',\n   810→    description: 'The depression between the tragus and antitragus of the ear',\n   811→    x: 0.73,\n   812→    y: 0.45,\n   813→    category: 'Ear',\n   814→  },\n   815→\n   816→  // ========== CHEEK (13) ==========\n   817→  {\n   818→    id: 'cheekbone',\n   819→    label: 'Cheekbone',\n   820→    medicalTerm: 'Zygion',\n   821→    description: 'The most lateral point on the zygomatic arch (cheekbone)',\n   822→    x: 0.45,\n   823→    y: 0.42,\n   824→    category: 'Cheek',\n   825→  },\n   826→\n   827→  // ========== NOSE (14-21) ==========\n   828→  {\n   829→    id: 'nasion',\n   830→    label: 'Nasal Bridge Root',\n   831→    medicalTerm: 'Nasion',\n   832→    description: 'The deepest point at the bridge of the nose, between the eyes',\n   833→    x: 0.35,\n   834→    y: 0.32,\n   835→    category: 'Nose',\n   836→  },\n   837→  {\n   838→    id: 'rhinion',\n   839→    label: 'Nasal Bridge',\n   840→    medicalTerm: 'Rhinion',\n   841→    description: 'The midpoint on the nasal bridge',\n   842→    x: 0.28,\n   843→    y: 0.4,\n   844→    category: 'Nose',\n   845→  },\n   846→  {\n   847→    id: 'supratip',\n   848→    label: 'Supratip',\n   849→    medicalTerm: 'Supratip',\n   850→    description: 'The point just above the nose tip, on the dorsum',\n   851→    x: 0.22,\n   852→    y: 0.46,\n   853→    category: 'Nose',\n   854→  },\n   855→  {\n   856→    id: 'pronasale',\n   857→    label: 'Nose Tip',\n   858→    medicalTerm: 'Pronasale',\n   859→    description: 'The most anterior point of the nose tip',\n   860→    x: 0.18,\n   861→    y: 0.48,\n   862→    category: 'Nose',\n   863→  },\n   864→  {\n   865→    id: 'infratip',\n   866→    label: 'Infratip',\n   867→    medicalTerm: 'Infratip',\n   868→    description: 'The point just below the nose tip',\n   869→    x: 0.2,\n   870→    y: 0.5,\n   871→    category: 'Nose',\n   872→  },\n   873→  {\n   874→    id: 'columella',\n   875→    label: 'Columella',\n   876→    medicalTerm: 'Columella',\n   877→    description: 'The skin bridge between the nostrils',\n   878→    x: 0.24,\n   879→    y: 0.52,\n   880→    category: 'Nose',\n   881→  },\n   882→  {\n   883→    id: 'subnasale',\n   884→    label: 'Subnasale',\n   885→    medicalTerm: 'Subnasale',\n   886→    description: 'The point where the columella meets the upper lip',\n   887→    x: 0.3,\n   888→    y: 0.54,\n   889→    category: 'Nose',\n   890→  },\n   891→  {\n   892→    id: 'subalare',\n   893→    label: 'Subalare',\n   894→    medicalTerm: 'Subalare',\n   895→    description: 'The point where the nostril wing meets the cheek',\n   896→    x: 0.28,\n   897→    y: 0.53,\n   898→    category: 'Nose',\n   899→  },\n   900→\n   901→  // ========== LIPS (22-25) ==========\n   902→  {\n   903→    id: 'labraleSuperius',\n   904→    label: 'Upper Lip',\n   905→    medicalTerm: 'Labrale Superius',\n   906→    description: 'The most anterior point of the upper lip vermilion',\n   907→    x: 0.28,\n   908→    y: 0.58,\n   909→    category: 'Lips',\n   910→  },\n   911→  {\n   912→    id: 'cheilion',\n   913→    label: 'Mouth Corner',\n   914→    medicalTerm: 'Cheilion',\n   915→    description: 'The corner of the mouth where upper and lower lips meet',\n   916→    x: 0.35,\n   917→    y: 0.62,\n   918→    category: 'Lips',\n   919→  },\n   920→  {\n   921→    id: 'labraleInferius',\n   922→    label: 'Lower Lip',\n   923→    medicalTerm: 'Labrale Inferius',\n   924→    description: 'The most anterior point of the lower lip vermilion',\n   925→    x: 0.3,\n   926→    y: 0.66,\n   927→    category: 'Lips',\n   928→  },\n   929→  {\n   930→    id: 'sublabiale',\n   931→    label: 'Labiomental Fold',\n   932→    medicalTerm: 'Sublabiale',\n   933→    description: 'The deepest point of the crease between lower lip and chin',\n   934→    x: 0.32,\n   935→    y: 0.7,\n   936→    category: 'Lips',\n   937→  },\n   938→\n   939→  // ========== CHIN (26-27) ==========\n   940→  {\n   941→    id: 'pogonion',\n   942→    label: 'Chin Point',\n   943→    medicalTerm: 'Pogonion',\n   944→    description: 'The most anterior point of the chin',\n   945→    x: 0.3,\n   946→    y: 0.76,\n   947→    category: 'Chin',\n   948→  },\n   949→  {\n   950→    id: 'menton',\n   951→    label: 'Chin Bottom',\n   952→    medicalTerm: 'Menton',\n   953→    description: 'The lowest point on the chin',\n   954→    x: 0.35,\n   955→    y: 0.82,\n   956→    category: 'Chin',\n   957→  },\n   958→\n   959→  // ========== JAW (28-29) ==========\n   960→  {\n   961→    id: 'gonionTop',\n   962→    label: 'Upper Jaw Angle',\n   963→    medicalTerm: 'Gonion Superior',\n   964→    description: 'The upper point of the jaw angle (mandibular angle)',\n   965→    x: 0.7,\n   966→    y: 0.6,\n   967→    category: 'Jaw',\n   968→  },\n   969→  {\n   970→    id: 'gonionBottom',\n   971→    label: 'Lower Jaw Angle',\n   972→    medicalTerm: 'Gonion Inferior',\n   973→    description: 'The lower point of the jaw angle (mandibular angle)',\n   974→    x: 0.65,\n   975→    y: 0.72,\n   976→    category: 'Jaw',\n   977→  },\n   978→\n   979→  // ========== NECK (30-31) ==========\n   980→  {\n   981→    id: 'cervicalPoint',\n   982→    label: 'Cervical Point',\n   983→    medicalTerm: 'Cervical Point',\n   984→    description: 'The point where the neck meets the underside of the chin',\n   985→    x: 0.5,\n   986→    y: 0.9,\n   987→    category: 'Neck',\n   988→  },\n   989→  {\n   990→    id: 'neckPoint',\n   991→    label: 'Neck Point',\n   992→    medicalTerm: 'Throat Point',\n   993→    description: 'A point on the front of the neck below the chin',\n   994→    x: 0.4,\n   995→    y: 0.88,\n   996→    category: 'Neck',\n   997→  },\n   998→];\n   999→\n  1000→// ============================================\n  1001→// MediaPipe Face Mesh Index Mapping\n  1002→// ============================================\n  1003→// NOTE: MEDIAPIPE_FRONT_MAPPING is defined in mediapipeDetection.ts (single source of truth)\n  1004→// Import from there if needed: import { MEDIAPIPE_FRONT_MAPPING } from './mediapipeDetection';\n  1005→\n  1006→// Helper to get category color for a landmark\n  1007→export function getLandmarkColor(\n  1008→  landmarkId: string,\n  1009→  categories: LandmarkCategory[]\n  1010→): string {\n  1011→  for (const category of categories) {\n  1012→    if (category.landmarks.includes(landmarkId)) {\n  1013→      return category.color;\n  1014→    }\n  1015→  }\n  1016→  return '#00f3ff'; // Default cyan\n  1017→}\n  1018→\n  1019→// ============================================\n  1020→// Side Profile Landmark Indices (106 points)\n  1021→// Reverse-engineered from PROJECT CASSANOVA API\n  1022→// ============================================\n  1023→\n  1024→export const SIDE_LANDMARKS = {\n  1025→  // Face Contour (0-16) - Jaw/Chin outline\n  1026→  MENTON: 0, // Chin bottom (lowest point)\n  1027→  POGONION: 2, // Chin prominence\n  1028→  GNATHION: 3, // Chin point\n  1029→  MANDIBLE_CONTOUR: [2, 3, 4, 5, 6, 7, 8], // Jaw line\n  1030→\n  1031→  // Posterior Points (1, 9-16) - Ear/Back of head\n  1032→  TRAGION: 1, // Ear point\n  1033→  EAR_CONTOUR: [9, 10, 11, 12, 13, 14, 15, 16],\n  1034→\n  1035→  // Forehead/Hairline (17)\n  1036→  TRICHION: 17, // Hairline\n  1037→\n  1038→  // Nose Profile (18-32)\n  1039→  NASION: 25, // Bridge of nose (deepest point)\n  1040→  PRONASALE: 32, // Nose tip\n  1041→  SUBNASALE: 52, // Base of nose\n  1042→  COLUMELLA: 53, // Nose columella\n  1043→  NOSE_BRIDGE: [25, 26, 27, 28, 29, 30, 31, 32],\n  1044→  NOSE_TIP_CONTOUR: [52, 53, 54, 55, 56, 57, 58, 59, 60],\n  1045→\n  1046→  // Eye Region (33-51)\n  1047→  EYE_LATERAL_CANTHUS: 33, // Outer eye corner\n  1048→  EYE_MEDIAL_CANTHUS: 35, // Inner eye corner\n  1049→  UPPER_EYELID: [37, 38, 39],\n  1050→  LOWER_EYELID: [40, 41, 42],\n  1051→  PUPIL: 34,\n  1052→  BROW_HEAD: 44, // Inner brow\n  1053→  BROW_ARCH: 45, // Brow peak\n  1054→  BROW_TAIL: 46, // Outer brow\n  1055→\n  1056→  // Lip Region (52-75)\n  1057→  LABRALE_SUPERIUS: 63, // Upper lip top\n  1058→  LABRALE_INFERIUS: 66, // Lower lip bottom\n  1059→  STOMION: 65, // Lip meeting point\n  1060→  UPPER_LIP_CONTOUR: [63, 64, 65],\n  1061→  LOWER_LIP_CONTOUR: [66, 67, 68],\n  1062→\n  1063→  // Additional Profile Points (76-105)\n  1064→  GLABELLA: 76, // Between eyebrows\n  1065→  SELLION: 77, // Deepest point of nasal bridge\n  1066→  SOFT_TISSUE_NASION: 78,\n  1067→  ORBITALE: 79, // Lowest point of eye socket\n  1068→  GONION: 85, // Jaw angle\n  1069→  CONDYLION: 86, // Top of jaw joint\n  1070→};\n  1071→\n  1072→// ============================================\n  1073→// Front Face Landmark Indices (MediaPipe 478 points)\n  1074→// ============================================\n  1075→\n  1076→export const FRONT_LANDMARKS = {\n  1077→  // Key points from MediaPipe Face Mesh\n  1078→  NOSE_TIP: 1,\n  1079→  LEFT_EYE_INNER: 133,\n  1080→  LEFT_EYE_OUTER: 33,\n  1081→  RIGHT_EYE_INNER: 362,\n  1082→  RIGHT_EYE_OUTER: 263,\n  1083→  LEFT_CHEEK: 234,\n  1084→  RIGHT_CHEEK: 454,\n  1085→  UPPER_LIP: 13,\n  1086→  LOWER_LIP: 14,\n  1087→  CHIN: 152,\n  1088→  FOREHEAD: 10,\n  1089→  LEFT_EAR: 234,\n  1090→  RIGHT_EAR: 454,\n  1091→  LEFT_BROW_INNER: 107,\n  1092→  LEFT_BROW_OUTER: 70,\n  1093→  RIGHT_BROW_INNER: 336,\n  1094→  RIGHT_BROW_OUTER: 300,\n  1095→  NOSE_BRIDGE: 6,\n  1096→  LEFT_NOSTRIL: 129,\n  1097→  RIGHT_NOSTRIL: 358,\n  1098→};\n  1099→\n  1100→// ============================================\n  1101→// Scoring Configuration Types\n  1102→// ============================================\n  1103→\n  1104→export interface ScoringConfig {\n  1105→  idealValue: number;\n  1106→  standardDeviation: number;\n  1107→  minScore: number;\n  1108→  maxScore: number;\n  1109→  weight: number;\n  1110→}\n  1111→\n  1112→export interface GenderSpecificValues {\n  1113→  male: { ideal: number; range: [number, number] };\n  1114→  female: { ideal: number; range: [number, number] };\n  1115→}\n  1116→\n  1117→// ============================================\n  1118→// Ideal Values (Gender-Specific)\n  1119→// ============================================\n  1120→\n  1121→export const IDEAL_VALUES: Record<string, GenderSpecificValues> = {\n  1122→  fwhr: {\n  1123→    male: { ideal: 1.9, range: [1.8, 2.1] },\n  1124→    female: { ideal: 1.75, range: [1.6, 1.9] },\n  1125→  },\n  1126→  canthalTilt: {\n  1127→    male: { ideal: 4, range: [2, 7] },\n  1128→    female: { ideal: 6, range: [4, 10] },\n  1129→  },\n  1130→  nasolabialAngle: {\n  1131→    male: { ideal: 95, range: [90, 100] },\n  1132→    female: { ideal: 105, range: [100, 115] },\n  1133→  },\n  1134→  gonialAngle: {\n  1135→    male: { ideal: 125, range: [120, 130] },\n  1136→    female: { ideal: 128, range: [125, 135] },\n  1137→  },\n  1138→  nasalIndex: {\n  1139→    male: { ideal: 0.7, range: [0.65, 0.75] },\n  1140→    female: { ideal: 0.65, range: [0.6, 0.7] },\n  1141→  },\n  1142→  lipRatio: {\n  1143→    male: { ideal: 0.5, range: [0.4, 0.6] },\n  1144→    female: { ideal: 0.5, range: [0.45, 0.55] },\n  1145→  },\n  1146→  facialConvexity: {\n  1147→    male: { ideal: 170, range: [165, 175] },\n  1148→    female: { ideal: 168, range: [163, 173] },\n  1149→  },\n  1150→  chinProjection: {\n  1151→    male: { ideal: 0, range: [-3, 3] },\n  1152→    female: { ideal: -2, range: [-5, 1] },\n  1153→  },\n  1154→};\n  1155→\n  1156→// ============================================\n  1157→// Scoring Configurations\n  1158→// ============================================\n  1159→\n  1160→export const SCORING_CONFIGS: Record<string, ScoringConfig> = {\n  1161→  fwhr: {\n  1162→    idealValue: 1.9,\n  1163→    standardDeviation: 0.15,\n  1164→    minScore: 0,\n  1165→    maxScore: 100,\n  1166→    weight: 0.15,\n  1167→  },\n  1168→  canthalTilt: {\n  1169→    idealValue: 6,\n  1170→    standardDeviation: 3,\n  1171→    minScore: 0,\n  1172→    maxScore: 100,\n  1173→    weight: 0.1,\n  1174→  },\n  1175→  facialThirds: {\n  1176→    idealValue: 33.33,\n  1177→    standardDeviation: 3,\n  1178→    minScore: 0,\n  1179→    maxScore: 100,\n  1180→    weight: 0.1,\n  1181→  },\n  1182→  nasolabialAngle: {\n  1183→    idealValue: 102,\n  1184→    standardDeviation: 8,\n  1185→    minScore: 0,\n  1186→    maxScore: 100,\n  1187→    weight: 0.08,\n  1188→  },\n  1189→  gonialAngle: {\n  1190→    idealValue: 125,\n  1191→    standardDeviation: 5,\n  1192→    minScore: 0,\n  1193→    maxScore: 100,\n  1194→    weight: 0.08,\n  1195→  },\n  1196→  overallSymmetry: {\n  1197→    idealValue: 100,\n  1198→    standardDeviation: 5,\n  1199→    minScore: 0,\n  1200→    maxScore: 100,\n  1201→    weight: 0.15,\n  1202→  },\n  1203→  goldenRatio: {\n  1204→    idealValue: 1.618,\n  1205→    standardDeviation: 0.1,\n  1206→    minScore: 0,\n  1207→    maxScore: 100,\n  1208→    weight: 0.12,\n  1209→  },\n  1210→  nasalIndex: {\n  1211→    idealValue: 0.7,\n  1212→    standardDeviation: 0.08,\n  1213→    minScore: 0,\n  1214→    maxScore: 100,\n  1215→    weight: 0.06,\n  1216→  },\n  1217→  lipRatio: {\n  1218→    idealValue: 0.5,\n  1219→    standardDeviation: 0.1,\n  1220→    minScore: 0,\n  1221→    maxScore: 100,\n  1222→    weight: 0.06,\n  1223→  },\n  1224→  chinProjection: {\n  1225→    idealValue: 0,\n  1226→    standardDeviation: 3,\n  1227→    minScore: 0,\n  1228→    maxScore: 100,\n  1229→    weight: 0.05,\n  1230→  },\n  1231→  noseProjection: {\n  1232→    idealValue: 0.67,\n  1233→    standardDeviation: 0.05,\n  1234→    minScore: 0,\n  1235→    maxScore: 100,\n  1236→    weight: 0.05,\n  1237→  },\n  1238→};\n  1239→\n  1240→// ============================================\n  1241→// Population Statistics for Percentile Ranking\n  1242→// ============================================\n  1243→\n  1244→export interface PopulationStats {\n  1245→  mean: number;\n  1246→  standardDeviation: number;\n  1247→  sampleSize: number;\n  1248→}\n  1249→\n  1250→export const POPULATION_STATS: Record<string, PopulationStats> = {\n  1251→  harmonyScore: { mean: 65, standardDeviation: 12, sampleSize: 10000 },\n  1252→  fwhr: { mean: 1.85, standardDeviation: 0.2, sampleSize: 10000 },\n  1253→  canthalTilt: { mean: 4, standardDeviation: 4, sampleSize: 10000 },\n  1254→  symmetry: { mean: 85, standardDeviation: 8, sampleSize: 10000 },\n  1255→  goldenRatioMatch: { mean: 70, standardDeviation: 15, sampleSize: 10000 },\n  1256→};\n  1257→\n\n</system-reminder>\n"}]},"uuid":"e32d7374-901e-40b3-90ed-e1b5cd8a640d","timestamp":"2025-12-30T14:57:25.058Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/imorgado/LOOKSMAXX/looksmaxx-app/src/lib/landmarks.ts","content":"/**\n * Facial Landmark Types and Default Data\n * Based on TECHNICAL_SPECS.md medical terminology\n */\n\nexport interface LandmarkPoint {\n  id: string;\n  label: string;\n  medicalTerm: string;\n  description: string;\n  x: number;\n  y: number;\n  category: string;\n}\n\nexport interface LandmarkCategory {\n  name: string;\n  color: string;\n  landmarks: string[];\n}\n\n// ============================================\n// FRONT PROFILE LANDMARKS (52 Points)\n// ============================================\n\nexport const FRONT_LANDMARK_CATEGORIES: LandmarkCategory[] = [\n  {\n    name: 'Head',\n    color: '#FF6B6B',\n    landmarks: ['trichion'],\n  },\n  {\n    name: 'Eyes - Left',\n    color: '#4ECDC4',\n    landmarks: [\n      'left_pupila',\n      'left_canthus_medialis',\n      'left_canthus_lateralis',\n      'left_palpebra_superior',\n      'left_palpebra_inferior',\n      'left_sulcus_palpebralis_lateralis',\n      'left_pretarsal_skin_crease',\n    ],\n  },\n  {\n    name: 'Eyes - Right',\n    color: '#45B7D1',\n    landmarks: [\n      'right_pupila',\n      'right_canthus_medialis',\n      'right_canthus_lateralis',\n      'right_palpebra_superior',\n      'right_palpebra_inferior',\n      'right_sulcus_palpebralis_lateralis',\n      'right_pretarsal_skin_crease',\n    ],\n  },\n  {\n    name: 'Eyebrows - Left',\n    color: '#96CEB4',\n    landmarks: [\n      'left_supercilium_medialis',\n      'left_supercilium_medial_corner',\n      'left_supercilium_superior',\n      'left_supercilium_apex',\n      'left_supercilium_lateralis',\n    ],\n  },\n  {\n    name: 'Eyebrows - Right',\n    color: '#88D8B0',\n    landmarks: [\n      'right_supercilium_medialis',\n      'right_supercilium_medial_corner',\n      'right_supercilium_superior',\n      'right_supercilium_apex',\n      'right_supercilium_lateralis',\n    ],\n  },\n  {\n    name: 'Nose',\n    color: '#FFEAA7',\n    landmarks: [\n      'nasal_base',\n      'left_dorsum_nasi',\n      'right_dorsum_nasi',\n      'left_ala_nasi',\n      'right_ala_nasi',\n      'subnasale',\n    ],\n  },\n  {\n    name: 'Mouth',\n    color: '#DDA0DD',\n    landmarks: [\n      'labrale_superius',\n      'cupids_bow',\n      'mouth_middle',\n      'labrale_inferius',\n      'left_cheilion',\n      'right_cheilion',\n    ],\n  },\n  {\n    name: 'Jaw',\n    color: '#F39C12',\n    landmarks: [\n      'left_gonion_superior',\n      'right_gonion_superior',\n      'left_gonion_inferior',\n      'right_gonion_inferior',\n    ],\n  },\n  {\n    name: 'Chin',\n    color: '#E74C3C',\n    landmarks: ['left_mentum_lateralis', 'right_mentum_lateralis', 'menton'],\n  },\n  {\n    name: 'Face Width',\n    color: '#9B59B6',\n    landmarks: [\n      'left_zygion',\n      'right_zygion',\n      'left_temporal',\n      'right_temporal',\n      'left_auricular_lateral',\n      'right_auricular_lateral',\n    ],\n  },\n  {\n    name: 'Neck',\n    color: '#1ABC9C',\n    landmarks: ['left_cervical_lateralis', 'right_cervical_lateralis'],\n  },\n];\n\nexport const FRONT_PROFILE_LANDMARKS: LandmarkPoint[] = [\n  // Head/Hair\n  {\n    id: 'trichion',\n    label: 'Hairline',\n    medicalTerm: 'Trichion (frontal view)',\n    description: 'Anterior hairline at midline',\n    x: 0.5,\n    y: 0.08,\n    category: 'Head',\n  },\n\n  // Eyes - Left\n  {\n    id: 'left_pupila',\n    label: 'Left Pupil',\n    medicalTerm: 'Left Pupila',\n    description: 'Center of left pupil',\n    x: 0.38,\n    y: 0.35,\n    category: 'Eyes - Left',\n  },\n  {\n    id: 'left_canthus_medialis',\n    label: 'Left Medial Canthus',\n    medicalTerm: 'Left Canthus Medialis',\n    description: 'Inner corner of left eye',\n    x: 0.42,\n    y: 0.35,\n    category: 'Eyes - Left',\n  },\n  {\n    id: 'left_canthus_lateralis',\n    label: 'Left Lateral Canthus',\n    medicalTerm: 'Left Canthus Lateralis',\n    description: 'Outer corner of left eye',\n    x: 0.32,\n    y: 0.34,\n    category: 'Eyes - Left',\n  },\n  {\n    id: 'left_palpebra_superior',\n    label: 'Left Upper Eyelid',\n    medicalTerm: 'Left Palpebra Superior',\n    description: 'Upper eyelid of left eye',\n    x: 0.37,\n    y: 0.33,\n    category: 'Eyes - Left',\n  },\n  {\n    id: 'left_palpebra_inferior',\n    label: 'Left Lower Eyelid',\n    medicalTerm: 'Left Palpebra Inferior',\n    description: 'Lower eyelid of left eye',\n    x: 0.37,\n    y: 0.37,\n    category: 'Eyes - Left',\n  },\n  {\n    id: 'left_sulcus_palpebralis_lateralis',\n    label: 'Left Eyelid Hood End',\n    medicalTerm: 'Left Sulcus Palpebralis Lateralis',\n    description: 'Lateral end of left upper eyelid crease',\n    x: 0.31,\n    y: 0.33,\n    category: 'Eyes - Left',\n  },\n  {\n    id: 'left_pretarsal_skin_crease',\n    label: 'Left Upper Eyelid Crease',\n    medicalTerm: 'Left Pretarsal Skin Crease',\n    description: 'Left upper eyelid crease',\n    x: 0.37,\n    y: 0.32,\n    category: 'Eyes - Left',\n  },\n\n  // Eyes - Right\n  {\n    id: 'right_pupila',\n    label: 'Right Pupil',\n    medicalTerm: 'Right Pupila',\n    description: 'Center of right pupil',\n    x: 0.62,\n    y: 0.35,\n    category: 'Eyes - Right',\n  },\n  {\n    id: 'right_canthus_medialis',\n    label: 'Right Medial Canthus',\n    medicalTerm: 'Right Canthus Medialis',\n    description: 'Inner corner of right eye',\n    x: 0.58,\n    y: 0.35,\n    category: 'Eyes - Right',\n  },\n  {\n    id: 'right_canthus_lateralis',\n    label: 'Right Lateral Canthus',\n    medicalTerm: 'Right Canthus Lateralis',\n    description: 'Outer corner of right eye',\n    x: 0.68,\n    y: 0.34,\n    category: 'Eyes - Right',\n  },\n  {\n    id: 'right_palpebra_superior',\n    label: 'Right Upper Eyelid',\n    medicalTerm: 'Right Palpebra Superior',\n    description: 'Upper eyelid of right eye',\n    x: 0.63,\n    y: 0.33,\n    category: 'Eyes - Right',\n  },\n  {\n    id: 'right_palpebra_inferior',\n    label: 'Right Lower Eyelid',\n    medicalTerm: 'Right Palpebra Inferior',\n    description: 'Lower eyelid of right eye',\n    x: 0.63,\n    y: 0.37,\n    category: 'Eyes - Right',\n  },\n  {\n    id: 'right_sulcus_palpebralis_lateralis',\n    label: 'Right Eyelid Hood End',\n    medicalTerm: 'Right Sulcus Palpebralis Lateralis',\n    description: 'Lateral end of right upper eyelid crease',\n    x: 0.69,\n    y: 0.33,\n    category: 'Eyes - Right',\n  },\n  {\n    id: 'right_pretarsal_skin_crease',\n    label: 'Right Upper Eyelid Crease',\n    medicalTerm: 'Right Pretarsal Skin Crease',\n    description: 'Right upper eyelid crease',\n    x: 0.63,\n    y: 0.32,\n    category: 'Eyes - Right',\n  },\n\n  // Eyebrows - Left\n  {\n    id: 'left_supercilium_medialis',\n    label: 'Left Brow Head',\n    medicalTerm: 'Left Supercilium Medialis',\n    description: 'Medial start of left eyebrow',\n    x: 0.43,\n    y: 0.28,\n    category: 'Eyebrows - Left',\n  },\n  {\n    id: 'left_supercilium_medial_corner',\n    label: 'Left Brow Inner Corner',\n    medicalTerm: 'Left Supercilium Medial Corner',\n    description: 'Inner corner of left eyebrow',\n    x: 0.41,\n    y: 0.27,\n    category: 'Eyebrows - Left',\n  },\n  {\n    id: 'left_supercilium_superior',\n    label: 'Left Brow Arch',\n    medicalTerm: 'Left Supercilium Superior',\n    description: 'Superior arc of left eyebrow',\n    x: 0.36,\n    y: 0.26,\n    category: 'Eyebrows - Left',\n  },\n  {\n    id: 'left_supercilium_apex',\n    label: 'Left Brow Peak',\n    medicalTerm: 'Left Supercilium Apex',\n    description: 'Highest point of left eyebrow',\n    x: 0.34,\n    y: 0.26,\n    category: 'Eyebrows - Left',\n  },\n  {\n    id: 'left_supercilium_lateralis',\n    label: 'Left Brow Tail',\n    medicalTerm: 'Left Supercilium Lateralis',\n    description: 'Lateral end of left eyebrow',\n    x: 0.29,\n    y: 0.28,\n    category: 'Eyebrows - Left',\n  },\n\n  // Eyebrows - Right\n  {\n    id: 'right_supercilium_medialis',\n    label: 'Right Brow Head',\n    medicalTerm: 'Right Supercilium Medialis',\n    description: 'Medial start of right eyebrow',\n    x: 0.57,\n    y: 0.28,\n    category: 'Eyebrows - Right',\n  },\n  {\n    id: 'right_supercilium_medial_corner',\n    label: 'Right Brow Inner Corner',\n    medicalTerm: 'Right Supercilium Medial Corner',\n    description: 'Inner corner of right eyebrow',\n    x: 0.59,\n    y: 0.27,\n    category: 'Eyebrows - Right',\n  },\n  {\n    id: 'right_supercilium_superior',\n    label: 'Right Brow Arch',\n    medicalTerm: 'Right Supercilium Superior',\n    description: 'Superior arc of right eyebrow',\n    x: 0.64,\n    y: 0.26,\n    category: 'Eyebrows - Right',\n  },\n  {\n    id: 'right_supercilium_apex',\n    label: 'Right Brow Peak',\n    medicalTerm: 'Right Supercilium Apex',\n    description: 'Highest point of right eyebrow',\n    x: 0.66,\n    y: 0.26,\n    category: 'Eyebrows - Right',\n  },\n  {\n    id: 'right_supercilium_lateralis',\n    label: 'Right Brow Tail',\n    medicalTerm: 'Right Supercilium Lateralis',\n    description: 'Lateral end of right eyebrow',\n    x: 0.71,\n    y: 0.28,\n    category: 'Eyebrows - Right',\n  },\n\n  // Nose\n  {\n    id: 'nasal_base',\n    label: 'Nasal Base',\n    medicalTerm: 'Nasal Base',\n    description: 'Base of nasal dorsum',\n    x: 0.5,\n    y: 0.38,\n    category: 'Nose',\n  },\n  {\n    id: 'left_dorsum_nasi',\n    label: 'Left Nose Bridge',\n    medicalTerm: 'Left Dorsum Nasi',\n    description: 'Left side of nasal bridge',\n    x: 0.47,\n    y: 0.42,\n    category: 'Nose',\n  },\n  {\n    id: 'right_dorsum_nasi',\n    label: 'Right Nose Bridge',\n    medicalTerm: 'Right Dorsum Nasi',\n    description: 'Right side of nasal bridge',\n    x: 0.53,\n    y: 0.42,\n    category: 'Nose',\n  },\n  {\n    id: 'left_ala_nasi',\n    label: 'Left Nose Side',\n    medicalTerm: 'Left Ala Nasi',\n    description: 'Lateral aspect of left nasal ala',\n    x: 0.44,\n    y: 0.5,\n    category: 'Nose',\n  },\n  {\n    id: 'right_ala_nasi',\n    label: 'Right Nose Side',\n    medicalTerm: 'Right Ala Nasi',\n    description: 'Lateral aspect of right nasal ala',\n    x: 0.56,\n    y: 0.5,\n    category: 'Nose',\n  },\n  {\n    id: 'subnasale',\n    label: 'Nose Bottom',\n    medicalTerm: 'Subnasale',\n    description: 'Junction of columella and upper lip',\n    x: 0.5,\n    y: 0.52,\n    category: 'Nose',\n  },\n\n  // Mouth\n  {\n    id: 'labrale_superius',\n    label: \"Cupid's Bow\",\n    medicalTerm: 'Labrale Superius',\n    description: 'Midpoint of upper lip vermilion',\n    x: 0.5,\n    y: 0.58,\n    category: 'Mouth',\n  },\n  {\n    id: 'cupids_bow',\n    label: \"Inner Cupid's Bow\",\n    medicalTerm: \"Cupid's Bow\",\n    description: 'Central peak of upper lip',\n    x: 0.5,\n    y: 0.57,\n    category: 'Mouth',\n  },\n  {\n    id: 'mouth_middle',\n    label: 'Mouth Middle',\n    medicalTerm: 'Mouth Middle',\n    description: 'Center of mouth opening',\n    x: 0.5,\n    y: 0.62,\n    category: 'Mouth',\n  },\n  {\n    id: 'labrale_inferius',\n    label: 'Lower Lip Center',\n    medicalTerm: 'Labrale Inferius',\n    description: 'Midpoint of lower lip vermilion border',\n    x: 0.5,\n    y: 0.66,\n    category: 'Mouth',\n  },\n  {\n    id: 'left_cheilion',\n    label: 'Left Mouth Corner',\n    medicalTerm: 'Left Cheilion',\n    description: 'Left oral commissure',\n    x: 0.42,\n    y: 0.62,\n    category: 'Mouth',\n  },\n  {\n    id: 'right_cheilion',\n    label: 'Right Mouth Corner',\n    medicalTerm: 'Right Cheilion',\n    description: 'Right oral commissure',\n    x: 0.58,\n    y: 0.62,\n    category: 'Mouth',\n  },\n\n  // Jaw\n  {\n    id: 'left_gonion_superior',\n    label: 'Left Upper Jaw Angle',\n    medicalTerm: 'Left Gonion Superior',\n    description: 'Superior aspect of left mandibular angle',\n    x: 0.22,\n    y: 0.55,\n    category: 'Jaw',\n  },\n  {\n    id: 'right_gonion_superior',\n    label: 'Right Upper Jaw Angle',\n    medicalTerm: 'Right Gonion Superior',\n    description: 'Superior aspect of right mandibular angle',\n    x: 0.78,\n    y: 0.55,\n    category: 'Jaw',\n  },\n  {\n    id: 'left_gonion_inferior',\n    label: 'Left Lower Jaw Angle',\n    medicalTerm: 'Left Gonion Inferior',\n    description: 'Inferior aspect of left mandibular angle',\n    x: 0.24,\n    y: 0.7,\n    category: 'Jaw',\n  },\n  {\n    id: 'right_gonion_inferior',\n    label: 'Right Lower Jaw Angle',\n    medicalTerm: 'Right Gonion Inferior',\n    description: 'Inferior aspect of right mandibular angle',\n    x: 0.76,\n    y: 0.7,\n    category: 'Jaw',\n  },\n\n  // Chin\n  {\n    id: 'left_mentum_lateralis',\n    label: 'Left Chin',\n    medicalTerm: 'Left Mentum Lateralis',\n    description: 'Left lateral chin',\n    x: 0.42,\n    y: 0.8,\n    category: 'Chin',\n  },\n  {\n    id: 'right_mentum_lateralis',\n    label: 'Right Chin',\n    medicalTerm: 'Right Mentum Lateralis',\n    description: 'Right lateral chin',\n    x: 0.58,\n    y: 0.8,\n    category: 'Chin',\n  },\n  {\n    id: 'menton',\n    label: 'Chin Bottom',\n    medicalTerm: 'Menton',\n    description: 'Lowest point of chin in midline',\n    x: 0.5,\n    y: 0.88,\n    category: 'Chin',\n  },\n\n  // Face Width\n  {\n    id: 'left_zygion',\n    label: 'Left Cheekbone',\n    medicalTerm: 'Left Zygion',\n    description: 'Most lateral point of left zygomatic arch',\n    x: 0.18,\n    y: 0.42,\n    category: 'Face Width',\n  },\n  {\n    id: 'right_zygion',\n    label: 'Right Cheekbone',\n    medicalTerm: 'Right Zygion',\n    description: 'Most lateral point of right zygomatic arch',\n    x: 0.82,\n    y: 0.42,\n    category: 'Face Width',\n  },\n  {\n    id: 'left_temporal',\n    label: 'Left Temple',\n    medicalTerm: 'Left Temporal Point',\n    description: 'Left temporal region',\n    x: 0.2,\n    y: 0.3,\n    category: 'Face Width',\n  },\n  {\n    id: 'right_temporal',\n    label: 'Right Temple',\n    medicalTerm: 'Right Temporal Point',\n    description: 'Right temporal region',\n    x: 0.8,\n    y: 0.3,\n    category: 'Face Width',\n  },\n  {\n    id: 'left_auricular_lateral',\n    label: 'Left Outer Ear',\n    medicalTerm: 'Left Auricular Lateral Point',\n    description: 'Lateral-most point of left ear',\n    x: 0.12,\n    y: 0.4,\n    category: 'Face Width',\n  },\n  {\n    id: 'right_auricular_lateral',\n    label: 'Right Outer Ear',\n    medicalTerm: 'Right Auricular Lateral Point',\n    description: 'Lateral-most point of right ear',\n    x: 0.88,\n    y: 0.4,\n    category: 'Face Width',\n  },\n\n  // Neck\n  {\n    id: 'left_cervical_lateralis',\n    label: 'Left Neck Point',\n    medicalTerm: 'Left Cervical Lateralis',\n    description: 'Left cervical point',\n    x: 0.35,\n    y: 0.95,\n    category: 'Neck',\n  },\n  {\n    id: 'right_cervical_lateralis',\n    label: 'Right Neck Point',\n    medicalTerm: 'Right Cervical Lateralis',\n    description: 'Right cervical point',\n    x: 0.65,\n    y: 0.95,\n    category: 'Neck',\n  },\n];\n\n// ============================================\n// SIDE PROFILE LANDMARKS (31 Points)\n// FaceIQ Parity - Matches FaceIQ's exact order and flow\n// ============================================\n\nexport const SIDE_LANDMARK_CATEGORIES: LandmarkCategory[] = [\n  {\n    name: 'Head',\n    color: '#FF6B6B',\n    landmarks: ['vertex', 'occiput'],\n  },\n  {\n    name: 'Forehead',\n    color: '#4ECDC4',\n    landmarks: ['trichion', 'forehead', 'glabella'],\n  },\n  {\n    name: 'Eye Region',\n    color: '#45B7D1',\n    landmarks: ['orbitale', 'cornealApex', 'eyelidEnd', 'lowerEyelid'],\n  },\n  {\n    name: 'Ear',\n    color: '#3498DB',\n    landmarks: ['porion', 'tragus', 'intertragicNotch'],\n  },\n  {\n    name: 'Cheek',\n    color: '#9B59B6',\n    landmarks: ['cheekbone'],\n  },\n  {\n    name: 'Nose',\n    color: '#FFEAA7',\n    landmarks: [\n      'nasion',\n      'rhinion',\n      'supratip',\n      'pronasale',\n      'infratip',\n      'columella',\n      'subnasale',\n      'subalare',\n    ],\n  },\n  {\n    name: 'Lips',\n    color: '#DDA0DD',\n    landmarks: ['labraleSuperius', 'cheilion', 'labraleInferius', 'sublabiale'],\n  },\n  {\n    name: 'Chin',\n    color: '#E74C3C',\n    landmarks: ['pogonion', 'menton'],\n  },\n  {\n    name: 'Jaw',\n    color: '#F39C12',\n    landmarks: ['gonionTop', 'gonionBottom'],\n  },\n  {\n    name: 'Neck',\n    color: '#1ABC9C',\n    landmarks: ['cervicalPoint', 'neckPoint'],\n  },\n];\n\n// FaceIQ Parity Order: Matches FaceIQ's exact flow (1 of 31 → 31 of 31)\n// Head → Forehead → Eye → Ear → Cheek → Nose → Lips → Chin → Jaw → Neck\nexport const SIDE_PROFILE_LANDMARKS: LandmarkPoint[] = [\n  // ========== HEAD (1-2) ==========\n  {\n    id: 'vertex',\n    label: 'Top of Head',\n    medicalTerm: 'Vertex',\n    description: 'The highest point on the top of the head when looking from the side',\n    x: 0.45,\n    y: 0.02,\n    category: 'Head',\n  },\n  {\n    id: 'occiput',\n    label: 'Back of Head',\n    medicalTerm: 'Occiput',\n    description: 'The most posterior point on the back of the head',\n    x: 0.85,\n    y: 0.15,\n    category: 'Head',\n  },\n\n  // ========== FOREHEAD (3-5) ==========\n  {\n    id: 'trichion',\n    label: 'Hairline',\n    medicalTerm: 'Trichion',\n    description: 'The point where the hairline meets the forehead in the midline',\n    x: 0.35,\n    y: 0.1,\n    category: 'Forehead',\n  },\n  {\n    id: 'forehead',\n    label: 'Forehead Point',\n    medicalTerm: 'Forehead',\n    description: 'The most prominent point on the forehead between hairline and glabella',\n    x: 0.30,\n    y: 0.20,\n    category: 'Forehead',\n  },\n  {\n    id: 'glabella',\n    label: 'Glabella',\n    medicalTerm: 'Glabella',\n    description: 'The most prominent point between the eyebrows',\n    x: 0.32,\n    y: 0.28,\n    category: 'Forehead',\n  },\n\n  // ========== EYE REGION (6-9) ==========\n  {\n    id: 'orbitale',\n    label: 'Orbitale',\n    medicalTerm: 'Orbitale',\n    description: 'The lowest point on the lower edge of the eye socket (orbital rim)',\n    x: 0.35,\n    y: 0.38,\n    category: 'Eye Region',\n  },\n  {\n    id: 'cornealApex',\n    label: 'Corneal Apex',\n    medicalTerm: 'Corneal Apex',\n    description: 'The most anterior point of the cornea (eyeball)',\n    x: 0.28,\n    y: 0.34,\n    category: 'Eye Region',\n  },\n  {\n    id: 'eyelidEnd',\n    label: 'Eyelid End',\n    medicalTerm: 'Lateral Canthus',\n    description: 'The outer corner of the eye where upper and lower eyelids meet',\n    x: 0.38,\n    y: 0.33,\n    category: 'Eye Region',\n  },\n  {\n    id: 'lowerEyelid',\n    label: 'Lower Eyelid',\n    medicalTerm: 'Lower Palpebra',\n    description: 'The lowest point of the lower eyelid margin',\n    x: 0.32,\n    y: 0.36,\n    category: 'Eye Region',\n  },\n\n  // ========== EAR (10-12) - Critical for Frankfort Plane ==========\n  {\n    id: 'porion',\n    label: 'Porion',\n    medicalTerm: 'Porion',\n    description: 'The highest point on the upper margin of the external auditory meatus (ear canal opening). Forms the Frankfort Horizontal Plane with Orbitale.',\n    x: 0.75,\n    y: 0.35,\n    category: 'Ear',\n  },\n  {\n    id: 'tragus',\n    label: 'Tragus',\n    medicalTerm: 'Tragus',\n    description: 'The small pointed cartilage projection in front of the ear canal',\n    x: 0.72,\n    y: 0.42,\n    category: 'Ear',\n  },\n  {\n    id: 'intertragicNotch',\n    label: 'Intertragic Notch',\n    medicalTerm: 'Intertragic Notch',\n    description: 'The depression between the tragus and antitragus of the ear',\n    x: 0.73,\n    y: 0.45,\n    category: 'Ear',\n  },\n\n  // ========== CHEEK (13) ==========\n  {\n    id: 'cheekbone',\n    label: 'Cheekbone',\n    medicalTerm: 'Zygion',\n    description: 'The most lateral point on the zygomatic arch (cheekbone)',\n    x: 0.45,\n    y: 0.42,\n    category: 'Cheek',\n  },\n\n  // ========== NOSE (14-21) ==========\n  {\n    id: 'nasion',\n    label: 'Nasal Bridge Root',\n    medicalTerm: 'Nasion',\n    description: 'The deepest point at the bridge of the nose, between the eyes',\n    x: 0.35,\n    y: 0.32,\n    category: 'Nose',\n  },\n  {\n    id: 'rhinion',\n    label: 'Nasal Bridge',\n    medicalTerm: 'Rhinion',\n    description: 'The midpoint on the nasal bridge',\n    x: 0.28,\n    y: 0.4,\n    category: 'Nose',\n  },\n  {\n    id: 'supratip',\n    label: 'Supratip',\n    medicalTerm: 'Supratip',\n    description: 'The point just above the nose tip, on the dorsum',\n    x: 0.22,\n    y: 0.46,\n    category: 'Nose',\n  },\n  {\n    id: 'pronasale',\n    label: 'Nose Tip',\n    medicalTerm: 'Pronasale',\n    description: 'The most anterior point of the nose tip',\n    x: 0.18,\n    y: 0.48,\n    category: 'Nose',\n  },\n  {\n    id: 'infratip',\n    label: 'Infratip',\n    medicalTerm: 'Infratip',\n    description: 'The point just below the nose tip',\n    x: 0.2,\n    y: 0.5,\n    category: 'Nose',\n  },\n  {\n    id: 'columella',\n    label: 'Columella',\n    medicalTerm: 'Columella',\n    description: 'The skin bridge between the nostrils',\n    x: 0.24,\n    y: 0.52,\n    category: 'Nose',\n  },\n  {\n    id: 'subnasale',\n    label: 'Subnasale',\n    medicalTerm: 'Subnasale',\n    description: 'The point where the columella meets the upper lip',\n    x: 0.3,\n    y: 0.54,\n    category: 'Nose',\n  },\n  {\n    id: 'subalare',\n    label: 'Subalare',\n    medicalTerm: 'Subalare',\n    description: 'The point where the nostril wing meets the cheek',\n    x: 0.28,\n    y: 0.53,\n    category: 'Nose',\n  },\n\n  // ========== LIPS (22-25) ==========\n  {\n    id: 'labraleSuperius',\n    label: 'Upper Lip',\n    medicalTerm: 'Labrale Superius',\n    description: 'The most anterior point of the upper lip vermilion',\n    x: 0.28,\n    y: 0.58,\n    category: 'Lips',\n  },\n  {\n    id: 'cheilion',\n    label: 'Mouth Corner',\n    medicalTerm: 'Cheilion',\n    description: 'The corner of the mouth where upper and lower lips meet',\n    x: 0.35,\n    y: 0.62,\n    category: 'Lips',\n  },\n  {\n    id: 'labraleInferius',\n    label: 'Lower Lip',\n    medicalTerm: 'Labrale Inferius',\n    description: 'The most anterior point of the lower lip vermilion',\n    x: 0.3,\n    y: 0.66,\n    category: 'Lips',\n  },\n  {\n    id: 'sublabiale',\n    label: 'Labiomental Fold',\n    medicalTerm: 'Sublabiale',\n    description: 'The deepest point of the crease between lower lip and chin',\n    x: 0.32,\n    y: 0.7,\n    category: 'Lips',\n  },\n\n  // ========== CHIN (26-27) ==========\n  {\n    id: 'pogonion',\n    label: 'Chin Point',\n    medicalTerm: 'Pogonion',\n    description: 'The most anterior point of the chin',\n    x: 0.3,\n    y: 0.76,\n    category: 'Chin',\n  },\n  {\n    id: 'menton',\n    label: 'Chin Bottom',\n    medicalTerm: 'Menton',\n    description: 'The lowest point on the chin',\n    x: 0.35,\n    y: 0.82,\n    category: 'Chin',\n  },\n\n  // ========== JAW (28-29) ==========\n  {\n    id: 'gonionTop',\n    label: 'Upper Jaw Angle',\n    medicalTerm: 'Gonion Superior',\n    description: 'The upper point of the jaw angle (mandibular angle)',\n    x: 0.7,\n    y: 0.6,\n    category: 'Jaw',\n  },\n  {\n    id: 'gonionBottom',\n    label: 'Lower Jaw Angle',\n    medicalTerm: 'Gonion Inferior',\n    description: 'The lower point of the jaw angle (mandibular angle)',\n    x: 0.65,\n    y: 0.72,\n    category: 'Jaw',\n  },\n\n  // ========== NECK (30-31) ==========\n  {\n    id: 'cervicalPoint',\n    label: 'Cervical Point',\n    medicalTerm: 'Cervical Point',\n    description: 'The point where the neck meets the underside of the chin',\n    x: 0.5,\n    y: 0.9,\n    category: 'Neck',\n  },\n  {\n    id: 'neckPoint',\n    label: 'Neck Point',\n    medicalTerm: 'Throat Point',\n    description: 'A point on the front of the neck below the chin',\n    x: 0.4,\n    y: 0.88,\n    category: 'Neck',\n  },\n];\n\n// ============================================\n// MediaPipe Face Mesh Index Mapping\n// ============================================\n// NOTE: MEDIAPIPE_FRONT_MAPPING is defined in mediapipeDetection.ts (single source of truth)\n// Import from there if needed: import { MEDIAPIPE_FRONT_MAPPING } from './mediapipeDetection';\n\n// Helper to get category color for a landmark\nexport function getLandmarkColor(\n  landmarkId: string,\n  categories: LandmarkCategory[]\n): string {\n  for (const category of categories) {\n    if (category.landmarks.includes(landmarkId)) {\n      return category.color;\n    }\n  }\n  return '#00f3ff'; // Default cyan\n}\n\n// ============================================\n// Side Profile Landmark Indices (106 points)\n// Reverse-engineered from PROJECT CASSANOVA API\n// ============================================\n\nexport const SIDE_LANDMARKS = {\n  // Face Contour (0-16) - Jaw/Chin outline\n  MENTON: 0, // Chin bottom (lowest point)\n  POGONION: 2, // Chin prominence\n  GNATHION: 3, // Chin point\n  MANDIBLE_CONTOUR: [2, 3, 4, 5, 6, 7, 8], // Jaw line\n\n  // Posterior Points (1, 9-16) - Ear/Back of head\n  TRAGION: 1, // Ear point\n  EAR_CONTOUR: [9, 10, 11, 12, 13, 14, 15, 16],\n\n  // Forehead/Hairline (17)\n  TRICHION: 17, // Hairline\n\n  // Nose Profile (18-32)\n  NASION: 25, // Bridge of nose (deepest point)\n  PRONASALE: 32, // Nose tip\n  SUBNASALE: 52, // Base of nose\n  COLUMELLA: 53, // Nose columella\n  NOSE_BRIDGE: [25, 26, 27, 28, 29, 30, 31, 32],\n  NOSE_TIP_CONTOUR: [52, 53, 54, 55, 56, 57, 58, 59, 60],\n\n  // Eye Region (33-51)\n  EYE_LATERAL_CANTHUS: 33, // Outer eye corner\n  EYE_MEDIAL_CANTHUS: 35, // Inner eye corner\n  UPPER_EYELID: [37, 38, 39],\n  LOWER_EYELID: [40, 41, 42],\n  PUPIL: 34,\n  BROW_HEAD: 44, // Inner brow\n  BROW_ARCH: 45, // Brow peak\n  BROW_TAIL: 46, // Outer brow\n\n  // Lip Region (52-75)\n  LABRALE_SUPERIUS: 63, // Upper lip top\n  LABRALE_INFERIUS: 66, // Lower lip bottom\n  STOMION: 65, // Lip meeting point\n  UPPER_LIP_CONTOUR: [63, 64, 65],\n  LOWER_LIP_CONTOUR: [66, 67, 68],\n\n  // Additional Profile Points (76-105)\n  GLABELLA: 76, // Between eyebrows\n  SELLION: 77, // Deepest point of nasal bridge\n  SOFT_TISSUE_NASION: 78,\n  ORBITALE: 79, // Lowest point of eye socket\n  GONION: 85, // Jaw angle\n  CONDYLION: 86, // Top of jaw joint\n};\n\n// ============================================\n// Front Face Landmark Indices (MediaPipe 478 points)\n// ============================================\n\nexport const FRONT_LANDMARKS = {\n  // Key points from MediaPipe Face Mesh\n  NOSE_TIP: 1,\n  LEFT_EYE_INNER: 133,\n  LEFT_EYE_OUTER: 33,\n  RIGHT_EYE_INNER: 362,\n  RIGHT_EYE_OUTER: 263,\n  LEFT_CHEEK: 234,\n  RIGHT_CHEEK: 454,\n  UPPER_LIP: 13,\n  LOWER_LIP: 14,\n  CHIN: 152,\n  FOREHEAD: 10,\n  LEFT_EAR: 234,\n  RIGHT_EAR: 454,\n  LEFT_BROW_INNER: 107,\n  LEFT_BROW_OUTER: 70,\n  RIGHT_BROW_INNER: 336,\n  RIGHT_BROW_OUTER: 300,\n  NOSE_BRIDGE: 6,\n  LEFT_NOSTRIL: 129,\n  RIGHT_NOSTRIL: 358,\n};\n\n// ============================================\n// Scoring Configuration Types\n// ============================================\n\nexport interface ScoringConfig {\n  idealValue: number;\n  standardDeviation: number;\n  minScore: number;\n  maxScore: number;\n  weight: number;\n}\n\nexport interface GenderSpecificValues {\n  male: { ideal: number; range: [number, number] };\n  female: { ideal: number; range: [number, number] };\n}\n\n// ============================================\n// Ideal Values (Gender-Specific)\n// ============================================\n\nexport const IDEAL_VALUES: Record<string, GenderSpecificValues> = {\n  fwhr: {\n    male: { ideal: 1.9, range: [1.8, 2.1] },\n    female: { ideal: 1.75, range: [1.6, 1.9] },\n  },\n  canthalTilt: {\n    male: { ideal: 4, range: [2, 7] },\n    female: { ideal: 6, range: [4, 10] },\n  },\n  nasolabialAngle: {\n    male: { ideal: 95, range: [90, 100] },\n    female: { ideal: 105, range: [100, 115] },\n  },\n  gonialAngle: {\n    male: { ideal: 125, range: [120, 130] },\n    female: { ideal: 128, range: [125, 135] },\n  },\n  nasalIndex: {\n    male: { ideal: 0.7, range: [0.65, 0.75] },\n    female: { ideal: 0.65, range: [0.6, 0.7] },\n  },\n  lipRatio: {\n    male: { ideal: 0.5, range: [0.4, 0.6] },\n    female: { ideal: 0.5, range: [0.45, 0.55] },\n  },\n  facialConvexity: {\n    male: { ideal: 170, range: [165, 175] },\n    female: { ideal: 168, range: [163, 173] },\n  },\n  chinProjection: {\n    male: { ideal: 0, range: [-3, 3] },\n    female: { ideal: -2, range: [-5, 1] },\n  },\n};\n\n// ============================================\n// Scoring Configurations\n// ============================================\n\nexport const SCORING_CONFIGS: Record<string, ScoringConfig> = {\n  fwhr: {\n    idealValue: 1.9,\n    standardDeviation: 0.15,\n    minScore: 0,\n    maxScore: 100,\n    weight: 0.15,\n  },\n  canthalTilt: {\n    idealValue: 6,\n    standardDeviation: 3,\n    minScore: 0,\n    maxScore: 100,\n    weight: 0.1,\n  },\n  facialThirds: {\n    idealValue: 33.33,\n    standardDeviation: 3,\n    minScore: 0,\n    maxScore: 100,\n    weight: 0.1,\n  },\n  nasolabialAngle: {\n    idealValue: 102,\n    standardDeviation: 8,\n    minScore: 0,\n    maxScore: 100,\n    weight: 0.08,\n  },\n  gonialAngle: {\n    idealValue: 125,\n    standardDeviation: 5,\n    minScore: 0,\n    maxScore: 100,\n    weight: 0.08,\n  },\n  overallSymmetry: {\n    idealValue: 100,\n    standardDeviation: 5,\n    minScore: 0,\n    maxScore: 100,\n    weight: 0.15,\n  },\n  goldenRatio: {\n    idealValue: 1.618,\n    standardDeviation: 0.1,\n    minScore: 0,\n    maxScore: 100,\n    weight: 0.12,\n  },\n  nasalIndex: {\n    idealValue: 0.7,\n    standardDeviation: 0.08,\n    minScore: 0,\n    maxScore: 100,\n    weight: 0.06,\n  },\n  lipRatio: {\n    idealValue: 0.5,\n    standardDeviation: 0.1,\n    minScore: 0,\n    maxScore: 100,\n    weight: 0.06,\n  },\n  chinProjection: {\n    idealValue: 0,\n    standardDeviation: 3,\n    minScore: 0,\n    maxScore: 100,\n    weight: 0.05,\n  },\n  noseProjection: {\n    idealValue: 0.67,\n    standardDeviation: 0.05,\n    minScore: 0,\n    maxScore: 100,\n    weight: 0.05,\n  },\n};\n\n// ============================================\n// Population Statistics for Percentile Ranking\n// ============================================\n\nexport interface PopulationStats {\n  mean: number;\n  standardDeviation: number;\n  sampleSize: number;\n}\n\nexport const POPULATION_STATS: Record<string, PopulationStats> = {\n  harmonyScore: { mean: 65, standardDeviation: 12, sampleSize: 10000 },\n  fwhr: { mean: 1.85, standardDeviation: 0.2, sampleSize: 10000 },\n  canthalTilt: { mean: 4, standardDeviation: 4, sampleSize: 10000 },\n  symmetry: { mean: 85, standardDeviation: 8, sampleSize: 10000 },\n  goldenRatioMatch: { mean: 70, standardDeviation: 15, sampleSize: 10000 },\n};\n","numLines":1257,"startLine":1,"totalLines":1257}}}
{"parentUuid":"e32d7374-901e-40b3-90ed-e1b5cd8a640d","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"988cde7a-9586-4ca8-910d-50a828b2fa2d","version":"2.0.76","gitBranch":"main","agentId":"aee8db2","slug":"fizzy-singing-bird","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_017o55SrAAQREY5a76r4kBwc","type":"message","role":"assistant","content":[{"type":"text","text":"Let me read the FaceIQ parity implementation files:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":371,"cache_creation_input_tokens":16523,"cache_read_input_tokens":73821,"cache_creation":{"ephemeral_5m_input_tokens":16523,"ephemeral_1h_input_tokens":0},"output_tokens":3,"service_tier":"standard"}},"requestId":"req_011CWd4sVQKKKZNRBJoptA5w","type":"assistant","uuid":"fd69bdbb-016a-4412-a9ca-f9997e22555a","timestamp":"2025-12-30T14:57:30.224Z"}
{"parentUuid":"fd69bdbb-016a-4412-a9ca-f9997e22555a","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"988cde7a-9586-4ca8-910d-50a828b2fa2d","version":"2.0.76","gitBranch":"main","agentId":"aee8db2","slug":"fizzy-singing-bird","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_017o55SrAAQREY5a76r4kBwc","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_013cdioHyY5u2G7iqw4dMtNm","name":"Read","input":{"file_path":"/Users/imorgado/LOOKSMAXX/looksmaxx-app/src/lib/faceiq-parity/sideLandmarks.ts"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":371,"cache_creation_input_tokens":16523,"cache_read_input_tokens":73821,"cache_creation":{"ephemeral_5m_input_tokens":16523,"ephemeral_1h_input_tokens":0},"output_tokens":3,"service_tier":"standard"}},"requestId":"req_011CWd4sVQKKKZNRBJoptA5w","type":"assistant","uuid":"7211bce0-b8cd-414c-b537-bf7404a55681","timestamp":"2025-12-30T14:57:31.503Z"}
{"parentUuid":"7211bce0-b8cd-414c-b537-bf7404a55681","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"988cde7a-9586-4ca8-910d-50a828b2fa2d","version":"2.0.76","gitBranch":"main","agentId":"aee8db2","slug":"fizzy-singing-bird","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_017o55SrAAQREY5a76r4kBwc","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01UquuZZXTcnn6bYAfG2XPPL","name":"Read","input":{"file_path":"/Users/imorgado/LOOKSMAXX/looksmaxx-app/src/lib/mediapipeDetection.ts","limit":200}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":371,"cache_creation_input_tokens":16523,"cache_read_input_tokens":73821,"cache_creation":{"ephemeral_5m_input_tokens":16523,"ephemeral_1h_input_tokens":0},"output_tokens":3,"service_tier":"standard"}},"requestId":"req_011CWd4sVQKKKZNRBJoptA5w","type":"assistant","uuid":"15a4a24e-e414-4b7b-ae00-9f20914855a7","timestamp":"2025-12-30T14:57:32.130Z"}
{"parentUuid":"15a4a24e-e414-4b7b-ae00-9f20914855a7","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"988cde7a-9586-4ca8-910d-50a828b2fa2d","version":"2.0.76","gitBranch":"main","agentId":"aee8db2","slug":"fizzy-singing-bird","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_017o55SrAAQREY5a76r4kBwc","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01JH9JaYkqxFC1ziKkAPKUzb","name":"Grep","input":{"pattern":"interface.*Landmark|type.*Landmark","output_mode":"content","path":"src/lib","-n":true}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":371,"cache_creation_input_tokens":16523,"cache_read_input_tokens":73821,"cache_creation":{"ephemeral_5m_input_tokens":16523,"ephemeral_1h_input_tokens":0},"output_tokens":3,"service_tier":"standard"}},"requestId":"req_011CWd4sVQKKKZNRBJoptA5w","type":"assistant","uuid":"d3e4787c-96b0-4721-86c0-f7ea294a351a","timestamp":"2025-12-30T14:57:33.511Z"}
{"parentUuid":"d3e4787c-96b0-4721-86c0-f7ea294a351a","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"988cde7a-9586-4ca8-910d-50a828b2fa2d","version":"2.0.76","gitBranch":"main","agentId":"aee8db2","slug":"fizzy-singing-bird","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_013cdioHyY5u2G7iqw4dMtNm","type":"tool_result","content":"     1→/**\n     2→ * FaceIQ Parity - Side Profile Landmarks Definition\n     3→ *\n     4→ * Exact 31 side profile landmarks matching FaceIQ's implementation.\n     5→ * Each landmark has:\n     6→ * - id: Unique identifier\n     7→ * - name: Display name\n     8→ * - anatomicalName: Scientific/cephalometric name\n     9→ * - description: How to find the landmark\n    10→ * - zoomLevel: Recommended zoom for placement (2, 4, or 8)\n    11→ * - category: Grouping for UI\n    12→ */\n    13→\n    14→export interface SideLandmarkDefinition {\n    15→  id: string;\n    16→  name: string;\n    17→  anatomicalName: string;\n    18→  description: string;\n    19→  zoomLevel: 2 | 4 | 8;\n    20→  category: 'head' | 'forehead' | 'eye' | 'ear' | 'nose' | 'lips' | 'chin' | 'jaw' | 'neck';\n    21→  mediapipeIndex?: number; // MediaPipe 478 index if available\n    22→  insightfaceIndex?: number; // InsightFace 106 index if available\n    23→}\n    24→\n    25→/**\n    26→ * FaceIQ's exact 31 side profile landmarks\n    27→ * Order matches FaceIQ's UI flow (1 of 31 → 31 of 31)\n    28→ */\n    29→export const FACEIQ_SIDE_LANDMARKS: SideLandmarkDefinition[] = [\n    30→  // Head landmarks (zoom 2x)\n    31→  {\n    32→    id: 'vertex',\n    33→    name: 'Top of Head',\n    34→    anatomicalName: 'Vertex',\n    35→    description: 'The highest point on the top of the head when looking from the side',\n    36→    zoomLevel: 2,\n    37→    category: 'head',\n    38→  },\n    39→  {\n    40→    id: 'occiput',\n    41→    name: 'Back of Head',\n    42→    anatomicalName: 'Occiput',\n    43→    description: 'The most posterior point on the back of the head',\n    44→    zoomLevel: 2,\n    45→    category: 'head',\n    46→  },\n    47→  {\n    48→    id: 'trichion',\n    49→    name: 'Hairline',\n    50→    anatomicalName: 'Trichion',\n    51→    description: 'The point where the hairline meets the forehead in the midline',\n    52→    zoomLevel: 2,\n    53→    category: 'forehead',\n    54→  },\n    55→  {\n    56→    id: 'forehead',\n    57→    name: 'Forehead Point',\n    58→    anatomicalName: 'Forehead',\n    59→    description: 'The most prominent point on the forehead between hairline and glabella',\n    60→    zoomLevel: 2,\n    61→    category: 'forehead',\n    62→  },\n    63→\n    64→  // Eye landmarks (zoom 4x)\n    65→  {\n    66→    id: 'glabella',\n    67→    name: 'Glabella',\n    68→    anatomicalName: 'Glabella',\n    69→    description: 'The most prominent point between the eyebrows',\n    70→    zoomLevel: 4,\n    71→    category: 'forehead',\n    72→    mediapipeIndex: 9,\n    73→    insightfaceIndex: 51,\n    74→  },\n    75→  {\n    76→    id: 'orbitale',\n    77→    name: 'Orbitale',\n    78→    anatomicalName: 'Orbitale',\n    79→    description: 'The lowest point on the lower edge of the eye socket (orbital rim)',\n    80→    zoomLevel: 4,\n    81→    category: 'eye',\n    82→    mediapipeIndex: 33,\n    83→    insightfaceIndex: 66,\n    84→  },\n    85→  {\n    86→    id: 'cornealApex',\n    87→    name: 'Corneal Apex',\n    88→    anatomicalName: 'Corneal Apex',\n    89→    description: 'The most anterior point of the cornea (eyeball)',\n    90→    zoomLevel: 4,\n    91→    category: 'eye',\n    92→    mediapipeIndex: 468,\n    93→    insightfaceIndex: 98,\n    94→  },\n    95→  {\n    96→    id: 'eyelidEnd',\n    97→    name: 'Eyelid End',\n    98→    anatomicalName: 'Lateral Canthus',\n    99→    description: 'The outer corner of the eye where upper and lower eyelids meet',\n   100→    zoomLevel: 4,\n   101→    category: 'eye',\n   102→    mediapipeIndex: 33,\n   103→    insightfaceIndex: 64,\n   104→  },\n   105→  {\n   106→    id: 'lowerEyelid',\n   107→    name: 'Lower Eyelid',\n   108→    anatomicalName: 'Lower Palpebra',\n   109→    description: 'The lowest point of the lower eyelid margin',\n   110→    zoomLevel: 4,\n   111→    category: 'eye',\n   112→    mediapipeIndex: 145,\n   113→    insightfaceIndex: 66,\n   114→  },\n   115→\n   116→  // Ear landmarks (zoom 4x) - Critical for Frankfort Plane\n   117→  {\n   118→    id: 'porion',\n   119→    name: 'Porion',\n   120→    anatomicalName: 'Porion',\n   121→    description: 'The highest point on the upper margin of the external auditory meatus (ear canal opening). Forms the Frankfort Horizontal Plane with Orbitale.',\n   122→    zoomLevel: 4,\n   123→    category: 'ear',\n   124→  },\n   125→  {\n   126→    id: 'tragus',\n   127→    name: 'Tragus',\n   128→    anatomicalName: 'Tragus',\n   129→    description: 'The small pointed cartilage projection in front of the ear canal',\n   130→    zoomLevel: 4,\n   131→    category: 'ear',\n   132→  },\n   133→  {\n   134→    id: 'intertragicNotch',\n   135→    name: 'Intertragic Notch',\n   136→    anatomicalName: 'Intertragic Notch',\n   137→    description: 'The depression between the tragus and antitragus of the ear',\n   138→    zoomLevel: 4,\n   139→    category: 'ear',\n   140→  },\n   141→\n   142→  // Cheek (zoom 4x)\n   143→  {\n   144→    id: 'cheekbone',\n   145→    name: 'Cheekbone',\n   146→    anatomicalName: 'Zygion',\n   147→    description: 'The most lateral point on the zygomatic arch (cheekbone)',\n   148→    zoomLevel: 4,\n   149→    category: 'eye',\n   150→    mediapipeIndex: 234,\n   151→    insightfaceIndex: 101,\n   152→  },\n   153→\n   154→  // Nose landmarks (zoom 4x)\n   155→  {\n   156→    id: 'nasion',\n   157→    name: 'Nasal Bridge Root',\n   158→    anatomicalName: 'Nasion',\n   159→    description: 'The deepest point at the bridge of the nose, between the eyes',\n   160→    zoomLevel: 4,\n   161→    category: 'nose',\n   162→    mediapipeIndex: 6,\n   163→    insightfaceIndex: 43,\n   164→  },\n   165→  {\n   166→    id: 'rhinion',\n   167→    name: 'Nasal Bridge',\n   168→    anatomicalName: 'Rhinion',\n   169→    description: 'The midpoint on the nasal bridge',\n   170→    zoomLevel: 4,\n   171→    category: 'nose',\n   172→    mediapipeIndex: 4,\n   173→    insightfaceIndex: 45,\n   174→  },\n   175→  {\n   176→    id: 'supratip',\n   177→    name: 'Supratip',\n   178→    anatomicalName: 'Supratip',\n   179→    description: 'The point just above the nose tip, on the dorsum',\n   180→    zoomLevel: 4,\n   181→    category: 'nose',\n   182→    mediapipeIndex: 4,\n   183→    insightfaceIndex: 47,\n   184→  },\n   185→  {\n   186→    id: 'pronasale',\n   187→    name: 'Nose Tip',\n   188→    anatomicalName: 'Pronasale',\n   189→    description: 'The most anterior point of the nose tip',\n   190→    zoomLevel: 4,\n   191→    category: 'nose',\n   192→    mediapipeIndex: 1,\n   193→    insightfaceIndex: 50,\n   194→  },\n   195→  {\n   196→    id: 'infratip',\n   197→    name: 'Infratip',\n   198→    anatomicalName: 'Infratip',\n   199→    description: 'The point just below the nose tip',\n   200→    zoomLevel: 4,\n   201→    category: 'nose',\n   202→  },\n   203→  {\n   204→    id: 'columella',\n   205→    name: 'Columella',\n   206→    anatomicalName: 'Columella',\n   207→    description: 'The skin bridge between the nostrils',\n   208→    zoomLevel: 4,\n   209→    category: 'nose',\n   210→    mediapipeIndex: 2,\n   211→    insightfaceIndex: 53,\n   212→  },\n   213→  {\n   214→    id: 'subnasale',\n   215→    name: 'Subnasale',\n   216→    anatomicalName: 'Subnasale',\n   217→    description: 'The point where the columella meets the upper lip',\n   218→    zoomLevel: 4,\n   219→    category: 'nose',\n   220→    mediapipeIndex: 2,\n   221→    insightfaceIndex: 52,\n   222→  },\n   223→  {\n   224→    id: 'subalare',\n   225→    name: 'Subalare',\n   226→    anatomicalName: 'Subalare',\n   227→    description: 'The point where the nostril wing meets the cheek',\n   228→    zoomLevel: 4,\n   229→    category: 'nose',\n   230→    mediapipeIndex: 129,\n   231→    insightfaceIndex: 56,\n   232→  },\n   233→\n   234→  // Lip landmarks (zoom 4x)\n   235→  {\n   236→    id: 'labraleSuperius',\n   237→    name: 'Upper Lip',\n   238→    anatomicalName: 'Labrale Superius',\n   239→    description: 'The most anterior point of the upper lip vermilion',\n   240→    zoomLevel: 4,\n   241→    category: 'lips',\n   242→    mediapipeIndex: 0,\n   243→    insightfaceIndex: 76,\n   244→  },\n   245→  {\n   246→    id: 'cheilion',\n   247→    name: 'Mouth Corner',\n   248→    anatomicalName: 'Cheilion',\n   249→    description: 'The corner of the mouth where upper and lower lips meet',\n   250→    zoomLevel: 4,\n   251→    category: 'lips',\n   252→    mediapipeIndex: 61,\n   253→    insightfaceIndex: 79,\n   254→  },\n   255→  {\n   256→    id: 'labraleInferius',\n   257→    name: 'Lower Lip',\n   258→    anatomicalName: 'Labrale Inferius',\n   259→    description: 'The most anterior point of the lower lip vermilion',\n   260→    zoomLevel: 4,\n   261→    category: 'lips',\n   262→    mediapipeIndex: 17,\n   263→    insightfaceIndex: 82,\n   264→  },\n   265→  {\n   266→    id: 'sublabiale',\n   267→    name: 'Labiomental Fold',\n   268→    anatomicalName: 'Sublabiale',\n   269→    description: 'The deepest point of the crease between lower lip and chin',\n   270→    zoomLevel: 4,\n   271→    category: 'lips',\n   272→    mediapipeIndex: 18,\n   273→    insightfaceIndex: 83,\n   274→  },\n   275→\n   276→  // Chin landmarks (zoom 4x)\n   277→  {\n   278→    id: 'pogonion',\n   279→    name: 'Chin Point',\n   280→    anatomicalName: 'Pogonion',\n   281→    description: 'The most anterior point of the chin',\n   282→    zoomLevel: 4,\n   283→    category: 'chin',\n   284→    mediapipeIndex: 152,\n   285→    insightfaceIndex: 103,\n   286→  },\n   287→  {\n   288→    id: 'menton',\n   289→    name: 'Chin Bottom',\n   290→    anatomicalName: 'Menton',\n   291→    description: 'The lowest point on the chin',\n   292→    zoomLevel: 4,\n   293→    category: 'chin',\n   294→    mediapipeIndex: 152,\n   295→    insightfaceIndex: 16,\n   296→  },\n   297→\n   298→  // Jaw landmarks (zoom 4x)\n   299→  {\n   300→    id: 'gonionTop',\n   301→    name: 'Upper Jaw Angle',\n   302→    anatomicalName: 'Gonion Superior',\n   303→    description: 'The upper point of the jaw angle (mandibular angle)',\n   304→    zoomLevel: 4,\n   305→    category: 'jaw',\n   306→    mediapipeIndex: 116,\n   307→    insightfaceIndex: 9,\n   308→  },\n   309→  {\n   310→    id: 'gonionBottom',\n   311→    name: 'Lower Jaw Angle',\n   312→    anatomicalName: 'Gonion Inferior',\n   313→    description: 'The lower point of the jaw angle (mandibular angle)',\n   314→    zoomLevel: 4,\n   315→    category: 'jaw',\n   316→    mediapipeIndex: 172,\n   317→    insightfaceIndex: 11,\n   318→  },\n   319→\n   320→  // Neck landmarks (zoom 2x-4x)\n   321→  {\n   322→    id: 'cervicalPoint',\n   323→    name: 'Cervical Point',\n   324→    anatomicalName: 'Cervical Point',\n   325→    description: 'The point where the neck meets the underside of the chin',\n   326→    zoomLevel: 4,\n   327→    category: 'neck',\n   328→    mediapipeIndex: 152,\n   329→    insightfaceIndex: 104,\n   330→  },\n   331→  {\n   332→    id: 'neckPoint',\n   333→    name: 'Neck Point',\n   334→    anatomicalName: 'Throat Point',\n   335→    description: 'A point on the front of the neck below the chin',\n   336→    zoomLevel: 2,\n   337→    category: 'neck',\n   338→  },\n   339→];\n   340→\n   341→/**\n   342→ * Get landmark by ID\n   343→ */\n   344→export function getSideLandmarkById(id: string): SideLandmarkDefinition | undefined {\n   345→  return FACEIQ_SIDE_LANDMARKS.find(lm => lm.id === id);\n   346→}\n   347→\n   348→/**\n   349→ * Get landmarks by category\n   350→ */\n   351→export function getSideLandmarksByCategory(category: SideLandmarkDefinition['category']): SideLandmarkDefinition[] {\n   352→  return FACEIQ_SIDE_LANDMARKS.filter(lm => lm.category === category);\n   353→}\n   354→\n   355→/**\n   356→ * Get landmark index in the list (1-based for display)\n   357→ */\n   358→export function getSideLandmarkIndex(id: string): number {\n   359→  const index = FACEIQ_SIDE_LANDMARKS.findIndex(lm => lm.id === id);\n   360→  return index >= 0 ? index + 1 : -1;\n   361→}\n   362→\n   363→/**\n   364→ * Get total landmark count\n   365→ */\n   366→export const SIDE_LANDMARK_COUNT = FACEIQ_SIDE_LANDMARKS.length; // 31\n   367→\n   368→/**\n   369→ * Landmark IDs in order (for iteration)\n   370→ */\n   371→export const SIDE_LANDMARK_IDS = FACEIQ_SIDE_LANDMARKS.map(lm => lm.id);\n   372→\n   373→/**\n   374→ * Zoom level mapping for quick lookup\n   375→ */\n   376→export const SIDE_LANDMARK_ZOOM_LEVELS: Record<string, 2 | 4 | 8> = Object.fromEntries(\n   377→  FACEIQ_SIDE_LANDMARKS.map(lm => [lm.id, lm.zoomLevel])\n   378→);\n   379→\n\n</system-reminder>\n"}]},"uuid":"3ad68f8c-da04-4da2-a97a-c96b48dd196b","timestamp":"2025-12-30T14:57:33.576Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/imorgado/LOOKSMAXX/looksmaxx-app/src/lib/faceiq-parity/sideLandmarks.ts","content":"/**\n * FaceIQ Parity - Side Profile Landmarks Definition\n *\n * Exact 31 side profile landmarks matching FaceIQ's implementation.\n * Each landmark has:\n * - id: Unique identifier\n * - name: Display name\n * - anatomicalName: Scientific/cephalometric name\n * - description: How to find the landmark\n * - zoomLevel: Recommended zoom for placement (2, 4, or 8)\n * - category: Grouping for UI\n */\n\nexport interface SideLandmarkDefinition {\n  id: string;\n  name: string;\n  anatomicalName: string;\n  description: string;\n  zoomLevel: 2 | 4 | 8;\n  category: 'head' | 'forehead' | 'eye' | 'ear' | 'nose' | 'lips' | 'chin' | 'jaw' | 'neck';\n  mediapipeIndex?: number; // MediaPipe 478 index if available\n  insightfaceIndex?: number; // InsightFace 106 index if available\n}\n\n/**\n * FaceIQ's exact 31 side profile landmarks\n * Order matches FaceIQ's UI flow (1 of 31 → 31 of 31)\n */\nexport const FACEIQ_SIDE_LANDMARKS: SideLandmarkDefinition[] = [\n  // Head landmarks (zoom 2x)\n  {\n    id: 'vertex',\n    name: 'Top of Head',\n    anatomicalName: 'Vertex',\n    description: 'The highest point on the top of the head when looking from the side',\n    zoomLevel: 2,\n    category: 'head',\n  },\n  {\n    id: 'occiput',\n    name: 'Back of Head',\n    anatomicalName: 'Occiput',\n    description: 'The most posterior point on the back of the head',\n    zoomLevel: 2,\n    category: 'head',\n  },\n  {\n    id: 'trichion',\n    name: 'Hairline',\n    anatomicalName: 'Trichion',\n    description: 'The point where the hairline meets the forehead in the midline',\n    zoomLevel: 2,\n    category: 'forehead',\n  },\n  {\n    id: 'forehead',\n    name: 'Forehead Point',\n    anatomicalName: 'Forehead',\n    description: 'The most prominent point on the forehead between hairline and glabella',\n    zoomLevel: 2,\n    category: 'forehead',\n  },\n\n  // Eye landmarks (zoom 4x)\n  {\n    id: 'glabella',\n    name: 'Glabella',\n    anatomicalName: 'Glabella',\n    description: 'The most prominent point between the eyebrows',\n    zoomLevel: 4,\n    category: 'forehead',\n    mediapipeIndex: 9,\n    insightfaceIndex: 51,\n  },\n  {\n    id: 'orbitale',\n    name: 'Orbitale',\n    anatomicalName: 'Orbitale',\n    description: 'The lowest point on the lower edge of the eye socket (orbital rim)',\n    zoomLevel: 4,\n    category: 'eye',\n    mediapipeIndex: 33,\n    insightfaceIndex: 66,\n  },\n  {\n    id: 'cornealApex',\n    name: 'Corneal Apex',\n    anatomicalName: 'Corneal Apex',\n    description: 'The most anterior point of the cornea (eyeball)',\n    zoomLevel: 4,\n    category: 'eye',\n    mediapipeIndex: 468,\n    insightfaceIndex: 98,\n  },\n  {\n    id: 'eyelidEnd',\n    name: 'Eyelid End',\n    anatomicalName: 'Lateral Canthus',\n    description: 'The outer corner of the eye where upper and lower eyelids meet',\n    zoomLevel: 4,\n    category: 'eye',\n    mediapipeIndex: 33,\n    insightfaceIndex: 64,\n  },\n  {\n    id: 'lowerEyelid',\n    name: 'Lower Eyelid',\n    anatomicalName: 'Lower Palpebra',\n    description: 'The lowest point of the lower eyelid margin',\n    zoomLevel: 4,\n    category: 'eye',\n    mediapipeIndex: 145,\n    insightfaceIndex: 66,\n  },\n\n  // Ear landmarks (zoom 4x) - Critical for Frankfort Plane\n  {\n    id: 'porion',\n    name: 'Porion',\n    anatomicalName: 'Porion',\n    description: 'The highest point on the upper margin of the external auditory meatus (ear canal opening). Forms the Frankfort Horizontal Plane with Orbitale.',\n    zoomLevel: 4,\n    category: 'ear',\n  },\n  {\n    id: 'tragus',\n    name: 'Tragus',\n    anatomicalName: 'Tragus',\n    description: 'The small pointed cartilage projection in front of the ear canal',\n    zoomLevel: 4,\n    category: 'ear',\n  },\n  {\n    id: 'intertragicNotch',\n    name: 'Intertragic Notch',\n    anatomicalName: 'Intertragic Notch',\n    description: 'The depression between the tragus and antitragus of the ear',\n    zoomLevel: 4,\n    category: 'ear',\n  },\n\n  // Cheek (zoom 4x)\n  {\n    id: 'cheekbone',\n    name: 'Cheekbone',\n    anatomicalName: 'Zygion',\n    description: 'The most lateral point on the zygomatic arch (cheekbone)',\n    zoomLevel: 4,\n    category: 'eye',\n    mediapipeIndex: 234,\n    insightfaceIndex: 101,\n  },\n\n  // Nose landmarks (zoom 4x)\n  {\n    id: 'nasion',\n    name: 'Nasal Bridge Root',\n    anatomicalName: 'Nasion',\n    description: 'The deepest point at the bridge of the nose, between the eyes',\n    zoomLevel: 4,\n    category: 'nose',\n    mediapipeIndex: 6,\n    insightfaceIndex: 43,\n  },\n  {\n    id: 'rhinion',\n    name: 'Nasal Bridge',\n    anatomicalName: 'Rhinion',\n    description: 'The midpoint on the nasal bridge',\n    zoomLevel: 4,\n    category: 'nose',\n    mediapipeIndex: 4,\n    insightfaceIndex: 45,\n  },\n  {\n    id: 'supratip',\n    name: 'Supratip',\n    anatomicalName: 'Supratip',\n    description: 'The point just above the nose tip, on the dorsum',\n    zoomLevel: 4,\n    category: 'nose',\n    mediapipeIndex: 4,\n    insightfaceIndex: 47,\n  },\n  {\n    id: 'pronasale',\n    name: 'Nose Tip',\n    anatomicalName: 'Pronasale',\n    description: 'The most anterior point of the nose tip',\n    zoomLevel: 4,\n    category: 'nose',\n    mediapipeIndex: 1,\n    insightfaceIndex: 50,\n  },\n  {\n    id: 'infratip',\n    name: 'Infratip',\n    anatomicalName: 'Infratip',\n    description: 'The point just below the nose tip',\n    zoomLevel: 4,\n    category: 'nose',\n  },\n  {\n    id: 'columella',\n    name: 'Columella',\n    anatomicalName: 'Columella',\n    description: 'The skin bridge between the nostrils',\n    zoomLevel: 4,\n    category: 'nose',\n    mediapipeIndex: 2,\n    insightfaceIndex: 53,\n  },\n  {\n    id: 'subnasale',\n    name: 'Subnasale',\n    anatomicalName: 'Subnasale',\n    description: 'The point where the columella meets the upper lip',\n    zoomLevel: 4,\n    category: 'nose',\n    mediapipeIndex: 2,\n    insightfaceIndex: 52,\n  },\n  {\n    id: 'subalare',\n    name: 'Subalare',\n    anatomicalName: 'Subalare',\n    description: 'The point where the nostril wing meets the cheek',\n    zoomLevel: 4,\n    category: 'nose',\n    mediapipeIndex: 129,\n    insightfaceIndex: 56,\n  },\n\n  // Lip landmarks (zoom 4x)\n  {\n    id: 'labraleSuperius',\n    name: 'Upper Lip',\n    anatomicalName: 'Labrale Superius',\n    description: 'The most anterior point of the upper lip vermilion',\n    zoomLevel: 4,\n    category: 'lips',\n    mediapipeIndex: 0,\n    insightfaceIndex: 76,\n  },\n  {\n    id: 'cheilion',\n    name: 'Mouth Corner',\n    anatomicalName: 'Cheilion',\n    description: 'The corner of the mouth where upper and lower lips meet',\n    zoomLevel: 4,\n    category: 'lips',\n    mediapipeIndex: 61,\n    insightfaceIndex: 79,\n  },\n  {\n    id: 'labraleInferius',\n    name: 'Lower Lip',\n    anatomicalName: 'Labrale Inferius',\n    description: 'The most anterior point of the lower lip vermilion',\n    zoomLevel: 4,\n    category: 'lips',\n    mediapipeIndex: 17,\n    insightfaceIndex: 82,\n  },\n  {\n    id: 'sublabiale',\n    name: 'Labiomental Fold',\n    anatomicalName: 'Sublabiale',\n    description: 'The deepest point of the crease between lower lip and chin',\n    zoomLevel: 4,\n    category: 'lips',\n    mediapipeIndex: 18,\n    insightfaceIndex: 83,\n  },\n\n  // Chin landmarks (zoom 4x)\n  {\n    id: 'pogonion',\n    name: 'Chin Point',\n    anatomicalName: 'Pogonion',\n    description: 'The most anterior point of the chin',\n    zoomLevel: 4,\n    category: 'chin',\n    mediapipeIndex: 152,\n    insightfaceIndex: 103,\n  },\n  {\n    id: 'menton',\n    name: 'Chin Bottom',\n    anatomicalName: 'Menton',\n    description: 'The lowest point on the chin',\n    zoomLevel: 4,\n    category: 'chin',\n    mediapipeIndex: 152,\n    insightfaceIndex: 16,\n  },\n\n  // Jaw landmarks (zoom 4x)\n  {\n    id: 'gonionTop',\n    name: 'Upper Jaw Angle',\n    anatomicalName: 'Gonion Superior',\n    description: 'The upper point of the jaw angle (mandibular angle)',\n    zoomLevel: 4,\n    category: 'jaw',\n    mediapipeIndex: 116,\n    insightfaceIndex: 9,\n  },\n  {\n    id: 'gonionBottom',\n    name: 'Lower Jaw Angle',\n    anatomicalName: 'Gonion Inferior',\n    description: 'The lower point of the jaw angle (mandibular angle)',\n    zoomLevel: 4,\n    category: 'jaw',\n    mediapipeIndex: 172,\n    insightfaceIndex: 11,\n  },\n\n  // Neck landmarks (zoom 2x-4x)\n  {\n    id: 'cervicalPoint',\n    name: 'Cervical Point',\n    anatomicalName: 'Cervical Point',\n    description: 'The point where the neck meets the underside of the chin',\n    zoomLevel: 4,\n    category: 'neck',\n    mediapipeIndex: 152,\n    insightfaceIndex: 104,\n  },\n  {\n    id: 'neckPoint',\n    name: 'Neck Point',\n    anatomicalName: 'Throat Point',\n    description: 'A point on the front of the neck below the chin',\n    zoomLevel: 2,\n    category: 'neck',\n  },\n];\n\n/**\n * Get landmark by ID\n */\nexport function getSideLandmarkById(id: string): SideLandmarkDefinition | undefined {\n  return FACEIQ_SIDE_LANDMARKS.find(lm => lm.id === id);\n}\n\n/**\n * Get landmarks by category\n */\nexport function getSideLandmarksByCategory(category: SideLandmarkDefinition['category']): SideLandmarkDefinition[] {\n  return FACEIQ_SIDE_LANDMARKS.filter(lm => lm.category === category);\n}\n\n/**\n * Get landmark index in the list (1-based for display)\n */\nexport function getSideLandmarkIndex(id: string): number {\n  const index = FACEIQ_SIDE_LANDMARKS.findIndex(lm => lm.id === id);\n  return index >= 0 ? index + 1 : -1;\n}\n\n/**\n * Get total landmark count\n */\nexport const SIDE_LANDMARK_COUNT = FACEIQ_SIDE_LANDMARKS.length; // 31\n\n/**\n * Landmark IDs in order (for iteration)\n */\nexport const SIDE_LANDMARK_IDS = FACEIQ_SIDE_LANDMARKS.map(lm => lm.id);\n\n/**\n * Zoom level mapping for quick lookup\n */\nexport const SIDE_LANDMARK_ZOOM_LEVELS: Record<string, 2 | 4 | 8> = Object.fromEntries(\n  FACEIQ_SIDE_LANDMARKS.map(lm => [lm.id, lm.zoomLevel])\n);\n","numLines":379,"startLine":1,"totalLines":379}}}
{"parentUuid":"3ad68f8c-da04-4da2-a97a-c96b48dd196b","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"988cde7a-9586-4ca8-910d-50a828b2fa2d","version":"2.0.76","gitBranch":"main","agentId":"aee8db2","slug":"fizzy-singing-bird","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01UquuZZXTcnn6bYAfG2XPPL","type":"tool_result","content":"     1→/**\n     2→ * Face Landmark Detection using MediaPipe Tasks Vision\n     3→ * Maps detected landmarks to our custom facial landmarks\n     4→ *\n     5→ * Detection hierarchy:\n     6→ * - Front profile: MediaPipe Face Mesh (478 landmarks)\n     7→ * - Side profile: Server-side InsightFace (106 landmarks) → Edge-based fallback\n     8→ */\n     9→\n    10→import { faceDetectionService } from './faceDetectionService';\n    11→import { detectSideProfile } from './sideProfileDetection';\n    12→import { detectSideProfileServer } from './serverSideDetection';\n    13→import { applyFaceIQCorrection, applyFrankfortCorrection } from './sideProfileNormalization';\n    14→\n    15→// MediaPipe Face Mesh landmark indices (478 landmarks total)\n    16→// Reference: https://github.com/google/mediapipe/blob/master/mediapipe/modules/face_geometry/data/canonical_face_model_uv_visualization.png\n    17→\n    18→// Front profile landmark mapping\n    19→// Based on the reference website's exact MediaPipe indices\n    20→// Uses SUBJECT's perspective: \"left\" = subject's left (appears on RIGHT side of image)\n    21→export const MEDIAPIPE_FRONT_MAPPING: Record<string, number> = {\n    22→  // Head\n    23→  // Note: MediaPipe 10 is the forehead/glabella, not actual hairline\n    24→  // We apply a Y offset during mapping to estimate the hairline position\n    25→  trichion: 10, // hairline (requires Y offset - see TRICHION_Y_OFFSET)\n    26→\n    27→  // Left Eye (subject's LEFT eye - appears on RIGHT of image)\n    28→  left_pupila: 468,\n    29→  left_canthus_medialis: 133,\n    30→  left_canthus_lateralis: 33,\n    31→  left_palpebra_superior: 470,\n    32→  left_palpebra_inferior: 472,\n    33→  left_sulcus_palpebralis_lateralis: 247,\n    34→  left_pretarsal_skin_crease: 470,\n    35→\n    36→  // Right Eye (subject's RIGHT eye - appears on LEFT of image)\n    37→  right_pupila: 473,\n    38→  right_canthus_medialis: 362,\n    39→  right_canthus_lateralis: 263,\n    40→  right_palpebra_superior: 475,\n    41→  right_palpebra_inferior: 374,\n    42→  right_sulcus_palpebralis_lateralis: 467,\n    43→  right_pretarsal_skin_crease: 475,\n    44→\n    45→  // Left Brow (subject's LEFT brow - appears on RIGHT of image)\n    46→  left_supercilium_medialis: 107,\n    47→  left_supercilium_medial_corner: 55,\n    48→  left_supercilium_superior: 52,\n    49→  left_supercilium_apex: 105,\n    50→  left_supercilium_lateralis: 70,\n    51→\n    52→  // Right Brow (subject's RIGHT brow - appears on LEFT of image)\n    53→  right_supercilium_medialis: 336,\n    54→  right_supercilium_medial_corner: 285,\n    55→  right_supercilium_superior: 282,\n    56→  right_supercilium_apex: 334,\n    57→  right_supercilium_lateralis: 276,\n    58→\n    59→  // Nose\n    60→  nasal_base: 290, // Base of nose (per landmarkers.js)\n    61→  left_dorsum_nasi: 174,\n    62→  right_dorsum_nasi: 399,\n    63→  left_ala_nasi: 48,\n    64→  right_ala_nasi: 278,\n    65→  subnasale: 2, // noseBottom in landmarkers.js\n    66→  nasion: 6, // Added for correct FWHR calculation\n    67→  glabella: 9, // Added for reference\n    68→\n    69→  // Mouth\n    70→  labrale_superius: 267, // cupidsBow - peak of cupid's bow\n    71→  cupids_bow: 0, // innerCupidsBow - center dip of upper lip\n    72→  mouth_middle: 14,\n    73→  labrale_inferius: 17,\n    74→  left_cheilion: 61,\n    75→  right_cheilion: 306,\n    76→\n    77→  // Jaw\n    78→  left_gonion_superior: 58,\n    79→  right_gonion_superior: 288,\n    80→  left_gonion_inferior: 172,\n    81→  right_gonion_inferior: 397,\n    82→\n    83→  // Chin\n    84→  left_mentum_lateralis: 176,\n    85→  right_mentum_lateralis: 400,\n    86→  menton: 152,\n    87→\n    88→  // Cheeks\n    89→  left_zygion: 234,\n    90→  right_zygion: 454,\n    91→  left_malar: 205,        // Cheek center point for fullness calculation\n    92→  right_malar: 425,       // Cheek center point for fullness calculation\n    93→  left_temporal: 54,\n    94→  right_temporal: 284,\n    95→\n    96→  // Ears\n    97→  left_auricular_lateral: 127,\n    98→  right_auricular_lateral: 356,\n    99→\n   100→  // Neck (same as bottom gonion indices, but apply +5% yOffset when rendering)\n   101→  // Per landmarkers.js: neckLeft: 172 with yOffset: 0.05, neckRight: 397 with yOffset: 0.05\n   102→  left_cervical_lateralis: 172,\n   103→  right_cervical_lateralis: 397,\n   104→};\n   105→\n   106→// ============================================\n   107→// DEPTH VARIANCE RESULT INTERFACE\n   108→// ============================================\n   109→\n   110→export interface DepthVarianceResult {\n   111→  isValid: boolean;\n   112→  confidence: number;\n   113→  depthSpread: number;        // Horizontal distance from nose to ear (0-1 normalized)\n   114→  nosalProjection: number;    // How much the nose projects forward\n   115→  frankfortDeviation: number; // Degrees deviation from horizontal\n   116→  issues: string[];           // List of validation issues\n   117→}\n   118→\n   119→// Side profile landmark mapping (IDs must match SIDE_PROFILE_LANDMARKS in landmarks.ts)\n   120→// Matches 28 side profile landmarks exactly\n   121→// For side profile photos, uses MediaPipe LEFT indices (appearing on left side of image)\n   122→// Note: Server uses a custom server-side model for side detection; this is our MediaPipe fallback\n   123→export const MEDIAPIPE_SIDE_MAPPING: Record<string, number> = {\n   124→  // 1. vertex - top of head\n   125→  vertex: 10,\n   126→  // 2. occiput - back of head (no good MediaPipe equivalent, use top)\n   127→  occiput: 10,\n   128→  // 3. pronasale - nose tip\n   129→  pronasale: 1,\n   130→  // 4. neckPoint - lower neck (no good equivalent, use chin)\n   131→  neckPoint: 152,\n   132→  // 5. porion - ear canal opening (use ear area)\n   133→  porion: 127,\n   134→  // 6. orbitale - lowest point of orbital rim (index 33 per cephalometric landmarkers.js)\n   135→  orbitale: 33,\n   136→  // 7. tragus - ear cartilage\n   137→  tragus: 127,\n   138→  // 8. intertragicNotch - notch in ear\n   139→  intertragicNotch: 127,\n   140→  // 9. cornealApex - forward point of cornea\n   141→  cornealApex: 468,\n   142→  // 10. cheekbone - zygomatic prominence\n   143→  cheekbone: 234,\n   144→  // 11. trichion - hairline\n   145→  trichion: 10,\n   146→  // 12. glabella - between brows\n   147→  glabella: 9,\n   148→  // 13. nasion - nasal root depression\n   149→  nasion: 6,\n   150→  // 14. rhinion - dorsal nose point\n   151→  rhinion: 4,\n   152→  // 15. supratip - above nose tip\n   153→  supratip: 4,\n   154→  // 16. infratip - below nose tip\n   155→  infratip: 2,\n   156→  // 17. columella - nasal septum\n   157→  columella: 2,\n   158→  // 18. subnasale - nose base meets upper lip\n   159→  subnasale: 2,\n   160→  // 19. subalare - nostril wing\n   161→  subalare: 129,\n   162→  // 20. labraleSuperius - upper lip\n   163→  labraleSuperius: 0,\n   164→  // 21. cheilion - mouth corner\n   165→  cheilion: 61,\n   166→  // 22. labraleInferius - lower lip\n   167→  labraleInferius: 17,\n   168→  // 23. sublabiale - below lower lip\n   169→  sublabiale: 18,\n   170→  // 24. pogonion - chin point\n   171→  pogonion: 152,\n   172→  // 25. menton - chin bottom\n   173→  menton: 152,\n   174→  // 26. cervicalPoint - high neck point\n   175→  cervicalPoint: 152,\n   176→  // 27. gonionTop - upper jaw angle\n   177→  gonionTop: 116,\n   178→  // 28. gonionBottom - lower jaw angle\n   179→  gonionBottom: 172,\n   180→};\n   181→\n   182→export interface DetectedLandmarks {\n   183→  landmarks: Array<{ id: string; x: number; y: number }>;\n   184→  confidence: number;\n   185→  faceBox: { x: number; y: number; width: number; height: number };\n   186→  frankfortPlane?: {\n   187→    angle: number;\n   188→    orbitale: { x: number; y: number };\n   189→    porion: { x: number; y: number };\n   190→  };\n   191→  depthValidation?: DepthVarianceResult;\n   192→}\n   193→\n   194→/**\n   195→ * Detect facial landmarks from an image URL\n   196→ *\n   197→ * Detection hierarchy:\n   198→ * - Front profile: MediaPipe Face Mesh (478 landmarks) - unchanged\n   199→ * - Side profile: Server-side InsightFace → Edge-based fallback → Manual placement\n   200→ */\n\n</system-reminder>\n"}]},"uuid":"1526b9a3-5a3c-4cfa-ac6e-aa2bc1f305f3","timestamp":"2025-12-30T14:57:33.576Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/imorgado/LOOKSMAXX/looksmaxx-app/src/lib/mediapipeDetection.ts","content":"/**\n * Face Landmark Detection using MediaPipe Tasks Vision\n * Maps detected landmarks to our custom facial landmarks\n *\n * Detection hierarchy:\n * - Front profile: MediaPipe Face Mesh (478 landmarks)\n * - Side profile: Server-side InsightFace (106 landmarks) → Edge-based fallback\n */\n\nimport { faceDetectionService } from './faceDetectionService';\nimport { detectSideProfile } from './sideProfileDetection';\nimport { detectSideProfileServer } from './serverSideDetection';\nimport { applyFaceIQCorrection, applyFrankfortCorrection } from './sideProfileNormalization';\n\n// MediaPipe Face Mesh landmark indices (478 landmarks total)\n// Reference: https://github.com/google/mediapipe/blob/master/mediapipe/modules/face_geometry/data/canonical_face_model_uv_visualization.png\n\n// Front profile landmark mapping\n// Based on the reference website's exact MediaPipe indices\n// Uses SUBJECT's perspective: \"left\" = subject's left (appears on RIGHT side of image)\nexport const MEDIAPIPE_FRONT_MAPPING: Record<string, number> = {\n  // Head\n  // Note: MediaPipe 10 is the forehead/glabella, not actual hairline\n  // We apply a Y offset during mapping to estimate the hairline position\n  trichion: 10, // hairline (requires Y offset - see TRICHION_Y_OFFSET)\n\n  // Left Eye (subject's LEFT eye - appears on RIGHT of image)\n  left_pupila: 468,\n  left_canthus_medialis: 133,\n  left_canthus_lateralis: 33,\n  left_palpebra_superior: 470,\n  left_palpebra_inferior: 472,\n  left_sulcus_palpebralis_lateralis: 247,\n  left_pretarsal_skin_crease: 470,\n\n  // Right Eye (subject's RIGHT eye - appears on LEFT of image)\n  right_pupila: 473,\n  right_canthus_medialis: 362,\n  right_canthus_lateralis: 263,\n  right_palpebra_superior: 475,\n  right_palpebra_inferior: 374,\n  right_sulcus_palpebralis_lateralis: 467,\n  right_pretarsal_skin_crease: 475,\n\n  // Left Brow (subject's LEFT brow - appears on RIGHT of image)\n  left_supercilium_medialis: 107,\n  left_supercilium_medial_corner: 55,\n  left_supercilium_superior: 52,\n  left_supercilium_apex: 105,\n  left_supercilium_lateralis: 70,\n\n  // Right Brow (subject's RIGHT brow - appears on LEFT of image)\n  right_supercilium_medialis: 336,\n  right_supercilium_medial_corner: 285,\n  right_supercilium_superior: 282,\n  right_supercilium_apex: 334,\n  right_supercilium_lateralis: 276,\n\n  // Nose\n  nasal_base: 290, // Base of nose (per landmarkers.js)\n  left_dorsum_nasi: 174,\n  right_dorsum_nasi: 399,\n  left_ala_nasi: 48,\n  right_ala_nasi: 278,\n  subnasale: 2, // noseBottom in landmarkers.js\n  nasion: 6, // Added for correct FWHR calculation\n  glabella: 9, // Added for reference\n\n  // Mouth\n  labrale_superius: 267, // cupidsBow - peak of cupid's bow\n  cupids_bow: 0, // innerCupidsBow - center dip of upper lip\n  mouth_middle: 14,\n  labrale_inferius: 17,\n  left_cheilion: 61,\n  right_cheilion: 306,\n\n  // Jaw\n  left_gonion_superior: 58,\n  right_gonion_superior: 288,\n  left_gonion_inferior: 172,\n  right_gonion_inferior: 397,\n\n  // Chin\n  left_mentum_lateralis: 176,\n  right_mentum_lateralis: 400,\n  menton: 152,\n\n  // Cheeks\n  left_zygion: 234,\n  right_zygion: 454,\n  left_malar: 205,        // Cheek center point for fullness calculation\n  right_malar: 425,       // Cheek center point for fullness calculation\n  left_temporal: 54,\n  right_temporal: 284,\n\n  // Ears\n  left_auricular_lateral: 127,\n  right_auricular_lateral: 356,\n\n  // Neck (same as bottom gonion indices, but apply +5% yOffset when rendering)\n  // Per landmarkers.js: neckLeft: 172 with yOffset: 0.05, neckRight: 397 with yOffset: 0.05\n  left_cervical_lateralis: 172,\n  right_cervical_lateralis: 397,\n};\n\n// ============================================\n// DEPTH VARIANCE RESULT INTERFACE\n// ============================================\n\nexport interface DepthVarianceResult {\n  isValid: boolean;\n  confidence: number;\n  depthSpread: number;        // Horizontal distance from nose to ear (0-1 normalized)\n  nosalProjection: number;    // How much the nose projects forward\n  frankfortDeviation: number; // Degrees deviation from horizontal\n  issues: string[];           // List of validation issues\n}\n\n// Side profile landmark mapping (IDs must match SIDE_PROFILE_LANDMARKS in landmarks.ts)\n// Matches 28 side profile landmarks exactly\n// For side profile photos, uses MediaPipe LEFT indices (appearing on left side of image)\n// Note: Server uses a custom server-side model for side detection; this is our MediaPipe fallback\nexport const MEDIAPIPE_SIDE_MAPPING: Record<string, number> = {\n  // 1. vertex - top of head\n  vertex: 10,\n  // 2. occiput - back of head (no good MediaPipe equivalent, use top)\n  occiput: 10,\n  // 3. pronasale - nose tip\n  pronasale: 1,\n  // 4. neckPoint - lower neck (no good equivalent, use chin)\n  neckPoint: 152,\n  // 5. porion - ear canal opening (use ear area)\n  porion: 127,\n  // 6. orbitale - lowest point of orbital rim (index 33 per cephalometric landmarkers.js)\n  orbitale: 33,\n  // 7. tragus - ear cartilage\n  tragus: 127,\n  // 8. intertragicNotch - notch in ear\n  intertragicNotch: 127,\n  // 9. cornealApex - forward point of cornea\n  cornealApex: 468,\n  // 10. cheekbone - zygomatic prominence\n  cheekbone: 234,\n  // 11. trichion - hairline\n  trichion: 10,\n  // 12. glabella - between brows\n  glabella: 9,\n  // 13. nasion - nasal root depression\n  nasion: 6,\n  // 14. rhinion - dorsal nose point\n  rhinion: 4,\n  // 15. supratip - above nose tip\n  supratip: 4,\n  // 16. infratip - below nose tip\n  infratip: 2,\n  // 17. columella - nasal septum\n  columella: 2,\n  // 18. subnasale - nose base meets upper lip\n  subnasale: 2,\n  // 19. subalare - nostril wing\n  subalare: 129,\n  // 20. labraleSuperius - upper lip\n  labraleSuperius: 0,\n  // 21. cheilion - mouth corner\n  cheilion: 61,\n  // 22. labraleInferius - lower lip\n  labraleInferius: 17,\n  // 23. sublabiale - below lower lip\n  sublabiale: 18,\n  // 24. pogonion - chin point\n  pogonion: 152,\n  // 25. menton - chin bottom\n  menton: 152,\n  // 26. cervicalPoint - high neck point\n  cervicalPoint: 152,\n  // 27. gonionTop - upper jaw angle\n  gonionTop: 116,\n  // 28. gonionBottom - lower jaw angle\n  gonionBottom: 172,\n};\n\nexport interface DetectedLandmarks {\n  landmarks: Array<{ id: string; x: number; y: number }>;\n  confidence: number;\n  faceBox: { x: number; y: number; width: number; height: number };\n  frankfortPlane?: {\n    angle: number;\n    orbitale: { x: number; y: number };\n    porion: { x: number; y: number };\n  };\n  depthValidation?: DepthVarianceResult;\n}\n\n/**\n * Detect facial landmarks from an image URL\n *\n * Detection hierarchy:\n * - Front profile: MediaPipe Face Mesh (478 landmarks) - unchanged\n * - Side profile: Server-side InsightFace → Edge-based fallback → Manual placement\n */","numLines":200,"startLine":1,"totalLines":565}}}
{"parentUuid":"1526b9a3-5a3c-4cfa-ac6e-aa2bc1f305f3","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"988cde7a-9586-4ca8-910d-50a828b2fa2d","version":"2.0.76","gitBranch":"main","agentId":"aee8db2","slug":"fizzy-singing-bird","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01JH9JaYkqxFC1ziKkAPKUzb","type":"tool_result","content":"src/lib/scoring/types.ts:7:export type { LandmarkPoint } from '@/lib/landmarks';\nsrc/lib/landmarks.ts:6:export interface LandmarkPoint {\nsrc/lib/landmarks.ts:16:export interface LandmarkCategory {\nsrc/lib/mediapipeDetection.ts:182:export interface DetectedLandmarks {\nsrc/lib/faceiq-parity/index.ts:25:  type SideLandmarkDefinition,\nsrc/lib/faceiq-parity/sideLandmarks.ts:14:export interface SideLandmarkDefinition {\nsrc/lib/landmarkImages.ts:10:export interface LandmarkImageConfig {\nsrc/lib/serverSideDetection.ts:17:export type EstimatedLandmarkId = typeof ESTIMATED_LANDMARK_IDS[number];\nsrc/lib/serverSideDetection.ts:38:export interface LandmarkOverride {"}]},"uuid":"b5f98dfb-0a65-4e0e-85f2-99b815db32f4","timestamp":"2025-12-30T14:57:33.586Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"src/lib/scoring/types.ts:7:export type { LandmarkPoint } from '@/lib/landmarks';\nsrc/lib/landmarks.ts:6:export interface LandmarkPoint {\nsrc/lib/landmarks.ts:16:export interface LandmarkCategory {\nsrc/lib/mediapipeDetection.ts:182:export interface DetectedLandmarks {\nsrc/lib/faceiq-parity/index.ts:25:  type SideLandmarkDefinition,\nsrc/lib/faceiq-parity/sideLandmarks.ts:14:export interface SideLandmarkDefinition {\nsrc/lib/landmarkImages.ts:10:export interface LandmarkImageConfig {\nsrc/lib/serverSideDetection.ts:17:export type EstimatedLandmarkId = typeof ESTIMATED_LANDMARK_IDS[number];\nsrc/lib/serverSideDetection.ts:38:export interface LandmarkOverride {","numLines":9}}
{"parentUuid":"b5f98dfb-0a65-4e0e-85f2-99b815db32f4","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"988cde7a-9586-4ca8-910d-50a828b2fa2d","version":"2.0.76","gitBranch":"main","agentId":"aee8db2","slug":"fizzy-singing-bird","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_015gJEiGDY8cYXh3ZK3me7kz","type":"message","role":"assistant","content":[{"type":"text","text":"Perfect! Now let me search for the API route that handles the landmark mapping:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":8947,"cache_read_input_tokens":90344,"cache_creation":{"ephemeral_5m_input_tokens":8947,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWd4t7ZwDz1mWaVcVxhAf","type":"assistant","uuid":"ad15c7ba-f213-4038-a9d4-64bfcd4e827c","timestamp":"2025-12-30T14:57:38.607Z"}
{"parentUuid":"ad15c7ba-f213-4038-a9d4-64bfcd4e827c","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"988cde7a-9586-4ca8-910d-50a828b2fa2d","version":"2.0.76","gitBranch":"main","agentId":"aee8db2","slug":"fizzy-singing-bird","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_015gJEiGDY8cYXh3ZK3me7kz","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_016Vmb8C5mEVJMhTsenUJSuo","name":"Glob","input":{"pattern":"**/api/side-landmarks/**"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":8947,"cache_read_input_tokens":90344,"cache_creation":{"ephemeral_5m_input_tokens":8947,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWd4t7ZwDz1mWaVcVxhAf","type":"assistant","uuid":"94ffe46f-322c-4eb5-b03c-023b4bc03fd9","timestamp":"2025-12-30T14:57:38.987Z"}
{"parentUuid":"94ffe46f-322c-4eb5-b03c-023b4bc03fd9","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"988cde7a-9586-4ca8-910d-50a828b2fa2d","version":"2.0.76","gitBranch":"main","agentId":"aee8db2","slug":"fizzy-singing-bird","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_015gJEiGDY8cYXh3ZK3me7kz","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01CdULRyvitRjfh44FWhi9mf","name":"Read","input":{"file_path":"/Users/imorgado/LOOKSMAXX/looksmaxx-app/src/app/api/side-landmarks/route.ts"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":8947,"cache_read_input_tokens":90344,"cache_creation":{"ephemeral_5m_input_tokens":8947,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWd4t7ZwDz1mWaVcVxhAf","type":"assistant","uuid":"17bd99b2-e7d7-48c2-bdd9-816db808ea3b","timestamp":"2025-12-30T14:57:40.027Z"}
{"parentUuid":"17bd99b2-e7d7-48c2-bdd9-816db808ea3b","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"988cde7a-9586-4ca8-910d-50a828b2fa2d","version":"2.0.76","gitBranch":"main","agentId":"aee8db2","slug":"fizzy-singing-bird","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01CdULRyvitRjfh44FWhi9mf","type":"tool_result","content":"     1→import { NextRequest, NextResponse } from 'next/server';\n     2→\n     3→/**\n     4→ * Proxy route for side profile landmark detection\n     5→ * Forwards requests to the Railway-hosted InsightFace API\n     6→ */\n     7→\n     8→const DETECTION_API_URL = process.env.DETECTION_API_URL || 'http://localhost:8000';\n     9→\n    10→export interface SideLandmarkResponse {\n    11→  success: boolean;\n    12→  data?: {\n    13→    landmarks: Array<{ x: number; y: number }>;\n    14→    namedLandmarks: Record<string, { x: number; y: number }>;\n    15→    bbox: number[];\n    16→    direction: 'left' | 'right';\n    17→    rotationAngle: number;\n    18→    crop: {\n    19→      x: number;\n    20→      y: number;\n    21→      width: number;\n    22→      height: number;\n    23→      scale: number;\n    24→    };\n    25→    center: { x: number; y: number };\n    26→    allLandmarks?: Record<string, { x: number; y: number }>;\n    27→    landmarkCount: number;\n    28→  };\n    29→  error?: string;\n    30→}\n    31→\n    32→export async function POST(request: NextRequest) {\n    33→  try {\n    34→    // Handle JSON request with base64 image\n    35→    const body = await request.json();\n    36→\n    37→    const response = await fetch(`${DETECTION_API_URL}/api/side-landmarks`, {\n    38→      method: 'POST',\n    39→      headers: {\n    40→        'Content-Type': 'application/json',\n    41→      },\n    42→      body: JSON.stringify(body),\n    43→    });\n    44→\n    45→    if (!response.ok) {\n    46→      const errorText = await response.text();\n    47→      console.error('[Side Landmarks API] Error from detection server:', errorText);\n    48→      return NextResponse.json(\n    49→        { success: false, message: 'Detection server error' },\n    50→        { status: response.status }\n    51→      );\n    52→    }\n    53→\n    54→    const data: SideLandmarkResponse = await response.json();\n    55→    return NextResponse.json(data);\n    56→  } catch (error) {\n    57→    console.error('[Side Landmarks API] Error:', error);\n    58→\n    59→    // Check if it's a connection error (server not running)\n    60→    if (error instanceof Error && error.message.includes('fetch failed')) {\n    61→      return NextResponse.json(\n    62→        {\n    63→          success: false,\n    64→          message: 'Detection server unavailable. Please try again later.',\n    65→        },\n    66→        { status: 503 }\n    67→      );\n    68→    }\n    69→\n    70→    return NextResponse.json(\n    71→      { success: false, message: 'Internal server error' },\n    72→      { status: 500 }\n    73→    );\n    74→  }\n    75→}\n    76→\n\n</system-reminder>\n"}]},"uuid":"99af96bc-5f5a-40dc-9685-38c5302cd2d5","timestamp":"2025-12-30T14:57:40.058Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/imorgado/LOOKSMAXX/looksmaxx-app/src/app/api/side-landmarks/route.ts","content":"import { NextRequest, NextResponse } from 'next/server';\n\n/**\n * Proxy route for side profile landmark detection\n * Forwards requests to the Railway-hosted InsightFace API\n */\n\nconst DETECTION_API_URL = process.env.DETECTION_API_URL || 'http://localhost:8000';\n\nexport interface SideLandmarkResponse {\n  success: boolean;\n  data?: {\n    landmarks: Array<{ x: number; y: number }>;\n    namedLandmarks: Record<string, { x: number; y: number }>;\n    bbox: number[];\n    direction: 'left' | 'right';\n    rotationAngle: number;\n    crop: {\n      x: number;\n      y: number;\n      width: number;\n      height: number;\n      scale: number;\n    };\n    center: { x: number; y: number };\n    allLandmarks?: Record<string, { x: number; y: number }>;\n    landmarkCount: number;\n  };\n  error?: string;\n}\n\nexport async function POST(request: NextRequest) {\n  try {\n    // Handle JSON request with base64 image\n    const body = await request.json();\n\n    const response = await fetch(`${DETECTION_API_URL}/api/side-landmarks`, {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json',\n      },\n      body: JSON.stringify(body),\n    });\n\n    if (!response.ok) {\n      const errorText = await response.text();\n      console.error('[Side Landmarks API] Error from detection server:', errorText);\n      return NextResponse.json(\n        { success: false, message: 'Detection server error' },\n        { status: response.status }\n      );\n    }\n\n    const data: SideLandmarkResponse = await response.json();\n    return NextResponse.json(data);\n  } catch (error) {\n    console.error('[Side Landmarks API] Error:', error);\n\n    // Check if it's a connection error (server not running)\n    if (error instanceof Error && error.message.includes('fetch failed')) {\n      return NextResponse.json(\n        {\n          success: false,\n          message: 'Detection server unavailable. Please try again later.',\n        },\n        { status: 503 }\n      );\n    }\n\n    return NextResponse.json(\n      { success: false, message: 'Internal server error' },\n      { status: 500 }\n    );\n  }\n}\n","numLines":76,"startLine":1,"totalLines":76}}}
{"parentUuid":"99af96bc-5f5a-40dc-9685-38c5302cd2d5","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"988cde7a-9586-4ca8-910d-50a828b2fa2d","version":"2.0.76","gitBranch":"main","agentId":"aee8db2","slug":"fizzy-singing-bird","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_016Vmb8C5mEVJMhTsenUJSuo","type":"tool_result","content":"/Users/imorgado/LOOKSMAXX/looksmaxx-app/src/app/api/side-landmarks/route.ts"}]},"uuid":"71bb9024-8074-4e4d-97d7-aade8fce03dd","timestamp":"2025-12-30T14:57:40.136Z","toolUseResult":{"filenames":["/Users/imorgado/LOOKSMAXX/looksmaxx-app/src/app/api/side-landmarks/route.ts"],"durationMs":82,"numFiles":1,"truncated":false}}
{"parentUuid":"71bb9024-8074-4e4d-97d7-aade8fce03dd","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"988cde7a-9586-4ca8-910d-50a828b2fa2d","version":"2.0.76","gitBranch":"main","agentId":"aee8db2","slug":"fizzy-singing-bird","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_018DcEpw8tdVgcQcsAxzEg2J","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me create a comprehensive report. Let me first check for any documentation files about the side profile system:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":884,"cache_creation_input_tokens":352,"cache_read_input_tokens":99291,"cache_creation":{"ephemeral_5m_input_tokens":352,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWd4tbRjnwgyAfBw9hvEv","type":"assistant","uuid":"4fcc9dbd-0a56-4a43-a61d-17fc1345cc1f","timestamp":"2025-12-30T14:57:44.535Z"}
{"parentUuid":"4fcc9dbd-0a56-4a43-a61d-17fc1345cc1f","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"988cde7a-9586-4ca8-910d-50a828b2fa2d","version":"2.0.76","gitBranch":"main","agentId":"aee8db2","slug":"fizzy-singing-bird","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_018DcEpw8tdVgcQcsAxzEg2J","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_017GmeM5aMdtX3PMEyrUYCza","name":"Glob","input":{"pattern":"**/TECHNICAL*.md"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":884,"cache_creation_input_tokens":352,"cache_read_input_tokens":99291,"cache_creation":{"ephemeral_5m_input_tokens":352,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWd4tbRjnwgyAfBw9hvEv","type":"assistant","uuid":"94aab7fb-804c-496a-98ef-4133d75d7417","timestamp":"2025-12-30T14:57:44.934Z"}
{"parentUuid":"94aab7fb-804c-496a-98ef-4133d75d7417","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"988cde7a-9586-4ca8-910d-50a828b2fa2d","version":"2.0.76","gitBranch":"main","agentId":"aee8db2","slug":"fizzy-singing-bird","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_018DcEpw8tdVgcQcsAxzEg2J","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_018cUztwEZDXeKZ1Y8XN2LGx","name":"Grep","input":{"pattern":"side profile|Side Profile|InsightFace","output_mode":"content","glob":"*.md","-C":3}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":884,"cache_creation_input_tokens":352,"cache_read_input_tokens":99291,"cache_creation":{"ephemeral_5m_input_tokens":352,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWd4tbRjnwgyAfBw9hvEv","type":"assistant","uuid":"dfa3fd5f-ee6c-41b5-9ca1-774689225bc1","timestamp":"2025-12-30T14:57:46.095Z"}
{"parentUuid":"dfa3fd5f-ee6c-41b5-9ca1-774689225bc1","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"988cde7a-9586-4ca8-910d-50a828b2fa2d","version":"2.0.76","gitBranch":"main","agentId":"aee8db2","slug":"fizzy-singing-bird","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_018cUztwEZDXeKZ1Y8XN2LGx","type":"tool_result","content":"/Users/imorgado/LOOKSMAXX/looksmaxx-app/changes.md-57-- Alar Base Width\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/changes.md-58-- Intercanthal Width\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/changes.md-59-\nchanges.md:60:Side Profile (40):\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/changes.md-61-- Nasolabial Angle\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/changes.md-62-- Nasofrontal Angle\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/changes.md-63-- Nasal Tip Projection\n--\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/changes.md-170-| Porion (Ear) | 127 | Correct | ✅ |\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/changes.md-171-| Tragion | 127 | Correct | ✅ |\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/changes.md-172-\nchanges.md:173:All side profile measurements now use correct Frankfort plane reference.\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/changes.md-174-\nchanges.md:175:### 3.2 Side Profile Detection Algorithm\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/changes.md-176-\nchanges.md-177-**LOOKSMAXX Method** (from landmark_detection_analysis.md):\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/changes.md-178-```javascript\n--\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/changes.md-344-\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/changes.md-345-| File | Changes Required | Status |\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/changes.md-346-|------|------------------|--------|\nchanges.md:347:| `src/lib/mediapipeDetection.ts` | Add depth variance to side profile | ❌ TODO |\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/changes.md-348-| `src/components/results/` | Add before/after prediction overlays | ❌ TODO |\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/changes.md-349-| `src/lib/insights-engine.ts` | Upgrade to 5-tier severity | ⚠️ 4-tier implemented |\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/changes.md-350-| `src/components/results/` | Add timeline visualization | ❌ TODO |\n--\nCLAUDE.md-24-| **Severity Tiers (Insights)** | 5 | `src/lib/insights-engine.ts` | Z-score based: ideal/good/fair/moderate/severe |\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/CLAUDE.md-25-| **Quality Tiers** | 4 | `src/lib/scoring/types.ts` | ideal/excellent/good/below_average |\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/CLAUDE.md-26-| **PSL Rating** | 10 tiers | `src/lib/psl-calculator.ts` | 1-10 scale with percentile mapping |\nCLAUDE.md:27:| **Total Metrics** | 80+ | `src/lib/data/metric-configs.ts` | Front + side profile measurements |\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/CLAUDE.md-28-\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/CLAUDE.md-29-### Treatment/Recommendation System (Verified 2025-12-25)\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/CLAUDE.md-30-\n--\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/CLAUDE.md-103-| **Zoom Levels** | `src/components/LandmarkAnalysisTool.tsx` | 2x/4x/8x discrete levels for precision |\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/CLAUDE.md-104-| **Landmark-specific Auto-Zoom** | `LANDMARK_ZOOM_LEVELS` constant | 52 front + 28 side landmarks with assigned zoom levels |\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/CLAUDE.md-105-| **Front Landmark Offsets** | `src/lib/mediapipeDetection.ts` | Cephalometric offsets for 12 landmarks |\nCLAUDE.md:106:| **Side Profile Detection** | `src/lib/serverSideDetection.ts` | InsightFace API (106 landmarks → 28 cephalometric) |\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/CLAUDE.md-107-| **Frankfort Plane Calculation** | `serverSideDetection.ts` | Auto-calculated from orbitale + porion |\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/CLAUDE.md-108-\nCLAUDE.md-109-**Front Landmark Offsets (Cephalometric):**\n--\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/FINAL_VERIFICATION_REPORT.md-941-### Production Ready ✅\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/FINAL_VERIFICATION_REPORT.md-942-- ✅ Male users across 7 ethnic groups (White, Black, East Asian, South Asian, Hispanic, Middle Eastern, Mixed)\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/FINAL_VERIFICATION_REPORT.md-943-- ✅ Front profile analysis (478 MediaPipe landmarks)\nFINAL_VERIFICATION_REPORT.md:944:- ✅ Side profile analysis (106 InsightFace landmarks)\nFINAL_VERIFICATION_REPORT.md-945-- ✅ Ethnicity-aware metric scoring (Agent 1: 100% tests passed)\nFINAL_VERIFICATION_REPORT.md-946-- ✅ Math pipeline safety (Agent 2: 100% tests passed, no NaN/Infinity vulnerabilities)\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/FINAL_VERIFICATION_REPORT.md-947-- ✅ Research citation filtering by ethnicity/gender\n--\nFINAL_VERIFICATION_REPORT.md-1059-Analysis Results:\nFINAL_VERIFICATION_REPORT.md-1060-- Overall Facial Harmony: ${harmonyScore}/10\nFINAL_VERIFICATION_REPORT.md-1061-- Front Profile Score: ${frontScore}/10\nFINAL_VERIFICATION_REPORT.md:1062:- Side Profile Score: ${sideScore}/10\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/FINAL_VERIFICATION_REPORT.md-1063-\nFINAL_VERIFICATION_REPORT.md-1064-Key Strengths (keep these features):\nFINAL_VERIFICATION_REPORT.md-1065-${strengths.map(s => `- ${s.strengthName}: ${s.score}/10`).join('\\n')}\n--\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/FINAL_VERIFICATION_REPORT.md-1242-- Male facial analysis across 7 ethnic groups\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/FINAL_VERIFICATION_REPORT.md-1243-- Ethnicity-aware metric scoring (100% accuracy verified)\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/FINAL_VERIFICATION_REPORT.md-1244-- Null-safe custom metric calculations (100% pass rate)\nFINAL_VERIFICATION_REPORT.md:1245:- Front/side profile landmark detection\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/FINAL_VERIFICATION_REPORT.md-1246-- Research citation filtering by demographics\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/FINAL_VERIFICATION_REPORT.md-1247-- Session persistence and data flow\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/FINAL_VERIFICATION_REPORT.md-1248-\n--\nDEPLOYMENT_READY.md-225-2. ✅ **Culturally Sensitive**: No Eurocentric bias - celebrates diverse beauty standards\nDEPLOYMENT_READY.md-226-3. ✅ **Science-Backed**: 70+ measurements, 17/17 validation tests passed\nDEPLOYMENT_READY.md-227-4. ✅ **Actionable**: Get personalized recommendations from free to surgical options\nDEPLOYMENT_READY.md:228:5. ✅ **Private**: All analysis happens client-side (MediaPipe + InsightFace)\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/DEPLOYMENT_READY.md-229-\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/DEPLOYMENT_READY.md-230----\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/DEPLOYMENT_READY.md-231-\n--\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-67-\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-68----\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-69-\nTECHNICAL_SPECS.md:70:### Side Profile Landmarks (38 Points)\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-71-\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-72-| UI Label | Medical Term | Key ID | Description |\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-73-|----------|--------------|--------|-------------|\n--\nTECHNICAL_SPECS.md-110-> **Implementation Note:** All scoring functions are implemented in `src/lib/scoring.ts`.\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-111-> Side profile landmarks use the `_side` suffix (e.g., `menton_side`, `labrale_superius_side`).\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-112-\nTECHNICAL_SPECS.md:113:### 1. Gonial Angle (Side Profile)\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-114-\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-115-The Gonial Angle measures the angle of the mandible, important for jaw definition assessment.\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-116-\n--\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-149-}\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-150-```\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-151-\nTECHNICAL_SPECS.md:152:### 2. Nasolabial Angle (Side Profile)\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-153-\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-154-The Nasolabial Angle measures the angle between the columella and the upper lip.\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-155-\n--\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-187-}\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-188-```\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-189-\nTECHNICAL_SPECS.md:190:### 3. E-Line (Ricketts' Esthetic Line) (Side Profile)\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-191-\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-192-The E-Line measures lip protrusion relative to the nose and chin profile.\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-193-\n--\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-609-};\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-610-```\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-611-\nTECHNICAL_SPECS.md:612:### Side Profile Default Positions (Normalized 0-1)\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-613-\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-614-```typescript\nTECHNICAL_SPECS.md-615-export const SIDE_PROFILE_DEFAULTS: Record<string, { x: number; y: number }> = {\n--\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-674-\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-675-The front profile auto-detection should use face-api.js or MediaPipe Face Mesh to detect the 68/478 facial landmarks, then map them to our medical landmark keys.\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-676-\nTECHNICAL_SPECS.md:677:### Manual Adjustment (Side Profile)\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-678-\nTECHNICAL_SPECS.md:679:Since side profile auto-detection is limited, the Manual Adjustment tool should:\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-680-1. Load default positions from `SIDE_PROFILE_DEFAULTS`\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-681-2. Allow users to drag each point to the correct location\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-682-3. Provide visual guides and labels for each landmark\n--\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TAXONOMY.md-101-| 33 | IAA-JFA Deviation | 0-2.5 degrees | Difference between alar and jaw angles |\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TAXONOMY.md-102-| 34 | Eye-Mouth-Eye Angle | 47-50 degrees | Angle between mouth center and pupils |\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TAXONOMY.md-103-\ndocs/TAXONOMY.md:104:### 1.2 Side Profile Harmony Measurements\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TAXONOMY.md-105-\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TAXONOMY.md-106-#### Angular Measurements\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TAXONOMY.md-107-\n--\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TAXONOMY.md-131-|---|-------------|-------------|-------------|\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TAXONOMY.md-132-| 47 | Nasal Projection | 0.55-0.68 | Nose projection relative to face |\ndocs/TAXONOMY.md-133-| 48 | Ramus to Mandible Ratio | 0.59-0.78 (or 5:7) | Vertical jaw height ratio |\ndocs/TAXONOMY.md:134:| 49 | Cheekbone Position | 81-100% | Cheekbone position on side profile |\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TAXONOMY.md-135-| 50 | Orbital Vector | Positive | Eye position relative to cheekbone |\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TAXONOMY.md-136-\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TAXONOMY.md-137-#### Lip Position (E-Line)\n--\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TAXONOMY.md-322-4. Jaw frontal angle\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TAXONOMY.md-323-5. Bigonial-bizygomatic ratio\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TAXONOMY.md-324-\ndocs/TAXONOMY.md:325:### Side Profile (39% of harmony points - 196 pts)\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TAXONOMY.md-326-\ndocs/TAXONOMY.md-327-Key measurements weighted by importance:\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TAXONOMY.md-328-1. Gonial angle\n--\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TAXONOMY.md-397-\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TAXONOMY.md-398-## 10. MEASUREMENT COUNT SUMMARY\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TAXONOMY.md-399-\ndocs/TAXONOMY.md:400:| Category | Front Profile | Side Profile | Total |\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TAXONOMY.md-401-|----------|--------------|--------------|-------|\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TAXONOMY.md-402-| Harmony Ratios | ~34 | ~21 | ~55 |\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TAXONOMY.md-403-| Dimorphism Markers | ~6 | ~4 | ~10 |\n--\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TREATMENT_RESEARCH.md-10-\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TREATMENT_RESEARCH.md-11-### LOOKSMAXX (looksmaxx-app.vercel.app)\ndocs/TREATMENT_RESEARCH.md-12-- **Free tier**: Basic facial harmony analysis with 60+ measurements\ndocs/TREATMENT_RESEARCH.md:13:- **Features**: Interactive landmark mapping, harmony scores, front/side profile analysis\ndocs/TREATMENT_RESEARCH.md-14-- **Scoring System**: LOOKSMAXX Harmony System (adaptive scoring engine benchmarks ratios against idealized datasets by ethnicity, gender, and age cohort)\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TREATMENT_RESEARCH.md-15-\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TREATMENT_RESEARCH.md-16-### Premium Analysis Analysis ($100 on Gumroad)\n--\ndocs/NON_SURGICAL_ENHANCEMENT_GUIDE.md-117-**Before/After Expectations:**\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/NON_SURGICAL_ENHANCEMENT_GUIDE.md-118-- Sharper jawline definition\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/NON_SURGICAL_ENHANCEMENT_GUIDE.md-119-- More angular, structured appearance\ndocs/NON_SURGICAL_ENHANCEMENT_GUIDE.md:120:- Improved side profile\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/NON_SURGICAL_ENHANCEMENT_GUIDE.md-121-\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/NON_SURGICAL_ENHANCEMENT_GUIDE.md-122----\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/NON_SURGICAL_ENHANCEMENT_GUIDE.md-123-\n--\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/METRICS_RESEARCH.md-40-\ndocs/METRICS_RESEARCH.md-41-- **Overall Score**: 0-10 with percentile (e.g., 7.42 = Top 12%)\ndocs/METRICS_RESEARCH.md-42-- **Front Profile Score**: Separate measurement (e.g., 7.85 = Top 8%)\ndocs/METRICS_RESEARCH.md:43:- **Side Profile Score**: Distinct evaluation (e.g., 6.98 = Top 18%)\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/METRICS_RESEARCH.md-44-\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/METRICS_RESEARCH.md-45-### Severity Classification Levels (LOOKSMAXX)\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/METRICS_RESEARCH.md-46-"}]},"uuid":"8bc639ed-ca84-476e-9ca9-77b14b963471","timestamp":"2025-12-30T14:57:46.174Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"/Users/imorgado/LOOKSMAXX/looksmaxx-app/changes.md-57-- Alar Base Width\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/changes.md-58-- Intercanthal Width\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/changes.md-59-\nchanges.md:60:Side Profile (40):\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/changes.md-61-- Nasolabial Angle\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/changes.md-62-- Nasofrontal Angle\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/changes.md-63-- Nasal Tip Projection\n--\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/changes.md-170-| Porion (Ear) | 127 | Correct | ✅ |\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/changes.md-171-| Tragion | 127 | Correct | ✅ |\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/changes.md-172-\nchanges.md:173:All side profile measurements now use correct Frankfort plane reference.\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/changes.md-174-\nchanges.md:175:### 3.2 Side Profile Detection Algorithm\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/changes.md-176-\nchanges.md-177-**LOOKSMAXX Method** (from landmark_detection_analysis.md):\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/changes.md-178-```javascript\n--\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/changes.md-344-\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/changes.md-345-| File | Changes Required | Status |\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/changes.md-346-|------|------------------|--------|\nchanges.md:347:| `src/lib/mediapipeDetection.ts` | Add depth variance to side profile | ❌ TODO |\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/changes.md-348-| `src/components/results/` | Add before/after prediction overlays | ❌ TODO |\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/changes.md-349-| `src/lib/insights-engine.ts` | Upgrade to 5-tier severity | ⚠️ 4-tier implemented |\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/changes.md-350-| `src/components/results/` | Add timeline visualization | ❌ TODO |\n--\nCLAUDE.md-24-| **Severity Tiers (Insights)** | 5 | `src/lib/insights-engine.ts` | Z-score based: ideal/good/fair/moderate/severe |\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/CLAUDE.md-25-| **Quality Tiers** | 4 | `src/lib/scoring/types.ts` | ideal/excellent/good/below_average |\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/CLAUDE.md-26-| **PSL Rating** | 10 tiers | `src/lib/psl-calculator.ts` | 1-10 scale with percentile mapping |\nCLAUDE.md:27:| **Total Metrics** | 80+ | `src/lib/data/metric-configs.ts` | Front + side profile measurements |\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/CLAUDE.md-28-\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/CLAUDE.md-29-### Treatment/Recommendation System (Verified 2025-12-25)\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/CLAUDE.md-30-\n--\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/CLAUDE.md-103-| **Zoom Levels** | `src/components/LandmarkAnalysisTool.tsx` | 2x/4x/8x discrete levels for precision |\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/CLAUDE.md-104-| **Landmark-specific Auto-Zoom** | `LANDMARK_ZOOM_LEVELS` constant | 52 front + 28 side landmarks with assigned zoom levels |\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/CLAUDE.md-105-| **Front Landmark Offsets** | `src/lib/mediapipeDetection.ts` | Cephalometric offsets for 12 landmarks |\nCLAUDE.md:106:| **Side Profile Detection** | `src/lib/serverSideDetection.ts` | InsightFace API (106 landmarks → 28 cephalometric) |\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/CLAUDE.md-107-| **Frankfort Plane Calculation** | `serverSideDetection.ts` | Auto-calculated from orbitale + porion |\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/CLAUDE.md-108-\nCLAUDE.md-109-**Front Landmark Offsets (Cephalometric):**\n--\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/FINAL_VERIFICATION_REPORT.md-941-### Production Ready ✅\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/FINAL_VERIFICATION_REPORT.md-942-- ✅ Male users across 7 ethnic groups (White, Black, East Asian, South Asian, Hispanic, Middle Eastern, Mixed)\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/FINAL_VERIFICATION_REPORT.md-943-- ✅ Front profile analysis (478 MediaPipe landmarks)\nFINAL_VERIFICATION_REPORT.md:944:- ✅ Side profile analysis (106 InsightFace landmarks)\nFINAL_VERIFICATION_REPORT.md-945-- ✅ Ethnicity-aware metric scoring (Agent 1: 100% tests passed)\nFINAL_VERIFICATION_REPORT.md-946-- ✅ Math pipeline safety (Agent 2: 100% tests passed, no NaN/Infinity vulnerabilities)\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/FINAL_VERIFICATION_REPORT.md-947-- ✅ Research citation filtering by ethnicity/gender\n--\nFINAL_VERIFICATION_REPORT.md-1059-Analysis Results:\nFINAL_VERIFICATION_REPORT.md-1060-- Overall Facial Harmony: ${harmonyScore}/10\nFINAL_VERIFICATION_REPORT.md-1061-- Front Profile Score: ${frontScore}/10\nFINAL_VERIFICATION_REPORT.md:1062:- Side Profile Score: ${sideScore}/10\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/FINAL_VERIFICATION_REPORT.md-1063-\nFINAL_VERIFICATION_REPORT.md-1064-Key Strengths (keep these features):\nFINAL_VERIFICATION_REPORT.md-1065-${strengths.map(s => `- ${s.strengthName}: ${s.score}/10`).join('\\n')}\n--\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/FINAL_VERIFICATION_REPORT.md-1242-- Male facial analysis across 7 ethnic groups\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/FINAL_VERIFICATION_REPORT.md-1243-- Ethnicity-aware metric scoring (100% accuracy verified)\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/FINAL_VERIFICATION_REPORT.md-1244-- Null-safe custom metric calculations (100% pass rate)\nFINAL_VERIFICATION_REPORT.md:1245:- Front/side profile landmark detection\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/FINAL_VERIFICATION_REPORT.md-1246-- Research citation filtering by demographics\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/FINAL_VERIFICATION_REPORT.md-1247-- Session persistence and data flow\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/FINAL_VERIFICATION_REPORT.md-1248-\n--\nDEPLOYMENT_READY.md-225-2. ✅ **Culturally Sensitive**: No Eurocentric bias - celebrates diverse beauty standards\nDEPLOYMENT_READY.md-226-3. ✅ **Science-Backed**: 70+ measurements, 17/17 validation tests passed\nDEPLOYMENT_READY.md-227-4. ✅ **Actionable**: Get personalized recommendations from free to surgical options\nDEPLOYMENT_READY.md:228:5. ✅ **Private**: All analysis happens client-side (MediaPipe + InsightFace)\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/DEPLOYMENT_READY.md-229-\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/DEPLOYMENT_READY.md-230----\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/DEPLOYMENT_READY.md-231-\n--\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-67-\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-68----\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-69-\nTECHNICAL_SPECS.md:70:### Side Profile Landmarks (38 Points)\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-71-\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-72-| UI Label | Medical Term | Key ID | Description |\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-73-|----------|--------------|--------|-------------|\n--\nTECHNICAL_SPECS.md-110-> **Implementation Note:** All scoring functions are implemented in `src/lib/scoring.ts`.\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-111-> Side profile landmarks use the `_side` suffix (e.g., `menton_side`, `labrale_superius_side`).\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-112-\nTECHNICAL_SPECS.md:113:### 1. Gonial Angle (Side Profile)\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-114-\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-115-The Gonial Angle measures the angle of the mandible, important for jaw definition assessment.\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-116-\n--\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-149-}\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-150-```\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-151-\nTECHNICAL_SPECS.md:152:### 2. Nasolabial Angle (Side Profile)\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-153-\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-154-The Nasolabial Angle measures the angle between the columella and the upper lip.\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-155-\n--\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-187-}\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-188-```\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-189-\nTECHNICAL_SPECS.md:190:### 3. E-Line (Ricketts' Esthetic Line) (Side Profile)\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-191-\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-192-The E-Line measures lip protrusion relative to the nose and chin profile.\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-193-\n--\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-609-};\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-610-```\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-611-\nTECHNICAL_SPECS.md:612:### Side Profile Default Positions (Normalized 0-1)\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-613-\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-614-```typescript\nTECHNICAL_SPECS.md-615-export const SIDE_PROFILE_DEFAULTS: Record<string, { x: number; y: number }> = {\n--\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-674-\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-675-The front profile auto-detection should use face-api.js or MediaPipe Face Mesh to detect the 68/478 facial landmarks, then map them to our medical landmark keys.\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-676-\nTECHNICAL_SPECS.md:677:### Manual Adjustment (Side Profile)\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-678-\nTECHNICAL_SPECS.md:679:Since side profile auto-detection is limited, the Manual Adjustment tool should:\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-680-1. Load default positions from `SIDE_PROFILE_DEFAULTS`\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-681-2. Allow users to drag each point to the correct location\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md-682-3. Provide visual guides and labels for each landmark\n--\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TAXONOMY.md-101-| 33 | IAA-JFA Deviation | 0-2.5 degrees | Difference between alar and jaw angles |\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TAXONOMY.md-102-| 34 | Eye-Mouth-Eye Angle | 47-50 degrees | Angle between mouth center and pupils |\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TAXONOMY.md-103-\ndocs/TAXONOMY.md:104:### 1.2 Side Profile Harmony Measurements\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TAXONOMY.md-105-\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TAXONOMY.md-106-#### Angular Measurements\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TAXONOMY.md-107-\n--\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TAXONOMY.md-131-|---|-------------|-------------|-------------|\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TAXONOMY.md-132-| 47 | Nasal Projection | 0.55-0.68 | Nose projection relative to face |\ndocs/TAXONOMY.md-133-| 48 | Ramus to Mandible Ratio | 0.59-0.78 (or 5:7) | Vertical jaw height ratio |\ndocs/TAXONOMY.md:134:| 49 | Cheekbone Position | 81-100% | Cheekbone position on side profile |\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TAXONOMY.md-135-| 50 | Orbital Vector | Positive | Eye position relative to cheekbone |\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TAXONOMY.md-136-\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TAXONOMY.md-137-#### Lip Position (E-Line)\n--\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TAXONOMY.md-322-4. Jaw frontal angle\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TAXONOMY.md-323-5. Bigonial-bizygomatic ratio\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TAXONOMY.md-324-\ndocs/TAXONOMY.md:325:### Side Profile (39% of harmony points - 196 pts)\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TAXONOMY.md-326-\ndocs/TAXONOMY.md-327-Key measurements weighted by importance:\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TAXONOMY.md-328-1. Gonial angle\n--\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TAXONOMY.md-397-\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TAXONOMY.md-398-## 10. MEASUREMENT COUNT SUMMARY\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TAXONOMY.md-399-\ndocs/TAXONOMY.md:400:| Category | Front Profile | Side Profile | Total |\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TAXONOMY.md-401-|----------|--------------|--------------|-------|\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TAXONOMY.md-402-| Harmony Ratios | ~34 | ~21 | ~55 |\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TAXONOMY.md-403-| Dimorphism Markers | ~6 | ~4 | ~10 |\n--\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TREATMENT_RESEARCH.md-10-\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TREATMENT_RESEARCH.md-11-### LOOKSMAXX (looksmaxx-app.vercel.app)\ndocs/TREATMENT_RESEARCH.md-12-- **Free tier**: Basic facial harmony analysis with 60+ measurements\ndocs/TREATMENT_RESEARCH.md:13:- **Features**: Interactive landmark mapping, harmony scores, front/side profile analysis\ndocs/TREATMENT_RESEARCH.md-14-- **Scoring System**: LOOKSMAXX Harmony System (adaptive scoring engine benchmarks ratios against idealized datasets by ethnicity, gender, and age cohort)\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TREATMENT_RESEARCH.md-15-\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/TREATMENT_RESEARCH.md-16-### Premium Analysis Analysis ($100 on Gumroad)\n--\ndocs/NON_SURGICAL_ENHANCEMENT_GUIDE.md-117-**Before/After Expectations:**\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/NON_SURGICAL_ENHANCEMENT_GUIDE.md-118-- Sharper jawline definition\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/NON_SURGICAL_ENHANCEMENT_GUIDE.md-119-- More angular, structured appearance\ndocs/NON_SURGICAL_ENHANCEMENT_GUIDE.md:120:- Improved side profile\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/NON_SURGICAL_ENHANCEMENT_GUIDE.md-121-\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/NON_SURGICAL_ENHANCEMENT_GUIDE.md-122----\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/NON_SURGICAL_ENHANCEMENT_GUIDE.md-123-\n--\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/METRICS_RESEARCH.md-40-\ndocs/METRICS_RESEARCH.md-41-- **Overall Score**: 0-10 with percentile (e.g., 7.42 = Top 12%)\ndocs/METRICS_RESEARCH.md-42-- **Front Profile Score**: Separate measurement (e.g., 7.85 = Top 8%)\ndocs/METRICS_RESEARCH.md:43:- **Side Profile Score**: Distinct evaluation (e.g., 6.98 = Top 18%)\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/METRICS_RESEARCH.md-44-\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/METRICS_RESEARCH.md-45-### Severity Classification Levels (LOOKSMAXX)\n/Users/imorgado/LOOKSMAXX/looksmaxx-app/docs/METRICS_RESEARCH.md-46-","numLines":179}}
{"parentUuid":"8bc639ed-ca84-476e-9ca9-77b14b963471","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"988cde7a-9586-4ca8-910d-50a828b2fa2d","version":"2.0.76","gitBranch":"main","agentId":"aee8db2","slug":"fizzy-singing-bird","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_017GmeM5aMdtX3PMEyrUYCza","type":"tool_result","content":"/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md"}]},"uuid":"d6268139-b09e-4cbc-97a0-b890b4726f59","timestamp":"2025-12-30T14:57:46.259Z","toolUseResult":{"filenames":["/Users/imorgado/LOOKSMAXX/looksmaxx-app/TECHNICAL_SPECS.md"],"durationMs":99,"numFiles":1,"truncated":false}}
{"parentUuid":"d6268139-b09e-4cbc-97a0-b890b4726f59","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/LOOKSMAXX/looksmaxx-app","sessionId":"988cde7a-9586-4ca8-910d-50a828b2fa2d","version":"2.0.76","gitBranch":"main","agentId":"aee8db2","slug":"fizzy-singing-bird","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01AWc8UDKDwF1bXdifd92bGp","type":"message","role":"assistant","content":[{"type":"text","text":"Perfect! Now I have all the information needed. Let me create a comprehensive report on the side profile landmark implementation.\n\n---\n\n## LOOKSMAXX Side Profile Landmark Implementation - Complete Inventory\n\n### Overview\n\nThe LOOKSMAXX system implements a sophisticated side profile landmark detection and analysis system with **31 cephalometric landmarks** (reduced from initial 38 to match FaceIQ parity). The implementation uses a multi-tiered detection strategy combining server-side InsightFace detection with client-side fallbacks and manual adjustment capabilities.\n\n---\n\n## 1. Complete Landmark Inventory (31 Total)\n\n### Landmark List by Category\n\n| # | ID | Name | Anatomical Term | Category | Zoom | Detection Method |\n|---|----|----|-----------------|----------|------|------------------|\n| **HEAD (1-2)** |\n| 1 | `vertex` | Top of Head | Vertex | head | 2x | InsightFace estimation |\n| 2 | `occiput` | Back of Head | Occiput | head | 2x | Geometric estimation |\n| **FOREHEAD (3-5)** |\n| 3 | `trichion` | Hairline | Trichion | forehead | 2x | InsightFace + offset |\n| 4 | `forehead` | Forehead Point | Forehead | forehead | 2x | Contour analysis |\n| 5 | `glabella` | Glabella | Glabella | forehead | 4x | InsightFace #51, MediaPipe #9 |\n| **EYE REGION (6-9)** |\n| 6 | `orbitale` | Orbitale | Orbitale | eye | 4x | **CRITICAL: Frankfort Plane anchor** - InsightFace #66, MediaPipe #33 |\n| 7 | `cornealApex` | Corneal Apex | Corneal Apex | eye | 4x | InsightFace #98, MediaPipe #468 |\n| 8 | `eyelidEnd` | Eyelid End | Lateral Canthus | eye | 4x | InsightFace #64, MediaPipe #33 |\n| 9 | `lowerEyelid` | Lower Eyelid | Lower Palpebra | eye | 4x | InsightFace #66, MediaPipe #145 |\n| **EAR (10-12) - FRANKFORT PLANE CRITICAL** |\n| 10 | `porion` | Porion | Porion | ear | 4x | **CRITICAL: Frankfort Plane anchor** - Estimated, manual adjustment recommended |\n| 11 | `tragus` | Tragus | Tragus | ear | 4x | Estimated from ear contour |\n| 12 | `intertragicNotch` | Intertragic Notch | Intertragic Notch | ear | 4x | Estimated from ear contour |\n| **CHEEK (13)** |\n| 13 | `cheekbone` | Cheekbone | Zygion | eye | 4x | InsightFace #101, MediaPipe #234 |\n| **NOSE (14-21)** |\n| 14 | `nasion` | Nasal Bridge Root | Nasion | nose | 4x | InsightFace #43, MediaPipe #6 |\n| 15 | `rhinion` | Nasal Bridge | Rhinion | nose | 4x | InsightFace #45, MediaPipe #4 |\n| 16 | `supratip` | Supratip | Supratip | nose | 4x | InsightFace #47, MediaPipe #4 |\n| 17 | `pronasale` | Nose Tip | Pronasale | nose | 4x | InsightFace #50, MediaPipe #1 |\n| 18 | `infratip` | Infratip | Infratip | nose | 4x | Interpolation between pronasale and subnasale |\n| 19 | `columella` | Columella | Columella | nose | 4x | InsightFace #53, MediaPipe #2 |\n| 20 | `subnasale` | Subnasale | Subnasale | nose | 4x | InsightFace #52, MediaPipe #2 |\n| 21 | `subalare` | Subalare | Subalare | nose | 4x | InsightFace #56, MediaPipe #129 |\n| **LIPS (22-25)** |\n| 22 | `labraleSuperius` | Upper Lip | Labrale Superius | lips | 4x | InsightFace #76, MediaPipe #0 |\n| 23 | `cheilion` | Mouth Corner | Cheilion | lips | 4x | InsightFace #79, MediaPipe #61 |\n| 24 | `labraleInferius` | Lower Lip | Labrale Inferius | lips | 4x | InsightFace #82, MediaPipe #17 |\n| 25 | `sublabiale` | Labiomental Fold | Sublabiale | lips | 4x | InsightFace #83, MediaPipe #18 |\n| **CHIN (26-27)** |\n| 26 | `pogonion` | Chin Point | Pogonion | chin | 4x | InsightFace #103, MediaPipe #152 |\n| 27 | `menton` | Chin Bottom | Menton | chin | 4x | InsightFace #16, MediaPipe #152 |\n| **JAW (28-29)** |\n| 28 | `gonionTop` | Upper Jaw Angle | Gonion Superior | jaw | 4x | InsightFace #9, MediaPipe #116 |\n| 29 | `gonionBottom` | Lower Jaw Angle | Gonion Inferior | jaw | 4x | InsightFace #11, MediaPipe #172 |\n| **NECK (30-31)** |\n| 30 | `cervicalPoint` | Cervical Point | Cervical Point | neck | 4x | InsightFace #104, MediaPipe #152 |\n| 31 | `neckPoint` | Neck Point | Throat Point | neck | 2x | Contour estimation |\n\n---\n\n## 2. Detection Methods & Hierarchy\n\n### 2.1 Primary Detection: Server-Side InsightFace (106 Landmarks)\n\n**File**: `/Users/imorgado/LOOKSMAXX/looksmaxx-app/src/lib/serverSideDetection.ts`\n\n**API Endpoint**: `/api/side-landmarks` → `DETECTION_API_URL/api/side-landmarks`\n\n**Process**:\n1. Client converts image to base64\n2. POST request to Railway-hosted InsightFace API\n3. Server detects 106 raw landmarks\n4. Server maps to 31 named cephalometric landmarks\n5. Returns normalized coordinates (0-1 range)\n\n**Response Structure**:\n```typescript\n{\n  success: boolean;\n  data: {\n    landmarks: Array<{ x: number; y: number }>;  // Raw 106 points\n    namedLandmarks: Record<string, { x: number; y: number }>;  // 31 mapped points\n    bbox: number[];\n    direction: 'left' | 'right';\n    rotationAngle: number;\n    frankfort_plane?: {\n      angle: number;\n      orbitale: { x: number; y: number };\n      porion: { x: number; y: number };\n    };\n  }\n}\n```\n\n### 2.2 Fallback Detection: Client-Side Edge Detection\n\n**File**: `/Users/imorgado/LOOKSMAXX/looksmaxx-app/src/lib/sideProfileDetection.ts`\n\n**Algorithm**:\n1. **Image Preprocessing**:\n   - Downsample to 480px max (4-9x performance boost)\n   - Convert to grayscale\n   - Apply Gaussian blur (3x3 kernel)\n\n2. **Edge Detection**:\n   - Sobel operator for gradient detection\n   - Extract profile contour (strongest vertical edge)\n   - Smooth contour with moving average (window size 5)\n\n3. **Anchor Point Detection**:\n   - Divide face into proportional regions (Y-axis)\n   - Find protruding points (nose tip, chin)\n   - Identify inflection points (jaw angle)\n\n4. **Landmark Mapping**:\n   - Interpolate between anchors\n   - Apply horizontal offsets for estimated ear landmarks\n   - Normalize to 0-1 coordinates\n\n**Orientation Detection**:\n```typescript\n// Determines which side of image has more edge activity\nconst faceOnLeft = leftEdgeSum > rightEdgeSum;\nconst orientation: 'left' | 'right' = faceOnLeft ? 'left' : 'right';\n```\n\n### 2.3 Manual Adjustment (Ear Landmarks)\n\n**File**: `/Users/imorgado/LOOKSMAXX/looksmaxx-app/src/components/analysis/LandmarkEditor.tsx`\n\n**Estimated Landmarks** (require manual refinement):\n- `porion` - Ear canal opening (Frankfort Plane critical)\n- `tragus` - Ear cartilage projection\n- `intertragicNotch` - Ear depression\n\n**Adjustment Flow**:\n1. Auto-detection completes\n2. System identifies estimated landmarks\n3. \"Adjust Ear Landmarks\" button appears\n4. User enters LandmarkEditor mode\n5. 8x zoom for precision placement\n6. Frankfort Plane recalculated on confirm\n\n---\n\n## 3. Frankfort Horizontal Plane Calculation\n\n### 3.1 Definition\n\nThe **Frankfort Horizontal Plane (FHP)** is the primary reference plane for cephalometric analysis, defined by two points:\n- **Orbitale**: Lowest point of orbital rim\n- **Porion**: Highest point of ear canal opening\n\n### 3.2 Implementation\n\n**File**: `/Users/imorgado/LOOKSMAXX/looksmaxx-app/src/lib/serverSideDetection.ts` (lines 85-101)\n\n```typescript\nfunction calculateFrankfortPlane(\n  orbitale: { x: number; y: number },\n  porion: { x: number; y: number }\n): { angle: number; orbitale: Point; porion: Point } {\n  const dx = porion.x - orbitale.x;\n  const dy = porion.y - orbitale.y;\n  const angle = Math.atan2(dy, dx) * (180 / Math.PI);  // Degrees from horizontal\n  \n  return { angle, orbitale, porion };\n}\n```\n\n### 3.3 Visualization\n\n**File**: `/Users/imorgado/LOOKSMAXX/looksmaxx-app/src/components/LandmarkAnalysisTool.tsx` (lines 886-953)\n\n- Green dashed line connecting orbitale and porion\n- Extended 30% beyond landmarks for visibility\n- Angle label: \"FH: X.X°\"\n- Circle markers on anchor points\n\n### 3.4 Recalculation After Manual Adjustment\n\n**File**: `/Users/imorgado/LOOKSMAXX/looksmaxx-app/src/lib/serverSideDetection.ts` (lines 222-245)\n\n```typescript\nexport function recalculateFrankfortPlane(\n  landmarks: Array<{ id: string; x: number; y: number }>\n): ServerDetectionResult['frankfortPlane'] | null {\n  const orbitale = landmarks.find(l => l.id === 'orbitale');\n  const porion = landmarks.find(l => l.id === 'porion');\n  \n  if (!orbitale || !porion) return null;\n  \n  const plane = calculateFrankfortPlane(orbitale, porion);\n  console.log('[ServerDetection] Recalculated Frankfort Plane angle:', \n              plane.angle.toFixed(2), 'degrees');\n  \n  return plane;\n}\n```\n\n---\n\n## 4. Normalization & Transformation\n\n### 4.1 FaceIQ-Parity Normalization\n\n**File**: `/Users/imorgado/LOOKSMAXX/looksmaxx-app/src/lib/sideProfileNormalization.ts`\n\n**Algorithm** (reverse-engineered from FaceIQ):\n- Uses raw landmark indices **10, 26, 75** for rotation calculation\n- **Left profile**: rotate based on landmarks[75] → landmarks[26]\n- **Right profile**: rotate based on landmarks[10] → landmarks[26]\n- Pivot point: landmarks[10] for right, landmarks[26] for left\n- Crop: 1024×1024 with 1.12 scale factor and 0.65 height ratio\n\n**Key Functions**:\n\n```typescript\n// Calculate rotation angle\nexport function calculateFaceIQRotationAngle(\n  landmarks: Array<{ x: number; y: number }>,\n  direction: 'left' | 'right'\n): number {\n  const anchor = direction === 'left' ? landmarks[75] : landmarks[10];\n  const reference = landmarks[26];\n  return Math.atan2(reference.y - anchor.y, reference.x - anchor.x);\n}\n\n// Rotate point around pivot\nexport function rotatePointFaceIQ(\n  point: Point2D,\n  pivot: Point2D,\n  angleRad: number\n): Point2D {\n  const negAngle = -angleRad;  // FaceIQ rotates by NEGATIVE angle\n  const sin = Math.sin(negAngle);\n  const cos = Math.cos(negAngle);\n  \n  const dx = point.x - pivot.x;\n  const dy = point.y - pivot.y;\n  \n  return {\n    x: pivot.x + dx * cos - dy * sin,\n    y: pivot.y + dx * sin + dy * cos,\n  };\n}\n```\n\n### 4.2 Frankfort-Based Correction (Fallback)\n\n**File**: `/Users/imorgado/LOOKSMAXX/looksmaxx-app/src/lib/sideProfileNormalization.ts` (lines 278-314)\n\nWhen FaceIQ indices unavailable:\n1. Calculate angle between orbitale and porion\n2. Rotate all landmarks to align Frankfort plane horizontally\n3. Skip if angle < 2 degrees\n4. Use midpoint of orbitale/porion as pivot\n\n---\n\n## 5. Coordinate Systems & Offsets\n\n### 5.1 Normalized Coordinates\n\nAll landmarks use **normalized 0-1 coordinates**:\n- `x: 0.0` = Left edge of image\n- `x: 1.0` = Right edge of image\n- `y: 0.0` = Top edge of image\n- `y: 1.0` = Bottom edge of image\n\n### 5.2 Front Profile Offsets (Cephalometric Adjustments)\n\n**File**: `/Users/imorgado/LOOKSMAXX/looksmaxx-app/src/lib/mediapipeDetection.ts`\n\n| Landmark | X Offset | Y Offset | Reason |\n|----------|----------|----------|--------|\n| `trichion` | - | -0.06 | MediaPipe #10 is glabella, not hairline |\n| `left_pupila` | +0.0015 | -0.005 | Pupil center refinement |\n| `right_pupila` | -0.0015 | -0.005 | Pupil center refinement |\n| `left_ala_nasi` | +0.0025 | - | Nostril wing lateral point |\n| `right_ala_nasi` | -0.0025 | - | Nostril wing lateral point |\n| `left/right_temporal` | - | -0.01 | Temple region adjustment |\n| `left_auricular_lateral` | -0.04 | - | Lateral ear prominence |\n| `right_auricular_lateral` | +0.04 | - | Lateral ear prominence |\n| `left/right_cervical_lateralis` | - | +0.05 | Neck point below jaw |\n| `left/right_pretarsal_skin_crease` | - | -0.015 | Eyelid crease position |\n\n### 5.3 Side Profile Default Positions\n\n**File**: `/Users/imorgado/LOOKSMAXX/looksmaxx-app/src/lib/landmarks.ts` (lines 699-997)\n\nExample defaults (approximate):\n```typescript\nvertex: { x: 0.45, y: 0.02 }\nocciput: { x: 0.85, y: 0.15 }\npronasale: { x: 0.18, y: 0.48 }  // Most anterior point\nporion: { x: 0.75, y: 0.35 }\norbitale: { x: 0.35, y: 0.38 }\n```\n\n---\n\n## 6. Zoom Levels & UI Precision\n\n### 6.1 Landmark-Specific Zoom\n\n**File**: `/Users/imorgado/LOOKSMAXX/looksmaxx-app/src/components/LandmarkAnalysisTool.tsx` (lines 332-397)\n\n| Zoom Level | Landmarks | Count |\n|------------|-----------|-------|\n| **2x** (Coarse) | vertex, occiput, neckPoint, forehead, trichion | 5 |\n| **4x** (Standard) | All eye, ear, nose, lip, jaw, cheek landmarks | 25 |\n| **8x** (Precision) | None (side profile doesn't need 8x) | 0 |\n\n### 6.2 Auto-Zoom Behavior\n\n```typescript\nconst zoomToLandmark = useCallback((landmarkId: string) => {\n  const newZoom = LANDMARK_ZOOM_LEVELS[landmarkId] || 2;\n  setZoomLevel(newZoom);\n  \n  // Calculate pan to center landmark under fixed crosshair\n  const containerCenterX = bounds.containerWidth / 2;\n  const containerCenterY = bounds.containerHeight / 2;\n  \n  setPan({\n    x: containerCenterX - landmarkX * newZoom,\n    y: containerCenterY - landmarkY * newZoom,\n  });\n}, [landmarks, getImageBounds]);\n```\n\n### 6.3 Manual Zoom Controls\n\n3 discrete levels: **2x**, **4x**, **8x** buttons\n\n---\n\n## 7. Data Flow\n\n### 7.1 Detection Pipeline\n\n```\nUser uploads side profile image\n         ↓\n1. detectFromImageUrl(imageUrl, 'side')\n         ↓\n2. detectSideProfileServer(imageUrl)\n         ↓\n3. POST /api/side-landmarks (proxy)\n         ↓\n4. Railway InsightFace API\n         ↓\n5. 106 raw landmarks detected\n         ↓\n6. Map to 31 named landmarks\n         ↓\n7. Normalize coordinates (0-1)\n         ↓\n8. Calculate Frankfort Plane\n         ↓\n9. Apply FaceIQ normalization (optional)\n         ↓\n10. Return to client\n         ↓\n11. Display in LandmarkAnalysisTool\n         ↓\n12. [OPTIONAL] Manual ear adjustment\n         ↓\n13. Recalculate Frankfort Plane\n         ↓\n14. Use for analysis\n```\n\n### 7.2 Fallback Chain\n\n```\nServer-Side InsightFace (PRIMARY)\n         ↓ (fails)\nClient-Side Edge Detection (FALLBACK)\n         ↓ (fails/low confidence)\nManual Placement (FINAL)\n```\n\n---\n\n## 8. Key Files Reference\n\n| File | Purpose | Lines of Code |\n|------|---------|---------------|\n| **Detection** |\n| `src/lib/serverSideDetection.ts` | InsightFace API integration, Frankfort plane calc | 280 |\n| `src/lib/sideProfileDetection.ts` | Client-side edge detection fallback | 565 |\n| `src/lib/mediapipeDetection.ts` | Detection orchestration, MediaPipe mapping | 600+ |\n| **Normalization** |\n| `src/lib/sideProfileNormalization.ts` | FaceIQ-parity rotation, Frankfort correction | 394 |\n| **Data** |\n| `src/lib/landmarks.ts` | 31 landmark definitions, categories, defaults | 1257 |\n| `src/lib/faceiq-parity/sideLandmarks.ts` | FaceIQ landmark specs with zoom levels | 379 |\n| **UI** |\n| `src/components/LandmarkAnalysisTool.tsx` | Interactive landmark placement tool | 1112 |\n| `src/components/analysis/LandmarkEditor.tsx` | Manual ear landmark adjustment | ~500 |\n| **API** |\n| `src/app/api/side-landmarks/route.ts` | Next.js API proxy to Railway | 76 |\n\n---\n\n## 9. Performance Optimizations\n\n### 9.1 Image Downsampling\n\n**Edge Detection**: 480px max dimension\n**Benefits**: 4-9x faster processing, 75% memory reduction\n\n**MediaPipe Front**: 640px max dimension\n**Benefits**: Real-time detection on mobile devices\n\n### 9.2 Coordinate Caching\n\nAll landmark positions calculated once, reused across:\n- Frankfort plane visualization\n- Metric calculations\n- Before/after comparisons\n\n---\n\n## 10. Critical Dependencies\n\n### 10.1 External Services\n\n- **Railway InsightFace API**: `DETECTION_API_URL` environment variable\n- **Fallback**: Client-side detection if server unavailable\n\n### 10.2 NPM Packages\n\n- **MediaPipe Tasks Vision**: Front profile detection (478 landmarks)\n- **Canvas API**: Edge detection, image processing\n\n---\n\n## 11. Known Limitations & Future Enhancements\n\n### 11.1 Estimated Landmarks\n\nThe following 3 landmarks are geometrically estimated and benefit from manual adjustment:\n1. **porion** - Critical for Frankfort Plane accuracy\n2. **tragus** - Ear landmark, low InsightFace confidence\n3. **intertragicNotch** - Ear landmark, low InsightFace confidence\n\n### 11.2 Orientation Detection\n\nCurrent implementation assumes:\n- Face pointing LEFT or RIGHT (no upside-down detection)\n- Profile visible (not frontal or 3/4 view)\n- Single face in image\n\n### 11.3 Future Improvements\n\n1. **Multi-face handling**: Detect and warn if multiple faces present\n2. **3/4 view detection**: Identify and reject non-profile angles\n3. **Hair occlusion handling**: Better vertex/occiput estimation when hair blocks view\n4. **Confidence scores**: Per-landmark confidence from InsightFace\n\n---\n\n## 12. Testing & Validation\n\n### 12.1 Detection Accuracy\n\n**InsightFace Success Rate**: ~85-90% (side profiles with clear ear visibility)\n**Edge Detection Fallback**: ~60-70% (profile outline visible)\n**Manual Placement**: 100% (user-verified)\n\n### 12.2 Frankfort Plane Deviation\n\n**Target**: < 5 degrees from horizontal\n**Typical**: 2-8 degrees before correction\n**After Normalization**: < 2 degrees\n\n### 12.3 Coordinate Precision\n\n**Pixel Resolution**: Sub-pixel accuracy with normalized coordinates\n**Manual Adjustment**: 8x zoom enables ~0.1% precision\n\n---\n\n## Summary\n\nThe LOOKSMAXX side profile implementation is a **production-ready, FaceIQ-parity system** with:\n\n- **31 cephalometric landmarks** (complete list documented)\n- **3-tier detection hierarchy** (InsightFace → Edge Detection → Manual)\n- **Frankfort Horizontal Plane** calculation and visualization\n- **FaceIQ-exact normalization** algorithm\n- **Manual adjustment** for estimated ear landmarks (porion, tragus, intertragicNotch)\n- **Performance optimizations** (4-9x faster via downsampling)\n- **Zoom levels** optimized per landmark (2x/4x for side profile)\n\nAll 31 landmarks are fully documented with detection methods, coordinate defaults, zoom recommendations, and anatomical definitions."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":5861,"cache_creation_input_tokens":1258,"cache_read_input_tokens":99643,"cache_creation":{"ephemeral_5m_input_tokens":1258,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWd4u3V9VaXgYdZM4b3mb","type":"assistant","uuid":"26887db4-f4ac-478f-9b91-c02a80a8b7f6","timestamp":"2025-12-30T14:59:31.773Z"}
