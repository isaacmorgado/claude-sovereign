{"parentUuid":null,"isSidechain":true,"userType":"external","cwd":"/Users/imorgado","sessionId":"39080ac9-1d46-4e6e-8a22-ffc01545de99","version":"2.0.76","gitBranch":"","agentId":"a0dd8cf","slug":"wild-fluttering-dusk","type":"user","message":{"role":"user","content":"Search for MCP (Model Context Protocol) servers that provide memory capabilities. Look for:\n\n1. Search grep MCP for:\n   - \"mcp-server-memory\" or \"@modelcontextprotocol/server-memory\"\n   - \"MemoryTool\" or \"memory_tool\"\n   - \"knowledgeBase\" MCP\n   - \"persistentMemory\" MCP\n\n2. Search the web for:\n   - \"MCP memory server\" implementations\n   - \"Claude memory MCP\" tools\n   - \"anthropic MCP memory\"\n\n3. Find existing MCP servers that provide:\n   - Key-value memory storage\n   - Semantic memory search\n   - Conversation persistence\n   - Knowledge graph storage\n\nReturn a list of available MCP memory servers with installation instructions."},"uuid":"93cd8db7-1f62-43a2-9977-c3a3ec116e0c","timestamp":"2026-01-12T08:05:04.411Z"}
{"parentUuid":"93cd8db7-1f62-43a2-9977-c3a3ec116e0c","isSidechain":true,"userType":"external","cwd":"/Users/imorgado","sessionId":"39080ac9-1d46-4e6e-8a22-ffc01545de99","version":"2.0.76","gitBranch":"","agentId":"a0dd8cf","slug":"wild-fluttering-dusk","message":{"model":"claude-opus-4-5-20251101","id":"msg_01CjTzoPZirHKMhqeBfxuTXK","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01F8YFfbpkoPiZ7omjQpQeQU","name":"mcp__grep__searchGitHub","input":{"query":"mcp-server-memory"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":17768,"cache_read_input_tokens":0,"cache_creation":{"ephemeral_5m_input_tokens":17768,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CX38wer1tn4cJ87FMfajk","type":"assistant","uuid":"c6efe60a-132b-47bd-8395-108be5d9e859","timestamp":"2026-01-12T08:05:09.119Z"}
{"parentUuid":"c6efe60a-132b-47bd-8395-108be5d9e859","isSidechain":true,"userType":"external","cwd":"/Users/imorgado","sessionId":"39080ac9-1d46-4e6e-8a22-ffc01545de99","version":"2.0.76","gitBranch":"","agentId":"a0dd8cf","slug":"wild-fluttering-dusk","message":{"model":"claude-opus-4-5-20251101","id":"msg_01CjTzoPZirHKMhqeBfxuTXK","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01GTPa1j77qJbgKiQVCfobih","name":"mcp__grep__searchGitHub","input":{"query":"@modelcontextprotocol/server-memory"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":17768,"cache_read_input_tokens":0,"cache_creation":{"ephemeral_5m_input_tokens":17768,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CX38wer1tn4cJ87FMfajk","type":"assistant","uuid":"b74ba597-03b0-4092-a81c-22a209f6f287","timestamp":"2026-01-12T08:05:09.520Z"}
{"parentUuid":"b74ba597-03b0-4092-a81c-22a209f6f287","isSidechain":true,"userType":"external","cwd":"/Users/imorgado","sessionId":"39080ac9-1d46-4e6e-8a22-ffc01545de99","version":"2.0.76","gitBranch":"","agentId":"a0dd8cf","slug":"wild-fluttering-dusk","message":{"model":"claude-opus-4-5-20251101","id":"msg_01CjTzoPZirHKMhqeBfxuTXK","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_018LaNH347meFUxiMTPhQ4P4","name":"mcp__grep__searchGitHub","input":{"query":"MemoryTool MCP"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":17768,"cache_read_input_tokens":0,"cache_creation":{"ephemeral_5m_input_tokens":17768,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CX38wer1tn4cJ87FMfajk","type":"assistant","uuid":"33d1b52b-660e-4e3f-a9ce-18a4ab05607e","timestamp":"2026-01-12T08:05:09.884Z"}
{"parentUuid":"33d1b52b-660e-4e3f-a9ce-18a4ab05607e","isSidechain":true,"userType":"external","cwd":"/Users/imorgado","sessionId":"39080ac9-1d46-4e6e-8a22-ffc01545de99","version":"2.0.76","gitBranch":"","agentId":"a0dd8cf","slug":"wild-fluttering-dusk","message":{"model":"claude-opus-4-5-20251101","id":"msg_01CjTzoPZirHKMhqeBfxuTXK","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01MVvqD1wdGnvTFX3ceugMzv","name":"mcp__grep__searchGitHub","input":{"query":"knowledgeBase MCP server"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":17768,"cache_read_input_tokens":0,"cache_creation":{"ephemeral_5m_input_tokens":17768,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CX38wer1tn4cJ87FMfajk","type":"assistant","uuid":"6fd3497e-2af4-4a7e-aaf0-5a50b9da7eb4","timestamp":"2026-01-12T08:05:10.247Z"}
{"parentUuid":"6fd3497e-2af4-4a7e-aaf0-5a50b9da7eb4","isSidechain":true,"userType":"external","cwd":"/Users/imorgado","sessionId":"39080ac9-1d46-4e6e-8a22-ffc01545de99","version":"2.0.76","gitBranch":"","agentId":"a0dd8cf","slug":"wild-fluttering-dusk","message":{"model":"claude-opus-4-5-20251101","id":"msg_01CjTzoPZirHKMhqeBfxuTXK","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01SRqKM2KnquH2BefbxyeTVk","name":"mcp__grep__searchGitHub","input":{"query":"persistentMemory MCP"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":17768,"cache_read_input_tokens":0,"cache_creation":{"ephemeral_5m_input_tokens":17768,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CX38wer1tn4cJ87FMfajk","type":"assistant","uuid":"f28a7697-092f-46ad-bfe3-0be6fa3e91a6","timestamp":"2026-01-12T08:05:10.551Z"}
{"parentUuid":"f28a7697-092f-46ad-bfe3-0be6fa3e91a6","isSidechain":true,"userType":"external","cwd":"/Users/imorgado","sessionId":"39080ac9-1d46-4e6e-8a22-ffc01545de99","version":"2.0.76","gitBranch":"","agentId":"a0dd8cf","slug":"wild-fluttering-dusk","message":{"model":"claude-opus-4-5-20251101","id":"msg_01CjTzoPZirHKMhqeBfxuTXK","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_0121cnijsQLsVuePvU7vp91x","name":"WebSearch","input":{"query":"MCP memory server Model Context Protocol implementations 2025"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":17768,"cache_read_input_tokens":0,"cache_creation":{"ephemeral_5m_input_tokens":17768,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CX38wer1tn4cJ87FMfajk","type":"assistant","uuid":"28e9d7ea-a887-4a9d-805b-09988e9c5f7d","timestamp":"2026-01-12T08:05:11.031Z"}
{"parentUuid":"28e9d7ea-a887-4a9d-805b-09988e9c5f7d","isSidechain":true,"userType":"external","cwd":"/Users/imorgado","sessionId":"39080ac9-1d46-4e6e-8a22-ffc01545de99","version":"2.0.76","gitBranch":"","agentId":"a0dd8cf","slug":"wild-fluttering-dusk","message":{"model":"claude-opus-4-5-20251101","id":"msg_01CjTzoPZirHKMhqeBfxuTXK","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01LXMqJkUaqXxYXqtCkqhG7p","name":"WebSearch","input":{"query":"Claude memory MCP tools anthropic 2025"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":17768,"cache_read_input_tokens":0,"cache_creation":{"ephemeral_5m_input_tokens":17768,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CX38wer1tn4cJ87FMfajk","type":"assistant","uuid":"64fc5a99-280d-486e-ac98-e252e61d2b9f","timestamp":"2026-01-12T08:05:11.457Z"}
{"parentUuid":"64fc5a99-280d-486e-ac98-e252e61d2b9f","isSidechain":true,"userType":"external","cwd":"/Users/imorgado","sessionId":"39080ac9-1d46-4e6e-8a22-ffc01545de99","version":"2.0.76","gitBranch":"","agentId":"a0dd8cf","slug":"wild-fluttering-dusk","message":{"model":"claude-opus-4-5-20251101","id":"msg_01CjTzoPZirHKMhqeBfxuTXK","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01A19ZE4VDThk6GrAX2QYc7q","name":"WebSearch","input":{"query":"MCP server knowledge graph semantic memory storage 2025"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":17768,"cache_read_input_tokens":0,"cache_creation":{"ephemeral_5m_input_tokens":17768,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CX38wer1tn4cJ87FMfajk","type":"assistant","uuid":"f95439b6-6e58-41a1-91c6-cb427911fbb6","timestamp":"2026-01-12T08:05:11.998Z"}
{"parentUuid":"f95439b6-6e58-41a1-91c6-cb427911fbb6","isSidechain":true,"userType":"external","cwd":"/Users/imorgado","sessionId":"39080ac9-1d46-4e6e-8a22-ffc01545de99","version":"2.0.76","gitBranch":"","agentId":"a0dd8cf","slug":"wild-fluttering-dusk","type":"user","message":{"role":"user","content":[{"type":"tool_result","content":"Unexpected token 'T', \"Too Many R\"... is not valid JSON","is_error":true,"tool_use_id":"toolu_01F8YFfbpkoPiZ7omjQpQeQU"}]},"uuid":"e2ef9db3-9b9b-4e71-9397-9ac6f9f79aef","timestamp":"2026-01-12T08:05:12.164Z","toolUseResult":"Error: Unexpected token 'T', \"Too Many R\"... is not valid JSON"}
{"parentUuid":"e2ef9db3-9b9b-4e71-9397-9ac6f9f79aef","isSidechain":true,"userType":"external","cwd":"/Users/imorgado","sessionId":"39080ac9-1d46-4e6e-8a22-ffc01545de99","version":"2.0.76","gitBranch":"","agentId":"a0dd8cf","slug":"wild-fluttering-dusk","type":"user","message":{"role":"user","content":[{"type":"tool_result","content":"Unexpected token 'T', \"Too Many R\"... is not valid JSON","is_error":true,"tool_use_id":"toolu_01GTPa1j77qJbgKiQVCfobih"}]},"uuid":"3813826b-4a1d-4168-ae2c-907dad626e4a","timestamp":"2026-01-12T08:05:12.347Z","toolUseResult":"Error: Unexpected token 'T', \"Too Many R\"... is not valid JSON"}
{"parentUuid":"3813826b-4a1d-4168-ae2c-907dad626e4a","isSidechain":true,"userType":"external","cwd":"/Users/imorgado","sessionId":"39080ac9-1d46-4e6e-8a22-ffc01545de99","version":"2.0.76","gitBranch":"","agentId":"a0dd8cf","slug":"wild-fluttering-dusk","type":"user","message":{"role":"user","content":[{"type":"tool_result","content":"Unexpected token 'T', \"Too Many R\"... is not valid JSON","is_error":true,"tool_use_id":"toolu_018LaNH347meFUxiMTPhQ4P4"}]},"uuid":"3eeff266-827e-47a9-9bc0-4df37b683e4b","timestamp":"2026-01-12T08:05:12.485Z","toolUseResult":"Error: Unexpected token 'T', \"Too Many R\"... is not valid JSON"}
{"parentUuid":"3eeff266-827e-47a9-9bc0-4df37b683e4b","isSidechain":true,"userType":"external","cwd":"/Users/imorgado","sessionId":"39080ac9-1d46-4e6e-8a22-ffc01545de99","version":"2.0.76","gitBranch":"","agentId":"a0dd8cf","slug":"wild-fluttering-dusk","type":"user","message":{"role":"user","content":[{"type":"tool_result","content":"Unexpected token 'T', \"Too Many R\"... is not valid JSON","is_error":true,"tool_use_id":"toolu_01MVvqD1wdGnvTFX3ceugMzv"}]},"uuid":"022483c5-7041-43ea-bc9a-f1cdc7c4df60","timestamp":"2026-01-12T08:05:12.642Z","toolUseResult":"Error: Unexpected token 'T', \"Too Many R\"... is not valid JSON"}
{"parentUuid":"022483c5-7041-43ea-bc9a-f1cdc7c4df60","isSidechain":true,"userType":"external","cwd":"/Users/imorgado","sessionId":"39080ac9-1d46-4e6e-8a22-ffc01545de99","version":"2.0.76","gitBranch":"","agentId":"a0dd8cf","slug":"wild-fluttering-dusk","type":"user","message":{"role":"user","content":[{"type":"tool_result","content":"Unexpected token 'T', \"Too Many R\"... is not valid JSON","is_error":true,"tool_use_id":"toolu_01SRqKM2KnquH2BefbxyeTVk"}]},"uuid":"8f06434e-7c4a-4574-b6b7-127d9643fbb6","timestamp":"2026-01-12T08:05:12.830Z","toolUseResult":"Error: Unexpected token 'T', \"Too Many R\"... is not valid JSON"}
{"parentUuid":"abb6a3eb-3042-4ced-84ae-7d209eaf6636","isSidechain":true,"userType":"external","cwd":"/Users/imorgado","sessionId":"39080ac9-1d46-4e6e-8a22-ffc01545de99","version":"2.0.76","gitBranch":"","agentId":"a0dd8cf","slug":"wild-fluttering-dusk","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_0121cnijsQLsVuePvU7vp91x","type":"tool_result","content":"Web search results for query: \"MCP memory server Model Context Protocol implementations 2025\"\n\nLinks: [{\"title\":\"One Year of MCP: November 2025 Spec Release | Model Context Protocol Blog\",\"url\":\"https://blog.modelcontextprotocol.io/posts/2025-11-25-first-mcp-anniversary/\"},{\"title\":\"Example Servers - Model Context Protocol\",\"url\":\"https://modelcontextprotocol.io/examples\"},{\"title\":\"Model Context Protocol - Wikipedia\",\"url\":\"https://en.wikipedia.org/wiki/Model_Context_Protocol\"},{\"title\":\"GitHub - modelcontextprotocol/servers: Model Context Protocol Servers\",\"url\":\"https://github.com/modelcontextprotocol/servers\"},{\"title\":\"@modelcontextprotocol/server-memory - npm\",\"url\":\"https://www.npmjs.com/package/@modelcontextprotocol/server-memory\"},{\"title\":\"Knowledge Graph Memory MCP server\",\"url\":\"https://github.com/modelcontextprotocol/servers/tree/main/src/memory\"},{\"title\":\"Update on the Next MCP Protocol Release – Model Context Protocol （MCP）\",\"url\":\"https://modelcontextprotocol.info/blog/mcp-next-version-update/\"},{\"title\":\"Model Context Protocol (MCP) Spec Updates from June 2025\",\"url\":\"https://auth0.com/blog/mcp-specs-update-all-about-auth/\"},{\"title\":\"Introducing the Model Context Protocol\",\"url\":\"https://www.anthropic.com/news/model-context-protocol\"},{\"title\":\"Model Context Protocol: Expanding LLM Capabilities\",\"url\":\"https://stvansolano.github.io/2025/03/16/AI-Agents-Model-Context-Protocol-Explained/\"}]\n\nHere's what I found about MCP memory server and Model Context Protocol implementations in 2025:\n\n## MCP Memory Server\n\nThe MCP Memory Server is a basic implementation of persistent memory using a local knowledge graph. This lets Claude remember information about the user across chats.(no content)Memory is described as a \"knowledge graph-based persistent memory system\" and is one of the official reference servers.\n\n### Key Features\nEntities are the primary nodes in the knowledge graph. Relations define directed connections between entities. They are always stored in active voice and describe how entities interact or relate to each other. Observations are discrete pieces of information about an entity.\n\n### Installation\nYou can start using @modelcontextprotocol/server-memory in your project by running `npm i @modelcontextprotocol/server-memory`. There are 12 other projects in the npm registry using this package.(no content)This MCP server is licensed under the MIT License, meaning you are free to use, modify, and distribute the software.\n\n## Model Context Protocol Overview (2025)\n\nThe Model Context Protocol (MCP) is an open standard and open-source framework introduced by Anthropic in November 2024 to standardize the way AI systems like large language models integrate and share data with external tools, systems, and data sources. MCP provides a universal interface for reading files, executing functions, and handling contextual prompts.\n\n### Major 2025 Developments\n\nIn March 2025, OpenAI officially adopted the MCP, after having integrated the standard across its products, including the ChatGPT desktop app.(no content)In December 2025, Anthropic donated the MCP to the Agentic AI Foundation (AAIF), a directed fund under the Linux Foundation, co-founded by Anthropic, Block and OpenAI.(no content)In September 2025, the MCP Registry preview was launched—an open catalog and API for indexing and discovery of MCP servers. The Registry serves as the single source of truth for available MCP servers.\n\n### November 2025 Spec Release\nThe latest spec supports server-side agent loops (servers can implement sophisticated multi-step reasoning), parallel tool calls (support for concurrent tool execution), and better context control.\n\n### Other Memory-Related Community Servers\n\nBasic Memory is a local-first knowledge management system that builds a semantic graph from Markdown files, enabling persistent memory across conversations with LLMs.(no content)cognee-mcp is a GraphRAG memory server with customizable ingestion, data processing and search.\n\n\nREMINDER: You MUST include the sources above in your response to the user using markdown hyperlinks."}]},"uuid":"08584e21-e668-4aa8-ac0a-147223949c02","timestamp":"2026-01-12T08:05:35.503Z","toolUseResult":{"query":"MCP memory server Model Context Protocol implementations 2025","results":[{"tool_use_id":"srvtoolu_01DkHYSXRg1FURxSLUFMzcoQ","content":[{"title":"One Year of MCP: November 2025 Spec Release | Model Context Protocol Blog","url":"https://blog.modelcontextprotocol.io/posts/2025-11-25-first-mcp-anniversary/"},{"title":"Example Servers - Model Context Protocol","url":"https://modelcontextprotocol.io/examples"},{"title":"Model Context Protocol - Wikipedia","url":"https://en.wikipedia.org/wiki/Model_Context_Protocol"},{"title":"GitHub - modelcontextprotocol/servers: Model Context Protocol Servers","url":"https://github.com/modelcontextprotocol/servers"},{"title":"@modelcontextprotocol/server-memory - npm","url":"https://www.npmjs.com/package/@modelcontextprotocol/server-memory"},{"title":"Knowledge Graph Memory MCP server","url":"https://github.com/modelcontextprotocol/servers/tree/main/src/memory"},{"title":"Update on the Next MCP Protocol Release – Model Context Protocol （MCP）","url":"https://modelcontextprotocol.info/blog/mcp-next-version-update/"},{"title":"Model Context Protocol (MCP) Spec Updates from June 2025","url":"https://auth0.com/blog/mcp-specs-update-all-about-auth/"},{"title":"Introducing the Model Context Protocol","url":"https://www.anthropic.com/news/model-context-protocol"},{"title":"Model Context Protocol: Expanding LLM Capabilities","url":"https://stvansolano.github.io/2025/03/16/AI-Agents-Model-Context-Protocol-Explained/"}]},"Here's what I found about MCP memory server and Model Context Protocol implementations in 2025:\n\n## MCP Memory Server\n\nThe MCP Memory Server is a basic implementation of persistent memory using a local knowledge graph. This lets Claude remember information about the user across chats.(no content)Memory is described as a \"knowledge graph-based persistent memory system\" and is one of the official reference servers.\n\n### Key Features\nEntities are the primary nodes in the knowledge graph. Relations define directed connections between entities. They are always stored in active voice and describe how entities interact or relate to each other. Observations are discrete pieces of information about an entity.\n\n### Installation\nYou can start using @modelcontextprotocol/server-memory in your project by running `npm i @modelcontextprotocol/server-memory`. There are 12 other projects in the npm registry using this package.(no content)This MCP server is licensed under the MIT License, meaning you are free to use, modify, and distribute the software.\n\n## Model Context Protocol Overview (2025)\n\nThe Model Context Protocol (MCP) is an open standard and open-source framework introduced by Anthropic in November 2024 to standardize the way AI systems like large language models integrate and share data with external tools, systems, and data sources. MCP provides a universal interface for reading files, executing functions, and handling contextual prompts.\n\n### Major 2025 Developments\n\nIn March 2025, OpenAI officially adopted the MCP, after having integrated the standard across its products, including the ChatGPT desktop app.(no content)In December 2025, Anthropic donated the MCP to the Agentic AI Foundation (AAIF), a directed fund under the Linux Foundation, co-founded by Anthropic, Block and OpenAI.(no content)In September 2025, the MCP Registry preview was launched—an open catalog and API for indexing and discovery of MCP servers. The Registry serves as the single source of truth for available MCP servers.\n\n### November 2025 Spec Release\nThe latest spec supports server-side agent loops (servers can implement sophisticated multi-step reasoning), parallel tool calls (support for concurrent tool execution), and better context control.\n\n### Other Memory-Related Community Servers\n\nBasic Memory is a local-first knowledge management system that builds a semantic graph from Markdown files, enabling persistent memory across conversations with LLMs.(no content)cognee-mcp is a GraphRAG memory server with customizable ingestion, data processing and search."],"durationSeconds":22.657727250000463}}
{"parentUuid":"08584e21-e668-4aa8-ac0a-147223949c02","isSidechain":true,"userType":"external","cwd":"/Users/imorgado","sessionId":"39080ac9-1d46-4e6e-8a22-ffc01545de99","version":"2.0.76","gitBranch":"","agentId":"a0dd8cf","slug":"wild-fluttering-dusk","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01LXMqJkUaqXxYXqtCkqhG7p","type":"tool_result","content":"Web search results for query: \"Claude memory MCP tools anthropic 2025\"\n\nLinks: [{\"title\":\"Connect Claude Code to tools via MCP - Claude Code Docs\",\"url\":\"https://docs.anthropic.com/en/docs/claude-code/mcp\"},{\"title\":\"Memory tool - Claude Docs\",\"url\":\"https://platform.claude.com/docs/en/agents-and-tools/tool-use/memory-tool\"},{\"title\":\"Anthropic\",\"url\":\"https://www.anthropic.com/engineering/code-execution-with-mcp\"},{\"title\":\"Anthropic Brings Automatic Memory to Claude Pro and Max Users - MacRumors\",\"url\":\"https://www.macrumors.com/2025/10/23/anthropic-automatic-memory-claude/\"},{\"title\":\"The Claude you’ll never need to remind: MCP in action\",\"url\":\"https://www.qed42.com/insights/the-claude-youll-never-need-to-remind-mcp-in-action\"},{\"title\":\"Fixing Claude Code's amnesia\",\"url\":\"https://blog.fsck.com/2025/10/23/episodic-memory/\"},{\"title\":\"Knowledge Graph Memory MCP Server by Anthropic | PulseMCP\",\"url\":\"https://www.pulsemcp.com/servers/modelcontextprotocol-knowledge-graph-memory\"},{\"title\":\"Memory tool - Claude Docs\",\"url\":\"https://docs.claude.com/en/docs/agents-and-tools/tool-use/memory-tool\"},{\"title\":\"Claude Memory Setup Guide | MCP Servers · LobeHub\",\"url\":\"https://lobehub.com/mcp/randall-gross-claude-memory-mcp\"},{\"title\":\"Exploring Anthropic’s Memory Tool – Leonie Monigatti\",\"url\":\"https://www.leoniemonigatti.com/blog/claude-memory-tool.html\"}]\n\nHere are the search results for \"Claude memory MCP tools anthropic 2025\":\n\n## Claude Memory and MCP Tools - Overview\n\n### Claude's Memory Tool API\n\nThe memory tool is currently in beta. To enable it, use the beta header `context-management-2025-06-27` in your API requests.(no content)The memory tool helps maintain project context across multiple agent executions and learn from past interactions, decisions, and feedback. When enabled, Claude automatically checks its memory directory before starting tasks. Claude can create, read, update, and delete files in the `/memories` directory to store what it learns while working, then reference those memories in future conversations to handle similar tasks more effectively or pick up where it left off.(no content)Since this is a client-side tool, Claude makes tool calls to perform memory operations, and your application executes those operations locally. This gives you complete control over where and how the memory is stored.\n\n### MCP (Model Context Protocol)\n\nThe Model Context Protocol (MCP) is an open standard for connecting AI agents to external systems. Connecting agents to tools and data traditionally requires a custom integration for each pairing, creating fragmentation and duplicated effort that makes it difficult to scale truly connected systems.(no content)MCP provides a universal protocol—developers implement MCP once in their agent and it unlocks an entire ecosystem of integrations. Since launching MCP in November 2024, adoption has been rapid: the community has built thousands of MCP servers, SDKs are available for all major programming languages, and the industry has adopted MCP as the de-facto standard for connecting agents to tools and data.\n\n### Claude Code MCP Integration\n\nClaude Code can connect to hundreds of external tools and data sources through the Model Context Protocol (MCP), an open source standard for AI-tool integrations. MCP servers give Claude Code access to your tools, databases, and APIs.(no content)Anthropic advises to use third party MCP servers at your own risk - Anthropic has not verified the correctness or security of all these servers. Make sure you trust MCP servers you are installing. Be especially careful when using MCP servers that could fetch untrusted content, as these can expose you to prompt injection risk.\n\n### Memory MCP Server\n\nThere is an official Anthropic memory server that implements the Model Context Protocol (MCP). It provides knowledge graph storage with entities and relations, observations for storing facts and notes, semantic search capabilities, and persistent storage across sessions. When you interact with Claude (Desktop or Code), the memory server runs via npx on-demand, connects to the local SQLite database at the specified path, and provides tools for creating and retrieving memories.\n\n### Consumer Memory Feature\n\nAnthropic updated the Claude chatbot with a memory feature. With memory enabled, Claude will be able to recall past conversations. Anthropic first added memory to Claude earlier this year, but with the initial implementation, Claude would only recall details when specifically asked.(no content)In August, Anthropic expanded the memory feature to allow Claude to automatically remember conversation details without a specific user request, and that functionality has been limited to Team and Enterprise subscribers. Claude's memory functionality is now expanding to all paid users, so Pro and Max subscribers can use the feature. Max users can turn it on now, while Pro subscribers will get access \"over the coming days.\" Memory is an opt-in feature that can be turned on in Claude's settings.\n\n\nREMINDER: You MUST include the sources above in your response to the user using markdown hyperlinks."}]},"uuid":"1e595b5c-4a04-44d5-a37a-13a6db4510bb","timestamp":"2026-01-12T08:05:36.153Z","toolUseResult":{"query":"Claude memory MCP tools anthropic 2025","results":[{"tool_use_id":"srvtoolu_01CiGrtEkzKqTdqbzuzQEnfG","content":[{"title":"Connect Claude Code to tools via MCP - Claude Code Docs","url":"https://docs.anthropic.com/en/docs/claude-code/mcp"},{"title":"Memory tool - Claude Docs","url":"https://platform.claude.com/docs/en/agents-and-tools/tool-use/memory-tool"},{"title":"Anthropic","url":"https://www.anthropic.com/engineering/code-execution-with-mcp"},{"title":"Anthropic Brings Automatic Memory to Claude Pro and Max Users - MacRumors","url":"https://www.macrumors.com/2025/10/23/anthropic-automatic-memory-claude/"},{"title":"The Claude you’ll never need to remind: MCP in action","url":"https://www.qed42.com/insights/the-claude-youll-never-need-to-remind-mcp-in-action"},{"title":"Fixing Claude Code's amnesia","url":"https://blog.fsck.com/2025/10/23/episodic-memory/"},{"title":"Knowledge Graph Memory MCP Server by Anthropic | PulseMCP","url":"https://www.pulsemcp.com/servers/modelcontextprotocol-knowledge-graph-memory"},{"title":"Memory tool - Claude Docs","url":"https://docs.claude.com/en/docs/agents-and-tools/tool-use/memory-tool"},{"title":"Claude Memory Setup Guide | MCP Servers · LobeHub","url":"https://lobehub.com/mcp/randall-gross-claude-memory-mcp"},{"title":"Exploring Anthropic’s Memory Tool – Leonie Monigatti","url":"https://www.leoniemonigatti.com/blog/claude-memory-tool.html"}]},"Here are the search results for \"Claude memory MCP tools anthropic 2025\":\n\n## Claude Memory and MCP Tools - Overview\n\n### Claude's Memory Tool API\n\nThe memory tool is currently in beta. To enable it, use the beta header `context-management-2025-06-27` in your API requests.(no content)The memory tool helps maintain project context across multiple agent executions and learn from past interactions, decisions, and feedback. When enabled, Claude automatically checks its memory directory before starting tasks. Claude can create, read, update, and delete files in the `/memories` directory to store what it learns while working, then reference those memories in future conversations to handle similar tasks more effectively or pick up where it left off.(no content)Since this is a client-side tool, Claude makes tool calls to perform memory operations, and your application executes those operations locally. This gives you complete control over where and how the memory is stored.\n\n### MCP (Model Context Protocol)\n\nThe Model Context Protocol (MCP) is an open standard for connecting AI agents to external systems. Connecting agents to tools and data traditionally requires a custom integration for each pairing, creating fragmentation and duplicated effort that makes it difficult to scale truly connected systems.(no content)MCP provides a universal protocol—developers implement MCP once in their agent and it unlocks an entire ecosystem of integrations. Since launching MCP in November 2024, adoption has been rapid: the community has built thousands of MCP servers, SDKs are available for all major programming languages, and the industry has adopted MCP as the de-facto standard for connecting agents to tools and data.\n\n### Claude Code MCP Integration\n\nClaude Code can connect to hundreds of external tools and data sources through the Model Context Protocol (MCP), an open source standard for AI-tool integrations. MCP servers give Claude Code access to your tools, databases, and APIs.(no content)Anthropic advises to use third party MCP servers at your own risk - Anthropic has not verified the correctness or security of all these servers. Make sure you trust MCP servers you are installing. Be especially careful when using MCP servers that could fetch untrusted content, as these can expose you to prompt injection risk.\n\n### Memory MCP Server\n\nThere is an official Anthropic memory server that implements the Model Context Protocol (MCP). It provides knowledge graph storage with entities and relations, observations for storing facts and notes, semantic search capabilities, and persistent storage across sessions. When you interact with Claude (Desktop or Code), the memory server runs via npx on-demand, connects to the local SQLite database at the specified path, and provides tools for creating and retrieving memories.\n\n### Consumer Memory Feature\n\nAnthropic updated the Claude chatbot with a memory feature. With memory enabled, Claude will be able to recall past conversations. Anthropic first added memory to Claude earlier this year, but with the initial implementation, Claude would only recall details when specifically asked.(no content)In August, Anthropic expanded the memory feature to allow Claude to automatically remember conversation details without a specific user request, and that functionality has been limited to Team and Enterprise subscribers. Claude's memory functionality is now expanding to all paid users, so Pro and Max subscribers can use the feature. Max users can turn it on now, while Pro subscribers will get access \"over the coming days.\" Memory is an opt-in feature that can be turned on in Claude's settings."],"durationSeconds":23.30230620800052}}
{"parentUuid":"1e595b5c-4a04-44d5-a37a-13a6db4510bb","isSidechain":true,"userType":"external","cwd":"/Users/imorgado","sessionId":"39080ac9-1d46-4e6e-8a22-ffc01545de99","version":"2.0.76","gitBranch":"","agentId":"a0dd8cf","slug":"wild-fluttering-dusk","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01A19ZE4VDThk6GrAX2QYc7q","type":"tool_result","content":"Web search results for query: \"MCP server knowledge graph semantic memory storage 2025\"\n\nLinks: [{\"title\":\"Knowledge Graph Memory MCP Server by Anthropic | PulseMCP\",\"url\":\"https://www.pulsemcp.com/servers/modelcontextprotocol-knowledge-graph-memory\"},{\"title\":\"GitHub - shaneholloman/mcp-knowledge-graph: MCP server enabling persistent memory for Claude through a local knowledge graph - fork focused on local development\",\"url\":\"https://github.com/shaneholloman/mcp-knowledge-graph\"},{\"title\":\"Knowledge Graph Memory Server - playbooks\",\"url\":\"https://playbooks.com/mcp/modelcontextprotocol-knowledge-graph-memory\"},{\"title\":\"GitHub - gannonh/memento-mcp: Memento MCP: A Knowledge Graph Memory System for LLMs\",\"url\":\"https://github.com/gannonh/memento-mcp\"},{\"title\":\"Model Context Protocol (MCP) Integrations for the Neo4j Graph Database - Developer Guides\",\"url\":\"https://neo4j.com/developer/genai-ecosystem/model-context-protocol-mcp/\"},{\"title\":\"Knowledge Graph Memory Server | MCP Servers · LobeHub\",\"url\":\"https://lobehub.com/mcp/flrngel-fuzzy-memory-mcp\"},{\"title\":\"Knowledge Graph Memory MCP Server by Evangelos Stavropoulos | PulseMCP\",\"url\":\"https://www.pulsemcp.com/servers/estav-knowledge-graph-memory\"},{\"title\":\"@modelcontextprotocol/server-memory - npm\",\"url\":\"https://www.npmjs.com/package/@modelcontextprotocol/server-memory\"},{\"title\":\"Knowledge Graph MCP Server by itseasy21 | PulseMCP\",\"url\":\"https://www.pulsemcp.com/servers/itseasy21-knowledge-graph\"},{\"title\":\"Knowledge Graph MCP Server - Zep | Zep\",\"url\":\"https://www.getzep.com/product/knowledge-graph-mcp/\"}]\n\nHere are the search results for \"MCP server knowledge graph semantic memory storage 2025\":\n\n## MCP Server Knowledge Graph & Semantic Memory Storage Options\n\n### Official Anthropic Implementation\n\nThe Knowledge Graph Memory Server provides a persistent memory layer for Claude by storing user information as a local knowledge graph of entities, observations, and their relationships. It helps the model remember details across chats and personalize interactions over time.(no content)You interact with the Memory Server through an MCP client, which connects to the server to read and update knowledge graph data. Use the server to create entities for recurring people, organizations, or events; define relationships between those entities; and attach atomic observations to entities. As you converse, add new observations (for example, a preferred meeting time or a location) and let the server keep them organized.\n\n### Memento MCP (Neo4j-based)\n\nMemento MCP is a scalable, high performance knowledge graph memory system with semantic retrieval, contextual recall, and temporal awareness. It provides any LLM client that supports the Model Context Protocol (e.g., Claude Desktop, Cursor, Github Copilot) with persistent memory capabilities.(no content)It uses Neo4j as its storage backend, providing a unified solution for both graph storage and vector search capabilities. Features include unified storage that consolidates both graph and vector storage into a single database, and native graph operations built specifically for graph traversal and queries.\n\n### Neo4j MCP Integrations\n\nMCP came with an example knowledge graph implementation for storing memories, which was upgraded to use Neo4j as a real graph database. The mcp-neo4j-memory Server stores and updates entities with observations and relationships between them in Neo4j and can search and retrieve subgraphs of relevance. It also works for long conversations or plans that turn into more comprehensive knowledge graphs.(no content)The MCP protocol saw a lot of adoption since the beginning of 2025 with thousands of servers for all kinds of APIs having been built by the community.\n\n### Zep's Graphiti MCP Server\n\nZep's Graphiti MCP server gives Claude Desktop, Raycast, note-taking apps, and other MCP clients powerful temporal knowledge graphs that persist across sessions. Powered by Graphiti, Zep's open source temporal graph framework, AI assistants remember context, track relationships, and understand how information evolves over time—all running locally.(no content)It can find relevant information through semantic similarity, keyword matching, and graph traversal, helping assistants locate exactly the right context for each interaction.\n\n### Fuzzy Memory MCP\n\nThe fuzzy-memory-mcp is an MCP server for enabling memory for Claude through a knowledge graph enhanced with fuzzy semantic searching using fuse.js. It's a basic implementation of persistent memory using a local knowledge graph that lets Claude remember information about the user across chats. This version has been enhanced with fuse.js to provide fuzzy, semantic searching capabilities.\n\n### Other Storage Options\n\nVarious implementations support different storage backends:\n- Redis Graph for long-term memory storage for LLM conversations, enabling persistent knowledge graphs\n- SQLite and vector embeddings for long-term memory storage, enabling persistent context across conversations\n- PostgreSQL and pgvector for persistent memory storage with semantic search capabilities\n\n\nREMINDER: You MUST include the sources above in your response to the user using markdown hyperlinks."}]},"uuid":"df893f40-cf84-4619-9de8-730d07166f6f","timestamp":"2026-01-12T08:05:38.436Z","toolUseResult":{"query":"MCP server knowledge graph semantic memory storage 2025","results":[{"tool_use_id":"srvtoolu_018nmfRzUij2ESYgERzufwsX","content":[{"title":"Knowledge Graph Memory MCP Server by Anthropic | PulseMCP","url":"https://www.pulsemcp.com/servers/modelcontextprotocol-knowledge-graph-memory"},{"title":"GitHub - shaneholloman/mcp-knowledge-graph: MCP server enabling persistent memory for Claude through a local knowledge graph - fork focused on local development","url":"https://github.com/shaneholloman/mcp-knowledge-graph"},{"title":"Knowledge Graph Memory Server - playbooks","url":"https://playbooks.com/mcp/modelcontextprotocol-knowledge-graph-memory"},{"title":"GitHub - gannonh/memento-mcp: Memento MCP: A Knowledge Graph Memory System for LLMs","url":"https://github.com/gannonh/memento-mcp"},{"title":"Model Context Protocol (MCP) Integrations for the Neo4j Graph Database - Developer Guides","url":"https://neo4j.com/developer/genai-ecosystem/model-context-protocol-mcp/"},{"title":"Knowledge Graph Memory Server | MCP Servers · LobeHub","url":"https://lobehub.com/mcp/flrngel-fuzzy-memory-mcp"},{"title":"Knowledge Graph Memory MCP Server by Evangelos Stavropoulos | PulseMCP","url":"https://www.pulsemcp.com/servers/estav-knowledge-graph-memory"},{"title":"@modelcontextprotocol/server-memory - npm","url":"https://www.npmjs.com/package/@modelcontextprotocol/server-memory"},{"title":"Knowledge Graph MCP Server by itseasy21 | PulseMCP","url":"https://www.pulsemcp.com/servers/itseasy21-knowledge-graph"},{"title":"Knowledge Graph MCP Server - Zep | Zep","url":"https://www.getzep.com/product/knowledge-graph-mcp/"}]},"Here are the search results for \"MCP server knowledge graph semantic memory storage 2025\":\n\n## MCP Server Knowledge Graph & Semantic Memory Storage Options\n\n### Official Anthropic Implementation\n\nThe Knowledge Graph Memory Server provides a persistent memory layer for Claude by storing user information as a local knowledge graph of entities, observations, and their relationships. It helps the model remember details across chats and personalize interactions over time.(no content)You interact with the Memory Server through an MCP client, which connects to the server to read and update knowledge graph data. Use the server to create entities for recurring people, organizations, or events; define relationships between those entities; and attach atomic observations to entities. As you converse, add new observations (for example, a preferred meeting time or a location) and let the server keep them organized.\n\n### Memento MCP (Neo4j-based)\n\nMemento MCP is a scalable, high performance knowledge graph memory system with semantic retrieval, contextual recall, and temporal awareness. It provides any LLM client that supports the Model Context Protocol (e.g., Claude Desktop, Cursor, Github Copilot) with persistent memory capabilities.(no content)It uses Neo4j as its storage backend, providing a unified solution for both graph storage and vector search capabilities. Features include unified storage that consolidates both graph and vector storage into a single database, and native graph operations built specifically for graph traversal and queries.\n\n### Neo4j MCP Integrations\n\nMCP came with an example knowledge graph implementation for storing memories, which was upgraded to use Neo4j as a real graph database. The mcp-neo4j-memory Server stores and updates entities with observations and relationships between them in Neo4j and can search and retrieve subgraphs of relevance. It also works for long conversations or plans that turn into more comprehensive knowledge graphs.(no content)The MCP protocol saw a lot of adoption since the beginning of 2025 with thousands of servers for all kinds of APIs having been built by the community.\n\n### Zep's Graphiti MCP Server\n\nZep's Graphiti MCP server gives Claude Desktop, Raycast, note-taking apps, and other MCP clients powerful temporal knowledge graphs that persist across sessions. Powered by Graphiti, Zep's open source temporal graph framework, AI assistants remember context, track relationships, and understand how information evolves over time—all running locally.(no content)It can find relevant information through semantic similarity, keyword matching, and graph traversal, helping assistants locate exactly the right context for each interaction.\n\n### Fuzzy Memory MCP\n\nThe fuzzy-memory-mcp is an MCP server for enabling memory for Claude through a knowledge graph enhanced with fuzzy semantic searching using fuse.js. It's a basic implementation of persistent memory using a local knowledge graph that lets Claude remember information about the user across chats. This version has been enhanced with fuse.js to provide fuzzy, semantic searching capabilities.\n\n### Other Storage Options\n\nVarious implementations support different storage backends:\n- Redis Graph for long-term memory storage for LLM conversations, enabling persistent knowledge graphs\n- SQLite and vector embeddings for long-term memory storage, enabling persistent context across conversations\n- PostgreSQL and pgvector for persistent memory storage with semantic search capabilities"],"durationSeconds":25.58558458299935}}
{"parentUuid":"df893f40-cf84-4619-9de8-730d07166f6f","isSidechain":true,"userType":"external","cwd":"/Users/imorgado","sessionId":"39080ac9-1d46-4e6e-8a22-ffc01545de99","version":"2.0.76","gitBranch":"","agentId":"a0dd8cf","slug":"wild-fluttering-dusk","message":{"model":"claude-opus-4-5-20251101","id":"msg_016DgTgTUG5HtwpwGjRbgSme","type":"message","role":"assistant","content":[{"type":"text","text":"Let me search for more specific implementations and installation details."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":0,"cache_creation_input_tokens":4220,"cache_read_input_tokens":17768,"cache_creation":{"ephemeral_5m_input_tokens":4220,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CX38z9XERVZy5KUnB1qyE","type":"assistant","uuid":"f7875ad9-e5fe-4595-9475-29e543662397","timestamp":"2026-01-12T08:05:42.133Z"}
{"parentUuid":"f7875ad9-e5fe-4595-9475-29e543662397","isSidechain":true,"userType":"external","cwd":"/Users/imorgado","sessionId":"39080ac9-1d46-4e6e-8a22-ffc01545de99","version":"2.0.76","gitBranch":"","agentId":"a0dd8cf","slug":"wild-fluttering-dusk","message":{"model":"claude-opus-4-5-20251101","id":"msg_016DgTgTUG5HtwpwGjRbgSme","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01UMpAWEWZ8AD6FwL8Dpz6dx","name":"WebSearch","input":{"query":"\"@modelcontextprotocol/server-memory\" npm installation setup 2025"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":0,"cache_creation_input_tokens":4220,"cache_read_input_tokens":17768,"cache_creation":{"ephemeral_5m_input_tokens":4220,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CX38z9XERVZy5KUnB1qyE","type":"assistant","uuid":"db5ca27b-5b01-4dd5-9a2c-470a1905d004","timestamp":"2026-01-12T08:05:42.651Z"}
{"parentUuid":"db5ca27b-5b01-4dd5-9a2c-470a1905d004","isSidechain":true,"userType":"external","cwd":"/Users/imorgado","sessionId":"39080ac9-1d46-4e6e-8a22-ffc01545de99","version":"2.0.76","gitBranch":"","agentId":"a0dd8cf","slug":"wild-fluttering-dusk","message":{"model":"claude-opus-4-5-20251101","id":"msg_016DgTgTUG5HtwpwGjRbgSme","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01LAEufj5P8qFEkusWDfbrpg","name":"WebSearch","input":{"query":"mem0 MCP server memory 2025"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":0,"cache_creation_input_tokens":4220,"cache_read_input_tokens":17768,"cache_creation":{"ephemeral_5m_input_tokens":4220,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CX38z9XERVZy5KUnB1qyE","type":"assistant","uuid":"904e9913-05de-405a-a8d6-cbd28d357632","timestamp":"2026-01-12T08:05:43.171Z"}
{"parentUuid":"904e9913-05de-405a-a8d6-cbd28d357632","isSidechain":true,"userType":"external","cwd":"/Users/imorgado","sessionId":"39080ac9-1d46-4e6e-8a22-ffc01545de99","version":"2.0.76","gitBranch":"","agentId":"a0dd8cf","slug":"wild-fluttering-dusk","message":{"model":"claude-opus-4-5-20251101","id":"msg_016DgTgTUG5HtwpwGjRbgSme","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01ETGeBUpQkyTaQZcXTEyh4G","name":"WebSearch","input":{"query":"basic-memory MCP server markdown semantic graph 2025"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":0,"cache_creation_input_tokens":4220,"cache_read_input_tokens":17768,"cache_creation":{"ephemeral_5m_input_tokens":4220,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CX38z9XERVZy5KUnB1qyE","type":"assistant","uuid":"dda08c8e-0d33-48c2-8a0d-86c763412252","timestamp":"2026-01-12T08:05:43.858Z"}
{"parentUuid":"dc5eddc5-52d1-41da-860c-13905a8bc818","isSidechain":true,"userType":"external","cwd":"/Users/imorgado","sessionId":"39080ac9-1d46-4e6e-8a22-ffc01545de99","version":"2.0.76","gitBranch":"","agentId":"a0dd8cf","slug":"wild-fluttering-dusk","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01ETGeBUpQkyTaQZcXTEyh4G","type":"tool_result","content":"Web search results for query: \"basic-memory MCP server markdown semantic graph 2025\"\n\nLinks: [{\"title\":\"Official Basic Memory MCP Server | PulseMCP\",\"url\":\"https://www.pulsemcp.com/servers/basicmachines-memory\"},{\"title\":\"Basic Memory MCP Server\",\"url\":\"https://mcp.so/server/basic-memory/basicmachines-co\"},{\"title\":\"Basic Memory - MCP Server\",\"url\":\"https://www.magicslides.app/mcps/basicmachines-memory\"},{\"title\":\"Basic Memory MCP Server - playbooks\",\"url\":\"https://playbooks.com/mcp/basicmachines-memory\"},{\"title\":\"Basic Memory MCP Server by Basic Machines | AI Toolhouse\",\"url\":\"https://www.aitoolhouse.com/mcp-servers/basicmachines-memory\"},{\"title\":\"Knowledge Graph Memory MCP Server by Anthropic | PulseMCP\",\"url\":\"https://www.pulsemcp.com/servers/modelcontextprotocol-knowledge-graph-memory\"},{\"title\":\"GitHub - mcp-research/basicmachines-co__basic-memory: Basic Memory is a knowledge management system that allows you to build a persistent semantic graph from conversations with AI assistants, stored in standard Markdown files on your computer. Integrates directly with Obsidan.md\",\"url\":\"https://github.com/mcp-research/basicmachines-co__basic-memory\"},{\"title\":\"basic-memory | Glama\",\"url\":\"https://glama.ai/mcp/servers/@basicmachines-co/basic-memory/blob/9b7bbc7116ca0f662e3d3f7dfe04d1a41dfbb6d2/.claude/commands/release/changelog.md\"},{\"title\":\"mcp/basic-memory - Docker Image\",\"url\":\"https://hub.docker.com/r/mcp/basic-memory\"},{\"title\":\"MCP Server: Basic-Memory - An Essential Guide for AI Engineers\",\"url\":\"https://skywork.ai/skypage/en/MCP-Server-Basic-Memory-An-Essential-Guide-for-AI-Engineers/1971049929135681536\"}]\n\nBased on my search, here's what I found about Basic Memory MCP Server:\n\n## Basic Memory MCP Server\n\nBasic Memory is a knowledge management system that allows you to build a persistent semantic graph from conversations with AI assistants. All knowledge is stored in standard Markdown files on your computer, giving you full control and ownership of your data.\n\n### Key Features\n\nBasic Memory lets you build persistent knowledge through natural conversations with Large Language Models (LLMs) like Claude, while keeping everything in simple Markdown files on your computer. It uses the Model Context Protocol (MCP) to enable any compatible LLM to read and write to your local knowledge base.\n\n### The Problem It Solves\n\nMost LLM interactions are ephemeral - you ask a question, get an answer, and everything is forgotten. Each conversation starts fresh, without the context or knowledge from previous ones. Current workarounds have limitations: Chat histories capture conversations but aren't structured knowledge; RAG systems can query documents but don't let LLMs write back; Vector databases require complex setups and often live in the cloud; Knowledge graphs typically need specialized tools to maintain. Basic Memory addresses these problems with a simple approach: structured Markdown files that both humans and LLMs can read and write to.\n\n### Architecture\n\nThe system uses familiar Markdown with semantic patterns, creates a traversable knowledge graph where LLMs can follow links between topics, works with existing editors like Obsidian, and uses lightweight infrastructure with just local files indexed in a local SQLite database.(no content)Basic Memory integrates directly with Obsidian.md.\n\n### Comparative Analysis\n\nCompared to other memory solutions like OpenMemory (Mem0), Vector DB MCPs (Qdrant, etc.), and LangChain Memory, Basic-Memory uses local Markdown files as primary storage and an explicit semantic graph via Markdown links as its core mechanism, providing high human readability.\n\n### Installation & Configuration\n\nYou can use Smithery to automatically configure Basic Memory for Claude Desktop, which installs and configures Basic Memory without requiring manual edits to the Claude Desktop configuration file. The Smithery server hosts the MCP server component, while your data remains stored locally as Markdown files.(no content)Basic Memory stores your knowledge as Markdown files and indexes them with a local search database. You can enable realtime synchronization with the command `basic-memory sync --watch` and access shared notes under your project directory (default location is ~/basic-memory).(no content)The server was released on March 15, 2025 and has over 64,400 downloads.\n\n\nREMINDER: You MUST include the sources above in your response to the user using markdown hyperlinks."}]},"uuid":"36600b43-e0c4-450e-9885-3c64bac8669f","timestamp":"2026-01-12T08:05:59.171Z","toolUseResult":{"query":"basic-memory MCP server markdown semantic graph 2025","results":[{"tool_use_id":"srvtoolu_018fBN9f2tzUh2C3kVc945vB","content":[{"title":"Official Basic Memory MCP Server | PulseMCP","url":"https://www.pulsemcp.com/servers/basicmachines-memory"},{"title":"Basic Memory MCP Server","url":"https://mcp.so/server/basic-memory/basicmachines-co"},{"title":"Basic Memory - MCP Server","url":"https://www.magicslides.app/mcps/basicmachines-memory"},{"title":"Basic Memory MCP Server - playbooks","url":"https://playbooks.com/mcp/basicmachines-memory"},{"title":"Basic Memory MCP Server by Basic Machines | AI Toolhouse","url":"https://www.aitoolhouse.com/mcp-servers/basicmachines-memory"},{"title":"Knowledge Graph Memory MCP Server by Anthropic | PulseMCP","url":"https://www.pulsemcp.com/servers/modelcontextprotocol-knowledge-graph-memory"},{"title":"GitHub - mcp-research/basicmachines-co__basic-memory: Basic Memory is a knowledge management system that allows you to build a persistent semantic graph from conversations with AI assistants, stored in standard Markdown files on your computer. Integrates directly with Obsidan.md","url":"https://github.com/mcp-research/basicmachines-co__basic-memory"},{"title":"basic-memory | Glama","url":"https://glama.ai/mcp/servers/@basicmachines-co/basic-memory/blob/9b7bbc7116ca0f662e3d3f7dfe04d1a41dfbb6d2/.claude/commands/release/changelog.md"},{"title":"mcp/basic-memory - Docker Image","url":"https://hub.docker.com/r/mcp/basic-memory"},{"title":"MCP Server: Basic-Memory - An Essential Guide for AI Engineers","url":"https://skywork.ai/skypage/en/MCP-Server-Basic-Memory-An-Essential-Guide-for-AI-Engineers/1971049929135681536"}]},"Based on my search, here's what I found about Basic Memory MCP Server:\n\n## Basic Memory MCP Server\n\nBasic Memory is a knowledge management system that allows you to build a persistent semantic graph from conversations with AI assistants. All knowledge is stored in standard Markdown files on your computer, giving you full control and ownership of your data.\n\n### Key Features\n\nBasic Memory lets you build persistent knowledge through natural conversations with Large Language Models (LLMs) like Claude, while keeping everything in simple Markdown files on your computer. It uses the Model Context Protocol (MCP) to enable any compatible LLM to read and write to your local knowledge base.\n\n### The Problem It Solves\n\nMost LLM interactions are ephemeral - you ask a question, get an answer, and everything is forgotten. Each conversation starts fresh, without the context or knowledge from previous ones. Current workarounds have limitations: Chat histories capture conversations but aren't structured knowledge; RAG systems can query documents but don't let LLMs write back; Vector databases require complex setups and often live in the cloud; Knowledge graphs typically need specialized tools to maintain. Basic Memory addresses these problems with a simple approach: structured Markdown files that both humans and LLMs can read and write to.\n\n### Architecture\n\nThe system uses familiar Markdown with semantic patterns, creates a traversable knowledge graph where LLMs can follow links between topics, works with existing editors like Obsidian, and uses lightweight infrastructure with just local files indexed in a local SQLite database.(no content)Basic Memory integrates directly with Obsidian.md.\n\n### Comparative Analysis\n\nCompared to other memory solutions like OpenMemory (Mem0), Vector DB MCPs (Qdrant, etc.), and LangChain Memory, Basic-Memory uses local Markdown files as primary storage and an explicit semantic graph via Markdown links as its core mechanism, providing high human readability.\n\n### Installation & Configuration\n\nYou can use Smithery to automatically configure Basic Memory for Claude Desktop, which installs and configures Basic Memory without requiring manual edits to the Claude Desktop configuration file. The Smithery server hosts the MCP server component, while your data remains stored locally as Markdown files.(no content)Basic Memory stores your knowledge as Markdown files and indexes them with a local search database. You can enable realtime synchronization with the command `basic-memory sync --watch` and access shared notes under your project directory (default location is ~/basic-memory).(no content)The server was released on March 15, 2025 and has over 64,400 downloads."],"durationSeconds":15.290738250000402}}
{"parentUuid":"36600b43-e0c4-450e-9885-3c64bac8669f","isSidechain":true,"userType":"external","cwd":"/Users/imorgado","sessionId":"39080ac9-1d46-4e6e-8a22-ffc01545de99","version":"2.0.76","gitBranch":"","agentId":"a0dd8cf","slug":"wild-fluttering-dusk","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01UMpAWEWZ8AD6FwL8Dpz6dx","type":"tool_result","content":"Web search results for query: \"\"@modelcontextprotocol/server-memory\" npm installation setup 2025\"\n\nLinks: [{\"title\":\"@modelcontextprotocol/server-memory - npm\",\"url\":\"https://www.npmjs.com/package/@modelcontextprotocol/server-memory\"},{\"title\":\"@modelcontextprotocol/sdk - npm\",\"url\":\"https://www.npmjs.com/package/@modelcontextprotocol/sdk\"},{\"title\":\"Knowledge Graph Memory MCP server\",\"url\":\"https://github.com/modelcontextprotocol/servers/tree/main/src/memory\"},{\"title\":\"@modelcontextprotocol/server-everything - npm\",\"url\":\"https://www.npmjs.com/package/@modelcontextprotocol/server-everything\"},{\"title\":\"@modelcontextprotocol/server-memory - npm Package Security A...\",\"url\":\"https://socket.dev/npm/package/@modelcontextprotocol/server-memory\"},{\"title\":\"Memory MCP Server | MCP Servers · LobeHub\",\"url\":\"https://lobehub.com/mcp/cbuntingde-memory-server\"},{\"title\":\"MCP-Windows · GitHub\",\"url\":\"https://gist.github.com/feveromo/7a340d7795fca1ccd535a5802b976e1f?permalink_comment_id=5311983\"},{\"title\":\"Creating a Model Context Protocol Server: A Step-by-Step Guide | by Michael Bauer-Wapp | Medium\",\"url\":\"https://michaelwapp.medium.com/creating-a-model-context-protocol-server-a-step-by-step-guide-4c853fbf5ff2\"},{\"title\":\"@modelcontextprotocol/server-github - npm\",\"url\":\"https://www.npmjs.com/package/@modelcontextprotocol/server-github\"},{\"title\":\"@modelcontextprotocol/server-filesystem - npm\",\"url\":\"https://www.npmjs.com/package/@modelcontextprotocol/server-filesystem\"}]\n\nHere's the information about installing and setting up `@modelcontextprotocol/server-memory` from npm:\n\n## Installation\n\nYou can install the package using npm: `npm i @modelcontextprotocol/server-memory`(no content)Alternatively, you can install it globally: `npm install -g @modelcontextprotocol/server-memory`\n\n## Configuration Setup\n\n### For Claude Desktop / MCP Clients\n\nAdd this configuration to your MCP settings:\n```json\n{\n  \"mcpServers\": {\n    \"memory\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@modelcontextprotocol/server-memory\"\n      ],\n      \"env\": {\n        \"MEMORY_FILE_PATH\": \"/path/to/custom/memory.jsonl\"\n      }\n    }\n  }\n}\n```\nThe `MEMORY_FILE_PATH` environment variable sets the path to the memory storage JSONL file (default: memory.jsonl in the server directory).\n\n### For VS Code\n\nOpen the Command Palette (Ctrl + Shift + P) and run MCP: Open User Configuration. This will open your user mcp.json file where you can add the server configuration.(no content)Alternatively, you can add the configuration to a file called `.vscode/mcp.json` in your workspace. This will allow you to share the configuration with others.\n\n### Docker Configuration\n\nYou can also run it via Docker:\n```json\n{\n  \"servers\": {\n    \"memory\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"-v\",\n        \"claude-memory:/app/dist\",\n        \"--rm\",\n        \"mcp/memory\"\n      ]\n    }\n  }\n}\n```\n\n## Important Note for Docker Users\n\nIf you are using a Docker volume for storage, be aware that a prior mcp/memory volume contains an index.js file that could be overwritten by the new container. Delete the old Docker volume's index.js file before starting the new container.\n\n## Package Details\n\nThis is an MCP server for enabling memory for Claude through a knowledge graph.(no content)The package demonstrates a healthy version release cadence and project activity. It has 3 open source maintainers collaborating on the project.\n\n\nREMINDER: You MUST include the sources above in your response to the user using markdown hyperlinks."}]},"uuid":"34d5f76c-f45f-4785-bbf8-f93a731d22cc","timestamp":"2026-01-12T08:06:00.604Z","toolUseResult":{"query":"\"@modelcontextprotocol/server-memory\" npm installation setup 2025","results":[{"tool_use_id":"srvtoolu_014S1VigCR6qVQQUDqQN4nW6","content":[{"title":"@modelcontextprotocol/server-memory - npm","url":"https://www.npmjs.com/package/@modelcontextprotocol/server-memory"},{"title":"@modelcontextprotocol/sdk - npm","url":"https://www.npmjs.com/package/@modelcontextprotocol/sdk"},{"title":"Knowledge Graph Memory MCP server","url":"https://github.com/modelcontextprotocol/servers/tree/main/src/memory"},{"title":"@modelcontextprotocol/server-everything - npm","url":"https://www.npmjs.com/package/@modelcontextprotocol/server-everything"},{"title":"@modelcontextprotocol/server-memory - npm Package Security A...","url":"https://socket.dev/npm/package/@modelcontextprotocol/server-memory"},{"title":"Memory MCP Server | MCP Servers · LobeHub","url":"https://lobehub.com/mcp/cbuntingde-memory-server"},{"title":"MCP-Windows · GitHub","url":"https://gist.github.com/feveromo/7a340d7795fca1ccd535a5802b976e1f?permalink_comment_id=5311983"},{"title":"Creating a Model Context Protocol Server: A Step-by-Step Guide | by Michael Bauer-Wapp | Medium","url":"https://michaelwapp.medium.com/creating-a-model-context-protocol-server-a-step-by-step-guide-4c853fbf5ff2"},{"title":"@modelcontextprotocol/server-github - npm","url":"https://www.npmjs.com/package/@modelcontextprotocol/server-github"},{"title":"@modelcontextprotocol/server-filesystem - npm","url":"https://www.npmjs.com/package/@modelcontextprotocol/server-filesystem"}]},"Here's the information about installing and setting up `@modelcontextprotocol/server-memory` from npm:\n\n## Installation\n\nYou can install the package using npm: `npm i @modelcontextprotocol/server-memory`(no content)Alternatively, you can install it globally: `npm install -g @modelcontextprotocol/server-memory`\n\n## Configuration Setup\n\n### For Claude Desktop / MCP Clients\n\nAdd this configuration to your MCP settings:\n```json\n{\n  \"mcpServers\": {\n    \"memory\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@modelcontextprotocol/server-memory\"\n      ],\n      \"env\": {\n        \"MEMORY_FILE_PATH\": \"/path/to/custom/memory.jsonl\"\n      }\n    }\n  }\n}\n```\nThe `MEMORY_FILE_PATH` environment variable sets the path to the memory storage JSONL file (default: memory.jsonl in the server directory).\n\n### For VS Code\n\nOpen the Command Palette (Ctrl + Shift + P) and run MCP: Open User Configuration. This will open your user mcp.json file where you can add the server configuration.(no content)Alternatively, you can add the configuration to a file called `.vscode/mcp.json` in your workspace. This will allow you to share the configuration with others.\n\n### Docker Configuration\n\nYou can also run it via Docker:\n```json\n{\n  \"servers\": {\n    \"memory\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"-v\",\n        \"claude-memory:/app/dist\",\n        \"--rm\",\n        \"mcp/memory\"\n      ]\n    }\n  }\n}\n```\n\n## Important Note for Docker Users\n\nIf you are using a Docker volume for storage, be aware that a prior mcp/memory volume contains an index.js file that could be overwritten by the new container. Delete the old Docker volume's index.js file before starting the new container.\n\n## Package Details\n\nThis is an MCP server for enabling memory for Claude through a knowledge graph.(no content)The package demonstrates a healthy version release cadence and project activity. It has 3 open source maintainers collaborating on the project."],"durationSeconds":16.72365016700048}}
{"parentUuid":"34d5f76c-f45f-4785-bbf8-f93a731d22cc","isSidechain":true,"userType":"external","cwd":"/Users/imorgado","sessionId":"39080ac9-1d46-4e6e-8a22-ffc01545de99","version":"2.0.76","gitBranch":"","agentId":"a0dd8cf","slug":"wild-fluttering-dusk","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01LAEufj5P8qFEkusWDfbrpg","type":"tool_result","content":"Web search results for query: \"mem0 MCP server memory 2025\"\n\nLinks: [{\"title\":\"GitHub - mem0ai/mem0-mcp\",\"url\":\"https://github.com/mem0ai/mem0-mcp\"},{\"title\":\"AI Memory OpenMemory MCP for Claude Desktop | Mem0\",\"url\":\"https://mem0.ai/blog/introducing-openmemory-mcp\"},{\"title\":\"AI Memory MCP Server for Coding Agents | Mem0\",\"url\":\"https://mem0.ai/openmemory\"},{\"title\":\"A Comprehensive Guide to the Mem0 MCP Server: Building AI with Persistent Memory\",\"url\":\"https://skywork.ai/skypage/en/A Comprehensive Guide to the Mem0 MCP Server: Building AI with Persistent Memory/1971044006807793664\"},{\"title\":\"Mem0 Memory Server | MCP Server | Smithery\",\"url\":\"https://smithery.ai/server/@big-omega/mem0-mcp\"},{\"title\":\"GitHub - coleam00/mcp-mem0: MCP server for long term agent memory with Mem0. Also useful as a template to get you started building your own MCP server with Python!\",\"url\":\"https://github.com/coleam00/mcp-mem0\"},{\"title\":\"Official Mem0 MCP Server | PulseMCP\",\"url\":\"https://www.pulsemcp.com/servers/mem0-coding-preferences\"},{\"title\":\"MCP-Mem0: Your Gateway to Long-Term Agent Memory 🚀 MCP Server\",\"url\":\"https://mcp.so/server/mcp-mem0/yellnuts\"},{\"title\":\"Local Mem0 MCP Server\",\"url\":\"https://lobehub.com/mcp/synapse-os-local-mem0-mcp\"},{\"title\":\"Mem0 MCP Server | MCP Servers · LobeHub\",\"url\":\"https://lobehub.com/mcp/mem0-ai-mem0-mcp-server\"}]\n\nHere are the search results for \"mem0 MCP server memory 2025\":\n\n## Mem0 MCP Server Overview\n\nThe mem0-mcp-server wraps the official Mem0 Memory API as a Model Context Protocol (MCP) server so any MCP-compatible client (Claude Desktop, Cursor, custom agents) can add, search, update, and delete long-term memories.\n\n### Key Products\n\n**1. Mem0 MCP Server (Official)**\nThis is a Model Context Protocol server that exposes the Mem0 long-term memory API as tools. It requires a MEM0_API_KEY environment variable for API access.(no content)You can run this server in three modes: Local Stdio (recommended for Claude Desktop, Cursor, or local development with no server port management needed), Smithery (for deploying as a hosted HTTP endpoint), and Docker (for containerized deployments where you need an HTTP endpoint).\n\n**2. OpenMemory MCP Server**\nThe OpenMemory MCP Server is a private, local-first memory server that creates a shared, persistent memory layer for MCP-compatible tools. This runs entirely on your machine, enabling seamless context handoff across tools.(no content)Key features include cross-client memory access (store context in Cursor and retrieve it later in Claude or Windsurf without repeating yourself), and a fully local memory store where all memory is stored on your machine with nothing going to the cloud, maintaining full ownership and control.(no content)It also includes a unified Memory UI - the built-in OpenMemory dashboard provides a central view of everything stored, allowing you to add, browse, delete and control memory access to clients directly from the dashboard.\n\n**3. Local Mem0 MCP Server (Self-Hosted)**\nThere's also a fully self-hosted Model Context Protocol (MCP) server integrating Mem0 for persistent memory capabilities. It requires Docker Desktop for containerized deployment and uses PostgreSQL with pgvector for vector storage and Ollama for local AI models.\n\n### Compatible Tools\nOpenMemory works with MCP compatible coding agents and tools like Cursor, VS Code, JetBrains, Claude, OpenAI, LangGraph, LlamaIndex, and more.\n\n### Memory Organization\nYou can group memories into types like user_preferences, implementation, troubleshooting, component_context, project_overview, and incident_rca. By default, agents read memories per project, and you can adjust this per agent.\n\n### Use Cases\nCase studies from EdTech applications like OpenNote and RevisionDojo demonstrate significant real-world impact. By using Mem0 to create AI tutors that track individual student strengths, weaknesses, and learning styles, they achieved a more personalized learning experience and a remarkable 40% reduction in token costs by avoiding redundant context passing.\n\n\nREMINDER: You MUST include the sources above in your response to the user using markdown hyperlinks."}]},"uuid":"bd232a9e-d372-4154-a4d7-3dc452126dfc","timestamp":"2026-01-12T08:06:05.404Z","toolUseResult":{"query":"mem0 MCP server memory 2025","results":[{"tool_use_id":"srvtoolu_01RxZjDjBZgf4aJXbEgL4N4Y","content":[{"title":"GitHub - mem0ai/mem0-mcp","url":"https://github.com/mem0ai/mem0-mcp"},{"title":"AI Memory OpenMemory MCP for Claude Desktop | Mem0","url":"https://mem0.ai/blog/introducing-openmemory-mcp"},{"title":"AI Memory MCP Server for Coding Agents | Mem0","url":"https://mem0.ai/openmemory"},{"title":"A Comprehensive Guide to the Mem0 MCP Server: Building AI with Persistent Memory","url":"https://skywork.ai/skypage/en/A Comprehensive Guide to the Mem0 MCP Server: Building AI with Persistent Memory/1971044006807793664"},{"title":"Mem0 Memory Server | MCP Server | Smithery","url":"https://smithery.ai/server/@big-omega/mem0-mcp"},{"title":"GitHub - coleam00/mcp-mem0: MCP server for long term agent memory with Mem0. Also useful as a template to get you started building your own MCP server with Python!","url":"https://github.com/coleam00/mcp-mem0"},{"title":"Official Mem0 MCP Server | PulseMCP","url":"https://www.pulsemcp.com/servers/mem0-coding-preferences"},{"title":"MCP-Mem0: Your Gateway to Long-Term Agent Memory 🚀 MCP Server","url":"https://mcp.so/server/mcp-mem0/yellnuts"},{"title":"Local Mem0 MCP Server","url":"https://lobehub.com/mcp/synapse-os-local-mem0-mcp"},{"title":"Mem0 MCP Server | MCP Servers · LobeHub","url":"https://lobehub.com/mcp/mem0-ai-mem0-mcp-server"}]},"Here are the search results for \"mem0 MCP server memory 2025\":\n\n## Mem0 MCP Server Overview\n\nThe mem0-mcp-server wraps the official Mem0 Memory API as a Model Context Protocol (MCP) server so any MCP-compatible client (Claude Desktop, Cursor, custom agents) can add, search, update, and delete long-term memories.\n\n### Key Products\n\n**1. Mem0 MCP Server (Official)**\nThis is a Model Context Protocol server that exposes the Mem0 long-term memory API as tools. It requires a MEM0_API_KEY environment variable for API access.(no content)You can run this server in three modes: Local Stdio (recommended for Claude Desktop, Cursor, or local development with no server port management needed), Smithery (for deploying as a hosted HTTP endpoint), and Docker (for containerized deployments where you need an HTTP endpoint).\n\n**2. OpenMemory MCP Server**\nThe OpenMemory MCP Server is a private, local-first memory server that creates a shared, persistent memory layer for MCP-compatible tools. This runs entirely on your machine, enabling seamless context handoff across tools.(no content)Key features include cross-client memory access (store context in Cursor and retrieve it later in Claude or Windsurf without repeating yourself), and a fully local memory store where all memory is stored on your machine with nothing going to the cloud, maintaining full ownership and control.(no content)It also includes a unified Memory UI - the built-in OpenMemory dashboard provides a central view of everything stored, allowing you to add, browse, delete and control memory access to clients directly from the dashboard.\n\n**3. Local Mem0 MCP Server (Self-Hosted)**\nThere's also a fully self-hosted Model Context Protocol (MCP) server integrating Mem0 for persistent memory capabilities. It requires Docker Desktop for containerized deployment and uses PostgreSQL with pgvector for vector storage and Ollama for local AI models.\n\n### Compatible Tools\nOpenMemory works with MCP compatible coding agents and tools like Cursor, VS Code, JetBrains, Claude, OpenAI, LangGraph, LlamaIndex, and more.\n\n### Memory Organization\nYou can group memories into types like user_preferences, implementation, troubleshooting, component_context, project_overview, and incident_rca. By default, agents read memories per project, and you can adjust this per agent.\n\n### Use Cases\nCase studies from EdTech applications like OpenNote and RevisionDojo demonstrate significant real-world impact. By using Mem0 to create AI tutors that track individual student strengths, weaknesses, and learning styles, they achieved a more personalized learning experience and a remarkable 40% reduction in token costs by avoiding redundant context passing."],"durationSeconds":21.523920959000474}}
{"parentUuid":"bd232a9e-d372-4154-a4d7-3dc452126dfc","isSidechain":true,"userType":"external","cwd":"/Users/imorgado","sessionId":"39080ac9-1d46-4e6e-8a22-ffc01545de99","version":"2.0.76","gitBranch":"","agentId":"a0dd8cf","slug":"wild-fluttering-dusk","message":{"model":"claude-opus-4-5-20251101","id":"msg_01283SRZwzbHqRpWRPZ6YSCh","type":"message","role":"assistant","content":[{"type":"text","text":"Let me search for a few more memory MCP implementations to provide a comprehensive list."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1115,"cache_creation_input_tokens":2488,"cache_read_input_tokens":21988,"cache_creation":{"ephemeral_5m_input_tokens":2488,"ephemeral_1h_input_tokens":0},"output_tokens":5,"service_tier":"standard"}},"requestId":"req_011CX3928uLA7ba5sATkmATn","type":"assistant","uuid":"dbeb191f-4304-413e-b299-186a64538c1e","timestamp":"2026-01-12T08:06:08.909Z"}
{"parentUuid":"dbeb191f-4304-413e-b299-186a64538c1e","isSidechain":true,"userType":"external","cwd":"/Users/imorgado","sessionId":"39080ac9-1d46-4e6e-8a22-ffc01545de99","version":"2.0.76","gitBranch":"","agentId":"a0dd8cf","slug":"wild-fluttering-dusk","message":{"model":"claude-opus-4-5-20251101","id":"msg_01283SRZwzbHqRpWRPZ6YSCh","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01TcDTwg2mk2fFvGJyjruBCF","name":"WebSearch","input":{"query":"cognee-mcp GraphRAG memory server installation 2025"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1115,"cache_creation_input_tokens":2488,"cache_read_input_tokens":21988,"cache_creation":{"ephemeral_5m_input_tokens":2488,"ephemeral_1h_input_tokens":0},"output_tokens":5,"service_tier":"standard"}},"requestId":"req_011CX3928uLA7ba5sATkmATn","type":"assistant","uuid":"405ff2b5-d9ed-47ec-8e80-b8c9cbbe9b94","timestamp":"2026-01-12T08:06:09.302Z"}
{"parentUuid":"405ff2b5-d9ed-47ec-8e80-b8c9cbbe9b94","isSidechain":true,"userType":"external","cwd":"/Users/imorgado","sessionId":"39080ac9-1d46-4e6e-8a22-ffc01545de99","version":"2.0.76","gitBranch":"","agentId":"a0dd8cf","slug":"wild-fluttering-dusk","message":{"model":"claude-opus-4-5-20251101","id":"msg_01283SRZwzbHqRpWRPZ6YSCh","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Mm31nnraFrFEhsaqQeZ2w6","name":"WebSearch","input":{"query":"qdrant MCP server vector memory semantic search 2025"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1115,"cache_creation_input_tokens":2488,"cache_read_input_tokens":21988,"cache_creation":{"ephemeral_5m_input_tokens":2488,"ephemeral_1h_input_tokens":0},"output_tokens":5,"service_tier":"standard"}},"requestId":"req_011CX3928uLA7ba5sATkmATn","type":"assistant","uuid":"fcbaa509-e5b2-4097-b420-7adc12eddec4","timestamp":"2026-01-12T08:06:09.758Z"}
{"parentUuid":"43579011-a984-4a78-8770-b9a7d4c4fb38","isSidechain":true,"userType":"external","cwd":"/Users/imorgado","sessionId":"39080ac9-1d46-4e6e-8a22-ffc01545de99","version":"2.0.76","gitBranch":"","agentId":"a0dd8cf","slug":"wild-fluttering-dusk","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Mm31nnraFrFEhsaqQeZ2w6","type":"tool_result","content":"Web search results for query: \"qdrant MCP server vector memory semantic search 2025\"\n\nLinks: [{\"title\":\"GitHub - qdrant/mcp-server-qdrant: An official Qdrant Model Context Protocol (MCP) server implementation\",\"url\":\"https://github.com/qdrant/mcp-server-qdrant\"},{\"title\":\"GitHub - delorenj/mcp-qdrant-memory: MCP server providing a knowledge graph implementation with semantic search capabilities powered by Qdrant vector database\",\"url\":\"https://github.com/delorenj/mcp-qdrant-memory\"},{\"title\":\"Qdrant MCP Server: The Ultimate Guide to Semantic Memory for AI Agents\",\"url\":\"https://skywork.ai/skypage/en/qdrant-mcp-semantic-memory-ai/1978001302501642240\"},{\"title\":\"mcp-server-qdrant · PyPI\",\"url\":\"https://pypi.org/project/mcp-server-qdrant/0.6.0/\"},{\"title\":\"Qdrant Memory | Awesome MCP Servers\",\"url\":\"https://mcpservers.org/servers/delorenj/mcp-qdrant-memory\"},{\"title\":\"MCP Memory Server with Qdrant Persistence\",\"url\":\"https://mcp.so/server/mcp-qdrant-memory\"},{\"title\":\"Qdrant - MCP Server | Cursor Directory\",\"url\":\"https://cursor.directory/mcp/qdrant\"},{\"title\":\"Official Qdrant MCP Server | PulseMCP\",\"url\":\"https://www.pulsemcp.com/servers/qdrant-mcp-server-qdrant\"},{\"title\":\"Qdrant MCP Server 2025: Features & Setup Guide | Rank&Compare\",\"url\":\"https://www.rankncompare.com/mcp-servers/qdrant-mcp-server-qdrant\"},{\"title\":\"Qdrant - MCP Server | Windsurf Directory\",\"url\":\"https://windsurf.run/mcp/qdrant\"}]\n\nHere are the search results for \"qdrant MCP server vector memory semantic search 2025\":\n\n## Official Qdrant MCP Server\n\nThe official Model Context Protocol server for Qdrant is designed for keeping and retrieving memories in the Qdrant vector search engine. It acts as a semantic memory layer on top of the Qdrant database.\n\n### Key Features\n\nThis configuration transforms the Qdrant MCP server into a specialized code search tool that can store code snippets, documentation, and implementation details, retrieve relevant code examples based on semantic search, and help developers find specific implementations or usage patterns.(no content)It keeps and retrieves memories in Qdrant via two MCP tools: qdrant-store and qdrant-find.\n\n### Configuration & Usage\n\nWhen using uv, no specific installation is needed to directly run mcp-server-qdrant. You can run it with: `uv run mcp-server-qdrant --qdrant-url \"http://localhost:6333\" --qdrant-api-key \"your_api_key\" --collection-name \"my_collection\" --embedding-model \"sentence-transformers/all-MiniLM-L6-v2\"`(no content)This MCP server will automatically create a collection with the specified name if it doesn't exist. By default, the server will use the sentence-transformers/all-MiniLM-L6-v2 embedding model to encode memories. For the time being, only FastEmbed models are supported.\n\n### Integration with Claude Code\n\nYou can enhance Claude Code's capabilities by connecting it to this MCP server, enabling semantic search over your existing codebase.\n\n## Alternative: MCP Qdrant Memory (Knowledge Graph)\n\nThere's also a community MCP server that provides a knowledge graph implementation with semantic search capabilities powered by Qdrant vector database.(no content)This MCP server provides a knowledge graph implementation with semantic search capabilities powered by Qdrant vector database, featuring graph-based knowledge representation with entities and relations.\n\n### Use Cases\n\nA key use case is semantic code search and \"Vibe Coding.\" Instead of searching your codebase with rigid keywords, you can search by intent. This concept allows you to describe the functionality you're looking for in natural language.(no content)Target users include LLM developers who want to expose semantic memories to LLM apps via MCP using Qdrant, code teams enabling semantic code search integration, and integration teams setting up memory-backed data sources for multi-LLM workflows across services.\n\n### Transport Options\n\nThe server supports stdio (default), SSE, and streamable-http transports for MCP communication.\n\n\nREMINDER: You MUST include the sources above in your response to the user using markdown hyperlinks."}]},"uuid":"73238ba1-4bc5-4b14-bf74-91ed08e8b539","timestamp":"2026-01-12T08:06:28.562Z","toolUseResult":{"query":"qdrant MCP server vector memory semantic search 2025","results":[{"tool_use_id":"srvtoolu_0141Ww8MXaLMYGNdXYnwTbF2","content":[{"title":"GitHub - qdrant/mcp-server-qdrant: An official Qdrant Model Context Protocol (MCP) server implementation","url":"https://github.com/qdrant/mcp-server-qdrant"},{"title":"GitHub - delorenj/mcp-qdrant-memory: MCP server providing a knowledge graph implementation with semantic search capabilities powered by Qdrant vector database","url":"https://github.com/delorenj/mcp-qdrant-memory"},{"title":"Qdrant MCP Server: The Ultimate Guide to Semantic Memory for AI Agents","url":"https://skywork.ai/skypage/en/qdrant-mcp-semantic-memory-ai/1978001302501642240"},{"title":"mcp-server-qdrant · PyPI","url":"https://pypi.org/project/mcp-server-qdrant/0.6.0/"},{"title":"Qdrant Memory | Awesome MCP Servers","url":"https://mcpservers.org/servers/delorenj/mcp-qdrant-memory"},{"title":"MCP Memory Server with Qdrant Persistence","url":"https://mcp.so/server/mcp-qdrant-memory"},{"title":"Qdrant - MCP Server | Cursor Directory","url":"https://cursor.directory/mcp/qdrant"},{"title":"Official Qdrant MCP Server | PulseMCP","url":"https://www.pulsemcp.com/servers/qdrant-mcp-server-qdrant"},{"title":"Qdrant MCP Server 2025: Features & Setup Guide | Rank&Compare","url":"https://www.rankncompare.com/mcp-servers/qdrant-mcp-server-qdrant"},{"title":"Qdrant - MCP Server | Windsurf Directory","url":"https://windsurf.run/mcp/qdrant"}]},"Here are the search results for \"qdrant MCP server vector memory semantic search 2025\":\n\n## Official Qdrant MCP Server\n\nThe official Model Context Protocol server for Qdrant is designed for keeping and retrieving memories in the Qdrant vector search engine. It acts as a semantic memory layer on top of the Qdrant database.\n\n### Key Features\n\nThis configuration transforms the Qdrant MCP server into a specialized code search tool that can store code snippets, documentation, and implementation details, retrieve relevant code examples based on semantic search, and help developers find specific implementations or usage patterns.(no content)It keeps and retrieves memories in Qdrant via two MCP tools: qdrant-store and qdrant-find.\n\n### Configuration & Usage\n\nWhen using uv, no specific installation is needed to directly run mcp-server-qdrant. You can run it with: `uv run mcp-server-qdrant --qdrant-url \"http://localhost:6333\" --qdrant-api-key \"your_api_key\" --collection-name \"my_collection\" --embedding-model \"sentence-transformers/all-MiniLM-L6-v2\"`(no content)This MCP server will automatically create a collection with the specified name if it doesn't exist. By default, the server will use the sentence-transformers/all-MiniLM-L6-v2 embedding model to encode memories. For the time being, only FastEmbed models are supported.\n\n### Integration with Claude Code\n\nYou can enhance Claude Code's capabilities by connecting it to this MCP server, enabling semantic search over your existing codebase.\n\n## Alternative: MCP Qdrant Memory (Knowledge Graph)\n\nThere's also a community MCP server that provides a knowledge graph implementation with semantic search capabilities powered by Qdrant vector database.(no content)This MCP server provides a knowledge graph implementation with semantic search capabilities powered by Qdrant vector database, featuring graph-based knowledge representation with entities and relations.\n\n### Use Cases\n\nA key use case is semantic code search and \"Vibe Coding.\" Instead of searching your codebase with rigid keywords, you can search by intent. This concept allows you to describe the functionality you're looking for in natural language.(no content)Target users include LLM developers who want to expose semantic memories to LLM apps via MCP using Qdrant, code teams enabling semantic code search integration, and integration teams setting up memory-backed data sources for multi-LLM workflows across services.\n\n### Transport Options\n\nThe server supports stdio (default), SSE, and streamable-http transports for MCP communication."],"durationSeconds":18.76339187499974}}
{"parentUuid":"73238ba1-4bc5-4b14-bf74-91ed08e8b539","isSidechain":true,"userType":"external","cwd":"/Users/imorgado","sessionId":"39080ac9-1d46-4e6e-8a22-ffc01545de99","version":"2.0.76","gitBranch":"","agentId":"a0dd8cf","slug":"wild-fluttering-dusk","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01TcDTwg2mk2fFvGJyjruBCF","type":"tool_result","content":"Web search results for query: \"cognee-mcp GraphRAG memory server installation 2025\"\n\nLinks: [{\"title\":\"GitHub - topoteretes/cognee: Memory for AI Agents in 6 lines of code\",\"url\":\"https://github.com/topoteretes/cognee\"},{\"title\":\"The Ultimate AI Engineer's Guide to the Official Cognee MCP Server\",\"url\":\"https://skywork.ai/skypage/en/ultimate-ai-engineer-guide-cognee-mcp-server/1977912822261551104\"},{\"title\":\"Cognee Mcp - Complete Cursor MCP Server Guide with Installation & Docs\",\"url\":\"https://cursormcp.dev/mcp-servers/453-cognee-mcp\"},{\"title\":\"cognee-mcp MCP Server | Search | Free MCP Servers - Free MCP Servers | Model Context Protocol Servers Directory\",\"url\":\"https://free-mcp-servers.app/server/cognee-mcp\"},{\"title\":\"Use cognee-mcp MCP Server with Copilot-MCP - MCP Stack\",\"url\":\"https://www.mcpstack.org/use/cognee-mcp/mcp-server/with/copilot-mcp\"},{\"title\":\"cognee-mcp | Glama\",\"url\":\"https://glama.ai/mcp/servers/@topoteretes/cognee\"},{\"title\":\"Cognee - Model Context Protocol + Cognee: LLM Memory Made Simple\",\"url\":\"https://www.cognee.ai/blog/deep-dives/model-context-protocol-cognee-llm-memory-made-simple\"},{\"title\":\"Cognee – Cloud Services MCP Server by Topoteretes Model Context Protocol Tool | Free DevTools by Hexmos\",\"url\":\"https://hexmos.com/freedevtools/mcp/cloud-services/topoteretes--cognee/\"},{\"title\":\"GitHub - modelcontextprotocol/servers: Model Context Protocol Servers\",\"url\":\"https://github.com/modelcontextprotocol/servers\"},{\"title\":\"GitHub - MCP-Mirror/topoteretes_cognee-mcp-server: Mirror of https://github.com/topoteretes/cognee-mcp-server\",\"url\":\"https://github.com/MCP-Mirror/topoteretes_cognee-mcp-server\"}]\n\nHere's what I found about cognee-mcp GraphRAG memory server installation:\n\n## Overview\n\nCognee-mcp is a GraphRAG memory server with customizable ingestion, data processing and search.(no content)Cognee is an open-source tool and platform that transforms your raw data into persistent and dynamic AI memory for Agents. It combines vector search with graph databases to make your documents both searchable by meaning and connected by relationships.\n\n## Key Features\n\nThe Cognee MCP server is a multi-functional tool for managing knowledge graphs with four main capabilities:\n- **Cognify**: Converts text into a structured knowledge graph\n- **Codify**: Transforms a codebase into a knowledge graph\n- **Search**: Allows searching within the knowledge graph with customizable search types\n- **Prune**: Simplifies and optimizes the knowledge graph as needed\n\n## Installation Methods\n\n### Using pip, poetry, or uv\nYou can install Cognee using either pip, poetry, uv or any other python package manager.\n\n### Using Smithery (Automatic Installation for Claude Desktop)\nTo install Cognee for Claude Desktop automatically via Smithery: `npx -y @smithery/cli install cognee --client claude`\n\n### Manual Configuration for Claude Desktop\nYou need to create `claude_desktop_config.json` in the appropriate folder if it doesn't exist. Use your editor of choice to add the configuration with your paths and LLM API key.\n\nExample configuration:\n```json\n{\n  \"mcpServers\": {\n    \"cognee\": {\n      \"command\": \"/Users/{user}/cognee/.venv/bin/uv\",\n      \"args\": [\n        \"--directory\",\n        \"/Users/{user}/cognee/cognee-mcp\",\n        \"run\",\n        \"cognee\"\n      ],\n      \"env\": {\n        \"ENV\": \"local\",\n        \"TOKENIZERS_PARALLELISM\": \"false\",\n        \"LLM_API_KEY\": \"sk-\"\n      }\n    }\n  }\n}\n```\n\n### Environment Configuration\nYou can also set the variables by creating .env file, using their template. To use different LLM providers, check out their documentation.\n\n## 2025 Research & Benchmarks\n\nThe team recently published a research paper on optimizing knowledge graphs for LLM reasoning titled \"Optimizing the Interface Between Knowledge Graphs and LLMs for Complex Reasoning\" (arXiv:2505.24478) in 2025.(no content)The Cognee team has conducted benchmarks comparing its graph-based approach against other memory tools like Mem0, LightRAG, and Graphiti on complex, multi-hop question-answering datasets like HotPotQA. The results are compelling. By using a graph completion method with Chain-of-Thought (CoT) reasoning, Cognee demonstrated significant performance gains.\n\n## Resources\n\n- **GitHub Repository**: https://github.com/topoteretes/cognee\n- Head over to the GitHub repository to grab the cognee MCP server code and get everything you need to start experimenting.\n- Whether you're using Claude Desktop or Cline, step-by-step instructions make installing and configuring the cognee MCP server straightforward.\n\n\nREMINDER: You MUST include the sources above in your response to the user using markdown hyperlinks."}]},"uuid":"51c2248d-47a9-4c58-9c62-099485b22627","timestamp":"2026-01-12T08:06:32.639Z","toolUseResult":{"query":"cognee-mcp GraphRAG memory server installation 2025","results":[{"tool_use_id":"srvtoolu_01KMMXJ5JZf7StKRmC9H9gr7","content":[{"title":"GitHub - topoteretes/cognee: Memory for AI Agents in 6 lines of code","url":"https://github.com/topoteretes/cognee"},{"title":"The Ultimate AI Engineer's Guide to the Official Cognee MCP Server","url":"https://skywork.ai/skypage/en/ultimate-ai-engineer-guide-cognee-mcp-server/1977912822261551104"},{"title":"Cognee Mcp - Complete Cursor MCP Server Guide with Installation & Docs","url":"https://cursormcp.dev/mcp-servers/453-cognee-mcp"},{"title":"cognee-mcp MCP Server | Search | Free MCP Servers - Free MCP Servers | Model Context Protocol Servers Directory","url":"https://free-mcp-servers.app/server/cognee-mcp"},{"title":"Use cognee-mcp MCP Server with Copilot-MCP - MCP Stack","url":"https://www.mcpstack.org/use/cognee-mcp/mcp-server/with/copilot-mcp"},{"title":"cognee-mcp | Glama","url":"https://glama.ai/mcp/servers/@topoteretes/cognee"},{"title":"Cognee - Model Context Protocol + Cognee: LLM Memory Made Simple","url":"https://www.cognee.ai/blog/deep-dives/model-context-protocol-cognee-llm-memory-made-simple"},{"title":"Cognee – Cloud Services MCP Server by Topoteretes Model Context Protocol Tool | Free DevTools by Hexmos","url":"https://hexmos.com/freedevtools/mcp/cloud-services/topoteretes--cognee/"},{"title":"GitHub - modelcontextprotocol/servers: Model Context Protocol Servers","url":"https://github.com/modelcontextprotocol/servers"},{"title":"GitHub - MCP-Mirror/topoteretes_cognee-mcp-server: Mirror of https://github.com/topoteretes/cognee-mcp-server","url":"https://github.com/MCP-Mirror/topoteretes_cognee-mcp-server"}]},"Here's what I found about cognee-mcp GraphRAG memory server installation:\n\n## Overview\n\nCognee-mcp is a GraphRAG memory server with customizable ingestion, data processing and search.(no content)Cognee is an open-source tool and platform that transforms your raw data into persistent and dynamic AI memory for Agents. It combines vector search with graph databases to make your documents both searchable by meaning and connected by relationships.\n\n## Key Features\n\nThe Cognee MCP server is a multi-functional tool for managing knowledge graphs with four main capabilities:\n- **Cognify**: Converts text into a structured knowledge graph\n- **Codify**: Transforms a codebase into a knowledge graph\n- **Search**: Allows searching within the knowledge graph with customizable search types\n- **Prune**: Simplifies and optimizes the knowledge graph as needed\n\n## Installation Methods\n\n### Using pip, poetry, or uv\nYou can install Cognee using either pip, poetry, uv or any other python package manager.\n\n### Using Smithery (Automatic Installation for Claude Desktop)\nTo install Cognee for Claude Desktop automatically via Smithery: `npx -y @smithery/cli install cognee --client claude`\n\n### Manual Configuration for Claude Desktop\nYou need to create `claude_desktop_config.json` in the appropriate folder if it doesn't exist. Use your editor of choice to add the configuration with your paths and LLM API key.\n\nExample configuration:\n```json\n{\n  \"mcpServers\": {\n    \"cognee\": {\n      \"command\": \"/Users/{user}/cognee/.venv/bin/uv\",\n      \"args\": [\n        \"--directory\",\n        \"/Users/{user}/cognee/cognee-mcp\",\n        \"run\",\n        \"cognee\"\n      ],\n      \"env\": {\n        \"ENV\": \"local\",\n        \"TOKENIZERS_PARALLELISM\": \"false\",\n        \"LLM_API_KEY\": \"sk-\"\n      }\n    }\n  }\n}\n```\n\n### Environment Configuration\nYou can also set the variables by creating .env file, using their template. To use different LLM providers, check out their documentation.\n\n## 2025 Research & Benchmarks\n\nThe team recently published a research paper on optimizing knowledge graphs for LLM reasoning titled \"Optimizing the Interface Between Knowledge Graphs and LLMs for Complex Reasoning\" (arXiv:2505.24478) in 2025.(no content)The Cognee team has conducted benchmarks comparing its graph-based approach against other memory tools like Mem0, LightRAG, and Graphiti on complex, multi-hop question-answering datasets like HotPotQA. The results are compelling. By using a graph completion method with Chain-of-Thought (CoT) reasoning, Cognee demonstrated significant performance gains.\n\n## Resources\n\n- **GitHub Repository**: https://github.com/topoteretes/cognee\n- Head over to the GitHub repository to grab the cognee MCP server code and get everything you need to start experimenting.\n- Whether you're using Claude Desktop or Cline, step-by-step instructions make installing and configuring the cognee MCP server straightforward."],"durationSeconds":22.840282541999592}}
{"parentUuid":"51c2248d-47a9-4c58-9c62-099485b22627","isSidechain":true,"userType":"external","cwd":"/Users/imorgado","sessionId":"39080ac9-1d46-4e6e-8a22-ffc01545de99","version":"2.0.76","gitBranch":"","agentId":"a0dd8cf","slug":"wild-fluttering-dusk","message":{"model":"claude-opus-4-5-20251101","id":"msg_014Sy8yLWcd6P2vx6BBTgE8E","type":"message","role":"assistant","content":[{"type":"text","text":"Now I have comprehensive information. Let me compile the complete list of MCP memory servers with installation instructions.\n\n---\n\n# MCP Memory Servers - Comprehensive List\n\nHere is a detailed list of available MCP servers that provide memory capabilities for Claude and other AI assistants.\n\n---\n\n## 1. Official Anthropic Knowledge Graph Memory Server\n\n**Package:** `@modelcontextprotocol/server-memory`\n\n**Description:** The official reference implementation from Anthropic. Provides persistent memory using a local knowledge graph with entities, relations, and observations stored in a JSONL file.\n\n**Features:**\n- Knowledge graph with entities as primary nodes\n- Relations defining directed connections between entities (stored in active voice)\n- Observations as discrete pieces of information about entities\n- Persistent storage across sessions\n\n**Installation:**\n\n```bash\nnpm install -g @modelcontextprotocol/server-memory\n```\n\n**Claude Desktop Configuration:**\n\n```json\n{\n  \"mcpServers\": {\n    \"memory\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@modelcontextprotocol/server-memory\"],\n      \"env\": {\n        \"MEMORY_FILE_PATH\": \"/path/to/custom/memory.jsonl\"\n      }\n    }\n  }\n}\n```\n\n**Docker Configuration:**\n\n```json\n{\n  \"mcpServers\": {\n    \"memory\": {\n      \"command\": \"docker\",\n      \"args\": [\"run\", \"-i\", \"-v\", \"claude-memory:/app/dist\", \"--rm\", \"mcp/memory\"]\n    }\n  }\n}\n```\n\n**Sources:**\n- [npm Package](https://www.npmjs.com/package/@modelcontextprotocol/server-memory)\n- [GitHub Repository](https://github.com/modelcontextprotocol/servers/tree/main/src/memory)\n\n---\n\n## 2. Mem0 MCP Server (OpenMemory)\n\n**Description:** A comprehensive memory solution from Mem0 that provides both cloud-based and local-first memory capabilities. OpenMemory is their fully local, private memory server.\n\n**Features:**\n- Cross-client memory access (store in Cursor, retrieve in Claude)\n- Fully local memory store with complete data ownership\n- Built-in Memory UI dashboard\n- Memory categorization (user_preferences, implementation, troubleshooting, etc.)\n- Supports Claude Desktop, Cursor, VS Code, JetBrains\n\n**Installation (Official Mem0 Cloud):**\n\nRequires a MEM0_API_KEY from mem0.ai\n\n```json\n{\n  \"mcpServers\": {\n    \"mem0\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"mem0-mcp\"],\n      \"env\": {\n        \"MEM0_API_KEY\": \"your_api_key\"\n      }\n    }\n  }\n}\n```\n\n**Installation (OpenMemory - Local):**\n\n```bash\n# Install via pip\npip install openmemory-mcp\n\n# Or via Docker\ndocker run -d openmemory/server\n```\n\n**Sources:**\n- [Mem0 MCP GitHub](https://github.com/mem0ai/mem0-mcp)\n- [OpenMemory Blog Post](https://mem0.ai/blog/introducing-openmemory-mcp)\n- [OpenMemory Product Page](https://mem0.ai/openmemory)\n\n---\n\n## 3. Basic Memory MCP Server\n\n**Description:** A local-first knowledge management system that builds a semantic graph from Markdown files. Integrates directly with Obsidian.md.\n\n**Features:**\n- Persistent semantic graph from conversations\n- Standard Markdown file storage (human-readable)\n- Works with Obsidian.md\n- SQLite indexing for search\n- Real-time synchronization\n\n**Installation via Smithery (Automatic):**\n\n```bash\nnpx @smithery/cli install basic-memory --client claude\n```\n\n**Manual Installation:**\n\n```bash\npip install basic-memory\n```\n\n**Configuration:**\n\n```json\n{\n  \"mcpServers\": {\n    \"basic-memory\": {\n      \"command\": \"basic-memory\",\n      \"args\": [\"serve\"]\n    }\n  }\n}\n```\n\n**Enable Real-time Sync:**\n\n```bash\nbasic-memory sync --watch\n```\n\n**Sources:**\n- [Basic Memory GitHub](https://github.com/mcp-research/basicmachines-co__basic-memory)\n- [PulseMCP Listing](https://www.pulsemcp.com/servers/basicmachines-memory)\n- [Docker Hub](https://hub.docker.com/r/mcp/basic-memory)\n\n---\n\n## 4. Cognee MCP Server (GraphRAG)\n\n**Description:** A GraphRAG memory server that combines knowledge graphs with customizable ingestion, data processing, and search capabilities.\n\n**Features:**\n- **Cognify:** Convert text to structured knowledge graph\n- **Codify:** Transform codebase into knowledge graph\n- **Search:** Customizable search types within the graph\n- **Prune:** Optimize and simplify knowledge graphs\n- Vector + graph database hybrid approach\n\n**Installation via Smithery:**\n\n```bash\nnpx -y @smithery/cli install cognee --client claude\n```\n\n**Manual Installation:**\n\n```bash\npip install cognee\n```\n\n**Configuration:**\n\n```json\n{\n  \"mcpServers\": {\n    \"cognee\": {\n      \"command\": \"uv\",\n      \"args\": [\"--directory\", \"/path/to/cognee-mcp\", \"run\", \"cognee\"],\n      \"env\": {\n        \"ENV\": \"local\",\n        \"TOKENIZERS_PARALLELISM\": \"false\",\n        \"LLM_API_KEY\": \"sk-your-key\"\n      }\n    }\n  }\n}\n```\n\n**Sources:**\n- [Cognee GitHub](https://github.com/topoteretes/cognee)\n- [Cognee Blog](https://www.cognee.ai/blog/deep-dives/model-context-protocol-cognee-llm-memory-made-simple)\n\n---\n\n## 5. Qdrant MCP Server (Vector Memory)\n\n**Description:** Official Qdrant vector database MCP server for semantic memory with vector search capabilities.\n\n**Features:**\n- Semantic memory layer on Qdrant\n- Two MCP tools: `qdrant-store` and `qdrant-find`\n- Automatic collection creation\n- FastEmbed model support\n- Semantic code search capability\n\n**Installation:**\n\n```bash\npip install mcp-server-qdrant\n```\n\n**Run with uv (no installation needed):**\n\n```bash\nuv run mcp-server-qdrant \\\n  --qdrant-url \"http://localhost:6333\" \\\n  --qdrant-api-key \"your_api_key\" \\\n  --collection-name \"my_collection\" \\\n  --embedding-model \"sentence-transformers/all-MiniLM-L6-v2\"\n```\n\n**Configuration:**\n\n```json\n{\n  \"mcpServers\": {\n    \"qdrant\": {\n      \"command\": \"mcp-server-qdrant\",\n      \"args\": [\n        \"--qdrant-url\", \"http://localhost:6333\",\n        \"--collection-name\", \"memories\"\n      ]\n    }\n  }\n}\n```\n\n**Sources:**\n- [Official Qdrant MCP GitHub](https://github.com/qdrant/mcp-server-qdrant)\n- [PyPI Package](https://pypi.org/project/mcp-server-qdrant/)\n- [MCP Qdrant Memory (Knowledge Graph variant)](https://github.com/delorenj/mcp-qdrant-memory)\n\n---\n\n## 6. Memento MCP (Neo4j-based)\n\n**Description:** A scalable, high-performance knowledge graph memory system using Neo4j as the storage backend.\n\n**Features:**\n- Unified graph and vector storage in Neo4j\n- Semantic retrieval with contextual recall\n- Temporal awareness\n- Native graph operations and traversal\n- Scalable for long conversations\n\n**Installation:**\n\n```bash\npip install memento-mcp\n```\n\n**Requirements:**\n- Neo4j database instance\n- Neo4j credentials\n\n**Configuration:**\n\n```json\n{\n  \"mcpServers\": {\n    \"memento\": {\n      \"command\": \"memento-mcp\",\n      \"env\": {\n        \"NEO4J_URI\": \"bolt://localhost:7687\",\n        \"NEO4J_USER\": \"neo4j\",\n        \"NEO4J_PASSWORD\": \"your_password\"\n      }\n    }\n  }\n}\n```\n\n**Sources:**\n- [Memento MCP GitHub](https://github.com/gannonh/memento-mcp)\n- [Neo4j MCP Documentation](https://neo4j.com/developer/genai-ecosystem/model-context-protocol-mcp/)\n\n---\n\n## 7. Zep Graphiti MCP Server\n\n**Description:** Temporal knowledge graph server powered by Zep's open-source Graphiti framework. Understands how information evolves over time.\n\n**Features:**\n- Temporal knowledge graphs\n- Semantic similarity search\n- Keyword matching\n- Graph traversal\n- Tracks relationships and information evolution\n- Fully local operation\n\n**Installation:**\n\n```bash\npip install graphiti-mcp\n```\n\n**Sources:**\n- [Zep Graphiti MCP](https://www.getzep.com/product/knowledge-graph-mcp/)\n\n---\n\n## 8. Fuzzy Memory MCP\n\n**Description:** Knowledge graph memory enhanced with fuzzy semantic searching using fuse.js.\n\n**Features:**\n- Local knowledge graph storage\n- Fuzzy semantic search with fuse.js\n- Persistent memory across chats\n\n**Sources:**\n- [LobeHub Listing](https://lobehub.com/mcp/flrngel-fuzzy-memory-mcp)\n\n---\n\n## Summary Table\n\n| Server | Storage Type | Key Feature | Installation |\n|--------|-------------|-------------|--------------|\n| @modelcontextprotocol/server-memory | JSONL file | Official reference, simple setup | `npm i @modelcontextprotocol/server-memory` |\n| Mem0 / OpenMemory | Local/Cloud | Cross-client memory, UI dashboard | `pip install openmemory-mcp` |\n| Basic Memory | Markdown files | Obsidian integration, human-readable | `pip install basic-memory` |\n| Cognee | GraphRAG | Code + text knowledge graphs | `pip install cognee` |\n| Qdrant MCP | Vector DB | Semantic search, code search | `pip install mcp-server-qdrant` |\n| Memento MCP | Neo4j | Scalable graph + vector | `pip install memento-mcp` |\n| Graphiti (Zep) | Temporal graph | Time-aware knowledge | `pip install graphiti-mcp` |\n\n---\n\n## Additional Resources\n\n- [Model Context Protocol Official Site](https://modelcontextprotocol.io/examples)\n- [MCP Servers GitHub Repository](https://github.com/modelcontextprotocol/servers)\n- [Claude Code MCP Documentation](https://docs.anthropic.com/en/docs/claude-code/mcp)\n- [Claude Memory Tool API Documentation](https://docs.claude.com/en/docs/agents-and-tools/tool-use/memory-tool)"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1129,"cache_creation_input_tokens":2681,"cache_read_input_tokens":24476,"cache_creation":{"ephemeral_5m_input_tokens":2681,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CX3949HxUSxPbe6w9JjtV","type":"assistant","uuid":"df6af4a5-6031-466b-a911-0a4096da5171","timestamp":"2026-01-12T08:07:12.846Z"}
