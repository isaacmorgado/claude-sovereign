{"type":"file-history-snapshot","messageId":"aa9ee566-6188-4d8d-9f57-811fc402469b","snapshot":{"messageId":"aa9ee566-6188-4d8d-9f57-811fc402469b","trackedFileBackups":{},"timestamp":"2026-01-08T01:06:18.418Z"},"isSnapshotUpdate":false}
{"parentUuid":null,"isSidechain":false,"userType":"external","cwd":"/Users/imorgado/Desktop/claudish","sessionId":"d00c22c1-fe94-4ad8-b0bf-aad6294d1cef","version":"2.0.76","gitBranch":"main","type":"user","message":{"role":"user","content":"what is the name of the model you are using?"},"uuid":"aa9ee566-6188-4d8d-9f57-811fc402469b","timestamp":"2026-01-08T01:06:18.410Z","thinkingMetadata":{"level":"high","disabled":false,"triggers":[]},"todos":[]}
{"type":"file-history-snapshot","messageId":"92488cc3-f090-4042-a181-847f63966529","snapshot":{"messageId":"92488cc3-f090-4042-a181-847f63966529","trackedFileBackups":{},"timestamp":"2026-01-08T01:06:39.737Z"},"isSnapshotUpdate":false}
{"parentUuid":"aa9ee566-6188-4d8d-9f57-811fc402469b","isSidechain":false,"userType":"external","cwd":"/Users/imorgado/Desktop/claudish","sessionId":"d00c22c1-fe94-4ad8-b0bf-aad6294d1cef","version":"2.0.76","gitBranch":"main","type":"user","message":{"role":"user","content":"what is the name of the model you are using?"},"uuid":"92488cc3-f090-4042-a181-847f63966529","timestamp":"2026-01-08T01:06:39.733Z","thinkingMetadata":{"level":"high","disabled":false,"triggers":[]},"todos":[]}
{"parentUuid":"92488cc3-f090-4042-a181-847f63966529","isSidechain":false,"userType":"external","cwd":"/Users/imorgado/Desktop/claudish","sessionId":"d00c22c1-fe94-4ad8-b0bf-aad6294d1cef","version":"2.0.76","gitBranch":"main","type":"assistant","uuid":"c2d0c8a1-bfb3-46de-b971-5af5eda418c4","timestamp":"2026-01-08T01:06:41.338Z","message":{"id":"81f3bba7-889b-4479-9029-9fecda94dfb3","container":null,"model":"<synthetic>","role":"assistant","stop_reason":"stop_sequence","stop_sequence":"","type":"message","usage":{"input_tokens":0,"output_tokens":0,"cache_creation_input_tokens":0,"cache_read_input_tokens":0,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":null,"cache_creation":{"ephemeral_1h_input_tokens":0,"ephemeral_5m_input_tokens":0}},"content":[{"type":"text","text":"API Error: 400 {\"error\":\"{\\\"error\\\":{\\\"message\\\":\\\"This model's maximum context length is 8192 tokens. However, you requested 20251 tokens (16155 in the messages, 4096 in the completion). Please reduce the length of the messages or completion.\\\",\\\"type\\\":\\\"invalid_request_error\\\",\\\"param\\\":null,\\\"code\\\":\\\"bad_request\\\"}}\"}"}],"context_management":null},"error":"unknown","isApiErrorMessage":true}
