     1→/**
     2→ * SPLICE Social Reframe Service
     3→ *
     4→ * Auto-crops video to vertical/square formats with face tracking.
     5→ * Supports TikTok (9:16), Instagram (1:1, 4:5), YouTube Shorts.
     6→ */
     7→
     8→const { trackFaces, identifySpeaker, calculateCropRegion, calculateCenterCrop } = require('./faceDetection');
     9→const fs = require('fs');
    10→const path = require('path');
    11→
    12→// ============================================================================
    13→// ASPECT RATIO PRESETS
    14→// ============================================================================
    15→
    16→const ASPECT_RATIOS = {
    17→  portrait: {
    18→    id: 'portrait',
    19→    name: 'Portrait (9:16)',
    20→    ratio: 9 / 16,
    21→    width: 1080,
    22→    height: 1920,
    23→    platforms: ['tiktok', 'reels', 'shorts']
    24→  },
    25→  square: {
    26→    id: 'square',
    27→    name: 'Square (1:1)',
    28→    ratio: 1,
    29→    width: 1080,
    30→    height: 1080,
    31→    platforms: ['instagram_feed', 'linkedin']
    32→  },
    33→  portrait_4_5: {
    34→    id: 'portrait_4_5',
    35→    name: 'Portrait (4:5)',
    36→    ratio: 4 / 5,
    37→    width: 1080,
    38→    height: 1350,
    39→    platforms: ['instagram_portrait']
    40→  },
    41→  landscape: {
    42→    id: 'landscape',
    43→    name: 'Landscape (16:9)',
    44→    ratio: 16 / 9,
    45→    width: 1920,
    46→    height: 1080,
    47→    platforms: ['youtube', 'twitter']
    48→  }
    49→};
    50→
    51→// ============================================================================
    52→// PLATFORM PRESETS
    53→// ============================================================================
    54→
    55→const PLATFORM_PRESETS = {
    56→  tiktok: {
    57→    id: 'tiktok',
    58→    name: 'TikTok',
    59→    aspectRatio: 'portrait',
    60→    safeZone: { top: 0.15, bottom: 0.2, left: 0.05, right: 0.05 },
    61→    maxDuration: 180
    62→  },
    63→  reels: {
    64→    id: 'reels',
    65→    name: 'Instagram Reels',
    66→    aspectRatio: 'portrait',
    67→    safeZone: { top: 0.1, bottom: 0.15, left: 0.05, right: 0.05 },
    68→    maxDuration: 90
    69→  },
    70→  shorts: {
    71→    id: 'shorts',
    72→    name: 'YouTube Shorts',
    73→    aspectRatio: 'portrait',
    74→    safeZone: { top: 0.1, bottom: 0.12, left: 0.05, right: 0.05 },
    75→    maxDuration: 60
    76→  },
    77→  instagram_feed: {
    78→    id: 'instagram_feed',
    79→    name: 'Instagram Feed',
    80→    aspectRatio: 'square',
    81→    safeZone: { top: 0.05, bottom: 0.05, left: 0.05, right: 0.05 },
    82→    maxDuration: 60
    83→  },
    84→  instagram_portrait: {
    85→    id: 'instagram_portrait',
    86→    name: 'Instagram Portrait',
    87→    aspectRatio: 'portrait_4_5',
    88→    safeZone: { top: 0.05, bottom: 0.1, left: 0.05, right: 0.05 },
    89→    maxDuration: 60
    90→  },
    91→  linkedin: {
    92→    id: 'linkedin',
    93→    name: 'LinkedIn',
    94→    aspectRatio: 'square',
    95→    safeZone: { top: 0.05, bottom: 0.08, left: 0.05, right: 0.05 },
    96→    maxDuration: 600
    97→  }
    98→};
    99→
   100→// ============================================================================
   101→// MAIN FUNCTIONS
   102→// ============================================================================
   103→
   104→/**
   105→ * Analyze video for reframe possibilities
   106→ * @param {string} videoPath - Path to video file
   107→ * @param {Object} options - Analysis options
   108→ * @returns {Promise<Object>} Analysis results with face positions
   109→ */
   110→async function analyzeForReframe(videoPath, options = {}) {
   111→  const {
   112→    sampleRate = 0.5,
   113→    smoothing = 0.3
   114→  } = options;
   115→
   116→  if (!fs.existsSync(videoPath)) {
   117→    return {
   118→      success: false,
   119→      error: `Video file not found: ${videoPath}`
   120→    };
   121→  }
   122→
   123→  console.log(`[SPLICE Reframe] Analyzing: ${videoPath}`);
   124→
   125→  try {
   126→    // Track faces in video
   127→    const tracking = await trackFaces(videoPath, { sampleRate, smoothing });
   128→
   129→    if (!tracking.success) {
   130→      return tracking;
   131→    }
   132→
   133→    // Identify primary speaker
   134→    const speaker = identifySpeaker(tracking.tracks);
   135→
   136→    // Calculate suggested crops for each aspect ratio
   137→    const suggestions = {};
   138→    for (const [key, preset] of Object.entries(ASPECT_RATIOS)) {
   139→      suggestions[key] = calculateReframeCrops(tracking, preset.ratio);
   140→    }
   141→
   142→    return {
   143→      success: true,
   144→      videoInfo: tracking.videoInfo,
   145→      faceTracking: {
   146→        tracksFound: tracking.tracks.length,
   147→        primarySpeaker: speaker.primarySpeaker,
   148→        tracks: tracking.tracks
   149→      },
   150→      suggestions,
   151→      metadata: {
   152→        analyzedAt: new Date().toISOString(),
   153→        sampleRate,
   154→        smoothing
   155→      }
   156→    };
   157→
   158→  } catch (err) {
   159→    console.error('[SPLICE Reframe] Analysis error:', err);
   160→    return {
   161→      success: false,
   162→      error: err.message
   163→    };
   164→  }
   165→}
   166→
   167→/**
   168→ * Calculate crop positions for target aspect ratio
   169→ * @param {Object} tracking - Face tracking data
   170→ * @param {number} targetAspect - Target aspect ratio
   171→ * @returns {Object} Crop positions over time
   172→ */
   173→function calculateReframeCrops(tracking, targetAspect) {
   174→  const { videoInfo, tracks } = tracking;
   175→
   176→  if (!tracks || tracks.length === 0) {
   177→    // No faces - use center crop
   178→    const crop = calculateCenterCrop(targetAspect, videoInfo);
   179→    return {
   180→      method: 'center',
   181→      static: true,
   182→      crop,
   183→      keyframes: []
   184→    };
   185→  }
   186→
   187→  // Use primary track
   188→  const primaryTrack = tracks[0];
   189→  const keyframes = [];
   190→
   191→  // Generate keyframes at each tracked position
   192→  primaryTrack.positions.forEach((pos, index) => {
   193→    const crop = calculateCropRegion(pos, targetAspect, videoInfo);
   194→    keyframes.push({
   195→      time: pos.timestamp,
   196→      frame: Math.round(pos.timestamp * videoInfo.frameRate),
   197→      crop
   198→    });
   199→  });
   200→
   201→  return {
   202→    method: 'face-tracking',
   203→    static: false,
   204→    trackId: primaryTrack.trackId,
   205→    keyframes,
   206→    totalKeyframes: keyframes.length
   207→  };
   208→}
   209→
   210→/**
   211→ * Generate motion path with smoothing
   212→ * @param {Array} crops - Array of crop positions
   213→ * @param {number} duration - Video duration
   214→ * @param {number} frameRate - Video frame rate
   215→ * @returns {Object} Smooth motion path
   216→ */
   217→function generateMotionPath(crops, duration, frameRate) {
   218→  if (!crops || crops.length === 0) {
   219→    return {
   220→      success: false,
   221→      error: 'No crop data provided'
   222→    };
   223→  }
   224→
   225→  const totalFrames = Math.ceil(duration * frameRate);
   226→  const path = [];
   227→
   228→  // Interpolate between keyframes
   229→  for (let frame = 0; frame < totalFrames; frame++) {
   230→    const time = frame / frameRate;
   231→
   232→    // Find surrounding keyframes
   233→    let before = crops[0];
   234→    let after = crops[crops.length - 1];
   235→
   236→    for (let i = 0; i < crops.length - 1; i++) {
   237→      if (crops[i].time <= time && crops[i + 1].time >= time) {
   238→        before = crops[i];
   239→        after = crops[i + 1];
   240→        break;
   241→      }
   242→    }
   243→
   244→    // Interpolate
   245→    const t = after.time !== before.time
   246→      ? (time - before.time) / (after.time - before.time)
   247→      : 0;
   248→
   249→    // Ease function (smooth step)
   250→    const ease = t * t * (3 - 2 * t);
   251→
   252→    path.push({
   253→      frame,
   254→      time,
   255→      x: lerp(before.crop.x, after.crop.x, ease),
   256→      y: lerp(before.crop.y, after.crop.y, ease),
   257→      width: lerp(before.crop.width, after.crop.width, ease),
   258→      height: lerp(before.crop.height, after.crop.height, ease)
   259→    });
   260→  }
   261→
   262→  return {
   263→    success: true,
   264→    totalFrames,
   265→    duration,
   266→    frameRate,
   267→    path
   268→  };
   269→}
   270→
   271→/**
   272→ * Get safe zones for platform UI elements
   273→ * @param {string} platform - Platform ID
   274→ * @returns {Object} Safe zone information
   275→ */
   276→function getSafeZones(platform) {
   277→  const preset = PLATFORM_PRESETS[platform];
   278→
   279→  if (!preset) {
   280→    return {
   281→      success: false,
   282→      error: `Unknown platform: ${platform}`,
   283→      availablePlatforms: Object.keys(PLATFORM_PRESETS)
   284→    };
   285→  }
   286→
   287→  const aspect = ASPECT_RATIOS[preset.aspectRatio];
   288→
   289→  return {
   290→    success: true,
   291→    platform: preset.name,
   292→    aspectRatio: preset.aspectRatio,
   293→    dimensions: {
   294→      width: aspect.width,
   295→      height: aspect.height,
   296→      ratio: aspect.ratio
   297→    },
   298→    safeZone: preset.safeZone,
   299→    safeArea: {
   300→      top: preset.safeZone.top * aspect.height,
   301→      bottom: preset.safeZone.bottom * aspect.height,
   302→      left: preset.safeZone.left * aspect.width,
   303→      right: preset.safeZone.right * aspect.width,
   304→      contentWidth: aspect.width * (1 - preset.safeZone.left - preset.safeZone.right),
   305→      contentHeight: aspect.height * (1 - preset.safeZone.top - preset.safeZone.bottom)
   306→    },
   307→    maxDuration: preset.maxDuration
   308→  };
   309→}
   310→
   311→/**
   312→ * Generate export settings for all formats
   313→ * @param {string} videoPath - Source video path
   314→ * @param {Array} formats - Array of format IDs
   315→ * @param {Object} settings - Export settings
   316→ * @returns {Promise<Object>} Export data for each format
   317→ */
   318→async function batchExportFormats(videoPath, formats = ['portrait', 'square'], settings = {}) {
   319→  const {
   320→    quality = 'high', // high, medium, draft
   321→    motionSmoothing = 0.3
   322→  } = settings;
   323→
   324→  // Analyze video first
   325→  const analysis = await analyzeForReframe(videoPath, { smoothing: motionSmoothing });
   326→
   327→  if (!analysis.success) {
   328→    return analysis;
   329→  }
   330→
   331→  const exports = [];
   332→
   333→  for (const formatId of formats) {
   334→    const aspect = ASPECT_RATIOS[formatId];
   335→    if (!aspect) continue;
   336→
   337→    const crops = analysis.suggestions[formatId];
   338→    const motionPath = crops.static
   339→      ? null
   340→      : generateMotionPath(crops.keyframes, analysis.videoInfo.duration, analysis.videoInfo.frameRate);
   341→
   342→    exports.push({
   343→      format: formatId,
   344→      name: aspect.name,
   345→      dimensions: {
   346→        width: aspect.width,
   347→        height: aspect.height
   348→      },
   349→      isStatic: crops.static,
   350→      crop: crops.static ? crops.crop : null,
   351→      motionPath: motionPath?.success ? motionPath : null,
   352→      ffmpegFilter: generateFFmpegFilter(crops, aspect, analysis.videoInfo),
   353→      platforms: aspect.platforms
   354→    });
   355→  }
   356→
   357→  return {
   358→    success: true,
   359→    sourceVideo: videoPath,
   360→    sourceInfo: analysis.videoInfo,
   361→    exports,
   362→    totalFormats: exports.length,
   363→    metadata: {
   364→      quality,
   365→      motionSmoothing,
   366→      generatedAt: new Date().toISOString()
   367→    }
   368→  };
   369→}
   370→
   371→/**
   372→ * Generate FFmpeg filter for reframe
   373→ */
   374→function generateFFmpegFilter(crops, aspect, videoInfo) {
   375→  if (crops.static) {
   376→    // Static crop
   377→    const crop = crops.crop;
   378→    return `crop=${crop.pixelWidth}:${crop.pixelHeight}:${crop.pixelX}:${crop.pixelY},scale=${aspect.width}:${aspect.height}`;
   379→  }
   380→
   381→  // For motion crops, would need complex filter with keyframes
   382→  // Return simplified version
   383→  const firstCrop = crops.keyframes[0]?.crop;
   384→  if (firstCrop) {
   385→    return `crop=${firstCrop.pixelWidth}:${firstCrop.pixelHeight}:${firstCrop.pixelX}:${firstCrop.pixelY},scale=${aspect.width}:${aspect.height}`;
   386→  }
   387→
   388→  // Fallback center crop
   389→  const targetHeight = videoInfo.height;
   390→  const targetWidth = Math.round(targetHeight * aspect.ratio);
   391→  const cropX = Math.round((videoInfo.width - targetWidth) / 2);
   392→
   393→  return `crop=${targetWidth}:${targetHeight}:${cropX}:0,scale=${aspect.width}:${aspect.height}`;
   394→}
   395→
   396→/**
   397→ * Get available platforms and aspect ratios
   398→ */
   399→function getPlatformPresets() {
   400→  return {
   401→    aspectRatios: Object.values(ASPECT_RATIOS).map(a => ({
   402→      id: a.id,
   403→      name: a.name,
   404→      ratio: a.ratio,
   405→      dimensions: { width: a.width, height: a.height }
   406→    })),
   407→    platforms: Object.values(PLATFORM_PRESETS).map(p => ({
   408→      id: p.id,
   409→      name: p.name,
   410→      aspectRatio: p.aspectRatio,
   411→      maxDuration: p.maxDuration
   412→    })),
   413→    defaults: {
   414→      quality: 'high',
   415→      motionSmoothing: 0.3
   416→    }
   417→  };
   418→}
   419→
   420→// ============================================================================
   421→// HELPER FUNCTIONS
   422→// ============================================================================
   423→
   424→/**
   425→ * Linear interpolation
   426→ */
   427→function lerp(a, b, t) {
   428→  return a + (b - a) * t;
   429→}
   430→
   431→// ============================================================================
   432→// EXPORTS
   433→// ============================================================================
   434→
   435→module.exports = {
   436→  analyzeForReframe,
   437→  calculateReframeCrops,
   438→  generateMotionPath,
   439→  getSafeZones,
   440→  batchExportFormats,
   441→  getPlatformPresets,
   442→  // Exposed for testing
   443→  ASPECT_RATIOS,
   444→  PLATFORM_PRESETS,
   445→  lerp,
   446→  generateFFmpegFilter
   447→};
   448→

<system-reminder>
Whenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.
</system-reminder>
