     1→/**
     2→ * SPLICE Backend Server
     3→ *
     4→ * Main entry point for the SPLICE backend API.
     5→ * Orchestrates the audio analysis pipeline.
     6→ *
     7→ * Slices:
     8→ * - Slice 4: Transcription (services/transcription.js)
     9→ * - Slice 5: Take Detection (services/takeDetection.js)
    10→ */
    11→
    12→/* global setTimeout, setInterval */
    13→
    14→require('dotenv').config();
    15→
    16→const express = require('express');
    17→const cors = require('cors');
    18→const fs = require('fs');
    19→const fsPromises = require('fs').promises;
    20→const https = require('https');
    21→const http = require('http');
    22→const path = require('path');
    23→
    24→// Async file existence check (non-blocking)
    25→async function fileExists(filePath) {
    26→  try {
    27→    await fsPromises.access(filePath, fs.constants.R_OK);
    28→    return true;
    29→  } catch {
    30→    return false;
    31→  }
    32→}
    33→
    34→// Check if running in production (Railway injects RAILWAY_ENVIRONMENT)
    35→const isProduction = process.env.NODE_ENV === 'production' || process.env.RAILWAY_ENVIRONMENT;
    36→
    37→// Import slice services
    38→const { transcribeAudio, transcribeWithWords } = require('./services/transcription');
    39→const { detectTakes } = require('./services/takeDetection');
    40→const { detectSilences } = require('./services/silenceDetection');
    41→const { detectAudioSilences, isFFprobeInstalled, getAudioDuration } = require('./services/ffprobeSilence');
    42→const { detectSilencesRMS, sensitivityToParams } = require('./services/rmsSilenceDetection');
    43→const {
    44→  detectProfanity,
    45→  getProfanityList,
    46→  getSupportedLanguages,
    47→  getAvailableBleepSounds,
    48→  parseWordList
    49→} = require('./services/profanityDetection');
    50→const {
    51→  detectStutters,
    52→  detectAllRepetitions
    53→} = require('./services/repetitionDetection');
    54→const {
    55→  analyzeMultitrack,
    56→  autoBalanceMultitrack
    57→} = require('./services/multitrackAnalysis');
    58→const {
    59→  toSRT,
    60→  toVTT,
    61→  toPlainText,
    62→  toJSON,
    63→  exportToFile,
    64→  getSupportedFormats
    65→} = require('./services/captionExporter');
    66→const { processXMLFile } = require('./services/xmlProcessor');
    67→const { isolateVocals, isReplicateConfigured } = require('./services/vocalIsolation');
    68→const { generateCutList, generateTakesCutList, validateCutList } = require('./services/cutListGenerator');
    69→
    70→// Usage tracking and billing
    71→const usageTracking = require('./services/usageTracking');
    72→// Rate limiter for usage-based endpoints
    73→const { requireCredits } = require('./middleware/rateLimiter');
    74→// Referral system
    75→const referralService = require('./services/referralService');
    76→// License key system
    77→const licenseService = require('./services/licenseService');
    78→
    79→// Maximum file size for audio processing (500MB)
    80→const MAX_FILE_SIZE_BYTES = 500 * 1024 * 1024;
    81→
    82→/**
    83→ * Validate file size to prevent OOM crashes
    84→ * @param {string} filePath - Path to file
    85→ * @returns {Promise<{valid: boolean, size?: number, error?: string}>}
    86→ */
    87→async function validateFileSize(filePath) {
    88→  try {
    89→    const stats = await require('fs').promises.stat(filePath);
    90→    if (stats.size > MAX_FILE_SIZE_BYTES) {
    91→      return {
    92→        valid: false,
    93→        size: stats.size,
    94→        error: `File too large (${(stats.size / 1024 / 1024).toFixed(1)}MB). Maximum allowed: ${MAX_FILE_SIZE_BYTES / 1024 / 1024}MB`
    95→      };
    96→    }
    97→    return { valid: true, size: stats.size };
    98→  } catch (err) {
    99→    return { valid: false, error: `Cannot access file: ${err.message}` };
   100→  }
   101→}
   102→
   103→// Stripe for webhooks
   104→const Stripe = require('stripe');
   105→const stripe = new Stripe(process.env.STRIPE_SECRET_KEY);
   106→
   107→// =============================================================================
   108→// Server Configuration
   109→// =============================================================================
   110→
   111→const app = express();
   112→const PORT = process.env.PORT || 3847;
   113→
   114→// HTTPS certificates (generated by mkcert) - only for local development
   115→let httpsOptions = null;
   116→if (!isProduction) {
   117→  const keyPath = path.join(__dirname, 'localhost+1-key.pem');
   118→  const certPath = path.join(__dirname, 'localhost+1.pem');
   119→  if (fs.existsSync(keyPath) && fs.existsSync(certPath)) {
   120→    httpsOptions = {
   121→      key: fs.readFileSync(keyPath),
   122→      cert: fs.readFileSync(certPath)
   123→    };
   124→  }
   125→}
   126→
   127→app.use(cors());
   128→
   129→// Helper to determine tier from price ID with logging
   130→function getTierFromPriceId(priceId) {
   131→  if (priceId === process.env.STRIPE_PRICE_STARTER) return 'starter';
   132→  if (priceId === process.env.STRIPE_PRICE_PRO) return 'pro';
   133→  if (priceId === process.env.STRIPE_PRICE_TEAM) return 'team';
   134→
   135→  // Log unknown price ID for debugging
   136→  console.warn(`[SPLICE] Unknown price ID: ${priceId} - defaulting to starter tier`);
   137→  return 'starter';
   138→}
   139→
   140→// Stripe webhook needs raw body - must be before express.json()
   141→app.post('/webhooks/stripe', express.raw({ type: 'application/json' }), async (req, res) => {
   142→  const sig = req.headers['stripe-signature'];
   143→  const webhookSecret = process.env.STRIPE_WEBHOOK_SECRET;
   144→
   145→  let event;
   146→
   147→  try {
   148→    if (webhookSecret) {
   149→      event = stripe.webhooks.constructEvent(req.body, sig, webhookSecret);
   150→    } else if (isProduction) {
   151→      // SECURITY: Reject unsigned webhooks in production
   152→      console.error('[SPLICE] CRITICAL: STRIPE_WEBHOOK_SECRET not set in production');
   153→      return res.status(500).json({ error: 'Webhook configuration error: secret not configured' });
   154→    } else {
   155→      // For local development testing only
   156→      // req.body is a Buffer from express.raw(), convert to string for JSON.parse
   157→      const bodyString = typeof req.body === 'string' ? req.body : req.body.toString('utf8');
   158→      event = JSON.parse(bodyString);
   159→      console.warn('[SPLICE] Warning: Processing webhook without signature verification (dev only)');
   160→    }
   161→  } catch (err) {
   162→    console.error('[SPLICE] Webhook signature verification failed:', err.message);
   163→    return res.status(400).json({ error: 'Webhook signature verification failed' });
   164→  }
   165→
   166→  console.log(`[SPLICE] Webhook received: ${event.type} (${event.id})`);
   167→
   168→  // Idempotency check - skip if already processed
   169→  if (await usageTracking.isEventProcessed(event.id)) {
   170→    console.log(`[SPLICE] Event ${event.id} already processed, skipping`);
   171→    return res.json({ received: true, skipped: true });
   172→  }
   173→
   174→  try {
   175→    switch (event.type) {
   176→      case 'customer.subscription.created':
   177→      case 'customer.subscription.updated': {
   178→        const subscription = event.data.object;
   179→        const customerId = subscription.customer;
   180→
   181→        // Validate customerId
   182→        if (!customerId) {
   183→          console.error('[SPLICE] Missing customer ID in subscription event');
   184→          return res.status(400).json({ error: 'Missing customer ID' });
   185→        }
   186→
   187→        // Get tier from price ID
   188→        const priceId = subscription.items?.data?.[0]?.price?.id;
   189→        const tier = getTierFromPriceId(priceId);
   190→
   191→        // Update user tier and reset hours
   192→        await usageTracking.updateTier(customerId, tier);
   193→        console.log(`[SPLICE] Updated customer ${customerId} to tier: ${tier}`);
   194→
   195→        // Generate license key for new subscriptions with retry and delivery
   196→        if (event.type === 'customer.subscription.created') {
   197→          let licenseResult = null;
   198→          let retryCount = 0;
   199→          const maxRetries = 3;
   200→
   201→          // Retry mechanism for license key generation
   202→          while (retryCount < maxRetries) {
   203→            licenseResult = await licenseService.generateLicenseKey(customerId);
   204→            if (licenseResult.success) {
   205→              break;
   206→            }
   207→            retryCount++;
   208→            console.warn(`[SPLICE] License key generation attempt ${retryCount}/${maxRetries} failed: ${licenseResult.error}`);
   209→            // Wait before retry (exponential backoff)
   210→            if (retryCount < maxRetries) {
   211→              await new Promise(resolve => setTimeout(resolve, 1000 * retryCount));
   212→            }
   213→          }
   214→
   215→          if (licenseResult && licenseResult.success) {
   216→            console.log(`[SPLICE] Generated license key for ${customerId}: ${licenseResult.key}`);
   217→
   218→            // Store license key in Stripe subscription metadata as backup
   219→            try {
   220→              await stripe.subscriptions.update(subscription.id, {
   221→                metadata: {
   222→                  license_key: licenseResult.key,
   223→                  license_generated_at: new Date().toISOString()
   224→                }
   225→              });
   226→              console.log(`[SPLICE] Stored license key in Stripe metadata for subscription ${subscription.id}`);
   227→            } catch (metaErr) {
   228→              console.error(`[SPLICE] Failed to store license key in Stripe metadata:`, metaErr.message);
   229→            }
   230→
   231→            // Get customer email and send license key
   232→            try {
   233→              const customer = await stripe.customers.retrieve(customerId);
   234→              if (customer.email) {
   235→                // Log email delivery (placeholder for actual email service)
   236→                console.log(`[SPLICE] License key ready for delivery to ${customer.email}: ${licenseResult.key}`);
   237→                // TODO: Integrate with email service (SendGrid, SES, etc.)
   238→                // await sendLicenseKeyEmail(customer.email, licenseResult.key, tier);
   239→
   240→                // Store email in database for reference
   241→                await usageTracking.updateTier(customerId, tier, customer.email);
   242→              } else {
   243→                console.warn(`[SPLICE] No email found for customer ${customerId}`);
   244→              }
   245→            } catch (emailErr) {
   246→              console.error(`[SPLICE] Error getting customer email:`, emailErr.message);
   247→            }
   248→          } else {
   249→            console.error(`[SPLICE] Failed to generate license key after ${maxRetries} attempts: ${licenseResult?.error || 'Unknown error'}`);
   250→          }
   251→        }
   252→        break;
   253→      }
   254→
   255→      case 'customer.subscription.deleted': {
   256→        const subscription = event.data.object;
   257→        const customerId = subscription.customer;
   258→
   259→        // Validate customerId
   260→        if (!customerId) {
   261→          console.error('[SPLICE] Missing customer ID in subscription.deleted event');
   262→          return res.status(400).json({ error: 'Missing customer ID' });
   263→        }
   264→
   265→        // Downgrade to cancelled (0 hours)
   266→        await usageTracking.updateTier(customerId, 'cancelled');
   267→        console.log(`[SPLICE] Subscription cancelled for customer ${customerId}`);
   268→        break;
   269→      }
   270→
   271→      case 'invoice.payment_succeeded': {
   272→        const invoice = event.data.object;
   273→        const customerId = invoice.customer;
   274→        const subscriptionId = invoice.subscription;
   275→
   276→        // Validate customerId
   277→        if (!customerId) {
   278→          console.error('[SPLICE] Missing customer ID in invoice event');
   279→          return res.status(400).json({ error: 'Missing customer ID' });
   280→        }
   281→
   282→        // Reset hours on successful payment (new billing period)
   283→        if (subscriptionId) {
   284→          const subscription = await stripe.subscriptions.retrieve(subscriptionId);
   285→          const priceId = subscription.items?.data?.[0]?.price?.id;
   286→          const tier = getTierFromPriceId(priceId);
   287→
   288→          await usageTracking.resetHours(customerId, tier);
   289→          console.log(`[SPLICE] Reset hours for customer ${customerId} (tier: ${tier})`);
   290→        }
   291→        break;
   292→      }
   293→
   294→      default:
   295→        console.log(`[SPLICE] Unhandled event type: ${event.type}`);
   296→    }
   297→
   298→    // Record event as processed (idempotency)
   299→    await usageTracking.recordWebhookEvent(event.id, event.type);
   300→
   301→    res.json({ received: true });
   302→  } catch (err) {
   303→    console.error('[SPLICE] Webhook handler error:', err);
   304→    res.status(500).json({ error: err.message });
   305→  }
   306→});
   307→
   308→app.use(express.json());
   309→
   310→// =============================================================================
   311→// Routes
   312→// =============================================================================
   313→
   314→/**
   315→ * GET / - API information
   316→ */
   317→app.get('/', (req, res) => {
   318→  res.json({
   319→    service: 'splice-backend',
   320→    version: '0.3.0',
   321→    endpoints: {
   322→      'GET /': 'This info',
   323→      'GET /health': 'Health check',
   324→      'GET /ffprobe-check': 'Check if FFprobe is installed',
   325→      'GET /replicate-check': 'Check if Replicate API is configured',
   326→      'POST /analyze': 'Analyze WAV file { wavPath }',
   327→      'POST /silences': 'Detect silences via Whisper gaps { wavPath, threshold: 0.5 }',
   328→      'POST /silences-audio': 'Detect silences via FFprobe { wavPath, threshold: -30, minDuration: 0.5, padding: 0.1 }',
   329→      'POST /silences-rms': 'Detect silences via RMS analysis { wavPath, threshold: -30, minSilenceLength: 0.5, paddingStart: 0.1, paddingEnd: 0.05, autoThreshold: false, sensitivity: 50 }',
   330→      'POST /profanity': 'Detect profanity in transcript { wavPath, language: "en", customBlocklist: [], customAllowlist: [] }',
   331→      'GET /profanity/languages': 'Get supported languages for profanity detection',
   332→      'GET /profanity/bleeps': 'Get available bleep sounds',
   333→      'POST /repetitions': 'Detect phrase repetitions and stutters { wavPath, phraseSize: 5, tolerance: 0.7, useOpenAI: false }',
   334→      'POST /fillers': 'Detect filler words (um, uh, like, etc.) { wavPath, customFillers: [] }',
   335→      'POST /stutters': 'Detect single-word stutters only { wavPath, minRepeats: 2 }',
   336→      'POST /export/captions': 'Export transcript to caption format { wavPath, format: srt|vtt|txt|json, outputPath? }',
   337→      'GET /export/formats': 'Get supported caption export formats',
   338→      'POST /multitrack': 'Analyze multiple audio tracks for multicam { audioPaths: [], speakerNames: [], videoTrackMapping: {} }',
   339→      'POST /multitrack/auto-balance': 'Auto-balance speaker screentime { audioPaths: [], speakerNames: [] }',
   340→      'POST /process-xml': 'Process FCP XML { xmlPath, silences, removeGaps: true }',
   341→      'POST /cut-list': 'Generate JSON cut list for DOM building (v3.5) { sourceName, sourcePath, duration, silences, takes?, settings? }',
   342→      'POST /cut-list/takes': 'Generate cut list keeping only takes { sourceName, sourcePath, duration, takes, settings? }',
   343→      'POST /isolate-vocals': 'Isolate vocals from audio { audioPath }',
   344→      'POST /batch/silences': 'Batch process multiple files for silence detection { files: [], options: {} }',
   345→      'GET /batch/status/:jobId': 'Get batch job status',
   346→      'GET /batch/results/:jobId': 'Get full batch job results',
   347→      'GET /batch/jobs': 'List all batch jobs',
   348→      'DELETE /batch/:jobId': 'Delete a batch job',
   349→      'GET /credits': 'Get user credit balance (requires x-stripe-customer-id header)',
   350→      'GET /usage-history': 'Get usage history (requires x-stripe-customer-id header)',
   351→      'POST /webhooks/stripe': 'Stripe webhook endpoint',
   352→      'GET /referral/code': 'Get or create referral code for user',
   353→      'POST /referral/validate': 'Validate a referral code',
   354→      'POST /referral/apply': 'Apply referral code at signup',
   355→      'GET /referral/stats': 'Get referral statistics for user',
   356→      'POST /license/activate': 'Activate license key { key: "SPLICE-XXXX-XXXX-XXXX" }',
   357→      'GET /license/key': 'Get license key for customer (requires x-stripe-customer-id)',
   358→      'POST /license/resend': 'Resend license key to customer email { customerId? }'
   359→    }
   360→  });
   361→});
   362→
   363→/**
   364→ * GET /health - Health check
   365→ */
   366→app.get('/health', (req, res) => {
   367→  res.json({ status: 'ok', service: 'splice-backend' });
   368→});
   369→
   370→/**
   371→ * POST /analyze - Main analysis endpoint
   372→ *
   373→ * Pipeline:
   374→ * 1. Validate input (wavPath)
   375→ * 2. Slice 4: Transcribe audio with Whisper
   376→ * 3. Slice 5: Detect takes with GPT-4o-mini
   377→ * 4. Return combined results
   378→ */
   379→app.post('/analyze', requireCredits({ endpoint: 'analyze' }), async (req, res) => {
   380→  const { wavPath } = req.body;
   381→
   382→  // Validate input
   383→  if (!wavPath) {
   384→    return res.status(400).json({ error: 'wavPath is required' });
   385→  }
   386→
   387→  if (!(await fileExists(wavPath))) {
   388→    return res.status(404).json({ error: `File not found: ${wavPath}` });
   389→  }
   390→
   391→  console.log(`[SPLICE] Analyzing: ${wavPath}`);
   392→
   393→  try {
   394→    // Slice 4 - GPT-4o-mini transcription
   395→    const transcript = await transcribeAudio(wavPath);
   396→
   397→    // Slice 5 - GPT-4o-mini take detection
   398→    const takes = await detectTakes(transcript);
   399→
   400→    // Deduct usage based on audio duration
   401→    const audioDuration = transcript.duration || 0;
   402→    let balance = null;
   403→    if (audioDuration > 0 && req.deductUsage) {
   404→      balance = await req.deductUsage(audioDuration);
   405→    }
   406→
   407→    res.json({
   408→      success: true,
   409→      wavPath,
   410→      transcript,
   411→      takes,
   412→      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
   413→    });
   414→  } catch (err) {
   415→    console.error('[SPLICE] Error:', err);
   416→    res.status(500).json({ error: err.message });
   417→  }
   418→});
   419→
   420→/**
   421→ * POST /silences - Detect silent gaps in audio
   422→ *
   423→ * Pipeline:
   424→ * 1. Transcribe audio with Whisper (cached)
   425→ * 2. Analyze gaps between segments
   426→ * 3. Return silence regions
   427→ */
   428→app.post('/silences', requireCredits({ endpoint: 'silences' }), async (req, res) => {
   429→  const { wavPath, threshold = 0.5 } = req.body;
   430→
   431→  if (!wavPath) {
   432→    return res.status(400).json({ error: 'wavPath is required' });
   433→  }
   434→
   435→  if (!(await fileExists(wavPath))) {
   436→    return res.status(404).json({ error: `File not found: ${wavPath}` });
   437→  }
   438→
   439→  console.log(`[SPLICE] Detecting silences: ${wavPath} (threshold: ${threshold}s)`);
   440→
   441→  try {
   442→    const transcript = await transcribeAudio(wavPath);
   443→    const silences = detectSilences(transcript.segments, threshold);
   444→
   445→    // Deduct usage based on audio duration
   446→    const audioDuration = transcript.duration || 0;
   447→    let balance = null;
   448→    if (audioDuration > 0 && req.deductUsage) {
   449→      balance = await req.deductUsage(audioDuration);
   450→    }
   451→
   452→    res.json({
   453→      success: true,
   454→      wavPath,
   455→      threshold,
   456→      silences,
   457→      count: silences.length,
   458→      totalSilenceDuration: silences.reduce((sum, s) => sum + s.duration, 0).toFixed(2),
   459→      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
   460→    });
   461→  } catch (err) {
   462→    console.error('[SPLICE] Silence detection error:', err);
   463→    res.status(500).json({ error: err.message });
   464→  }
   465→});
   466→
   467→/**
   468→ * POST /silences-audio - Detect silences using FFprobe audio analysis
   469→ *
   470→ * Uses actual audio levels (dB threshold) instead of transcript gaps.
   471→ * More accurate for detecting silence vs background noise.
   472→ */
   473→app.post('/silences-audio', requireCredits({ endpoint: 'silences-audio' }), async (req, res) => {
   474→  const {
   475→    wavPath,
   476→    threshold = -30,
   477→    minDuration = 0.5,
   478→    padding = 0.1
   479→  } = req.body;
   480→
   481→  if (!wavPath) {
   482→    return res.status(400).json({ error: 'wavPath is required' });
   483→  }
   484→
   485→  if (!(await fileExists(wavPath))) {
   486→    return res.status(404).json({ error: `File not found: ${wavPath}` });
   487→  }
   488→
   489→  // Check FFprobe availability
   490→  const ffprobeAvailable = await isFFprobeInstalled();
   491→  if (!ffprobeAvailable) {
   492→    return res.status(500).json({
   493→      error: 'FFprobe not installed. Run: brew install ffmpeg'
   494→    });
   495→  }
   496→
   497→  console.log(`[SPLICE] FFprobe silence detection: ${wavPath} (threshold: ${threshold}dB, min: ${minDuration}s)`);
   498→
   499→  try {
   500→    const silences = await detectAudioSilences(wavPath, {
   501→      threshold,
   502→      minDuration,
   503→      padding
   504→    });
   505→
   506→    const totalDuration = silences.reduce((sum, s) => sum + s.duration, 0);
   507→
   508→    // Deduct usage based on audio duration
   509→    let balance = null;
   510→    try {
   511→      const audioDuration = await getAudioDuration(wavPath);
   512→      if (audioDuration > 0 && req.deductUsage) {
   513→        balance = await req.deductUsage(audioDuration);
   514→      }
   515→    } catch (durErr) {
   516→      console.warn('[SPLICE] Could not get audio duration for billing:', durErr.message);
   517→    }
   518→
   519→    res.json({
   520→      success: true,
   521→      wavPath,
   522→      threshold,
   523→      minDuration,
   524→      padding,
   525→      silences,
   526→      count: silences.length,
   527→      totalSilenceDuration: totalDuration.toFixed(2),
   528→      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
   529→    });
   530→  } catch (err) {
   531→    console.error('[SPLICE] FFprobe silence detection error:', err);
   532→    res.status(500).json({ error: err.message });
   533→  }
   534→});
   535→
   536→/**
   537→ * POST /silences-rms - Detect silences using RMS audio analysis
   538→ *
   539→ * Advanced silence detection with:
   540→ * - RMS (Root Mean Square) audio level analysis
   541→ * - Auto-threshold detection from audio histogram
   542→ * - Configurable padding (before/after cuts)
   543→ * - Sensitivity slider mapping (0-100)
   544→ *
   545→ * Options:
   546→ * - threshold: dBFS threshold (-60 to -20, default: -30)
   547→ * - minSilenceLength: Minimum silence duration in seconds (default: 0.5)
   548→ * - seekStep: Analysis window step in seconds (default: 0.05)
   549→ * - paddingStart: Buffer before silence in seconds (default: 0.1)
   550→ * - paddingEnd: Buffer after silence in seconds (default: 0.05)
   551→ * - autoThreshold: Auto-detect optimal threshold (default: false)
   552→ * - sensitivity: UI sensitivity 0-100 (overrides other params if provided)
   553→ */
   554→app.post('/silences-rms', requireCredits({ endpoint: 'silences-rms' }), async (req, res) => {
   555→  const { wavPath, sensitivity, ...manualOptions } = req.body;
   556→
   557→  if (!wavPath) {
   558→    return res.status(400).json({ error: 'wavPath is required' });
   559→  }
   560→
   561→  if (!(await fileExists(wavPath))) {
   562→    return res.status(404).json({ error: `File not found: ${wavPath}` });
   563→  }
   564→
   565→  // Validate file size to prevent OOM
   566→  const sizeCheck = await validateFileSize(wavPath);
   567→  if (!sizeCheck.valid) {
   568→    return res.status(413).json({ error: sizeCheck.error });
   569→  }
   570→
   571→  // Check FFprobe availability (needed for audio extraction)
   572→  const ffprobeAvailable = await isFFprobeInstalled();
   573→  if (!ffprobeAvailable) {
   574→    return res.status(500).json({
   575→      error: 'FFprobe not installed. Run: brew install ffmpeg'
   576→    });
   577→  }
   578→
   579→  // Build options - use sensitivity if provided, otherwise use manual options
   580→  let options = {};
   581→  if (typeof sensitivity === 'number') {
   582→    options = sensitivityToParams(sensitivity);
   583→    console.log(`[SPLICE] RMS detection with sensitivity ${sensitivity}`);
   584→  } else {
   585→    options = {
   586→      threshold: manualOptions.threshold ?? -30,
   587→      minSilenceLength: manualOptions.minSilenceLength ?? 0.5,
   588→      seekStep: manualOptions.seekStep ?? 0.05,
   589→      paddingStart: manualOptions.paddingStart ?? 0.1,
   590→      paddingEnd: manualOptions.paddingEnd ?? 0.05,
   591→      autoThreshold: manualOptions.autoThreshold ?? false,
   592→      mergeDistance: manualOptions.mergeDistance ?? 0.2
   593→    };
   594→  }
   595→
   596→  console.log(`[SPLICE] RMS silence detection: ${wavPath}`);
   597→
   598→  try {
   599→    const result = await detectSilencesRMS(wavPath, options);
   600→
   601→    // Deduct usage based on audio duration
   602→    const audioDuration = result.metadata?.audioDuration || 0;
   603→    let balance = null;
   604→    if (audioDuration > 0 && req.deductUsage) {
   605→      balance = await req.deductUsage(audioDuration);
   606→    }
   607→
   608→    res.json({
   609→      success: true,
   610→      wavPath,
   611→      ...result,
   612→      count: result.silences.length,
   613→      totalSilenceDuration: result.metadata.totalSilenceDuration.toFixed(2),
   614→      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
   615→    });
   616→  } catch (err) {
   617→    console.error('[SPLICE] RMS silence detection error:', err);
   618→    res.status(500).json({ error: err.message });
   619→  }
   620→});
   621→
   622→// =============================================================================
   623→// Profanity Detection Routes
   624→// =============================================================================
   625→
   626→/**
   627→ * POST /profanity - Detect profanity in audio/transcript
   628→ *
   629→ * Transcribes audio (if needed) and detects profanity words.
   630→ * Returns word-level and segment-level results for muting/bleeping.
   631→ *
   632→ * Options:
   633→ * - wavPath: Path to audio file (required)
   634→ * - transcript: Pre-existing transcript (optional, skips transcription)
   635→ * - language: Language code (en, es, fr, de) - default: en
   636→ * - customBlocklist: Array or comma-separated string of additional words to censor
   637→ * - customAllowlist: Array or comma-separated string of words to allow
   638→ * - frameRate: Frame rate for boundary alignment (default: 30)
   639→ */
   640→app.post('/profanity', requireCredits({ endpoint: 'profanity' }), async (req, res) => {
   641→  const {
   642→    wavPath,
   643→    transcript: providedTranscript,
   644→    language = 'en',
   645→    customBlocklist = [],
   646→    customAllowlist = [],
   647→    frameRate = 30
   648→  } = req.body;
   649→
   650→  if (!wavPath && !providedTranscript) {
   651→    return res.status(400).json({ error: 'wavPath or transcript is required' });
   652→  }
   653→
   654→  if (wavPath && !(await fileExists(wavPath))) {
   655→    return res.status(404).json({ error: `File not found: ${wavPath}` });
   656→  }
   657→
   658→  console.log(`[SPLICE] Profanity detection: ${wavPath || 'provided transcript'} (language: ${language})`);
   659→
   660→  try {
   661→    // Get or create transcript with word-level timestamps
   662→    let transcript = providedTranscript;
   663→    if (!transcript && wavPath) {
   664→      // Use transcribeWithWords for word-level timestamps required by profanity detection
   665→      transcript = await transcribeWithWords(wavPath);
   666→    }
   667→
   668→    // Validate transcript has words
   669→    if (!transcript || !transcript.words || transcript.words.length === 0) {
   670→      return res.status(400).json({
   671→        error: 'Transcript must contain word-level timing data',
   672→        hint: 'Ensure transcription returns words array with start/end times'
   673→      });
   674→    }
   675→
   676→    // Parse custom lists
   677→    const blocklist = parseWordList(customBlocklist);
   678→    const allowlist = parseWordList(customAllowlist);
   679→
   680→    // Detect profanity
   681→    const result = detectProfanity(transcript, {
   682→      language,
   683→      customBlocklist: blocklist,
   684→      customAllowlist: allowlist,
   685→      frameRate
   686→    });
   687→
   688→    // Deduct usage based on audio duration
   689→    const audioDuration = transcript.duration || 0;
   690→    let balance = null;
   691→    if (audioDuration > 0 && req.deductUsage) {
   692→      balance = await req.deductUsage(audioDuration);
   693→    }
   694→
   695→    res.json({
   696→      success: true,
   697→      wavPath,
   698→      ...result,
   699→      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
   700→    });
   701→  } catch (err) {
   702→    console.error('[SPLICE] Profanity detection error:', err);
   703→    res.status(500).json({ error: err.message });
   704→  }
   705→});
   706→
   707→/**
   708→ * GET /profanity/languages - Get supported languages
   709→ */
   710→app.get('/profanity/languages', (req, res) => {
   711→  res.json({
   712→    success: true,
   713→    languages: getSupportedLanguages()
   714→  });
   715→});
   716→
   717→/**
   718→ * GET /profanity/bleeps - Get available bleep sounds
   719→ */
   720→app.get('/profanity/bleeps', (req, res) => {
   721→  res.json({
   722→    success: true,
   723→    sounds: getAvailableBleepSounds()
   724→  });
   725→});
   726→
   727→/**
   728→ * GET /profanity/list/:language - Get default profanity list for a language
   729→ */
   730→app.get('/profanity/list/:language', (req, res) => {
   731→  const { language } = req.params;
   732→  const list = getProfanityList(language);
   733→
   734→  res.json({
   735→    success: true,
   736→    language,
   737→    wordCount: list.length,
   738→    // Return first 50 words as sample (full list is large)
   739→    sample: list.slice(0, 50),
   740→    note: 'Full list available but truncated for response size'
   741→  });
   742→});
   743→
   744→// =============================================================================
   745→// Repetition/Stutter Detection Routes
   746→// =============================================================================
   747→
   748→/**
   749→ * POST /repetitions - Detect phrase repetitions and stutters
   750→ *
   751→ * Analyzes transcript for repeated phrases and stutters.
   752→ * Returns segments that can be removed to clean up the edit.
   753→ *
   754→ * Options:
   755→ * - wavPath: Path to audio file (required unless transcript provided)
   756→ * - transcript: Pre-existing transcript (optional)
   757→ * - phraseSize: Words per comparison window (default: 5)
   758→ * - tolerance: Similarity threshold 0-1 (default: 0.7)
   759→ * - searchRadius: Words to search ahead (default: 100)
   760→ * - useOpenAI: Use OpenAI for boundary refinement (default: false)
   761→ * - includeStutters: Also detect single-word stutters (default: true)
   762→ */
   763→app.post('/repetitions', requireCredits({ endpoint: 'repetitions' }), async (req, res) => {
   764→  const {
   765→    wavPath,
   766→    transcript: providedTranscript,
   767→    phraseSize = 5,
   768→    tolerance = 0.7,
   769→    searchRadius = 100,
   770→    useOpenAI = false,
   771→    includeStutters = true
   772→  } = req.body;
   773→
   774→  if (!wavPath && !providedTranscript) {
   775→    return res.status(400).json({ error: 'wavPath or transcript is required' });
   776→  }
   777→
   778→  if (wavPath && !(await fileExists(wavPath))) {
   779→    return res.status(404).json({ error: `File not found: ${wavPath}` });
   780→  }
   781→
   782→  console.log(`[SPLICE] Repetition detection: ${wavPath || 'provided transcript'}`);
   783→
   784→  try {
   785→    // Get or create transcript with word-level timestamps
   786→    let transcript = providedTranscript;
   787→    if (!transcript && wavPath) {
   788→      // Use transcribeWithWords for word-level timestamps required by repetition detection
   789→      transcript = await transcribeWithWords(wavPath);
   790→    }
   791→
   792→    // Validate transcript has words
   793→    if (!transcript || !transcript.words || transcript.words.length === 0) {
   794→      return res.status(400).json({
   795→        error: 'Transcript must contain word-level timing data'
   796→      });
   797→    }
   798→
   799→    // Detect all repetitions (phrases + stutters)
   800→    const result = await detectAllRepetitions(transcript, {
   801→      phraseSize,
   802→      tolerance,
   803→      searchRadius,
   804→      useOpenAI
   805→    });
   806→
   807→    // Optionally filter out stutters
   808→    if (!includeStutters) {
   809→      result.stutters = [];
   810→      result.removalSegments = result.removalSegments.filter(s => s.type !== 'stutter');
   811→    }
   812→
   813→    // Deduct usage based on audio duration
   814→    const audioDuration = transcript.duration || 0;
   815→    let balance = null;
   816→    if (audioDuration > 0 && req.deductUsage) {
   817→      balance = await req.deductUsage(audioDuration);
   818→    }
   819→
   820→    res.json({
   821→      success: true,
   822→      wavPath,
   823→      ...result,
   824→      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
   825→    });
   826→  } catch (err) {
   827→    console.error('[SPLICE] Repetition detection error:', err);
   828→    res.status(500).json({ error: err.message });
   829→  }
   830→});
   831→
   832→/**
   833→ * POST /fillers - Detect filler words (um, uh, like, etc.)
   834→ *
   835→ * Transcribes audio and identifies filler words with timestamps.
   836→ * Returns segments that can be cut or reviewed for removal.
   837→ *
   838→ * Options:
   839→ * - wavPath: Path to audio file (required unless transcript provided)
   840→ * - transcript: Pre-existing transcript with word-level timing (optional)
   841→ * - customFillers: Additional filler words to detect (optional)
   842→ */
   843→app.post('/fillers', requireCredits({ endpoint: 'fillers' }), async (req, res) => {
   844→  const {
   845→    wavPath,
   846→    transcript: providedTranscript,
   847→    customFillers = []
   848→  } = req.body;
   849→
   850→  if (!wavPath && !providedTranscript) {
   851→    return res.status(400).json({ error: 'wavPath or transcript is required' });
   852→  }
   853→
   854→  if (wavPath && !(await fileExists(wavPath))) {
   855→    return res.status(404).json({ error: `File not found: ${wavPath}` });
   856→  }
   857→
   858→  console.log(`[SPLICE] Filler word detection: ${wavPath || 'provided transcript'}`);
   859→
   860→  try {
   861→    // Get or create transcript with word-level timestamps
   862→    let transcript = providedTranscript;
   863→    if (!transcript && wavPath) {
   864→      transcript = await transcribeWithWords(wavPath);
   865→    }
   866→
   867→    // Validate transcript has words
   868→    if (!transcript || !transcript.words || transcript.words.length === 0) {
   869→      return res.status(400).json({
   870→        error: 'Transcript must contain word-level timing data'
   871→      });
   872→    }
   873→
   874→    // Default filler words (common in English speech)
   875→    const defaultFillers = [
   876→      'um', 'uh', 'ah', 'er', 'eh',           // Hesitation sounds
   877→      'like', 'so', 'well', 'right',           // Discourse markers
   878→      'you know', 'i mean', 'basically',       // Filler phrases
   879→      'actually', 'literally', 'honestly',     // Overused qualifiers
   880→      'kind of', 'sort of', 'you see'          // Hedging phrases
   881→    ];
   882→
   883→    // Combine default + custom fillers (lowercase for matching)
   884→    const fillerSet = new Set([
   885→      ...defaultFillers,
   886→      ...customFillers.map(f => f.toLowerCase().trim())
   887→    ]);
   888→
   889→    // Detect filler words
   890→    const fillers = [];
   891→    const words = transcript.words;
   892→
   893→    for (let i = 0; i < words.length; i++) {
   894→      const word = words[i];
   895→      const normalizedWord = word.word.toLowerCase().replace(/[.,!?;:'"]/g, '').trim();
   896→
   897→      // Check single-word fillers
   898→      if (fillerSet.has(normalizedWord)) {
   899→        fillers.push({
   900→          word: word.word,
   901→          normalizedWord,
   902→          start: word.start,
   903→          end: word.end,
   904→          duration: word.end - word.start,
   905→          index: i,
   906→          type: 'filler'
   907→        });
   908→        continue;
   909→      }
   910→
   911→      // Check two-word phrases (e.g., "you know", "kind of")
   912→      if (i < words.length - 1) {
   913→        const nextWord = words[i + 1];
   914→        const twoWordPhrase = `${normalizedWord} ${nextWord.word.toLowerCase().replace(/[.,!?;:'"]/g, '').trim()}`;
   915→        if (fillerSet.has(twoWordPhrase)) {
   916→          fillers.push({
   917→            word: `${word.word} ${nextWord.word}`,
   918→            normalizedWord: twoWordPhrase,
   919→            start: word.start,
   920→            end: nextWord.end,
   921→            duration: nextWord.end - word.start,
   922→            index: i,
   923→            type: 'filler_phrase'
   924→          });
   925→          // Skip next word since it's part of this phrase
   926→          i++;
   927→        }
   928→      }
   929→    }
   930→
   931→    // Calculate total filler time
   932→    const totalFillerDuration = fillers.reduce((sum, f) => sum + f.duration, 0);
   933→    const audioDuration = transcript.duration || (words.length > 0 ? words[words.length - 1].end : 0);
   934→    const fillerPercentage = audioDuration > 0 ? (totalFillerDuration / audioDuration) * 100 : 0;
   935→
   936→    // Deduct usage based on audio duration
   937→    let balance = null;
   938→    if (audioDuration > 0 && req.deductUsage) {
   939→      balance = await req.deductUsage(audioDuration);
   940→    }
   941→
   942→    res.json({
   943→      success: true,
   944→      wavPath,
   945→      fillers,
   946→      metadata: {
   947→        totalWords: words.length,
   948→        fillerCount: fillers.length,
   949→        totalFillerDuration: parseFloat(totalFillerDuration.toFixed(3)),
   950→        audioDuration: parseFloat(audioDuration.toFixed(3)),
   951→        fillerPercentage: parseFloat(fillerPercentage.toFixed(2)),
   952→        fillersPerMinute: audioDuration > 0 ? parseFloat((fillers.length / (audioDuration / 60)).toFixed(2)) : 0
   953→      },
   954→      removalSegments: fillers.map(f => ({
   955→        start: f.start,
   956→        end: f.end,
   957→        duration: f.duration,
   958→        reason: `Filler: "${f.word}"`,
   959→        type: f.type
   960→      })),
   961→      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
   962→    });
   963→  } catch (err) {
   964→    console.error('[SPLICE] Filler detection error:', err);
   965→    res.status(500).json({ error: err.message });
   966→  }
   967→});
   968→
   969→/**
   970→ * POST /stutters - Detect single-word stutters only
   971→ *
   972→ * Focused detection for word-level stutters (e.g., "I I I think").
   973→ * Faster than full repetition detection.
   974→ */
   975→app.post('/stutters', requireCredits({ endpoint: 'stutters' }), async (req, res) => {
   976→  const {
   977→    wavPath,
   978→    transcript: providedTranscript,
   979→    options = {},
   980→    // Support both top-level and nested options for flexibility
   981→    minRepeats = options.minRepeats ?? 2,
   982→    maxGapMs = options.maxGapMs ?? 500,
   983→    ignoreFillers = options.ignoreFillers ?? true,
   984→    minWordLength = options.minWordLength ?? 1
   985→  } = req.body;
   986→
   987→  if (!wavPath && !providedTranscript) {
   988→    return res.status(400).json({ error: 'wavPath or transcript is required' });
   989→  }
   990→
   991→  if (wavPath && !(await fileExists(wavPath))) {
   992→    return res.status(404).json({ error: `File not found: ${wavPath}` });
   993→  }
   994→
   995→  console.log(`[SPLICE] Stutter detection: ${wavPath || 'provided transcript'}`);
   996→
   997→  try {
   998→    // Get or create transcript with word-level timestamps
   999→    let transcript = providedTranscript;
  1000→    if (!transcript && wavPath) {
  1001→      // Use transcribeWithWords for word-level timestamps required by stutter detection
  1002→      transcript = await transcribeWithWords(wavPath);
  1003→    }
  1004→
  1005→    // Validate transcript exists and has words array
  1006→    if (!transcript || !transcript.words) {
  1007→      return res.status(400).json({
  1008→        error: 'Transcript must contain word-level timing data'
  1009→      });
  1010→    }
  1011→
  1012→    // Empty transcript returns empty result (not an error)
  1013→    if (transcript.words.length === 0) {
  1014→      return res.json({
  1015→        success: true,
  1016→        stutters: [],
  1017→        metadata: { type: 'stutters', totalWords: 0, stutterCount: 0, totalRepeatedWords: 0 }
  1018→      });
  1019→    }
  1020→
  1021→    // Detect stutters only
  1022→    const result = detectStutters(transcript, {
  1023→      minRepeats,
  1024→      maxGapMs,
  1025→      ignoreFillers,
  1026→      minWordLength
  1027→    });
  1028→
  1029→    // Deduct usage based on audio duration
  1030→    const audioDuration = transcript.duration || 0;
  1031→    let balance = null;
  1032→    if (audioDuration > 0 && req.deductUsage) {
  1033→      balance = await req.deductUsage(audioDuration);
  1034→    }
  1035→
  1036→    res.json({
  1037→      success: true,
  1038→      wavPath,
  1039→      ...result,
  1040→      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
  1041→    });
  1042→  } catch (err) {
  1043→    console.error('[SPLICE] Stutter detection error:', err);
  1044→    res.status(500).json({ error: err.message });
  1045→  }
  1046→});
  1047→
  1048→// =============================================================================
  1049→// Caption Export Routes
  1050→// =============================================================================
  1051→
  1052→/**
  1053→ * POST /export/captions - Export transcript to caption format (SRT, VTT, etc.)
  1054→ *
  1055→ * Converts a transcript to the specified caption format.
  1056→ * Can optionally save to file.
  1057→ *
  1058→ * Options:
  1059→ * - wavPath: Path to audio file (to transcribe first)
  1060→ * - transcript: Pre-existing transcript with word-level timing
  1061→ * - format: Export format (srt, vtt, txt, json) - default: srt
  1062→ * - outputPath: Optional file path to save to
  1063→ * - maxWordsPerCaption: Max words per caption (default: 8)
  1064→ * - maxDuration: Max duration per caption in seconds (default: 5)
  1065→ */
  1066→app.post('/export/captions', requireCredits({ endpoint: 'export-captions' }), async (req, res) => {
  1067→  const {
  1068→    wavPath,
  1069→    transcript: providedTranscript,
  1070→    format = 'srt',
  1071→    outputPath = null,
  1072→    maxWordsPerCaption = 8,
  1073→    maxDuration = 5
  1074→  } = req.body;
  1075→
  1076→  if (!wavPath && !providedTranscript) {
  1077→    return res.status(400).json({ error: 'wavPath or transcript is required' });
  1078→  }
  1079→
  1080→  if (wavPath && !(await fileExists(wavPath))) {
  1081→    return res.status(404).json({ error: `File not found: ${wavPath}` });
  1082→  }
  1083→
  1084→  console.log(`[SPLICE] Caption export: ${wavPath || 'provided transcript'} -> ${format}`);
  1085→
  1086→  try {
  1087→    // Get or create transcript with word-level timestamps
  1088→    let transcript = providedTranscript;
  1089→    if (!transcript && wavPath) {
  1090→      transcript = await transcribeWithWords(wavPath);
  1091→    }
  1092→
  1093→    const exportOptions = { maxWordsPerCaption, maxDuration };
  1094→
  1095→    // Generate caption content based on format
  1096→    let content;
  1097→    let mimeType;
  1098→
  1099→    switch (format.toLowerCase()) {
  1100→      case 'srt':
  1101→        content = toSRT(transcript, exportOptions);
  1102→        mimeType = 'application/x-subrip';
  1103→        break;
  1104→      case 'vtt':
  1105→      case 'webvtt':
  1106→        content = toVTT(transcript, exportOptions);
  1107→        mimeType = 'text/vtt';
  1108→        break;
  1109→      case 'txt':
  1110→      case 'text':
  1111→        content = toPlainText(transcript, { ...exportOptions, includeTimestamps: true });
  1112→        mimeType = 'text/plain';
  1113→        break;
  1114→      case 'json':
  1115→        content = toJSON(transcript);
  1116→        mimeType = 'application/json';
  1117→        break;
  1118→      default:
  1119→        return res.status(400).json({
  1120→          error: `Unsupported format: ${format}`,
  1121→          supportedFormats: getSupportedFormats()
  1122→        });
  1123→    }
  1124→
  1125→    // Save to file if outputPath provided
  1126→    let savedPath = null;
  1127→    if (outputPath) {
  1128→      const result = await exportToFile(transcript, outputPath, format, exportOptions);
  1129→      savedPath = result.path;
  1130→      console.log(`[SPLICE] Saved captions to: ${savedPath}`);
  1131→    }
  1132→
  1133→    // Deduct usage based on audio duration
  1134→    const audioDuration = transcript.duration || 0;
  1135→    let balance = null;
  1136→    if (audioDuration > 0 && req.deductUsage) {
  1137→      balance = await req.deductUsage(audioDuration);
  1138→    }
  1139→
  1140→    res.json({
  1141→      success: true,
  1142→      format,
  1143→      content,
  1144→      mimeType,
  1145→      savedPath,
  1146→      wordCount: transcript.words?.length || 0,
  1147→      duration: transcript.duration || 0,
  1148→      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
  1149→    });
  1150→  } catch (err) {
  1151→    console.error('[SPLICE] Caption export error:', err);
  1152→    res.status(500).json({ error: err.message });
  1153→  }
  1154→});
  1155→
  1156→/**
  1157→ * GET /export/formats - Get supported export formats
  1158→ */
  1159→app.get('/export/formats', (req, res) => {
  1160→  res.json({
  1161→    success: true,
  1162→    formats: getSupportedFormats()
  1163→  });
  1164→});
  1165→
  1166→// =============================================================================
  1167→// Multitrack/Multicam Analysis Routes
  1168→// =============================================================================
  1169→
  1170→/**
  1171→ * POST /multitrack - Analyze multiple audio tracks for multicam editing
  1172→ *
  1173→ * Analyzes audio levels across multiple tracks to determine optimal
  1174→ * video angle selection based on who is speaking.
  1175→ *
  1176→ * Options:
  1177→ * - audioPaths: Array of paths to audio files (one per speaker) - required
  1178→ * - speakerNames: Array of speaker names (optional)
  1179→ * - videoTrackMapping: Object mapping speaker index to video track { 0: 0, 1: 1 }
  1180→ * - minShotDuration: Minimum seconds before next cut (default: 2.0)
  1181→ * - switchingFrequency: How often to allow cuts 0-100 (default: 50)
  1182→ * - wideShotEnabled: Enable wide shot detection (default: true)
  1183→ * - wideShotPercentage: Target % of wide shots (default: 20)
  1184→ * - wideShotTracks: Video track indices for wide shots
  1185→ * - cutawayEnabled: Enable cutaway insertion (default: false)
  1186→ * - cutawayTracks: Video track indices for cutaways
  1187→ * - speakerBoosts: Per-speaker dB adjustments { "Speaker 1": 5 }
  1188→ */
  1189→app.post('/multitrack', requireCredits({ endpoint: 'multitrack' }), async (req, res) => {
  1190→  const {
  1191→    audioPaths,
  1192→    speakerNames,
  1193→    videoTrackMapping = {},
  1194→    minShotDuration = 2.0,
  1195→    switchingFrequency = 50,
  1196→    wideShotEnabled = true,
  1197→    wideShotPercentage = 20,
  1198→    wideShotTracks = [],
  1199→    cutawayEnabled = false,
  1200→    cutawayTracks = [],
  1201→    speakerBoosts = {},
  1202→    frameRate = 30
  1203→  } = req.body;
  1204→
  1205→  // Validate audioPaths
  1206→  if (!audioPaths || !Array.isArray(audioPaths) || audioPaths.length === 0) {
  1207→    return res.status(400).json({ error: 'audioPaths array is required (at least 1 path)' });
  1208→  }
  1209→
  1210→  // Validate all files exist
  1211→  for (const audioPath of audioPaths) {
  1212→    if (!fs.existsSync(audioPath)) {
  1213→      return res.status(404).json({ error: `File not found: ${audioPath}` });
  1214→    }
  1215→  }
  1216→
  1217→  // Check FFprobe availability
  1218→  const ffprobeAvailable = await isFFprobeInstalled();
  1219→  if (!ffprobeAvailable) {
  1220→    return res.status(500).json({
  1221→      error: 'FFprobe not installed. Run: brew install ffmpeg'
  1222→    });
  1223→  }
  1224→
  1225→  console.log(`[SPLICE] Multitrack analysis: ${audioPaths.length} track(s)`);
  1226→
  1227→  try {
  1228→    const result = await analyzeMultitrack(audioPaths, {
  1229→      speakerNames: speakerNames || audioPaths.map((_, i) => `Speaker ${i + 1}`),
  1230→      videoTrackMapping,
  1231→      minShotDuration,
  1232→      switchingFrequency,
  1233→      wideShotEnabled,
  1234→      wideShotPercentage,
  1235→      wideShotTracks,
  1236→      cutawayEnabled,
  1237→      cutawayTracks,
  1238→      speakerBoosts,
  1239→      frameRate
  1240→    });
  1241→
  1242→    // Deduct usage based on total duration (use longest track)
  1243→    const audioDuration = result.metadata?.totalDuration || 0;
  1244→    let balance = null;
  1245→    if (audioDuration > 0 && req.deductUsage) {
  1246→      balance = await req.deductUsage(audioDuration);
  1247→    }
  1248→
  1249→    res.json({
  1250→      success: true,
  1251→      ...result,
  1252→      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
  1253→    });
  1254→  } catch (err) {
  1255→    console.error('[SPLICE] Multitrack analysis error:', err);
  1256→    res.status(500).json({ error: err.message });
  1257→  }
  1258→});
  1259→
  1260→/**
  1261→ * POST /multitrack/auto-balance - Auto-balance speaker screentime
  1262→ *
  1263→ * Automatically adjusts speaker boosts to achieve equal screentime distribution.
  1264→ * Runs multiple iterations to find optimal parameters.
  1265→ */
  1266→app.post('/multitrack/auto-balance', requireCredits({ endpoint: 'multitrack-auto-balance' }), async (req, res) => {
  1267→  const {
  1268→    audioPaths,
  1269→    speakerNames,
  1270→    videoTrackMapping = {},
  1271→    minShotDuration = 2.0,
  1272→    switchingFrequency = 50,
  1273→    wideShotEnabled = false, // Disable wide shots for balance calc
  1274→    frameRate = 30
  1275→  } = req.body;
  1276→
  1277→  // Validate audioPaths
  1278→  if (!audioPaths || !Array.isArray(audioPaths) || audioPaths.length < 2) {
  1279→    return res.status(400).json({ error: 'audioPaths array requires at least 2 tracks for balancing' });
  1280→  }
  1281→
  1282→  // Validate all files exist
  1283→  for (const audioPath of audioPaths) {
  1284→    if (!fs.existsSync(audioPath)) {
  1285→      return res.status(404).json({ error: `File not found: ${audioPath}` });
  1286→    }
  1287→  }
  1288→
  1289→  // Check FFprobe availability
  1290→  const ffprobeAvailable = await isFFprobeInstalled();
  1291→  if (!ffprobeAvailable) {
  1292→    return res.status(500).json({
  1293→      error: 'FFprobe not installed. Run: brew install ffmpeg'
  1294→    });
  1295→  }
  1296→
  1297→  console.log(`[SPLICE] Auto-balancing multitrack: ${audioPaths.length} track(s)`);
  1298→
  1299→  try {
  1300→    const result = await autoBalanceMultitrack(audioPaths, {
  1301→      speakerNames: speakerNames || audioPaths.map((_, i) => `Speaker ${i + 1}`),
  1302→      videoTrackMapping,
  1303→      minShotDuration,
  1304→      switchingFrequency,
  1305→      wideShotEnabled,
  1306→      frameRate
  1307→    });
  1308→
  1309→    // Deduct usage based on total duration
  1310→    const audioDuration = result.metadata?.totalDuration || 0;
  1311→    let balance = null;
  1312→    if (audioDuration > 0 && req.deductUsage) {
  1313→      balance = await req.deductUsage(audioDuration);
  1314→    }
  1315→
  1316→    res.json({
  1317→      success: true,
  1318→      ...result,
  1319→      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
  1320→    });
  1321→  } catch (err) {
  1322→    console.error('[SPLICE] Auto-balance error:', err);
  1323→    res.status(500).json({ error: err.message });
  1324→  }
  1325→});
  1326→
  1327→/**
  1328→ * POST /process-xml - Process FCP XML to split clips at silences
  1329→ *
  1330→ * Takes an FCP XML file and silence timestamps, splits clips
  1331→ * at silence boundaries, and optionally removes gaps.
  1332→ */
  1333→app.post('/process-xml', async (req, res) => {
  1334→  const {
  1335→    xmlPath,
  1336→    silences,
  1337→    removeGaps = true,
  1338→    outputPath = null
  1339→  } = req.body;
  1340→
  1341→  if (!xmlPath) {
  1342→    return res.status(400).json({ error: 'xmlPath is required' });
  1343→  }
  1344→
  1345→  if (!silences || !Array.isArray(silences)) {
  1346→    return res.status(400).json({ error: 'silences array is required' });
  1347→  }
  1348→
  1349→  if (!fs.existsSync(xmlPath)) {
  1350→    return res.status(404).json({ error: `XML file not found: ${xmlPath}` });
  1351→  }
  1352→
  1353→  console.log(`[SPLICE] Processing XML: ${xmlPath} with ${silences.length} silence(s)`);
  1354→
  1355→  try {
  1356→    const result = await processXMLFile(xmlPath, silences, {
  1357→      outputPath,
  1358→      removeGaps
  1359→    });
  1360→
  1361→    res.json({
  1362→      success: true,
  1363→      inputPath: xmlPath,
  1364→      outputPath: result.outputPath,
  1365→      stats: result.stats
  1366→    });
  1367→  } catch (err) {
  1368→    console.error('[SPLICE] XML processing error:', err);
  1369→    res.status(500).json({ error: err.message });
  1370→  }
  1371→});
  1372→
  1373→/**
  1374→ * POST /cut-list - Generate a JSON cut list for direct DOM building (v3.5)
  1375→ *
  1376→ * Takes silences and optionally takes, returns a cut list that the
  1377→ * plugin can use to build sequences directly via UXP APIs.
  1378→ *
  1379→ * Body:
  1380→ * - sourceName: Name of the source clip
  1381→ * - sourcePath: Full path to the source file
  1382→ * - duration: Total duration in seconds
  1383→ * - silences: Array of silence segments [{start, end, duration}]
  1384→ * - takes: (optional) Array of detected takes
  1385→ * - settings: (optional) Generation settings
  1386→ */
  1387→app.post('/cut-list', async (req, res) => {
  1388→  const {
  1389→    sourceName,
  1390→    sourcePath,
  1391→    duration,
  1392→    silences,
  1393→    takes = [],
  1394→    settings = {}
  1395→  } = req.body;
  1396→
  1397→  // Validate required fields
  1398→  if (!sourceName && !sourcePath) {
  1399→    return res.status(400).json({ error: 'sourceName or sourcePath is required' });
  1400→  }
  1401→
  1402→  if (typeof duration !== 'number' || duration <= 0) {
  1403→    return res.status(400).json({ error: 'duration must be a positive number' });
  1404→  }
  1405→
  1406→  if (!silences || !Array.isArray(silences)) {
  1407→    return res.status(400).json({ error: 'silences array is required' });
  1408→  }
  1409→
  1410→  console.log(`[SPLICE] Generating cut list for ${sourceName || sourcePath} (${silences.length} silences)`);
  1411→
  1412→  try {
  1413→    const cutList = generateCutList({
  1414→      sourceName: sourceName || path.basename(sourcePath),
  1415→      sourcePath,
  1416→      duration,
  1417→      silences,
  1418→      takes,
  1419→      settings
  1420→    });
  1421→
  1422→    // Validate the generated cut list
  1423→    const validation = validateCutList(cutList);
  1424→    if (!validation.valid) {
  1425→      return res.status(500).json({
  1426→        error: 'Generated cut list is invalid',
  1427→        validationErrors: validation.errors
  1428→      });
  1429→    }
  1430→
  1431→    res.json({
  1432→      success: true,
  1433→      cutList
  1434→    });
  1435→  } catch (err) {
  1436→    console.error('[SPLICE] Cut list generation error:', err);
  1437→    res.status(500).json({ error: err.message });
  1438→  }
  1439→});
  1440→
  1441→/**
  1442→ * POST /cut-list/takes - Generate a cut list that keeps only takes
  1443→ *
  1444→ * Alternative endpoint for "keep best takes only" workflow.
  1445→ */
  1446→app.post('/cut-list/takes', async (req, res) => {
  1447→  const {
  1448→    sourceName,
  1449→    sourcePath,
  1450→    duration,
  1451→    takes,
  1452→    settings = {}
  1453→  } = req.body;
  1454→
  1455→  // Validate required fields
  1456→  if (!sourceName && !sourcePath) {
  1457→    return res.status(400).json({ error: 'sourceName or sourcePath is required' });
  1458→  }
  1459→
  1460→  if (typeof duration !== 'number' || duration <= 0) {
  1461→    return res.status(400).json({ error: 'duration must be a positive number' });
  1462→  }
  1463→
  1464→  if (!takes || !Array.isArray(takes) || takes.length === 0) {
  1465→    return res.status(400).json({ error: 'takes array is required and must not be empty' });
  1466→  }
  1467→
  1468→  console.log(`[SPLICE] Generating takes cut list for ${sourceName || sourcePath} (${takes.length} takes)`);
  1469→
  1470→  try {
  1471→    const cutList = generateTakesCutList({
  1472→      sourceName: sourceName || path.basename(sourcePath),
  1473→      sourcePath,
  1474→      duration,
  1475→      takes,
  1476→      settings
  1477→    });
  1478→
  1479→    res.json({
  1480→      success: true,
  1481→      cutList
  1482→    });
  1483→  } catch (err) {
  1484→    console.error('[SPLICE] Takes cut list generation error:', err);
  1485→    res.status(500).json({ error: err.message });
  1486→  }
  1487→});
  1488→
  1489→/**
  1490→ * GET /ffprobe-check - Check if FFprobe is installed
  1491→ */
  1492→app.get('/ffprobe-check', async (req, res) => {
  1493→  const installed = await isFFprobeInstalled();
  1494→  res.json({
  1495→    installed,
  1496→    message: installed
  1497→      ? 'FFprobe is available'
  1498→      : 'FFprobe not found. Install with: brew install ffmpeg'
  1499→  });
  1500→});
  1501→
  1502→/**
  1503→ * GET /replicate-check - Check if Replicate API is configured
  1504→ */
  1505→app.get('/replicate-check', async (req, res) => {
  1506→  const configured = isReplicateConfigured();
  1507→  res.json({
  1508→    configured,
  1509→    message: configured
  1510→      ? 'Replicate API is configured'
  1511→      : 'REPLICATE_API_TOKEN not set. Add to .env file.'
  1512→  });
  1513→});
  1514→
  1515→/**
  1516→ * POST /isolate-vocals - Isolate vocals from audio using Demucs
  1517→ *
  1518→ * Uses Replicate's Demucs model to separate vocals from background audio.
  1519→ * Cost: ~$0.015/min of audio
  1520→ *
  1521→ * Tier access:
  1522→ * - Starter: No access (upgrade required)
  1523→ * - Pro: 2 hours included, then $0.08/min overage
  1524→ * - Team: 5 hours included, then $0.08/min overage
  1525→ */
  1526→app.post('/isolate-vocals', requireCredits({ endpoint: 'isolate-vocals' }), async (req, res) => {
  1527→  const { audioPath, stem = 'vocals', outputDir = null } = req.body;
  1528→  const stripeCustomerId = req.headers['x-stripe-customer-id'];
  1529→
  1530→  if (!audioPath) {
  1531→    return res.status(400).json({ error: 'audioPath is required' });
  1532→  }
  1533→
  1534→  if (!fs.existsSync(audioPath)) {
  1535→    return res.status(404).json({ error: `File not found: ${audioPath}` });
  1536→  }
  1537→
  1538→  // Check Replicate configuration
  1539→  if (!isReplicateConfigured()) {
  1540→    return res.status(500).json({
  1541→      error: 'Replicate API not configured. Set REPLICATE_API_TOKEN in .env'
  1542→    });
  1543→  }
  1544→
  1545→  // Get audio duration for billing
  1546→  let audioDurationSeconds = 0;
  1547→  try {
  1548→    audioDurationSeconds = await getAudioDuration(audioPath);
  1549→  } catch (err) {
  1550→    console.warn('[SPLICE] Could not get audio duration:', err.message);
  1551→  }
  1552→
  1553→  const audioDurationMinutes = audioDurationSeconds / 60;
  1554→
  1555→  // Check isolation access if customer ID provided
  1556→  if (stripeCustomerId) {
  1557→    const accessCheck = await usageTracking.checkIsolationAccess(stripeCustomerId, audioDurationMinutes);
  1558→
  1559→    if (!accessCheck.allowed) {
  1560→      return res.status(403).json({
  1561→        error: accessCheck.message,
  1562→        reason: accessCheck.reason,
  1563→        upgradeRequired: accessCheck.reason === 'upgrade_required'
  1564→      });
  1565→    }
  1566→
  1567→    console.log(`[SPLICE] Isolation access: ${accessCheck.message}`);
  1568→  }
  1569→
  1570→  console.log(`[SPLICE] Isolating vocals: ${audioPath} (${audioDurationMinutes.toFixed(1)} min)`);
  1571→
  1572→  try {
  1573→    const result = await isolateVocals(audioPath, {
  1574→      stem,
  1575→      outputDir: outputDir || undefined
  1576→    });
  1577→
  1578→    // Deduct isolation usage if customer ID provided
  1579→    let usageInfo = null;
  1580→    if (stripeCustomerId) {
  1581→      usageInfo = await usageTracking.deductIsolationUsage(
  1582→        stripeCustomerId,
  1583→        audioDurationSeconds,
  1584→        'isolate-vocals'
  1585→      );
  1586→      console.log(`[SPLICE] Isolation usage deducted: ${audioDurationMinutes.toFixed(1)} min`);
  1587→      if (usageInfo.isolationUsed?.overageCost > 0) {
  1588→        console.log(`[SPLICE] Overage cost: $${usageInfo.isolationUsed.overageCost.toFixed(2)}`);
  1589→      }
  1590→    }
  1591→
  1592→    res.json({
  1593→      success: true,
  1594→      inputPath: audioPath,
  1595→      outputPath: result.outputPath,
  1596→      stem: result.stem,
  1597→      processingTime: result.processingTime,
  1598→      availableStems: result.allStems,
  1599→      audioDurationMinutes,
  1600→      usage: usageInfo ? {
  1601→        isolationHoursRemaining: usageInfo.isolationHoursRemaining,
  1602→        overageCost: usageInfo.isolationUsed?.overageCost || 0
  1603→      } : null
  1604→    });
  1605→  } catch (err) {
  1606→    console.error('[SPLICE] Vocal isolation error:', err);
  1607→    res.status(500).json({ error: err.message });
  1608→  }
  1609→});
  1610→
  1611→// =============================================================================
  1612→// Batch Processing Routes
  1613→// =============================================================================
  1614→
  1615→// In-memory job queue for batch processing
  1616→const batchJobs = new Map();
  1617→
  1618→// Batch job limits to prevent memory leak
  1619→const MAX_BATCH_JOBS = 10000;
  1620→const BATCH_JOB_MAX_AGE_MS = 24 * 60 * 60 * 1000; // 24 hours
  1621→
  1622→/**
  1623→ * Generate a unique job ID
  1624→ */
  1625→function generateJobId() {
  1626→  return `batch_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
  1627→}
  1628→
  1629→/**
  1630→ * Clean up old batch jobs to prevent memory leak
  1631→ * Removes jobs older than 24 hours
  1632→ */
  1633→function cleanupOldBatchJobs() {
  1634→  const now = Date.now();
  1635→  let removedCount = 0;
  1636→
  1637→  for (const [jobId, job] of batchJobs.entries()) {
  1638→    const createdAt = new Date(job.createdAt).getTime();
  1639→    if (now - createdAt > BATCH_JOB_MAX_AGE_MS) {
  1640→      batchJobs.delete(jobId);
  1641→      removedCount++;
  1642→    }
  1643→  }
  1644→
  1645→  if (removedCount > 0) {
  1646→    console.log(`[SPLICE] Cleaned up ${removedCount} old batch job(s)`);
  1647→  }
  1648→}
  1649→
  1650→/**
  1651→ * Enforce max job limit by removing oldest completed jobs
  1652→ */
  1653→function enforceJobLimit() {
  1654→  if (batchJobs.size < MAX_BATCH_JOBS) return;
  1655→
  1656→  // Get completed jobs sorted by creation date (oldest first)
  1657→  const completedJobs = Array.from(batchJobs.entries())
  1658→    .filter(([_, job]) => job.status !== 'processing')
  1659→    .sort((a, b) => new Date(a[1].createdAt) - new Date(b[1].createdAt));
  1660→
  1661→  // Remove oldest completed jobs until under limit
  1662→  const toRemove = batchJobs.size - MAX_BATCH_JOBS + 1;
  1663→  for (let i = 0; i < Math.min(toRemove, completedJobs.length); i++) {
  1664→    batchJobs.delete(completedJobs[i][0]);
  1665→  }
  1666→
  1667→  console.log(`[SPLICE] Enforced job limit, removed ${Math.min(toRemove, completedJobs.length)} job(s)`);
  1668→}
  1669→
  1670→// Run cleanup every hour
  1671→setInterval(cleanupOldBatchJobs, 60 * 60 * 1000);
  1672→
  1673→/**
  1674→ * POST /batch/silences - Process multiple files for silence detection
  1675→ *
  1676→ * Creates a batch job that processes multiple audio files.
  1677→ * Returns a job ID for tracking progress.
  1678→ *
  1679→ * Body:
  1680→ * - files: Array of file paths to process
  1681→ * - options: Detection options (sensitivity, threshold, etc.)
  1682→ */
  1683→app.post('/batch/silences', requireCredits({ endpoint: 'batch-silences' }), async (req, res) => {
  1684→  const { files, options = {} } = req.body;
  1685→
  1686→  if (!files || !Array.isArray(files) || files.length === 0) {
  1687→    return res.status(400).json({ error: 'files array is required' });
  1688→  }
  1689→
  1690→  // Validate all files exist
  1691→  const missingFiles = files.filter(f => !fs.existsSync(f));
  1692→  if (missingFiles.length > 0) {
  1693→    return res.status(404).json({
  1694→      error: 'Some files not found',
  1695→      missingFiles
  1696→    });
  1697→  }
  1698→
  1699→  // Enforce job limit before creating new job
  1700→  enforceJobLimit();
  1701→
  1702→  const jobId = generateJobId();
  1703→
  1704→  // Initialize job with customer ID for usage tracking
  1705→  const job = {
  1706→    id: jobId,
  1707→    type: 'silences',
  1708→    status: 'processing',
  1709→    createdAt: new Date().toISOString(),
  1710→    stripeCustomerId: req.stripeCustomerId,  // Store for usage deduction
  1711→    files: files.map(f => ({
  1712→      path: f,
  1713→      status: 'pending',
  1714→      result: null,
  1715→      error: null
  1716→    })),
  1717→    options,
  1718→    progress: {
  1719→      total: files.length,
  1720→      completed: 0,
  1721→      failed: 0,
  1722→      percentage: 0
  1723→    },
  1724→    results: [],
  1725→    errors: [],
  1726→    totalUsageDeducted: 0  // Track total seconds deducted
  1727→  };
  1728→
  1729→  batchJobs.set(jobId, job);
  1730→  console.log(`[SPLICE] Batch job ${jobId} created with ${files.length} files`);
  1731→
  1732→  // Start processing in background
  1733→  processBatchJob(jobId);
  1734→
  1735→  res.json({
  1736→    success: true,
  1737→    jobId,
  1738→    message: `Batch job created with ${files.length} files`,
  1739→    statusUrl: `/batch/status/${jobId}`
  1740→  });
  1741→});
  1742→
  1743→/**
  1744→ * Process a batch job (runs in background)
  1745→ */
  1746→async function processBatchJob(jobId) {
  1747→  const job = batchJobs.get(jobId);
  1748→  if (!job) return;
  1749→
  1750→  const { sensitivity, ...manualOptions } = job.options;
  1751→
  1752→  // Build detection options
  1753→  let detectionOptions = {};
  1754→  if (typeof sensitivity === 'number') {
  1755→    detectionOptions = sensitivityToParams(sensitivity);
  1756→  } else {
  1757→    detectionOptions = {
  1758→      threshold: manualOptions.threshold ?? -30,
  1759→      minSilenceLength: manualOptions.minSilenceLength ?? 0.5,
  1760→      paddingStart: manualOptions.paddingStart ?? 0.1,
  1761→      paddingEnd: manualOptions.paddingEnd ?? 0.05,
  1762→      autoThreshold: manualOptions.autoThreshold ?? false
  1763→    };
  1764→  }
  1765→
  1766→  // Process files sequentially to avoid overwhelming the system
  1767→  for (let i = 0; i < job.files.length; i++) {
  1768→    const fileEntry = job.files[i];
  1769→    fileEntry.status = 'processing';
  1770→
  1771→    try {
  1772→      const result = await detectSilencesRMS(fileEntry.path, detectionOptions);
  1773→
  1774→      fileEntry.status = 'completed';
  1775→      fileEntry.result = {
  1776→        silences: result.silences,
  1777→        count: result.silences.length,
  1778→        totalSilenceDuration: result.metadata.totalSilenceDuration,
  1779→        audioDuration: result.metadata.audioDuration
  1780→      };
  1781→
  1782→      job.results.push({
  1783→        file: fileEntry.path,
  1784→        ...fileEntry.result
  1785→      });
  1786→
  1787→      // Deduct usage for this file
  1788→      const audioDuration = result.metadata?.audioDuration || 0;
  1789→      if (audioDuration > 0 && job.stripeCustomerId) {
  1790→        try {
  1791→          await usageTracking.deductUsage(job.stripeCustomerId, audioDuration, 'batch-silences');
  1792→          job.totalUsageDeducted += audioDuration;
  1793→        } catch (usageErr) {
  1794→          console.warn(`[SPLICE] Batch ${jobId}: Usage deduction failed:`, usageErr.message);
  1795→        }
  1796→      }
  1797→
  1798→      job.progress.completed++;
  1799→      console.log(`[SPLICE] Batch ${jobId}: ${i + 1}/${job.files.length} completed`);
  1800→    } catch (err) {
  1801→      fileEntry.status = 'failed';
  1802→      fileEntry.error = err.message;
  1803→
  1804→      job.errors.push({
  1805→        file: fileEntry.path,
  1806→        error: err.message
  1807→      });
  1808→
  1809→      job.progress.failed++;
  1810→      console.error(`[SPLICE] Batch ${jobId}: ${fileEntry.path} failed:`, err.message);
  1811→    }
  1812→
  1813→    // Update progress
  1814→    job.progress.percentage = Math.round(
  1815→      ((job.progress.completed + job.progress.failed) / job.progress.total) * 100
  1816→    );
  1817→  }
  1818→
  1819→  // Mark job as complete
  1820→  job.status = job.progress.failed === job.progress.total ? 'failed' :
  1821→               job.progress.failed > 0 ? 'completed_with_errors' : 'completed';
  1822→  job.completedAt = new Date().toISOString();
  1823→
  1824→  console.log(`[SPLICE] Batch job ${jobId} ${job.status}`);
  1825→}
  1826→
  1827→/**
  1828→ * GET /batch/status/:jobId - Get batch job status and results
  1829→ */
  1830→app.get('/batch/status/:jobId', (req, res) => {
  1831→  const { jobId } = req.params;
  1832→  const job = batchJobs.get(jobId);
  1833→
  1834→  if (!job) {
  1835→    return res.status(404).json({ error: 'Job not found' });
  1836→  }
  1837→
  1838→  res.json({
  1839→    success: true,
  1840→    job: {
  1841→      id: job.id,
  1842→      type: job.type,
  1843→      status: job.status,
  1844→      createdAt: job.createdAt,
  1845→      completedAt: job.completedAt,
  1846→      progress: job.progress,
  1847→      files: job.files.map(f => ({
  1848→        path: f.path,
  1849→        status: f.status,
  1850→        silenceCount: f.result?.count,
  1851→        error: f.error
  1852→      }))
  1853→    }
  1854→  });
  1855→});
  1856→
  1857→/**
  1858→ * GET /batch/results/:jobId - Get full results for a completed batch job
  1859→ */
  1860→app.get('/batch/results/:jobId', (req, res) => {
  1861→  const { jobId } = req.params;
  1862→  const job = batchJobs.get(jobId);
  1863→
  1864→  if (!job) {
  1865→    return res.status(404).json({ error: 'Job not found' });
  1866→  }
  1867→
  1868→  if (job.status === 'processing') {
  1869→    return res.status(202).json({
  1870→      success: false,
  1871→      message: 'Job still processing',
  1872→      progress: job.progress
  1873→    });
  1874→  }
  1875→
  1876→  res.json({
  1877→    success: true,
  1878→    jobId: job.id,
  1879→    status: job.status,
  1880→    progress: job.progress,
  1881→    results: job.results,
  1882→    errors: job.errors,
  1883→    summary: {
  1884→      totalFiles: job.progress.total,
  1885→      successful: job.progress.completed,
  1886→      failed: job.progress.failed,
  1887→      totalSilences: job.results.reduce((sum, r) => sum + (r.count || 0), 0),
  1888→      totalSilenceDuration: job.results.reduce((sum, r) => sum + (r.totalSilenceDuration || 0), 0)
  1889→    }
  1890→  });
  1891→});
  1892→
  1893→/**
  1894→ * DELETE /batch/:jobId - Cancel or delete a batch job
  1895→ */
  1896→app.delete('/batch/:jobId', (req, res) => {
  1897→  const { jobId } = req.params;
  1898→  const job = batchJobs.get(jobId);
  1899→
  1900→  if (!job) {
  1901→    return res.status(404).json({ error: 'Job not found' });
  1902→  }
  1903→
  1904→  // Note: This doesn't actually cancel in-progress processing
  1905→  // but prevents the job from being queried
  1906→  batchJobs.delete(jobId);
  1907→
  1908→  res.json({
  1909→    success: true,
  1910→    message: `Job ${jobId} deleted`
  1911→  });
  1912→});
  1913→
  1914→/**
  1915→ * GET /batch/jobs - List all batch jobs
  1916→ */
  1917→app.get('/batch/jobs', (req, res) => {
  1918→  const jobs = Array.from(batchJobs.values()).map(job => ({
  1919→    id: job.id,
  1920→    type: job.type,
  1921→    status: job.status,
  1922→    createdAt: job.createdAt,
  1923→    completedAt: job.completedAt,
  1924→    progress: job.progress
  1925→  }));
  1926→
  1927→  // Sort by creation date (newest first)
  1928→  jobs.sort((a, b) => new Date(b.createdAt) - new Date(a.createdAt));
  1929→
  1930→  res.json({
  1931→    success: true,
  1932→    count: jobs.length,
  1933→    jobs
  1934→  });
  1935→});
  1936→
  1937→// =============================================================================
  1938→// Billing & Credits Routes
  1939→// =============================================================================
  1940→
  1941→/**
  1942→ * GET /credits - Get user's credit balance
  1943→ *
  1944→ * Requires x-stripe-customer-id header
  1945→ */
  1946→app.get('/credits', async (req, res) => {
  1947→  const stripeCustomerId = req.headers['x-stripe-customer-id'];
  1948→
  1949→  if (!stripeCustomerId) {
  1950→    return res.status(401).json({
  1951→      error: 'Authentication required',
  1952→      message: 'Missing x-stripe-customer-id header'
  1953→    });
  1954→  }
  1955→
  1956→  try {
  1957→    const balance = await usageTracking.getBalance(stripeCustomerId);
  1958→    res.json({
  1959→      success: true,
  1960→      ...balance
  1961→    });
  1962→  } catch (err) {
  1963→    console.error('[SPLICE] Credits error:', err);
  1964→    res.status(500).json({ error: err.message });
  1965→  }
  1966→});
  1967→
  1968→/**
  1969→ * GET /usage-history - Get user's usage history
  1970→ */
  1971→app.get('/usage-history', async (req, res) => {
  1972→  const stripeCustomerId = req.headers['x-stripe-customer-id'];
  1973→
  1974→  if (!stripeCustomerId) {
  1975→    return res.status(401).json({
  1976→      error: 'Authentication required',
  1977→      message: 'Missing x-stripe-customer-id header'
  1978→    });
  1979→  }
  1980→
  1981→  try {
  1982→    const history = await usageTracking.getUsageHistory(stripeCustomerId);
  1983→    res.json({
  1984→      success: true,
  1985→      history
  1986→    });
  1987→  } catch (err) {
  1988→    console.error('[SPLICE] Usage history error:', err);
  1989→    res.status(500).json({ error: err.message });
  1990→  }
  1991→});
  1992→
  1993→// =============================================================================
  1994→// Referral System Endpoints
  1995→// =============================================================================
  1996→
  1997→/**
  1998→ * GET /referral/code - Get or create referral code for user
  1999→ *
  2000→ * Requires x-stripe-customer-id header
  2001→ */
  2002→app.get('/referral/code', async (req, res) => {
  2003→  const stripeCustomerId = req.headers['x-stripe-customer-id'];
  2004→
  2005→  if (!stripeCustomerId) {
  2006→    return res.status(401).json({
  2007→      error: 'Authentication required',
  2008→      message: 'Missing x-stripe-customer-id header'
  2009→    });
  2010→  }
  2011→
  2012→  try {
  2013→    const codeInfo = await referralService.getOrCreateCode(stripeCustomerId);
  2014→    res.json({
  2015→      success: true,
  2016→      ...codeInfo
  2017→    });
  2018→  } catch (err) {
  2019→    console.error('[SPLICE] Referral code error:', err);
  2020→    res.status(500).json({ error: err.message });
  2021→  }
  2022→});
  2023→
  2024→/**
  2025→ * POST /referral/validate - Validate a referral code
  2026→ *
  2027→ * Body: { code: string, customerId?: string }
  2028→ */
  2029→app.post('/referral/validate', async (req, res) => {
  2030→  const { code, customerId } = req.body;
  2031→
  2032→  if (!code) {
  2033→    return res.status(400).json({
  2034→      error: 'Missing code',
  2035→      message: 'Referral code is required'
  2036→    });
  2037→  }
  2038→
  2039→  try {
  2040→    const result = await referralService.validateCode(code, customerId);
  2041→    res.json({
  2042→      success: true,
  2043→      ...result
  2044→    });
  2045→  } catch (err) {
  2046→    console.error('[SPLICE] Referral validate error:', err);
  2047→    res.status(500).json({ error: err.message });
  2048→  }
  2049→});
  2050→
  2051→/**
  2052→ * POST /referral/apply - Apply referral code at signup
  2053→ *
  2054→ * Body: { code: string, customerId: string }
  2055→ */
  2056→app.post('/referral/apply', async (req, res) => {
  2057→  const { code, customerId } = req.body;
  2058→
  2059→  if (!code || !customerId) {
  2060→    return res.status(400).json({
  2061→      error: 'Missing required fields',
  2062→      message: 'Both code and customerId are required'
  2063→    });
  2064→  }
  2065→
  2066→  try {
  2067→    const result = await referralService.applyCode(code, customerId, stripe);
  2068→    res.json({
  2069→      success: true,
  2070→      ...result
  2071→    });
  2072→  } catch (err) {
  2073→    console.error('[SPLICE] Referral apply error:', err);
  2074→    // Return user-friendly errors for validation failures
  2075→    if (err.message.includes('Cannot use your own') ||
  2076→        err.message.includes('already used') ||
  2077→        err.message.includes('not found') ||
  2078→        err.message.includes('no longer active')) {
  2079→      return res.status(400).json({ error: err.message });
  2080→    }
  2081→    res.status(500).json({ error: err.message });
  2082→  }
  2083→});
  2084→
  2085→/**
  2086→ * GET /referral/stats - Get referral statistics for user
  2087→ *
  2088→ * Requires x-stripe-customer-id header
  2089→ */
  2090→app.get('/referral/stats', async (req, res) => {
  2091→  const stripeCustomerId = req.headers['x-stripe-customer-id'];
  2092→
  2093→  if (!stripeCustomerId) {
  2094→    return res.status(401).json({
  2095→      error: 'Authentication required',
  2096→      message: 'Missing x-stripe-customer-id header'
  2097→    });
  2098→  }
  2099→
  2100→  try {
  2101→    const stats = await referralService.getStats(stripeCustomerId);
  2102→    res.json({
  2103→      success: true,
  2104→      ...stats
  2105→    });
  2106→  } catch (err) {
  2107→    console.error('[SPLICE] Referral stats error:', err);
  2108→    res.status(500).json({ error: err.message });
  2109→  }
  2110→});
  2111→
  2112→// =============================================================================
  2113→// License Key Endpoints
  2114→// =============================================================================
  2115→
  2116→/**
  2117→ * POST /license/activate - Activate a license key
  2118→ *
  2119→ * Body: { key: "SPLICE-XXXX-XXXX-XXXX" }
  2120→ * Returns: { success, customerId, tier, hoursRemaining }
  2121→ */
  2122→app.post('/license/activate', async (req, res) => {
  2123→  const { key } = req.body;
  2124→
  2125→  if (!key) {
  2126→    return res.status(400).json({
  2127→      error: 'Missing license key',
  2128→      message: 'License key is required'
  2129→    });
  2130→  }
  2131→
  2132→  // Validate format
  2133→  if (!licenseService.isValidKeyFormat(key)) {
  2134→    return res.status(400).json({
  2135→      error: 'Invalid license key format',
  2136→      message: 'License key should be in format: SPLICE-XXXX-XXXX-XXXX'
  2137→    });
  2138→  }
  2139→
  2140→  try {
  2141→    // Activate the key
  2142→    const result = await licenseService.activateLicenseKey(key);
  2143→
  2144→    if (!result.success) {
  2145→      return res.status(400).json({
  2146→        success: false,
  2147→        error: result.error
  2148→      });
  2149→    }
  2150→
  2151→    // Get the customer's balance and tier info
  2152→    const balance = await usageTracking.getBalance(result.customerId);
  2153→
  2154→    res.json({
  2155→      success: true,
  2156→      customerId: result.customerId,
  2157→      tier: balance.tier,
  2158→      tierName: balance.tierName,
  2159→      hoursRemaining: balance.hoursRemaining,
  2160→      hoursTotal: balance.hoursTotal
  2161→    });
  2162→  } catch (err) {
  2163→    console.error('[SPLICE] License activation error:', err);
  2164→    res.status(500).json({ error: err.message });
  2165→  }
  2166→});
  2167→
  2168→/**
  2169→ * GET /license/key - Get license key for a customer (for display/resend)
  2170→ *
  2171→ * Requires x-stripe-customer-id header
  2172→ */
  2173→app.get('/license/key', async (req, res) => {
  2174→  const stripeCustomerId = req.headers['x-stripe-customer-id'];
  2175→
  2176→  if (!stripeCustomerId) {
  2177→    return res.status(401).json({
  2178→      error: 'Authentication required',
  2179→      message: 'Missing x-stripe-customer-id header'
  2180→    });
  2181→  }
  2182→
  2183→  try {
  2184→    const result = await licenseService.getLicenseByCustomerId(stripeCustomerId);
  2185→
  2186→    if (!result.success) {
  2187→      return res.status(404).json({
  2188→        success: false,
  2189→        error: result.error
  2190→      });
  2191→    }
  2192→
  2193→    res.json({
  2194→      success: true,
  2195→      key: result.key,
  2196→      activated: result.activated,
  2197→      createdAt: result.createdAt
  2198→    });
  2199→  } catch (err) {
  2200→    console.error('[SPLICE] License lookup error:', err);
  2201→    res.status(500).json({ error: err.message });
  2202→  }
  2203→});
  2204→
  2205→/**
  2206→ * POST /license/resend - Resend license key to customer email
  2207→ *
  2208→ * For support cases where customer didn't receive their license key.
  2209→ * Requires x-stripe-customer-id header or customerId in body (for support).
  2210→ */
  2211→app.post('/license/resend', async (req, res) => {
  2212→  // Allow customerId from header or body (for support staff)
  2213→  const stripeCustomerId = req.headers['x-stripe-customer-id'] || req.body.customerId;
  2214→
  2215→  if (!stripeCustomerId) {
  2216→    return res.status(401).json({
  2217→      error: 'Authentication required',
  2218→      message: 'Missing customer ID'
  2219→    });
  2220→  }
  2221→
  2222→  try {
  2223→    // Get existing license key
  2224→    const licenseResult = await licenseService.getLicenseByCustomerId(stripeCustomerId);
  2225→
  2226→    if (!licenseResult.success) {
  2227→      // No license exists - try to generate one
  2228→      console.log(`[SPLICE] No license found for ${stripeCustomerId}, generating new one`);
  2229→      const newLicense = await licenseService.generateLicenseKey(stripeCustomerId);
  2230→
  2231→      if (!newLicense.success) {
  2232→        return res.status(500).json({
  2233→          success: false,
  2234→          error: 'Failed to generate license key',
  2235→          details: newLicense.error
  2236→        });
  2237→      }
  2238→
  2239→      licenseResult.key = newLicense.key;
  2240→      licenseResult.success = true;
  2241→    }
  2242→
  2243→    // Get customer email from Stripe
  2244→    let customerEmail = null;
  2245→    try {
  2246→      const customer = await stripe.customers.retrieve(stripeCustomerId);
  2247→      customerEmail = customer.email;
  2248→    } catch (stripeErr) {
  2249→      console.error(`[SPLICE] Failed to get customer email:`, stripeErr.message);
  2250→    }
  2251→
  2252→    if (!customerEmail) {
  2253→      return res.status(400).json({
  2254→        success: false,
  2255→        error: 'No email address found for customer',
  2256→        key: licenseResult.key, // Still return key for manual delivery
  2257→        manualDeliveryRequired: true
  2258→      });
  2259→    }
  2260→
  2261→    // Log the resend request (placeholder for actual email service)
  2262→    console.log(`[SPLICE] License key resend requested for ${customerEmail}: ${licenseResult.key}`);
  2263→    // TODO: Integrate with email service
  2264→    // await sendLicenseKeyEmail(customerEmail, licenseResult.key);
  2265→
  2266→    res.json({
  2267→      success: true,
  2268→      message: `License key will be sent to ${customerEmail}`,
  2269→      email: customerEmail,
  2270→      key: licenseResult.key, // Include key for immediate display
  2271→      activated: licenseResult.activated
  2272→    });
  2273→  } catch (err) {
  2274→    console.error('[SPLICE] License resend error:', err);
  2275→    res.status(500).json({ error: err.message });
  2276→  }
  2277→});
  2278→
  2279→// =============================================================================
  2280→// Start Server
  2281→// =============================================================================
  2282→
  2283→// Initialize database and start server
  2284→async function startServer() {
  2285→  try {
  2286→    await usageTracking.initDatabase();
  2287→    await referralService.initReferralTables();
  2288→    await licenseService.initLicenseTables();
  2289→    console.log('[SPLICE] Database initialized');
  2290→
  2291→    if (isProduction || !httpsOptions) {
  2292→      // Production: Railway provides TLS termination, use HTTP
  2293→      http.createServer(app).listen(PORT, () => {
  2294→        console.log(`[SPLICE] Backend running at http://0.0.0.0:${PORT} (production)`);
  2295→      });
  2296→    } else {
  2297→      // Development: Use HTTPS with local certificates
  2298→      https.createServer(httpsOptions, app).listen(PORT, () => {
  2299→        console.log(`[SPLICE] Backend running at https://127.0.0.1:${PORT} (development)`);
  2300→        console.log(`[SPLICE] POST /analyze with { "wavPath": "/path/to/audio.wav" }`);
  2301→      });
  2302→    }
  2303→  } catch (err) {
  2304→    console.error('[SPLICE] Failed to start server:', err);
  2305→    process.exit(1);
  2306→  }
  2307→}
  2308→
  2309→startServer();
  2310→

<system-reminder>
Whenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.
</system-reminder>
