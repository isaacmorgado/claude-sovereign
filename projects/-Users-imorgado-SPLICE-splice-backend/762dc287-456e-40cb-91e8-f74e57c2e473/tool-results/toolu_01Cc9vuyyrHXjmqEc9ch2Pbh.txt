The file /Users/imorgado/SPLICE/splice-backend/services/transcription.js has been updated. Here's the result of running `cat -n` on a snippet of the edited file:
   103→    console.log('[SPLICE] Using cached transcription (file unchanged)');
   104→    return cached.result;
   105→  }
   106→
   107→  console.log('[SPLICE] Starting GPT-4o-mini transcription...');
   108→
   109→  // GPT-4o-mini-transcribe uses the same transcriptions API as Whisper
   110→  // but only supports 'json' response format (not verbose_json)
   111→  const transcription = await withRetry(async () => {
   112→    return await openai.audio.transcriptions.create({
   113→      file: fs.createReadStream(wavPath),
   114→      model: 'gpt-4o-mini-transcribe',
   115→      response_format: 'json',
   116→      language: 'en',
   117→    });
   118→  });
   119→
   120→  console.log(`[SPLICE] Transcription complete: ${transcription.text.slice(0, 100)}...`);
   121→
   122→  // GPT-4o-mini-transcribe returns simpler response than verbose_json
   123→  // We need to estimate segments from the text if not provided
   124→  const result = {
   125→    text: transcription.text,
   126→    segments: transcription.segments || estimateSegments(transcription.text),
   127→    language: transcription.language || 'en',
   128→    duration: transcription.duration || 0
   129→  };
   130→
   131→  // Cache the result (with LRU eviction)
   132→  cacheSet(wavPath, { mtime, result });
   133→  console.log('[SPLICE] Transcription cached');
   134→
   135→  return result;
   136→}
   137→