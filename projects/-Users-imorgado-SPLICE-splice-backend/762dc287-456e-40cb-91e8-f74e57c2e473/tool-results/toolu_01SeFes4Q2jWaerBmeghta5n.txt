     1→async function remove_silences_sequential(showMessageFlag = true, mode = "basic", silences = null, method = "jsx_and_compare", unit = "Seconds", operation = "delete", singleTrackMode = false, targetTrackIndex = null, targetTrackType = null, ripple = true, anchorEvery = 10, showProgress = false) {
     2→    let evalString = "app.project.activeSequence.getWorkAreaInPoint()";
     3→    console.log("eval_string", evalString);
     4→    const workAreaIn = await new Promise((resolve, reject) => {
     5→        jsx.evalScript(evalString, function(result) {
     6→            console.log("result", result);
     7→            resolve(parseFloat(result));
     8→        });
     9→    });
    10→
    11→    evalString = "app.project.activeSequence.getWorkAreaOutPoint()";
    12→    console.log("eval_string", evalString);
    13→    var workAreaOut = await new Promise((resolve, reject) => {
    14→        jsx.evalScript(evalString, function(result) {
    15→            console.log("result", result);
    16→            resolve(parseFloat(result));
    17→        });
    18→    });
    19→    var duration = workAreaOut - workAreaIn;
    20→
    21→    if (silences) {
    22→        var totalSilenceDuration = silences.reduce((acc, range) => acc + (range[1] - range[0]), 0);
    23→        evalString = "addSilenceCuttingControlClipToNewTrack(0, " + (Math.max(silences[silences.length - 1][1], workAreaOut) + 10) + ")";
    24→        console.log("eval_string", evalString);
    25→        await new Promise((resolve, reject) => {
    26→            jsx.evalScript(evalString, function(result) {
    27→                console.log("result", result);
    28→                resolve(result);
    29→            });
    30→        });
    31→
    32→        evalString = "getTimecodeFormat()";
    33→        console.log("eval_string", evalString);
    34→        var originalTimecodeFormat = await new Promise((resolve, reject) => {
    35→            jsx.evalScript(evalString, function(result) {
    36→                console.log("result", result);
    37→                resolve(parseInt(result));
    38→            });
    39→        });
    40→
    41→        showSpinner(spinner_msg_cutting);
    42→        var trackNames = await buildTrackNamesArray();
    43→        var videoTrackNames = trackNames[0];
    44→        var audioTrackNames = trackNames[1];
    45→        isVideoTrackEmpty = [];
    46→        isAudioTrackEmpty = [];
    47→
    48→        evalString = "getVideoFrameRateInSeconds()";
    49→        console.log("eval_string", evalString);
    50→        var videoFrameRate = await new Promise((resolve, reject) => {
    51→            jsx.evalScript(evalString, function(result) {
    52→                console.log("result", result);
    53→                resolve(result);
    54→            });
    55→        });
    56→        videoFrameRate = parseFloat(videoFrameRate);
    57→
    58→        var error_margin;
    59→        if (unit == "Seconds") {
    60→            error_margin = videoFrameRate / 2;
    61→        } else {
    62→            error_margin = 0.5;
    63→        }
    64→
    65→        var removedSilencesDuration = 0;
    66→        var min_duration = 0.01;
    67→
    68→        for (let i = 0; i < silences.length; i++) {
    69→            for (var j = 0; j < silences[i].length; j++) {
    70→                var silence_edge_frames = Math.round(silences[i][j] / videoFrameRate);
    71→                silences[i][j] = silence_edge_frames * videoFrameRate;
    72→            }
    73→        }
    74→
    75→        if (unit == "Frames") {
    76→            silences = silences.map(range => [Math.round(range[0] / videoFrameRate), Math.round(range[1] / videoFrameRate)]);
    77→        }
    78→
    79→        if (silences.length > 2000) {
    80→            let batchSize = 10;
    81→            let numBatches = Math.ceil(silences.length / batchSize);
    82→            console.log("batch_size", numBatches);
    83→            for (let i = 0; i < batchSize; i++) {
    84→                var batched_silences = silences.slice(i * numBatches, (i + 1) * numBatches);
    85→                console.log("batched_silences", batched_silences);
    86→                if (batched_silences.length > 0) {
    87→                    console.log("sent to JSX");
    88→                    showSpinner("Cutting silences (" + (i / 10 * 100).toFixed(0) + "%)");
    89→                    let silencesStringified = JSON.stringify(batched_silences);
    90→                    console.log("batched_silences_stringified", silencesStringified);
    91→                    evalString = 'razorSequenceAtFramesArray("' + silencesStringified + '")';
    92→                    console.log("eval_string", evalString);
    93→                    await new Promise((resolve, reject) => {
    94→                        jsx.evalScript(evalString, function(result) {
    95→                            console.log("result", result);
    96→                            resolve(result);
    97→                        });
    98→                    });
    99→                }
   100→            }
   101→        } else {
   102→            console.log("silences", silences);
   103→            let silencesStringified = JSON.stringify(silences);
   104→            console.log("silences_stringified", silencesStringified);
   105→            evalString = 'razorSequenceAtFramesArray("' + JSON.stringify(silences) + '")';
   106→            console.log("eval_string", evalString);
   107→            await new Promise((resolve, reject) => {
   108→                jsx.evalScript(evalString, function(result) {
   109→                    console.log("result", result);
   110→                    resolve(result);
   111→                });
   112→            });
   113→        }
   114→
   115→        console.log("Getting clips to remove");
   116→        if (showProgress) {
   117→            showSpinner("Deleting silent clips");
   118→        }
   119→
   120→        var video_clips = [];
   121→        for (var i = 0; i < videoTrackNames.length; i++) {
   122→            evalString = "getClipsInTrack_Timings_" + unit + "(" + i + ', "video")';
   123→            console.log("eval_string", evalString);
   124→            var clips = await new Promise((resolve, reject) => {
   125→                jsx.evalScript(evalString, function(result) {
   126→                    console.log("result", result);
   127→                    resolve(JSON.parse(result));
   128→                });
   129→            });
   130→            video_clips.push(clips);
   131→        }
   132→
   133→        var audio_clips = [];
   134→        for (var i = 0; i < audioTrackNames.length; i++) {
   135→            evalString = "getClipsInTrack_Timings_" + unit + "(" + i + ', "audio")';
   136→            console.log("eval_string", evalString);
   137→            var clips = await new Promise((resolve, reject) => {
   138→                jsx.evalScript(evalString, function(result) {
   139→                    console.log("result", result);
   140→                    resolve(JSON.parse(result));
   141→                });
   142→            });
   143→            audio_clips.push(clips);
   144→        }
   145→
   146→        console.log("video_clips", JSON.stringify(video_clips));
   147→        console.log("audio_clips", JSON.stringify(audio_clips));
   148→
   149→        let video_clips_to_remove = [];
   150→        let audio_clips_to_remove = [];
   151→
   152→        for (var i = 0; i < video_clips.length; i++) {
   153→            var trackClips = video_clips[i];
   154→            let clipsToRemoveInTrack = [];
   155→            for (var j = 0; j < trackClips.length; j++) {
   156→                for (var m = 0; m < silences.length; m++) {
   157→                    var silence = silences[m];
   158→                    if (trackClips[j][0] >= silence[0] - error_margin && trackClips[j][1] <= silence[1] + error_margin) {
   159→                        clipsToRemoveInTrack.push(j);
   160→                    }
   161→                }
   162→            }
   163→            video_clips_to_remove.push(clipsToRemoveInTrack);
   164→        }
   165→
   166→        for (var i = 0; i < audio_clips.length; i++) {
   167→            var trackClips = audio_clips[i];
   168→            let clipsToRemoveInTrack = [];
   169→            for (var j = 0; j < trackClips.length; j++) {
   170→                for (var m = 0; m < silences.length; m++) {
   171→                    var silence = silences[m];
   172→                    if (trackClips[j][0] >= silence[0] - error_margin && trackClips[j][1] <= silence[1] + error_margin) {
   173→                        clipsToRemoveInTrack.push(j);
   174→                    }
   175→                }
   176→            }
   177→            audio_clips_to_remove.push(clipsToRemoveInTrack);
   178→        }
   179→
   180→        console.log("video_clips_to_remove", JSON.stringify(video_clips_to_remove));
   181→        console.log("audio_clips_to_remove", JSON.stringify(audio_clips_to_remove));
   182→
   183→        for (var i = 0; i < audio_clips_to_remove.length; i++) {
   184→            var clipsToRemove = audio_clips_to_remove[i];
   185→            for (var x = clipsToRemove.length - 1; x >= 0; x--) {
   186→                var clipIndex = clipsToRemove[x];
   187→                evalString = "app.project.activeSequence.audioTracks[" + i + "].clips[" + clipIndex + "].remove(0, 0)";
   188→                console.log("eval_string", evalString);
   189→                await new Promise((resolve, reject) => {
   190→                    jsx.evalScript(evalString, function(result) {
   191→                        console.log("result", result);
   192→                        resolve(result);
   193→                    });
   194→                });
   195→            }
   196→        }
   197→
   198→        for (var i = 0; i < video_clips_to_remove.length; i++) {
   199→            var clipsToRemove = video_clips_to_remove[i];
   200→            for (var x = clipsToRemove.length - 1; x >= 0; x--) {
   201→                var clipIndex = clipsToRemove[x];
   202→                if (i == video_clips_to_remove.length - 1) {
   203→                    evalString = "app.project.activeSequence.videoTracks[" + i + "].clips[" + clipIndex + "].remove(1, 1)";
   204→                } else {
   205→                    evalString = "app.project.activeSequence.videoTracks[" + i + "].clips[" + clipIndex + "].remove(0, 0)";
   206→                }
   207→                console.log("eval_string", evalString);
   208→                await new Promise((resolve, reject) => {
   209→                    jsx.evalScript(evalString, function(result) {
   210→                        console.log("result", result);
   211→                        resolve(result);
   212→                    });
   213→                });
   214→            }
   215→        }
   216→
   217→        evalString = "setTimecodeFormat(" + originalTimecodeFormat + ")";
   218→        console.log("eval_string", evalString);
   219→        await new Promise((resolve, reject) => {
   220→            jsx.evalScript(evalString, function(result) {
   221→                console.log("result", result);
   222→                resolve(result);
   223→            });
   224→        });
   225→
   226→        console.log("Past setTimecodeFormat");
   227→        if (showMessageFlag) {
   228→            removedSilencesDuration = totalSilenceDuration;
   229→            if (removedSilencesDuration < 10) {
   230→                showMessage("Cut " + removedSilencesDuration.toFixed(1) + "s of silence");
   231→            } else {
   232→                showMessage("Cut " + removedSilencesDuration.toFixed(0) + "s of silence");
   233→            }
   234→        }
   235→    } else {
   236→        console.log("No silences found");
   237→        showError('No silences found. Try increasing "cut tightness" in the slider above, and ensure your silences are sufficiently quiet (lowering track volume can help).');
   238→    }
   239→
   240→    evalString = "deleteSilenceCuttingControlClip()";
   241→    console.log("eval_string", evalString);
   242→    await new Promise((resolve, reject) => {
   243→        jsx.evalScript(evalString, function(result) {
   244→            console.log("result", result);
   245→            resolve(result);
   246→        });
   247→    });
   248→
   249→    if (mode == "basic") {
   250→        showSpinner(spinner_msg_restoring_mute);
   251→        evalString = "setMuteState('" + JSON.stringify(original_mute_state) + "')";
   252→        console.log("eval_string", evalString);
   253→        await new Promise((resolve, reject) => {
   254→            jsx.evalScript(evalString, function(result) {
   255→                console.log("result of setting ORIGINAL mute state", result);
   256→                resolve(result);
   257→            });
   258→        });
   259→    }
   260→}
   261→async function remove_silences(showMessageFlag = true, mode = "basic", silences = null, method = "jsx_and_compare", unit = "Seconds", operation = "delete", singleTrackMode = false, targetTrackIndex = null, targetTrackType = null, ripple = true, anchorEvery = 10, showProgress = false, j_cut = false, j_cut_seconds = 0, hideSpinnerAtTheEnd = true) {
   262→    console.log("silences", silences);
   263→    const licenseVerified = await verify_license_throttled();
   264→    if (!licenseVerified) {
   265→        showError("Please provide a valid license key in the Settings menu");
   266→        return;
   267→    }
   268→    if (!check_function_availability("remove_silences")) {
   269→        showError("Please provide a valid license key in the Settings menu");
   270→        return;
   271→    }
   272→    test_52_schedule_log_upload(time_delay = 0);
   273→    regular_license_key_checker();
   274→    showSpinner();
   275→    const trackerId = tracker.start("remove_silences");
   276→    try {
   277→        if (method == "sequential") {
   278→            await remove_silences_sequential(showMessageFlag, "advanced", silences, "sequential", "Frames", operation, singleTrackMode, targetTrackIndex, targetTrackType, ripple, anchorEvery, showProgress);
   279→            return;
   280→        }
   281→        if (method == "turbo") {
   282→            console.log("CHECKING FOR JCUT FLAG");
   283→            if (j_cut) {
   284→                console.log("J-CUT FLAG DETECTED");
   285→                var trackNames = await buildTrackNamesArray();
   286→                var audioTrackNames = trackNames[1];
   287→                isAudioTrackEmpty = [];
   288→                for (var i = 0; i < audioTrackNames.length; i++) {
   289→                    var evalString = "getNumClipsInTrack(" + i + ', "audio")';
   290→                    console.log("eval_string", evalString);
   291→                    var numClips = await new Promise((resolve, reject) => {
   292→                        jsx.evalScript(evalString, function(result) {
   293→                            console.log("result", result);
   294→                            resolve(parseInt(result));
   295→                        });
   296→                    });
   297→                    numClips == 0 ? isAudioTrackEmpty.push(true) : isAudioTrackEmpty.push(false);
   298→                }
   299→                console.log("J-CUT FLAG DETECTED");
   300→                for (let i = 0; i < audioTrackNames.length; i++) {
   301→                    console.log("j", i);
   302→                    if (isAudioTrackEmpty[i]) {
   303→                        console.log("audio track is empty, skipping");
   304→                        continue;
   305→                    }
   306→                    var evalString = "moveAllClipsInTrack(" + i + ', "audio", ' + j_cut_seconds + ")";
   307→                    console.log("eval_string", evalString);
   308→                    await new Promise((resolve, reject) => {
   309→                        jsx.evalScript(evalString, function(result) {
   310→                            console.log("result", result);
   311→                            resolve(result);
   312→                        });
   313→                    });
   314→                }
   315→                silences = silences.map(range => [range[0] + j_cut_seconds, range[1] + j_cut_seconds]);
   316→            }
   317→            const turboParams = await test_57_get_turbo_cutting_params();
   318→            if (turboParams.useLegacy) {
   319→                await xml_8(silences, turboParams);
   320→                await delay(3000);
   321→            } else {
   322→                const frameRate = await jsxProject.getFrameRate();
   323→                const timebase = await jsxProject.getTimebase();
   324→                const frameDuration = timebase * frameRate;
   325→                await turboSilenceCutting(silences.map(range => {
   326→                    var start = Math.trunc(range[0] * frameDuration);
   327→                    var end = Math.trunc(range[1] * frameDuration);
   328→                    return {
   329→                        from: start,
   330→                        to: end,
   331→                        diff: end - start
   332→                    };
   333→                }));
   334→            }
   335→            if (j_cut) {
   336→                for (let i = 0; i < audioTrackNames.length; i++) {
   337→                    if (isAudioTrackEmpty[i]) continue;
   338→                    var evalString = "moveAllClipsInTrack(" + i + ', "audio", ' + -1 * j_cut_seconds + ")";
   339→                    console.log("eval_string", evalString);
   340→                    await new Promise((resolve, reject) => {
   341→                        jsx.evalScript(evalString, function(result) {
   342→                            console.log("result", result);
   343→                            resolve(result);
   344→                        });
   345→                    });
   346→                }
   347→            }
   348→            return;
   349→        }
   350→        keyAudioTrackIndex = 0;
   351→        try {
   352→            if (mode == "basic") {
   353→                keyAudioTrackIndex = parseInt($("#silence-cutting-audio-track-basic").val());
   354→            }
   355→            if (mode == "advanced") {
   356→                keyAudioTrackIndex = parseInt($("#silence-cutting-audio-track-advanced").val());
   357→            }
   358→        } catch (err) {
   359→            console.log("error while reading master audio track", err);
   360→        }
   361→        if (isNaN(keyAudioTrackIndex)) {
   362→            keyAudioTrackIndex = 0;
   363→        }
   364→        if (mode == "basic") {
   365→            showSpinner(spinner_msg_muting);
   366→            var evalString = "getMuteState()";
   367→            console.log("eval_string", evalString);
   368→            const muteState = await new Promise((resolve, reject) => {
   369→                jsx.evalScript(evalString, function(result) {
   370→                    console.log("result", result);
   371→                    resolve(JSON.parse(result));
   372→                });
   373→            });
   374→            var modifiedMuteState = JSON.parse(JSON.stringify(muteState));
   375→            modifiedMuteState.audio = modifiedMuteState.audio.map((isMuted, index) => +(index !== keyAudioTrackIndex));
   376→            evalString = "setMuteState('" + JSON.stringify(modifiedMuteState) + "')";
   377→            console.log("eval_string", evalString);
   378→            await new Promise((resolve, reject) => {
   379→                jsx.evalScript(evalString, function(result) {
   380→                    console.log("result of setting mute state", result);
   381→                    resolve(result);
   382→                });
   383→            });
   384→        }
   385→        evalString = "app.project.activeSequence.getWorkAreaInPoint()";
   386→        console.log("eval_string", evalString);
   387→        const workAreaIn = await new Promise((resolve, reject) => {
   388→            jsx.evalScript(evalString, function(result) {
   389→                console.log("result", result);
   390→                resolve(parseFloat(result));
   391→            });
   392→        });
   393→        evalString = "app.project.activeSequence.getWorkAreaOutPoint()";
   394→        console.log("eval_string", evalString);
   395→        var workAreaOut = await new Promise((resolve, reject) => {
   396→            jsx.evalScript(evalString, function(result) {
   397→                console.log("result", result);
   398→                resolve(parseFloat(result));
   399→            });
   400→        });
   401→        var duration = workAreaOut - workAreaIn;
   402→        if (mode == "basic") {
   403→            console.log("BASIC MODE. Detecting silences");
   404→            showSpinner(spinner_msg_rendering);
   405→            file_path = await test_1_extract_audio_from_sequence();
   406→            console.log("test_1_extract_audio_from_sequence complete");
   407→            silences = await test_2_detect_silences(file_path);
   408→        } else {
   409→            console.log("ADVANCED MODE. Using provided silences");
   410→        }
   411→        if (silences) {
   412→            var totalSilenceDuration = silences.reduce((acc, range) => acc + (range[1] - range[0]), 0);
   413→            evalString = "addSilenceCuttingControlClipToNewTrack(0, " + (Math.max(silences[silences.length - 1][1], workAreaOut) + 10) + ")";
   414→            console.log("eval_string", evalString);
   415→            var controlClipResult = await new Promise((resolve, reject) => {
   416→                jsx.evalScript(evalString, function(result) {
   417→                    console.log("result", result);
   418→                    resolve(result);
   419→                });
   420→            });
   421→            evalString = "getTimecodeFormat()";
   422→            console.log("eval_string", evalString);
   423→            var originalTimecodeFormat = await new Promise((resolve, reject) => {
   424→                jsx.evalScript(evalString, function(result) {
   425→                    console.log("result", result);
   426→                    resolve(parseInt(result));
   427→                });
   428→            });
   429→            showSpinner(spinner_msg_cutting);
   430→            var trackNames = await buildTrackNamesArray();
   431→            var videoTrackNames = trackNames[0];
   432→            var audioTrackNames = trackNames[1];
   433→            isVideoTrackEmpty = [];
   434→            isAudioTrackEmpty = [];
   435→            for (var i = 0; i < videoTrackNames.length - 1; i++) {
   436→                var evalString = "getNumClipsInTrack(" + i + ', "video")';
   437→                console.log("eval_string", evalString);
   438→                var numClips = await new Promise((resolve, reject) => {
   439→                    jsx.evalScript(evalString, function(result) {
   440→                        console.log("result", result);
   441→                        resolve(parseInt(result));
   442→                    });
   443→                });
   444→                numClips == 0 ? isVideoTrackEmpty.push(true) : isVideoTrackEmpty.push(false);
   445→            }
   446→            for (var i = 0; i < audioTrackNames.length; i++) {
   447→                var evalString = "getNumClipsInTrack(" + i + ', "audio")';
   448→                console.log("eval_string", evalString);
   449→                var numClips = await new Promise((resolve, reject) => {
   450→                    jsx.evalScript(evalString, function(result) {
   451→                        console.log("result", result);
   452→                        resolve(parseInt(result));
   453→                    });
   454→                });
   455→                numClips == 0 ? isAudioTrackEmpty.push(true) : isAudioTrackEmpty.push(false);
   456→            }
   457→            evalString = "getVideoFrameRateInSeconds()";
   458→            console.log("eval_string", evalString);
   459→            videoFrameRate = await new Promise((resolve, reject) => {
   460→                jsx.evalScript(evalString, function(result) {
   461→                    console.log("result", result);
   462→                    resolve(result);
   463→                });
   464→            });
   465→            videoFrameRate = parseFloat(videoFrameRate);
   466→            if (unit == "Seconds") {
   467→                error_margin = videoFrameRate / 2;
   468→            } else {
   469→                error_margin = 0.5;
   470→            }
   471→            var removedSilencesDuration = 0;
   472→            var min_duration = 0.01;
   473→            console.log("CHECKING FOR JCUT FLAG");
   474→            if (j_cut) {
   475→                console.log("J-CUT FLAG DETECTED");
   476→                for (let i = 0; i < audioTrackNames.length; i++) {
   477→                    console.log("j", i);
   478→                    if (isAudioTrackEmpty[i]) {
   479→                        console.log("audio track is empty, skipping");
   480→                        continue;
   481→                    }
   482→                    var evalString = "moveAllClipsInTrack(" + i + ', "audio", ' + j_cut_seconds + ")";
   483→                    console.log("eval_string", evalString);
   484→                    await new Promise((resolve, reject) => {
   485→                        jsx.evalScript(evalString, function(result) {
   486→                            console.log("result", result);
   487→                            resolve(result);
   488→                        });
   489→                    });
   490→                }
   491→                silences = silences.map(range => [range[0] + j_cut_seconds, range[1] + j_cut_seconds]);
   492→            }
   493→            video_clips = [];
   494→            for (var i = 0; i < videoTrackNames.length; i++) {
   495→                var evalString = "getClipsInTrack(" + i + ', "video")';
   496→                console.log("eval_string", evalString);
   497→                var clips = await new Promise((resolve, reject) => {
   498→                    jsx.evalScript(evalString, function(result) {
   499→                        console.log("result", result);
   500→                        resolve(JSON.parse(result));
   501→                    });
   502→                });
   503→                video_clips.push(clips);
   504→            }
   505→            audio_clips = [];
   506→            for (var i = 0; i < audioTrackNames.length; i++) {
   507→                var evalString = "getClipsInTrack(" + i + ', "audio")';
   508→                console.log("eval_string", evalString);
   509→                var clips = await new Promise((resolve, reject) => {
   510→                    jsx.evalScript(evalString, function(result) {
   511→                        console.log("result", result);
   512→                        resolve(JSON.parse(result));
   513→                    });
   514→                });
   515→                audio_clips.push(clips);
   516→            }
   517→            console.log("video_clips", JSON.stringify(video_clips));
   518→            console.log("audio_clips", JSON.stringify(audio_clips));
   519→            local_video_clips = [];
   520→            local_audio_clips = [];
   521→            if (method == "jsx_and_compare" || method == "local") {
   522→                for (var i = 0; i < video_clips.length; i++) {
   523→                    console.log("video_clips[j]", video_clips[i]);
   524→                    local_video_clips.push([]);
   525→                    for (var j = 0; j < video_clips[i].length; j++) {
   526→                        local_video_clips[i].push([video_clips[i][j].start.seconds, video_clips[i][j].end.seconds]);
   527→                    }
   528→                }
   529→                for (var i = 0; i < audio_clips.length; i++) {
   530→                    console.log("audio_clips[j]", audio_clips[i]);
   531→                    local_audio_clips.push([]);
   532→                    for (var j = 0; j < audio_clips[i].length; j++) {
   533→                        local_audio_clips[i].push([audio_clips[i][j].start.seconds, audio_clips[i][j].end.seconds]);
   534→                    }
   535→                }
   536→            }
   537→            for (let i = 0; i < silences.length; i++) {
   538→                for (var j = 0; j < silences[i].length; j++) {
   539→                    var silence_edge_frames = Math.round(silences[i][j] / videoFrameRate);
   540→                    silences[i][j] = silence_edge_frames * videoFrameRate;
   541→                }
   542→            }
   543→            if (unit == "Frames") {
   544→                silences = silences.map(range => [Math.round(range[0] / videoFrameRate), Math.round(range[1] / videoFrameRate)]);
   545→                for (var i = 0; i < local_video_clips.length; i++) {
   546→                    local_video_clips[i] = local_video_clips[i].map(range => [Math.round(range[0] / videoFrameRate), Math.round(range[1] / videoFrameRate)]);
   547→                }
   548→                for (var i = 0; i < local_audio_clips.length; i++) {
   549→                    local_audio_clips[i] = local_audio_clips[i].map(range => [Math.round(range[0] / videoFrameRate), Math.round(range[1] / videoFrameRate)]);
   550→                }
   551→            }
   552→            for (let i = 0; i < silences.length; i++) {
   553→                if (showProgress) {
   554→                    showSpinner("Cutting silence # " + (i + 1) + " of " + silences.length);
   555→                }
   556→                console.log("silence # ", (i + 1), " of ", silences.length);
   557→                console.log("local_video_clips", local_video_clips);
   558→                console.log("local_audio_clips", local_audio_clips);
   559→                var silence = silences[i];
   560→                var silence_duration = silence[1] - silence[0];
   561→                if (method == "local" && (i + 1) % anchorEvery == 0) {
   562→                    console.log("ANCHORING");
   563→                    var ret = await test_49_get_clip_times_in_frames(videoTrackNames, audioTrackNames, videoFrameRate);
   564→                    local_video_clips = ret["video_clips"];
   565→                    local_audio_clips = ret["audio_clips"];
   566→                    var is_equal = {};
   567→                    is_equal["video_clips"] = (JSON.stringify(ret.video_clips) == JSON.stringify(local_video_clips));
   568→                    console.log("REGULAR LOCAL CHECK IS EQUAL? VIDEO:", is_equal.video_clips);
   569→                    if (!is_equal["video_clips"]) {
   570→                        try {
   571→                            LOGGING_MAX_CHARS_PER_LINE = 2000;
   572→                            console.log('ret["video_clips"]:');
   573→                            console.log(ret.video_clips);
   574→                            console.log("local_video_clips:");
   575→                            console.log(local_video_clips);
   576→                        } catch (err) {
   577→                            console.log("error in console logging:", err);
   578→                        } finally {
   579→                            LOGGING_MAX_CHARS_PER_LINE = LOGGING_MAX_CHARS_PER_LINE_DEFAULT;
   580→                        }
   581→                    }
   582→                    is_equal["audio_clips"] = (JSON.stringify(ret["audio_clips"]) == JSON.stringify(local_audio_clips));
   583→                    console.log("REGULAR LOCAL CHECK IS EQUAL? AUDIO:", is_equal["audio_clips"]);
   584→                    if (!is_equal["audio_clips"]) {
   585→                        try {
   586→                            console.log("local_audio_clips:");
   587→                            console.log(local_audio_clips);
   588→                            console.log(ret["audio_clips"]);
   589→                            LOGGING_MAX_CHARS_PER_LINE = 2000;
   590→                            console.log('ret["audio_clips"]:');
   591→                        } catch (err) {
   592→                            console.log("error in console logging:", err);
   593→                        } finally {
   594→                            LOGGING_MAX_CHARS_PER_LINE = LOGGING_MAX_CHARS_PER_LINE_DEFAULT;
   595→                        }
   596→                    }
   597→                }
   598→                if (operation == "delete" && !singleTrackMode) {
   599→                    silence[0] = silence[0] - removedSilencesDuration;
   600→                    silence[1] = silence[1] - removedSilencesDuration;
   601→                }
   602→                for (var silence_edge of silence) {
   603→                    if (singleTrackMode && !ripple) {
   604→                        var evalString = "razorTrackAt" + unit + '("' + targetTrackType + '", ' + targetTrackIndex + ", " + silence_edge + ")";
   605→                    } else {
   606→                        var evalString = "razorSequenceAt" + unit + "(" + silence_edge + ")";
   607→                    }
   608→                    console.log("eval_string", evalString);
   609→                    await new Promise((resolve, reject) => {
   610→                        jsx.evalScript(evalString, function(result) {
   611→                            console.log("result", result);
   612→                            resolve(result);
   613→                        });
   614→                    });
   615→                }
   616→                if (method == "jsx_and_compare" || method == "local") {
   617→                    var razor1 = silence[0];
   618→                    var razor2 = silence[1];
   619→                    if (unit == "Seconds") {
   620→                        razor1 = Math.round(razor1 / videoFrameRate) * videoFrameRate;
   621→                        razor2 = Math.round(razor2 / videoFrameRate) * videoFrameRate;
   622→                    }
   623→                    var diff = razor2 - razor1;
   624→                    for (let j = 0; j < local_video_clips.length; j++) {
   625→                        if (singleTrackMode && (targetTrackIndex != j || targetTrackType != "video") && !ripple) continue;
   626→                        for (let k = 0; k < local_video_clips[j].length; k++) {
   627→                            let clip = local_video_clips[j][k];
   628→                            for (var razor of [razor1, razor2]) {
   629→                                if (razor > clip[0] && razor < clip[1]) {
   630→                                    var new_clip = [razor, clip[1]];
   631→                                    clip[1] = razor;
   632→                                    local_video_clips[j].splice(k + 1, 0, new_clip);
   633→                                }
   634→                            }
   635→                        }
   636→                    }
   637→                    for (let j = 0; j < local_audio_clips.length; j++) {
   638→                        if (singleTrackMode && (targetTrackIndex != j || targetTrackType != "audio") && !ripple) continue;
   639→                        for (let k = 0; k < local_audio_clips[j].length; k++) {
   640→                            let clip = local_audio_clips[j][k];
   641→                            for (var razor of [razor1, razor2]) {
   642→                                if (razor > clip[0] && razor < clip[1]) {
   643→                                    var new_clip = [razor, clip[1]];
   644→                                    clip[1] = razor;
   645→                                    local_audio_clips[j].splice(k + 1, 0, new_clip);
   646→                                }
   647→                            }
   648→                        }
   649→                    }
   650→                }
   651→                for (var j = 0; j < videoTrackNames.length - 1; j++) {
   652→                    if (isVideoTrackEmpty[j]) {
   653→                        console.log("Video track " + j + " is empty. Skipping");
   654→                        continue;
   655→                    }
   656→                    if (singleTrackMode && targetTrackType == "video") {
   657→                        console.log("target_track_type=" + targetTrackType + " and current track is a video track. Skipping");
   658→                        continue;
   659→                    }
   660→                    if (singleTrackMode && targetTrackIndex != j) {
   661→                        console.log("single_track_mode=True and Video track " + j + " is not the target track (" + targetTrackIndex + "). Skipping");
   662→                        continue;
   663→                    }
   664→                    if (method == "jsx_and_compare" || method == "jsx") {
   665→                        var evalString = "getClipsInTrack_Timings_" + unit + "(" + j + ', "video")';
   666→                        console.log("eval_string", evalString);
   667→                        var clipsInTrack = await new Promise((resolve, reject) => {
   668→                            jsx.evalScript(evalString, function(result) {
   669→                                console.log("result", result);
   670→                                resolve(JSON.parse(result));
   671→                            });
   672→                        });
   673→                    } else {
   674→                        if (method == "local") {
   675→                            var clipsInTrack = local_video_clips[j];
   676→                        }
   677→                    }
   678→                    if (method == "jsx_and_compare") {
   679→                        var clips_in_video_track_ms_int = clipsInTrack.map(clip => {
   680→                            return [Math.round(clip[0] * 1000), Math.round(clip[1] * 1000)];
   681→                        });
   682→                        var local_video_clips_ms_int = local_video_clips[j].map(clip => {
   683→                            return [Math.round(clip[0] * 1000), Math.round(clip[1] * 1000)];
   684→                        });
   685→                        console.log("local version of local_video_clips_ms_int", JSON.parse(JSON.stringify(local_video_clips_ms_int)));
   686→                        console.log("local version of local_video_clips_ms_int.length", local_video_clips_ms_int.length);
   687→                        console.log("clips_in_video_track_ms_int.length", clips_in_video_track_ms_int.length);
   688→                        console.log("IS EQUAL?", JSON.stringify(clips_in_video_track_ms_int) == JSON.stringify(local_video_clips_ms_int));
   689→                        console.log("clips_in_video_track_ms_int", JSON.parse(JSON.stringify(clips_in_video_track_ms_int)));
   690→                    }
   691→                    var delete_duration_remaining = silence_duration;
   692→                    for (var clipIndex = clipsInTrack.length - 1; clipIndex >= 0; clipIndex--) {
   693→                        if (clipsInTrack[clipIndex][0] >= silence[0] - error_margin && clipsInTrack[clipIndex][1] <= silence[1] + error_margin) {
   694→                            delete_duration_remaining -= (clipsInTrack[clipIndex][1] - clipsInTrack[clipIndex][0]);
   695→                            if (!ripple) {
   696→                                var evalString = 'removeAllLinks("video", ' + j + ", " + clipIndex + ")";
   697→                                console.log("eval_string", evalString);
   698→                                await new Promise((resolve, reject) => {
   699→                                    jsx.evalScript(evalString, function(result) {
   700→                                        console.log("result", result);
   701→                                        resolve(result);
   702→                                    });
   703→                                });
   704→                            }
   705→                            console.log("eval_string", evalString);
   706→                            if (operation == "delete") {
   707→                                var evalString = "app.project.activeSequence.videoTracks[" + j + "].clips[" + clipIndex + "].remove(0, 0)";
   708→                            } else {
   709→                                if (operation == "disable") {
   710→                                    var evalString = 'disableClip("video", ' + j + ", " + clipIndex + ", " + ripple + ")";
   711→                                }
   712→                            }
   713→                            await new Promise((resolve, reject) => {
   714→                                jsx.evalScript(evalString, function(result) {
   715→                                    console.log("result", result);
   716→                                    resolve(result);
   717→                                });
   718→                            });
   719→                        }
   720→                    }
   721→                    if (method == "jsx_and_compare" || method == "local") {
   722→                        if (operation == "delete") {
   723→                            for (var x = local_video_clips[j].length - 1; x >= 0; x--) {
   724→                                if (local_video_clips[j][x][0] >= silence[0] - error_margin && local_video_clips[j][x][1] <= silence[1] + error_margin) {
   725→                                    local_video_clips[j].splice(x, 1);
   726→                                }
   727→                            }
   728→                            for (var x = local_video_clips[j].length - 1; x >= 0; x--) {
   729→                                if (local_video_clips[j][x][0] >= silence[1] - error_margin) {
   730→                                    local_video_clips[j][x][0] -= diff;
   731→                                    local_video_clips[j][x][1] -= diff;
   732→                                }
   733→                            }
   734→                        }
   735→                    }
   736→                    console.log("silence_duration", silence_duration);
   737→                    if (delete_duration_remaining > min_duration) {
   738→                        console.log("move the remaining clips to the left by delete_duration_remaining");
   739→                    }
   740→                }
   741→                for (var j = 0; j < audioTrackNames.length; j++) {
   742→                    if (isAudioTrackEmpty[j]) {
   743→                        console.log("Audio track " + j + " is empty. Skipping");
   744→                        continue;
   745→                    }
   746→                    if (singleTrackMode && targetTrackType == "audio") {
   747→                        console.log("target_track_type=" + targetTrackType + " and current track is a audio track. Skipping");
   748→                        continue;
   749→                    }
   750→                    if (singleTrackMode && targetTrackIndex != j) {
   751→                        console.log("single_track_mode=True and Video track " + j + " is not the target track (" + targetTrackIndex + "). Skipping");
   752→                        continue;
   753→                    }
   754→                    if (method == "jsx_and_compare" || method == "jsx") {
   755→                        var evalString = "getClipsInTrack_Timings_" + unit + "(" + j + ', "audio")';
   756→                        console.log("eval_string", evalString);
   757→                        var clipsInTrack = await new Promise((resolve, reject) => {
   758→                            jsx.evalScript(evalString, function(result) {
   759→                                console.log("result", result);
   760→                                resolve(JSON.parse(result));
   761→                            });
   762→                        });
   763→                    } else {
   764→                        if (method == "local") {
   765→                            var clipsInTrack = local_audio_clips[j];
   766→                        }
   767→                    }
   768→                    if (method == "jsx_and_compare") {
   769→                        var clips_in_audio_track_ms_int = clipsInTrack.map(clip => {
   770→                            return [Math.round(clip[0] * 1000), Math.round(clip[1] * 1000)];
   771→                        });
   772→                        var local_audio_clips_ms_int = local_audio_clips[j].map(clip => {
   773→                            return [Math.round(clip[0] * 1000), Math.round(clip[1] * 1000)];
   774→                        });
   775→                        console.log("clips_in_audio_track_ms_int", JSON.parse(JSON.stringify(clips_in_audio_track_ms_int)));
   776→                        console.log("clips_in_audio_track_ms_int.length", clips_in_audio_track_ms_int.length);
   777→                        console.log("local version of local_audio_clips_ms_int", JSON.parse(JSON.stringify(local_audio_clips_ms_int)));
   778→                        console.log("local version of local_audio_clips_ms_int.length", local_audio_clips_ms_int.length);
   779→                        console.log("IS EQUAL?", JSON.stringify(clips_in_audio_track_ms_int) == JSON.stringify(local_audio_clips_ms_int));
   780→                    }
   781→                    var delete_duration_remaining = silence_duration;
   782→                    for (var clipIndex = clipsInTrack.length - 1; clipIndex >= 0; clipIndex--) {
   783→                        if (clipsInTrack[clipIndex][0] >= silence[0] - error_margin && clipsInTrack[clipIndex][1] <= silence[1] + error_margin) {
   784→                            if (operation == "delete") {
   785→                                var evalString = "app.project.activeSequence.audioTracks[" + j + "].clips[" + clipIndex + "].remove(0, 0)";
   786→                            } else {
   787→                                if (operation == "disable") {
   788→                                    var evalString = 'disableClip("audio", ' + j + ", " + clipIndex + ", " + ripple + ")";
   789→                                }
   790→                            }
   791→                            console.log("eval_string", evalString);
   792→                            await new Promise((resolve, reject) => {
   793→                                jsx.evalScript(evalString, function(result) {
   794→                                    console.log("result", result);
   795→                                    resolve(result);
   796→                                });
   797→                            });
   798→                            delete_duration_remaining -= (clipsInTrack[clipIndex][1] - clipsInTrack[clipIndex][0]);
   799→                        }
   800→                    }
   801→                    if (method == "jsx_and_compare" || method == "local") {
   802→                        if (operation == "delete") {
   803→                            for (var x = local_audio_clips[j].length - 1; x >= 0; x--) {
   804→                                if (local_audio_clips[j][x][0] >= silence[0] - error_margin && local_audio_clips[j][x][1] <= silence[1] + error_margin) {
   805→                                    local_audio_clips[j].splice(x, 1);
   806→                                }
   807→                            }
   808→                            for (var x = local_audio_clips[j].length - 1; x >= 0; x--) {
   809→                                if (local_audio_clips[j][x][0] >= silence[1] - error_margin) {
   810→                                    local_audio_clips[j][x][0] -= diff;
   811→                                    local_audio_clips[j][x][1] -= diff;
   812→                                }
   813→                            }
   814→                        }
   815→                    }
   816→                    console.log("silence_duration", silence_duration);
   817→                    if (delete_duration_remaining > min_duration) {
   818→                        console.log("move the remaining clips to the left by delete_duration_remaining");
   819→                    }
   820→                }
   821→                var controlTrackIndex = videoTrackNames.length - 1;
   822→                if (method == "jsx_and_compare" || method == "jsx") {
   823→                    var evalString = "getClipsInTrack_Timings_" + unit + "(" + controlTrackIndex + ', "video")';
   824→                    console.log("eval_string", evalString);
   825→                    var clipsInTrack = await new Promise((resolve, reject) => {
   826→                        jsx.evalScript(evalString, function(result) {
   827→                            resolve(JSON.parse(result));
   828→                        });
   829→                    });
   830→                } else {
   831→                    if (method == "local") {
   832→                        var clipsInTrack = local_video_clips[controlTrackIndex];
   833→                    }
   834→                }
   835→                if (method == "jsx_and_compare") {
   836→                    var clips_in_video_track_ms_int = clipsInTrack.map(clip => {
   837→                        return [Math.round(clip[0] * 1000), Math.round(clip[1] * 1000)];
   838→                    });
   839→                    var local_video_clips_ms_int = local_video_clips[controlTrackIndex].map(clip => {
   840→                        return [Math.round(clip[0] * 1000), Math.round(clip[1] * 1000)];
   841→                    });
   842→                    console.log("IS EQUAL?", JSON.stringify(clips_in_video_track_ms_int) == JSON.stringify(local_video_clips_ms_int));
   843→                    console.log("local version of local_video_clips_ms_int", JSON.parse(JSON.stringify(local_video_clips_ms_int)));
   844→                    console.log("clips_in_video_track_ms_int.length", clips_in_video_track_ms_int.length);
   845→                    console.log("local version of local_video_clips_ms_int.length", local_video_clips_ms_int.length);
   846→                    console.log("clips_in_video_track_ms_int", JSON.parse(JSON.stringify(clips_in_video_track_ms_int)));
   847→                }
   848→                if (operation == "delete" && !singleTrackMode) {
   849→                    console.log("clips_in_video_track", clipsInTrack);
   850→                    for (var clipIndex = clipsInTrack.length - 1; clipIndex >= 0; clipIndex--) {
   851→                        if (clipsInTrack[clipIndex][0] >= silence[0] - error_margin && clipsInTrack[clipIndex][1] <= silence[1] + error_margin) {
   852→                            var evalString = "app.project.activeSequence.videoTracks[" + controlTrackIndex + "].clips[" + clipIndex + "].remove(1, 1)";
   853→                            console.log("eval_string", evalString);
   854→                            await new Promise((resolve, reject) => {
   855→                                jsx.evalScript(evalString, function(result) {
   856→                                    console.log("result", result);
   857→                                    resolve(result);
   858→                                });
   859→                            });
   860→                        }
   861→                    }
   862→                    if (method == "jsx_and_compare" || method == "local") {
   863→                        for (var x = local_video_clips[controlTrackIndex].length - 1; x >= 0; x--) {
   864→                            if (local_video_clips[controlTrackIndex][x][0] >= silence[0] - error_margin && local_video_clips[controlTrackIndex][x][1] <= silence[1] + error_margin) {
   865→                                local_video_clips[controlTrackIndex].splice(x, 1);
   866→                            }
   867→                        }
   868→                        for (var x = local_video_clips[controlTrackIndex].length - 1; x >= 0; x--) {
   869→                            if (local_video_clips[controlTrackIndex][x][0] >= silence[1] - error_margin) {
   870→                                local_video_clips[controlTrackIndex][x][0] -= diff;
   871→                                local_video_clips[controlTrackIndex][x][1] -= diff;
   872→                            }
   873→                        }
   874→                    }
   875→                }
   876→                removedSilencesDuration += silence[1] - silence[0];
   877→            }
   878→            var evalString = "setTimecodeFormat(" + originalTimecodeFormat + ")";
   879→            console.log("eval_string", evalString);
   880→            await new Promise((resolve, reject) => {
   881→                jsx.evalScript(evalString, function(result) {
   882→                    console.log("result", result);
   883→                    resolve(result);
   884→                });
   885→            });
   886→            console.log("Past setTimecodeFormat");
   887→            if (unit == "Frames") {
   888→                removedSilencesDuration *= videoFrameRate;
   889→            }
   890→            if (showMessageFlag) {
   891→                if (removedSilencesDuration < 10) {
   892→                    showMessage("Cut " + removedSilencesDuration.toFixed(1) + "s of silence");
   893→                } else {
   894→                    showMessage("Cut " + removedSilencesDuration.toFixed(0) + "s of silence");
   895→                }
   896→            }
   897→            if (j_cut) {
   898→                for (let i = 0; i < audioTrackNames.length; i++) {
   899→                    if (isAudioTrackEmpty[i]) continue;
   900→                    var evalString = "moveAllClipsInTrack(" + i + ', "audio", ' + -1 * j_cut_seconds + ")";
   901→                    console.log("eval_string", evalString);
   902→                    await new Promise((resolve, reject) => {
   903→                        jsx.evalScript(evalString, function(result) {
   904→                            console.log("result", result);
   905→                            resolve(result);
   906→                        });
   907→                    });
   908→                }
   909→            }
   910→        } else {
   911→            console.log("No silences found");
   912→            showError('No silences found. Try increasing "cut tightness" in the slider above, and ensure your silences are sufficiently quiet (lowering track volume can help).');
   913→        }
   914→        var evalString = "deleteSilenceCuttingControlClip()";
   915→        console.log("eval_string", evalString);
   916→        await new Promise((resolve, reject) => {
   917→            jsx.evalScript(evalString, function(result) {
   918→                console.log("result", result);
   919→                resolve(result);
   920→            });
   921→        });
   922→        if (mode == "basic") {
   923→            showSpinner(spinner_msg_restoring_mute);
   924→            evalString = "setMuteState('" + JSON.stringify(original_mute_state) + "')";
   925→            console.log("eval_string", evalString);
   926→            await new Promise((resolve, reject) => {
   927→                jsx.evalScript(evalString, function(result) {
   928→                    console.log("result of setting ORIGINAL mute state", result);
   929→                    resolve(result);
   930→                });
   931→            });
   932→        }
   933→    } catch (err) {
   934→        handleErrorNotification(err);
   935→    } finally {
   936→        if (hideSpinnerAtTheEnd) {
   937→            hideSpinner();
   938→        }
   939→        tracker.end(trackerId);
   940→        test_52_schedule_log_upload(200);
   941→    }
   942→}
   943→async function analyze_audio(force = false) {
   944→    const licenseVerified = await verify_license_throttled();
   945→    if (!licenseVerified) {
   946→        showError("Please provide a valid license key in the Settings menu");
   947→        return;
   948→    }
   949→    if (!check_function_availability("analyze_audio")) {
   950→        showError("Please provide a valid license key in the Settings menu");
   951→        return;
   952→    }
   953→    test_52_schedule_log_upload(time_delay = 0);
   954→    regular_license_key_checker();
   955→    await test_45_save_state("Before analyzing audio");
   956→    await test_46_retrieve_undo_state_info();
   957→    const trackerId = tracker.start("analyze_audio");
   958→    try {
   959→        console.log("track_code", trackerId);
   960→        showSpinner();
   961→        silence_cutting_parameters = await test_40_get_silence_params();
   962→        console.log("silence_cutting_parameters", JSON.stringify(silence_cutting_parameters));
   963→        if (silence_cutting_parameters.keyAudioTrackIndices.length == 0) {
   964→            showError("Please select at least one audio track");
   965→            hideSpinner();
   966→            return;
   967→        }
   968→        if (!silence_cutting_parameters.scopeValid) {
   969→            showError("Please ensure your In/Out points are valid");
   970→            hideSpinner();
   971→            return;
   972→        }
   973→        if (silence_cutting_parameters.format == "wav" && (silence_cutting_parameters.outPoint - silence_cutting_parameters.inPoint) > remove_silences_max_duration_wav && !force) {
   974→            showWarning('Your chosen settings may result in a crash (you have selected the "WAV" analysis format for ' + Math.ceil((silence_cutting_parameters.outPoint - silence_cutting_parameters.inPoint) / 60).toFixed(0) + " minutes of sequence, which is greater than the suggested maximum of " + (remove_silences_max_duration_wav / 60).toFixed(0) + ' minutes for this format).\n                  \n                  Suggested solutions: Pick the "MP3" analysis format, or reduce your scope using In/Out Points.', analyze_audio.bind(null, true));
   975→            return;
   976→        }
   977→        let originalMuteState, modifiedMuteState;
   978→        var evalString = "getMuteState()";
   979→        console.log("eval_string", evalString);
   980→        originalMuteState = await new Promise((resolve, reject) => {
   981→            jsx.evalScript(evalString, function(result) {
   982→                console.log("result", result);
   983→                resolve(result);
   984→            });
   985→        });
   986→        if (originalMuteState.includes("EvalScript")) throw new Error(originalMuteState);
   987→        originalMuteState = JSON.parse(originalMuteState);
   988→        modifiedMuteState = JSON.parse(JSON.stringify(originalMuteState));
   989→        modifiedMuteState.audio = modifiedMuteState.audio.map((isMuted, index) => +!silence_cutting_parameters.keyAudioTrackIndices.includes(index));
   990→        evalString = "setMuteState('" + JSON.stringify(modifiedMuteState) + "')";
   991→        console.log("eval_string", evalString);
   992→        await new Promise((resolve, reject) => {
   993→            jsx.evalScript(evalString, function(result) {
   994→                console.log("result of setting mute state", result);
   995→                resolve(result);
   996→            });
   997→        });
   998→        evalString = "app.project.activeSequence.getWorkAreaInPoint()";
   999→        console.log("eval_string", evalString);
  1000→        const workAreaIn = await new Promise((resolve, reject) => {
  1001→            jsx.evalScript(evalString, function(result) {
  1002→                console.log("result", result);
  1003→                resolve(parseFloat(result));
  1004→            });
  1005→        });
  1006→        evalString = "app.project.activeSequence.getWorkAreaOutPoint()";
  1007→        console.log("eval_string", evalString);
  1008→        var workAreaOut = await new Promise((resolve, reject) => {
  1009→            jsx.evalScript(evalString, function(result) {
  1010→                console.log("result", result);
  1011→                resolve(parseFloat(result));
  1012→            });
  1013→        });
  1014→        let chunks = chunk(start = silence_cutting_parameters.inPoint, end = silence_cutting_parameters.outPoint, chunk_size = remove_silences_max_duration, upto_twice = false);
  1015→        console.log("chunks", chunks);
  1016→        let offset = 0;
  1017→        let totalDuration = 0;
  1018→        g_silences = [];
  1019→        g_nonspeech_centerpoints = [];
  1020→        g_RMS_x = [];
  1021→        g_RMS_y = [];
  1022→        g_RMS_x_draw = [];
  1023→        g_RMS_y_draw = [];
  1024→        for (let i = 0; i < chunks.length; i++) {
  1025→            silence_cutting_parameters.inPoint = chunks[i][0] - totalDuration;
  1026→            silence_cutting_parameters.outPoint = chunks[i][1] - totalDuration;
  1027→            silence_cutting_parameters.scope = "inout";
  1028→            g_RMS_x_offset = silence_cutting_parameters.inPoint;
  1029→            let evalString = "app.project.activeSequence.setInPoint(" + silence_cutting_parameters.inPoint + ")";
  1030→            console.log("eval_string", evalString);
  1031→            await new Promise((resolve, reject) => {
  1032→                jsx.evalScript(evalString, function(result) {
  1033→                    console.log("result", result);
  1034→                    resolve(parseFloat(result));
  1035→                });
  1036→            });
  1037→            evalString = "app.project.activeSequence.setOutPoint(" + silence_cutting_parameters.outPoint + ")";
  1038→            console.log("eval_string", evalString);
  1039→            await new Promise((resolve, reject) => {
  1040→                jsx.evalScript(evalString, function(result) {
  1041→                    console.log("result", result);
  1042→                    resolve(parseFloat(result));
  1043→                });
  1044→            });
  1045→            showSpinner("Rendering audio");
  1046→            console.log("Remove silences");
  1047→            file_path = await test_1_extract_audio_from_sequence(silence_cutting_parameters.scope, silence_cutting_parameters.format);
  1048→            showSpinner("Detecting silences (0%)");
  1049→            console.log("test_1 complete");
  1050→            await test_37_create_arrays(file_path);
  1051→        }
  1052→        let threshold = null;
  1053→        console.log("Going to threshold_analysis");
  1054→        analysis = threshold_analysis(g_RMS_y);
  1055→        threshold = analysis.value;
  1056→        console.log("got back value as ", threshold);
  1057→        if (threshold === null) {
  1058→            console.log("Setting it to -30dBFS");
  1059→            threshold = -30;
  1060→        }
  1061→        threshold = Math.round(threshold);
  1062→        $("#range-silence-threshold-2").val(threshold);
  1063→        $("#value-silence-threshold-2").val(threshold);
  1064→        $("#range-silence-min-2").val(silence_cutting_parameters.min_silence_length);
  1065→        $("#value-silence-min-2").val(silence_cutting_parameters.min_silence_length);
  1066→        open_menu("silence-cutting-advanced-results-list");
  1067→        g_RMS_x_draw = g_RMS_x;
  1068→        g_RMS_y_draw = g_RMS_y;
  1069→        draw_audio_canvas_waveform();
  1070→        update_silences_advanced();
  1071→        evalString = "setMuteState('" + JSON.stringify(originalMuteState) + "')";
  1072→        console.log("eval_string", evalString);
  1073→        await new Promise((resolve, reject) => {
  1074→            jsx.evalScript(evalString, function(result) {
  1075→                console.log("result of setting ORIGINAL mute state", result);
  1076→                resolve(result);
  1077→            });
  1078→        });
  1079→    } catch (err) {
  1080→        handleErrorNotification(err);
  1081→    } finally {
  1082→        hideSpinner();
  1083→        clear_abort_undo_state();
  1084→        console.log("track_code", trackerId);
  1085→        tracker.end(trackerId);
  1086→        test_52_schedule_log_upload(200);
  1087→    }
  1088→}
  1089→async function remove_silences_advanced(force = false) {
  1090→    await test_45_save_state("Before cutting silences (advanced)");
  1091→    await test_46_retrieve_undo_state_info();
  1092→    const licenseVerified = await verify_license_throttled();
  1093→    if (!licenseVerified) {
  1094→        showError("Please provide a valid license key in the Settings menu");
  1095→        return;
  1096→    }
  1097→    if (!check_function_availability("remove_silences_advanced")) {
  1098→        showError("Please provide a valid license key in the Settings menu");
  1099→        return;
  1100→    }
  1101→    test_52_schedule_log_upload(time_delay = 0);
  1102→    regular_license_key_checker();
  1103→    const trackerId = tracker.start("remove_silences_advanced");
  1104→    try {
  1105→        console.log("g_silences_padded", JSON.stringify(g_silences_padded));
  1106→        var silences_padded_valid_only = [];
  1107→        console.log("Remove silences advanced called. Constructing silences_padded_valid_only array from silences_padded");
  1108→        for (let i = 0; i < g_silences_padded.length; i++) {
  1109→            if (g_silences_padded[i][0] < g_silences_padded[i][1]) {
  1110→                silences_padded_valid_only.push(g_silences_padded[i]);
  1111→            }
  1112→        }
  1113→        console.log("silences_padded_valid_only", silences_padded_valid_only);
  1114→        if (silences_padded_valid_only.length == 0) {
  1115→            showError("No valid silences found (likely because the padding is longer than the detected silences). Please try reducing the padding.");
  1116→            hideSpinner();
  1117→            return;
  1118→        }
  1119→        silence_cutting_parameters = await test_40_get_silence_params();
  1120→        console.log("silence_cutting_parameters", JSON.stringify(silence_cutting_parameters));
  1121→        if (silence_cutting_parameters.method != "turbo" && silences_padded_valid_only.length > remove_silences_max_silences_to_cut && !force) {
  1122→            showWarning('Your chosen settings may result in a long processing time (you have selected the "' + (silence_cutting_parameters.method[0].toUpperCase() + silence_cutting_parameters.method.substr(1)) + '" algorithm for cutting ' + silences_padded_valid_only.length + " silences, which is greater than the suggested maximum of " + remove_silences_max_silences_to_cut + ' for this algorithm).\n  \n                  Suggested solutions: Reduce the number of silences by increasing the minimum silence duration or padding settings, or pick the "Turbo" algorithm (experimental).', remove_silences_advanced.bind(null, true));
  1123→            return;
  1124→        }
  1125→        method = REMOVE_SILENCES_METHODS[silence_cutting_parameters.method];
  1126→        time_method = REMOVE_SILENCES_TIME_METHODS[silence_cutting_parameters.method];
  1127→        console.log("method", method);
  1128→        console.log("time_method", time_method);
  1129→        let j_cut = silence_cutting_parameters.jcuts && silence_cutting_parameters.jcut_offset_frames > 0;
  1130→        let j_cut_seconds = 0;
  1131→        if (silence_cutting_parameters.jcut_offset_frames > 0) {
  1132→            var evalString = "getVideoFrameRateInSeconds()";
  1133→            console.log("eval_string", evalString);
  1134→            let videoFrameRate = await new Promise((resolve, reject) => {
  1135→                jsx.evalScript(evalString, function(result) {
  1136→                    console.log("result", result);
  1137→                    resolve(result);
  1138→                });
  1139→            });
  1140→            videoFrameRate = parseFloat(videoFrameRate);
  1141→            j_cut_seconds = silence_cutting_parameters.jcut_offset_frames * videoFrameRate;
  1142→        }
  1143→        await remove_silences(showEndMessage = true, mode = "advanced", silences = silences_padded_valid_only, method = method, time_method = time_method, operation = silence_cutting_parameters.operation, single_track_mode = false, target_track_index = null, target_track_type = null, affect_linked_tracks = true, anchor_every = 10, show_progress = true, j_cut = j_cut, j_cut_seconds = j_cut_seconds);
  1144→        if (g_selected_silence_number !== null) {
  1145→            clear_silence_selection();
  1146→        }
  1147→        open_menu("silence-cutting-advanced");
  1148→    } catch (err) {
  1149→        handleErrorNotification(err);
  1150→    } finally {
  1151→        hideSpinner();
  1152→        clear_abort_undo_state();
  1153→        tracker.end(trackerId);
  1154→        test_52_schedule_log_upload(200);
  1155→    }
  1156→}
  1157→async function detect_silence_threshold() {
  1158→    const licenseVerified = await verify_license_throttled();
  1159→    if (!licenseVerified) {
  1160→        showError("Please provide a valid license key in the Settings menu");
  1161→        return;
  1162→    }
  1163→    if (!check_function_availability("detect_silence_threshold")) {
  1164→        showError("Please provide a valid license key in the Settings menu");
  1165→        return;
  1166→    }
  1167→    test_52_schedule_log_upload(time_delay = 0);
  1168→    regular_license_key_checker();
  1169→    showSpinner();
  1170→    await test_45_save_state("Before detecting silence threshold");
  1171→    await test_46_retrieve_undo_state_info();
  1172→    const trackerId = tracker.start("detect_silence_threshold");
  1173→    try {
  1174→        silence_cutting_parameters = await test_40_get_silence_params();
  1175→        console.log("silence_cutting_parameters", JSON.stringify(silence_cutting_parameters));
  1176→        if (silence_cutting_parameters.keyAudioTrackIndices.length == 0) {
  1177→            showError("Please select at least one audio track");
  1178→            hideSpinner();
  1179→            return;
  1180→        }
  1181→        if (!silence_cutting_parameters.scopeValid) {
  1182→            showError("Please select a valid scope (you may need to set the in and out points explicitly)");
  1183→            hideSpinner();
  1184→            return;
  1185→        }
  1186→        showSpinner(spinner_msg_threshold_exporting);
  1187→        let originalMuteState, modifiedMuteState;
  1188→        var evalString = "getMuteState()";
  1189→        console.log("eval_string", evalString);
  1190→        originalMuteState = await new Promise((resolve, reject) => {
  1191→            jsx.evalScript(evalString, function(result) {
  1192→                console.log("result", result);
  1193→                resolve(JSON.parse(result));
  1194→            });
  1195→        });
  1196→        modifiedMuteState = JSON.parse(JSON.stringify(originalMuteState));
  1197→        modifiedMuteState.audio = modifiedMuteState.audio.map((isMuted, index) => +!silence_cutting_parameters.keyAudioTrackIndices.includes(index));
  1198→        evalString = "setMuteState('" + JSON.stringify(modifiedMuteState) + "')";
  1199→        console.log("eval_string", evalString);
  1200→        await new Promise((resolve, reject) => {
  1201→            jsx.evalScript(evalString, function(result) {
  1202→                console.log("result of setting mute state", result);
  1203→                resolve(result);
  1204→            });
  1205→        });
  1206→        console.log("Remove silences");
  1207→        file_path = await test_1_extract_audio_from_sequence(silence_cutting_parameters.scope, silence_cutting_parameters.format);
  1208→        console.log("test_1 complete");
  1209→        autodetected_threshold = null;
  1210→        showSpinner(spinner_msg_threshold_detecting);
  1211→        try {
  1212→            autodetected_threshold = await test_38a_cut_silences(file_path);
  1213→            console.log("autodetected_threshold recevied from test_38a_cut_silences:", autodetected_threshold);
  1214→        } catch (err) {
  1215→            console.log("error while autodetecting threshold", err);
  1216→            showError("Could not auto-detect threshold. Please set it manually.");
  1217→            hideSpinner();
  1218→        }
  1219→        $("#range-silence-threshold").val(Math.round(autodetected_threshold));
  1220→        $("#value-silence-threshold").val(Math.round(autodetected_threshold));
  1221→        showMessage("Silence threshold auto-detected as " + Math.round(autodetected_threshold) + " dBFS. Please check and adjust if necessary.");
  1222→        evalString = "setMuteState('" + JSON.stringify(originalMuteState) + "')";
  1223→        console.log("eval_string", evalString);
  1224→        await new Promise((resolve, reject) => {
  1225→            jsx.evalScript(evalString, function(result) {
  1226→                console.log("result of setting ORIGINAL mute state", result);
  1227→                resolve(result);
  1228→            });
  1229→        });
  1230→    } catch (err) {
  1231→        handleErrorNotification(err);
  1232→    } finally {
  1233→        hideSpinner();
  1234→        clear_abort_undo_state();
  1235→        tracker.end(trackerId);
  1236→        test_52_schedule_log_upload(200);
  1237→    }
  1238→}
  1239→async function detect_silence_threshold_2() {
  1240→    let threshold = null;
  1241→    console.log("Going to threshold_analysis");
  1242→    analysis = threshold_analysis(g_RMS_y);
  1243→    threshold = analysis.value;
  1244→    console.log("got back value as ", threshold);
  1245→    if (threshold === null) {
  1246→        console.log("Setting it to -30dBFS");
  1247→        threshold = -30;
  1248→    }
  1249→    threshold = Math.round(threshold);
  1250→    $("#range-silence-threshold-2").val(threshold);
  1251→    $("#value-silence-threshold-2").val(threshold);
  1252→    update_silences_advanced();
  1253→}
  1254→var g_silences_removed = [];
  1255→async function silences_basic_go(force = false, params = null, returnResult = false) {
  1256→    const licenseVerified = await verify_license_throttled();
  1257→    if (!licenseVerified) {
  1258→        showError("Please provide a valid license key in the Settings menu");
  1259→        return;
  1260→    }
  1261→    if (!check_function_availability("silences_basic_go")) {
  1262→        showError("Please provide a valid license key in the Settings menu");
  1263→        return;
  1264→    }
  1265→    test_52_schedule_log_upload(0);
  1266→    regular_license_key_checker();
  1267→    await test_45_save_state("Before cutting silences (basic)");
  1268→    await test_46_retrieve_undo_state_info();
  1269→    const trackerId = tracker.start("silences_basic_go");
  1270→    try {
  1271→        showSpinner("Rendering audio");
  1272→        silence_cutting_parameters = params || await test_40_get_silence_params();
  1273→        console.log("silence_cutting_parameters", JSON.stringify(silence_cutting_parameters));
  1274→        if (silence_cutting_parameters.keyAudioTrackIndices.length === 0) {
  1275→            showError("Please select at least one audio track");
  1276→            hideSpinner();
  1277→            return;
  1278→        }
  1279→        if (!silence_cutting_parameters.scopeValid) {
  1280→            showError("Please select a valid scope (you may need to set the in and out points explicitly)");
  1281→            hideSpinner();
  1282→            return;
  1283→        }
  1284→        if (silence_cutting_parameters.format === "wav" && (silence_cutting_parameters.outPoint - silence_cutting_parameters.inPoint) > remove_silences_max_duration_wav && !force) {
  1285→            showWarning('Your chosen settings may result in a crash (you have selected the "WAV" analysis format for ' + Math.ceil((silence_cutting_parameters.outPoint - silence_cutting_parameters.inPoint) / 60).toFixed(0) + " minutes of sequence, which is greater than the suggested maximum of " + (remove_silences_max_duration_wav / 60).toFixed(0) + ' minutes for this format).\n                  \n                  Suggested solutions: Pick the "MP3" analysis format, or reduce your scope using In/Out Points.', analyze_audio.bind(null, true));
  1286→            return;
  1287→        }
  1288→        const chunks = chunk(silence_cutting_parameters.inPoint, silence_cutting_parameters.outPoint, remove_silences_max_duration, false);
  1289→        console.log("chunks", chunks);
  1290→        let totalSilencesCount = 0;
  1291→        let totalSilencesDuration = 0;
  1292→        for (let i = 0; i < chunks.length; i++) {
  1293→            silence_cutting_parameters.inPoint = chunks[i][0] - totalSilencesDuration;
  1294→            silence_cutting_parameters.outPoint = chunks[i][1] - totalSilencesDuration;
  1295→            silence_cutting_parameters.scope = "inout";
  1296→            var evalString = "app.project.activeSequence.setInPoint(" + silence_cutting_parameters.inPoint + ")";
  1297→            console.log("eval_string", evalString);
  1298→            await new Promise((resolve, reject) => {
  1299→                jsx.evalScript(evalString, function(result) {
  1300→                    console.log("result", result);
  1301→                    resolve(parseFloat(result));
  1302→                });
  1303→            });
  1304→            var evalString = "app.project.activeSequence.setOutPoint(" + silence_cutting_parameters.outPoint + ")";
  1305→            console.log("eval_string", evalString);
  1306→            await new Promise((resolve, reject) => {
  1307→                jsx.evalScript(evalString, function(result) {
  1308→                    console.log("result", result);
  1309→                    resolve(parseFloat(result));
  1310→                });
  1311→            });
  1312→            silences_return = await test_39_detect_silences(silence_cutting_parameters.keyAudioTrackIndices, silence_cutting_parameters.min_silence_length, null, silence_cutting_parameters.scope, silence_cutting_parameters.format);
  1313→            console.log("silences_return", silences_return);
  1314→            g_silences = silences_return.silentRanges;
  1315→            console.log("g_silences", g_silences);
  1316→            if (silence_cutting_parameters.scope === "inout" && g_silences.length > 0) {
  1317→                g_silences = g_silences.map((range) => [range[0] + silence_cutting_parameters.inPoint, range[1] + silence_cutting_parameters.inPoint]);
  1318→            }
  1319→            g_silences_padded = g_silences.map((range, index) => [index === 0 ? range[0] : range[0] + silence_cutting_parameters.padding_start / 1000, index === g_silences.length - 1 ? range[1] : range[1] - silence_cutting_parameters.padding_end / 1000]);
  1320→            console.log("g_silences_padded.length", g_silences_padded.length);
  1321→            silences_padded_valid_only = g_silences_padded.filter((range) => range[0] < range[1]);
  1322→            console.log("silences_padded_valid_only.length", silences_padded_valid_only.length);
  1323→            totalSilencesCount += silences_padded_valid_only.length;
  1324→            totalSilencesDuration += silences_padded_valid_only.reduce((acc, range) => acc + (range[1] - range[0]), 0);
  1325→            if (silences_padded_valid_only.length === 0) continue;
  1326→            showSpinner("Cutting silences");
  1327→            method = REMOVE_SILENCES_METHODS[silence_cutting_parameters.method];
  1328→            time_method = REMOVE_SILENCES_TIME_METHODS[silence_cutting_parameters.method];
  1329→            console.log("method", method);
  1330→            console.log("time_method", time_method);
  1331→            await remove_silences(showEndMessage = false, mode = "advanced", silences = silences_padded_valid_only, method = method, time_method = time_method, operation = silence_cutting_parameters.operation, single_track_mode = false, target_track_index = null, target_track_type = null, affect_linked_tracks = true, anchor_every = 10, show_progress = true, j_cut = false, j_cut_seconds = 0, hideSpinnerAtTheEnd = !returnResult);
  1332→        }
  1333→        if (totalSilencesCount === 0) {
  1334→            if (returnResult) return {
  1335→                status: "skipped",
  1336→                message: "No silences detected."
  1337→            };
  1338→            showMessage("No silences detected. Please try changing parameters.");
  1339→            hideSpinner();
  1340→            return;
  1341→        }
  1342→        if (returnResult) return {
  1343→            status: "completed",
  1344→            message: "Cut " + totalSilencesCount + " silences (" + totalSilencesDuration.toFixed(1) + " seconds)."
  1345→        };
  1346→        else showMessage("Cut " + totalSilencesCount + " silences (" + totalSilencesDuration.toFixed(1) + " seconds)");
  1347→    } catch (err) {
  1348→        if (returnResult) return {
  1349→            status: "failed",
  1350→            message: err && err.message ? err.message : String(err) || "Unknown error."
  1351→        };
  1352→        handleErrorNotification(err);
  1353→    } finally {
  1354→        if (!returnResult) hideSpinner();
  1355→        clear_abort_undo_state();
  1356→        tracker.end(trackerId);
  1357→        test_52_schedule_log_upload(200);
  1358→    }
  1359→}
  1360→async function silences_basic_go_2() {
  1361→    const licenseVerified = await verify_license_throttled();
  1362→    if (!licenseVerified) {
  1363→        showError("Please provide a valid license key in the Settings menu");
  1364→        return;
  1365→    }
  1366→    if (!check_function_availability("silences_basic_go")) {
  1367→        showError("Please provide a valid license key in the Settings menu");
  1368→        return;
  1369→    }
  1370→    test_52_schedule_log_upload(time_delay = 0);
  1371→    regular_license_key_checker();
  1372→    await test_45_save_state("Before cutting silences (basic)");
  1373→    await test_46_retrieve_undo_state_info();
  1374→    const trackerId = tracker.start("analyze_audio");
  1375→    try {
  1376→        console.log("track_code", trackerId);
  1377→        showSpinner();
  1378→        silence_cutting_parameters = await test_40_get_silence_params();
  1379→        console.log("silence_cutting_parameters", JSON.stringify(silence_cutting_parameters));
  1380→        if (silence_cutting_parameters.keyAudioTrackIndices.length == 0) {
  1381→            showError("Please select at least one audio track");
  1382→            hideSpinner();
  1383→            return;
  1384→        }
  1385→        if (!silence_cutting_parameters.scopeValid) {
  1386→            showError("Please ensure your In/Out points are valid");
  1387→            hideSpinner();
  1388→            return;
  1389→        }
  1390→        let originalMuteState, modifiedMuteState;
  1391→        var evalString = "getMuteState()";
  1392→        console.log("eval_string", evalString);
  1393→        originalMuteState = await new Promise((resolve, reject) => {
  1394→            jsx.evalScript(evalString, function(result) {
  1395→                console.log("result", result);
  1396→                resolve(result);
  1397→            });
  1398→        });
  1399→        if (originalMuteState.includes("EvalScript")) throw new Error(originalMuteState);
  1400→        originalMuteState = JSON.parse(originalMuteState);
  1401→        modifiedMuteState = JSON.parse(JSON.stringify(originalMuteState));
  1402→        modifiedMuteState.audio = modifiedMuteState.audio.map((isMuted, index) => +!silence_cutting_parameters.keyAudioTrackIndices.includes(index));
  1403→        evalString = "setMuteState('" + JSON.stringify(modifiedMuteState) + "')";
  1404→        console.log("eval_string", evalString);
  1405→        await new Promise((resolve, reject) => {
  1406→            jsx.evalScript(evalString, function(result) {
  1407→                console.log("result", result);
  1408→                resolve(result);
  1409→            });
  1410→        });
  1411→        evalString = "app.project.activeSequence.getWorkAreaInPoint()";
  1412→        console.log("eval_string", evalString);
  1413→        const workAreaIn = await new Promise((resolve, reject) => {
  1414→            jsx.evalScript(evalString, function(result) {
  1415→                console.log("result", result);
  1416→                resolve(parseFloat(result));
  1417→            });
  1418→        });
  1419→        evalString = "app.project.activeSequence.getWorkAreaOutPoint()";
  1420→        console.log("eval_string", evalString);
  1421→        var workAreaOut = await new Promise((resolve, reject) => {
  1422→            jsx.evalScript(evalString, function(result) {
  1423→                console.log("result", result);
  1424→                resolve(parseFloat(result));
  1425→            });
  1426→        });
  1427→        var duration = workAreaOut - workAreaIn;
  1428→        let chunks = chunk(start = silence_cutting_parameters.inPoint, end = silence_cutting_parameters.outPoint, chunk_size = remove_silences_max_duration, upto_twice = false);
  1429→        console.log("chunks", chunks);
  1430→        let totalSilencesCount = 0;
  1431→        let totalSilencesDuration = 0;
  1432→        g_silences = [];
  1433→        g_nonspeech_centerpoints = [];
  1434→        g_RMS_x = [];
  1435→        g_RMS_y = [];
  1436→        for (let i = 0; i < chunks.length; i++) {
  1437→            silence_cutting_parameters.inPoint = chunks[i][0] - totalSilencesDuration;
  1438→            silence_cutting_parameters.outPoint = chunks[i][1] - totalSilencesDuration;
  1439→            silence_cutting_parameters.scope = "inout";
  1440→            g_RMS_x_offset = silence_cutting_parameters.inPoint;
  1441→            var evalString = "app.project.activeSequence.setInPoint(" + silence_cutting_parameters.inPoint + ")";
  1442→            console.log("eval_string", evalString);
  1443→            await new Promise((resolve, reject) => {
  1444→                jsx.evalScript(evalString, function(result) {
  1445→                    console.log("result", result);
  1446→                    resolve(parseFloat(result));
  1447→                });
  1448→            });
  1449→            var evalString = "app.project.activeSequence.setOutPoint(" + silence_cutting_parameters.outPoint + ")";
  1450→            console.log("eval_string", evalString);
  1451→            await new Promise((resolve, reject) => {
  1452→                jsx.evalScript(evalString, function(result) {
  1453→                    console.log("result", result);
  1454→                    resolve(parseFloat(result));
  1455→                });
  1456→            });
  1457→            showSpinner("Rendering audio");
  1458→            console.log("Remove silences");
  1459→            file_path = await test_1_extract_audio_from_sequence(silence_cutting_parameters.scope, silence_cutting_parameters.format);
  1460→            console.log("test_1 complete");
  1461→            showSpinner("Detecting silences (0%)");
  1462→            await test_37_create_arrays(file_path);
  1463→        }
  1464→        let threshold = null;
  1465→        console.log("Going to threshold_analysis");
  1466→        analysis = threshold_analysis(g_RMS_y);
  1467→        threshold = analysis.value;
  1468→        console.log("got back value as ", threshold);
  1469→        if (threshold === null) {
  1470→            console.log("Setting it to -30dBFS");
  1471→            threshold = -30;
  1472→        }
  1473→        threshold = Math.round(threshold);
  1474→        $("#range-silence-threshold-2").val(threshold);
  1475→        $("#value-silence-threshold-2").val(threshold);
  1476→        $("#range-silence-min-2").val(silence_cutting_parameters.min_silence_length);
  1477→        $("#value-silence-min-2").val(silence_cutting_parameters.min_silence_length);
  1478→        await update_silences_advanced({
  1479→            silenceThresh: threshold
  1480→        });
  1481→        console.log("g_silences_padded.length", g_silences_padded.length);
  1482→        silences_padded_valid_only = g_silences_padded.filter((range) => range[0] < range[1]);
  1483→        console.log("silences_padded_valid_only.length", silences_padded_valid_only.length);
  1484→        totalSilencesCount += silences_padded_valid_only.length;
  1485→        totalSilencesDuration += silences_padded_valid_only.reduce((acc, range) => acc + (range[1] - range[0]), 0);
  1486→        if (totalSilencesCount == 0) {
  1487→            showMessage("No silences detected. Please try changing parameters.");
  1488→            hideSpinner();
  1489→            return;
  1490→        }
  1491→        showSpinner("Cutting silences");
  1492→        method = REMOVE_SILENCES_METHODS[silence_cutting_parameters.method];
  1493→        time_method = REMOVE_SILENCES_TIME_METHODS[silence_cutting_parameters.method];
  1494→        console.log("method", method);
  1495→        console.log("time_method", time_method);
  1496→        await remove_silences(showEndMessage = false, mode = "advanced", silences = silences_padded_valid_only, method = method, time_method = time_method, operation = silence_cutting_parameters.operation, single_track_mode = false, target_track_index = null, target_track_type = null, affect_linked_tracks = true, anchor_every = 10, show_progress = true);
  1497→        showMessage("Cut " + totalSilencesCount + " silences (" + totalSilencesDuration.toFixed(1) + " seconds)");
  1498→        evalString = "setMuteState('" + JSON.stringify(originalMuteState) + "')";
  1499→        console.log("eval_string", evalString);
  1500→        await new Promise((resolve, reject) => {
  1501→            jsx.evalScript(evalString, function(result) {
  1502→                console.log("result of setting ORIGINAL mute state", result);
  1503→                resolve(result);
  1504→            });
  1505→        });
  1506→    } catch (err) {
  1507→        handleErrorNotification(err);
  1508→    } finally {
  1509→        hideSpinner();
  1510→        clear_abort_undo_state();
  1511→        console.log("track_code", trackerId);
  1512→        tracker.end(trackerId);
  1513→        test_52_schedule_log_upload(200);
  1514→    }
  1515→}
  1516→

<system-reminder>
Whenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.
</system-reminder>
