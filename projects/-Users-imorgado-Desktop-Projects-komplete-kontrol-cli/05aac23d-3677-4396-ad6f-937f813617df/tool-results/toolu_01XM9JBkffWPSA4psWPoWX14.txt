     1→#!/bin/bash
     2→# Parallel Execution Planner - Analyzes tasks for parallel execution opportunities
     3→# Returns JSON with canParallelize flag and groups of independent tasks
     4→
     5→set -eo pipefail
     6→
     7→LOG_FILE="${HOME}/.claude/logs/parallel-planner.log"
     8→mkdir -p "$(dirname "$LOG_FILE")"
     9→
    10→log() {
    11→    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" >> "$LOG_FILE"
    12→}
    13→
    14→# ============================================================================
    15→# Pattern Detection - Identify parallelizable task types
    16→# ============================================================================
    17→
    18→detect_parallelizable_pattern() {
    19→    local task="$1"
    20→    local context="$2"
    21→    local task_lower=$(echo "$task" | tr '[:upper:]' '[:lower:]')
    22→
    23→    # PATTERN 1: Testing/Validation (multiple independent test suites)
    24→    if echo "$task_lower" | grep -qiE 'test|validate|check|verify|spec|unit|integration|e2e'; then
    25→        echo "testing"
    26→        return 0
    27→    fi
    28→
    29→    # PATTERN 2: Research/Analysis (multiple independent aspects)
    30→    if echo "$task_lower" | grep -qiE 'research|analyze|investigate|explore|study|audit|review'; then
    31→        echo "research"
    32→        return 0
    33→    fi
    34→
    35→    # PATTERN 3: Code generation for multiple components
    36→    if echo "$task_lower" | grep -qiE 'implement.*modules|create.*components|build.*features|generate.*functions'; then
    37→        echo "multi_component"
    38→        return 0
    39→    fi
    40→
    41→    # PATTERN 4: Documentation (multiple docs)
    42→    if echo "$task_lower" | grep -qiE 'document|write.*docs|create.*documentation'; then
    43→        echo "documentation"
    44→        return 0
    45→    fi
    46→
    47→    # PATTERN 5: Data processing (batch operations)
    48→    if echo "$task_lower" | grep -qiE 'process.*files|convert.*data|batch.*process|transform.*all'; then
    49→        echo "batch_processing"
    50→        return 0
    51→    fi
    52→
    53→    # PATTERN 6: Multiple distinct tasks (comma or 'and' separated)
    54→    if echo "$task_lower" | grep -qiE '\s+(and|,)\s+'; then
    55→        echo "multi_task"
    56→        return 0
    57→    fi
    58→
    59→    # Not parallelizable
    60→    echo "none"
    61→    return 0
    62→}
    63→
    64→# ============================================================================
    65→# Dependency Analysis - Check for task dependencies
    66→# ============================================================================
    67→
    68→has_dependencies() {
    69→    local task="$1"
    70→    local task_lower=$(echo "$task" | tr '[:upper:]' '[:lower:]')
    71→
    72→    # Keywords that suggest sequential dependency (with word boundaries)
    73→    local dep_keywords=('\bthen\b' '\bafter\b' '\bbefore\b' 'followed by' 'depends on' '\brequires\b' '\bsequential\b' 'step 1' 'step 2' 'first\b.*\bthen\b')
    74→
    75→    for keyword in "${dep_keywords[@]}"; do
    76→        if echo "$task_lower" | grep -qiE "$keyword"; then
    77→            return 0  # Has dependencies
    78→        fi
    79→    done
    80→
    81→    return 1  # No dependencies
    82→}
    83→
    84→# ============================================================================
    85→# Generate Groups - Create parallelizable task groups
    86→# ============================================================================
    87→
    88→generate_test_groups() {
    89→    local task="$1"
    90→    local context="$2"
    91→
    92→    # Extract potential test types from task
    93→    local task_lower=$(echo "$task" | tr '[:upper:]' '[:lower:]')
    94→
    95→    local groups_json='['
    96→
    97→    # Default test types
    98→    local test_groups=(
    99→        "Unit tests"
   100→        "Integration tests"
   101→        "E2E tests"
   102→        "Performance tests"
   103→        "Security tests"
   104→    )
   105→
   106→    # Customized based on task content
   107→    if echo "$task_lower" | grep -qiE 'api|rest|graphql'; then
   108→        test_groups=(
   109→            "API endpoint tests"
   110→            "Schema validation tests"
   111→            "Authentication tests"
   112→            "Rate limiting tests"
   113→        )
   114→    elif echo "$task_lower" | grep -qiE 'ui|frontend|react|vue'; then
   115→        test_groups=(
   116→            "Component tests"
   117→            "User flow tests"
   118→            "Accessibility tests"
   119→            "Responsiveness tests"
   120→        )
   121→    elif echo "$task_lower" | grep -qiE 'database|sql|mongo|postgres'; then
   122→        test_groups=(
   123→            "Schema tests"
   124→            "Query tests"
   125→            "Migration tests"
   126→            "Performance tests"
   127→        )
   128→    fi
   129→
   130→    # Generate groups
   131→    local first=true
   132→    for group in "${test_groups[@]}"; do
   133→        if ! $first; then
   134→            groups_json+=','
   135→        fi
   136→        groups_json+=$(jq -n \
   137→            --arg name "$group" \
   138→            --arg task "$task" \
   139→            '{
   140→                id: ($name | gsub(" "; "_") | ascii_downcase),
   141→                name: $name,
   142→                description: "Run '"$group"' for: " + $task,
   143→                tasks: [$task + " - " + $name],
   144→                dependencies: [],
   145→                estimatedEffort: "medium",
   146→                ioBound: true
   147→            }')
   148→        first=false
   149→    done
   150→
   151→    groups_json+=']'
   152→    echo "$groups_json"
   153→}
   154→
   155→generate_research_groups() {
   156→    local task="$1"
   157→    local context="$2"
   158→
   159→    local task_lower=$(echo "$task" | tr '[:upper:]' '[:lower:]')
   160→
   161→    local groups_json='['
   162→    local research_groups=(
   163→        "Codebase patterns analysis"
   164→        "External solutions research"
   165→        "Architecture review"
   166→        "Dependency mapping"
   167→        "Performance analysis"
   168→    )
   169→
   170→    # Customize based on task
   171→    if echo "$task_lower" | grep -qiE 'security|auth|vulnerability'; then
   172→        research_groups=(
   173→            "Security patterns research"
   174→            "Known vulnerabilities check"
   175→            "Authentication mechanisms review"
   176→            "Authorization flows analysis"
   177→            "Best practices research"
   178→        )
   179→    elif echo "$task_lower" | grep -qiE 'performance|optimization|speed'; then
   180→        research_groups=(
   181→            "Performance bottlenecks analysis"
   182→            "Caching strategies research"
   183→            "Database optimization review"
   184→            "Network patterns research"
   185→        )
   186→    fi
   187→
   188→    local first=true
   189→    for group in "${research_groups[@]}"; do
   190→        if ! $first; then
   191→            groups_json+=','
   192→        fi
   193→        groups_json+=$(jq -n \
   194→            --arg name "$group" \
   195→            --arg task "$task" \
   196→            '{
   197→                id: ($name | gsub(" "; "_") | gsub("[^a-z0-9_]"; "") | ascii_downcase),
   198→                name: $name,
   199→                description: $name + " for: " + $task,
   200→                tasks: [$task + " - " + $name],
   201→                dependencies: [],
   202→                estimatedEffort: "medium",
   203→                ioBound: true
   204→            }')
   205→        first=false
   206→    done
   207→
   208→    groups_json+=']'
   209→    echo "$groups_json"
   210→}
   211→
   212→generate_multi_component_groups() {
   213→    local task="$1"
   214→    local context="$2"
   215→
   216→    local groups_json='['
   217→    local component_groups=(
   218→        "Backend implementation"
   219→        "Frontend implementation"
   220→        "API layer"
   221→        "Data models"
   222→        "Tests"
   223→    )
   224→
   225→    local first=true
   226→    for group in "${component_groups[@]}"; do
   227→        if ! $first; then
   228→            groups_json+=','
   229→        fi
   230→        groups_json+=$(jq -n \
   231→            --arg name "$group" \
   232→            --arg task "$task" \
   233→            '{
   234→                id: ($name | gsub(" "; "_") | ascii_downcase),
   235→                name: $name,
   236→                description: $name + " for: " + $task,
   237→                tasks: [$task + " - " + $name],
   238→                dependencies: [],
   239→                estimatedEffort: "medium",
   240→                ioBound: false
   241→            }')
   242→        first=false
   243→    done
   244→
   245→    groups_json+=']'
   246→    echo "$groups_json"
   247→}
   248→
   249→generate_documentation_groups() {
   250→    local task="$1"
   251→    local context="$2"
   252→
   253→    local groups_json='['
   254→    local doc_groups=(
   255→        "API documentation"
   256→        "User guide"
   257→        "Developer documentation"
   258→        "Installation guide"
   259→        "Examples and tutorials"
   260→    )
   261→
   262→    local first=true
   263→    for group in "${doc_groups[@]}"; do
   264→        if ! $first; then
   265→            groups_json+=','
   266→        fi
   267→        groups_json+=$(jq -n \
   268→            --arg name "$group" \
   269→            --arg task "$task" \
   270→            '{
   271→                id: ($name | gsub(" "; "_") | ascii_downcase),
   272→                name: $name,
   273→                description: "Create " + $name + " for: " + $task,
   274→                tasks: [$task + " - " + $name],
   275→                dependencies: [],
   276→                estimatedEffort: "low",
   277→                ioBound: true
   278→            }')
   279→        first=false
   280→    done
   281→
   282→    groups_json+=']'
   283→    echo "$groups_json"
   284→}
   285→
   286→generate_batch_processing_groups() {
   287→    local task="$1"
   288→    local context="$2"
   289→
   290→    # Try to extract file patterns from context
   291→    local file_count=4
   292→    if [[ -n "$context" ]]; then
   293→        # Count files mentioned or in current directory
   294→        if command -v jq &>/dev/null; then
   295→            file_count=$(echo "$context" | jq -r 'length // 4' 2>/dev/null || echo "4")
   296→            if [[ $file_count -gt 10 ]]; then
   297→                file_count=10  # Cap at 10 groups
   298→            elif [[ $file_count -lt 2 ]]; then
   299→                file_count=2
   300→            fi
   301→        fi
   302→    fi
   303→
   304→    local groups_json='['
   305→    local first=true
   306→
   307→    for ((i=1; i<=file_count; i++)); do
   308→        if ! $first; then
   309→            groups_json+=','
   310→        fi
   311→        groups_json+=$(jq -n \
   312→            --arg i "$i" \
   313→            --arg total "$file_count" \
   314→            --arg task "$task" \
   315→            '{
   316→                id: ("batch_\($i)"),
   317→                name: "Batch \($i) of \($total)",
   318→                description: "Process batch \($i)/\($total) for: " + $task,
   319→                tasks: [$task + " - batch " + $i],
   320→                dependencies: [],
   321→                estimatedEffort: "medium",
   322→                ioBound: true
   323→            }')
   324→        first=false
   325→    done
   326→
   327→    groups_json+=']'
   328→    echo "$groups_json"
   329→}
   330→
   331→generate_multi_task_groups() {
   332→    local task="$1"
   333→    local context="$2"
   334→
   335→    # Split task by ' and ', ',', or ' also ' using awk
   336→    # Awk handles word-boundary splitting better than sed
   337→    local normalized
   338→    normalized=$(echo "$task" | awk -v RS=' and | also |,' '{gsub(/^[ \t]+|[ \t]+$/, ""); if (NR>1) printf "\n"; printf "%s", $0} END {printf "\n"}')
   339→
   340→    # Read into array
   341→    local tasks=()
   342→    while IFS= read -r line; do
   343→        # Trim whitespace and skip empty lines
   344→        line=$(echo "$line" | sed -e 's/^[[:space:]]*//' -e 's/[[:space:]]*$//')
   345→        [[ -n "$line" ]] && tasks+=("$line")
   346→    done <<< "$normalized"
   347→
   348→    # If we got 0 or 1 tasks, just use the original task
   349→    if [[ ${#tasks[@]} -le 1 ]]; then
   350→        tasks=("$task")
   351→    fi
   352→
   353→    # Limit to 10 groups max
   354→    if [[ ${#tasks[@]} -gt 10 ]]; then
   355→        tasks=("${tasks[@]:0:10}")
   356→    fi
   357→
   358→    local groups_json='['
   359→    local first=true
   360→
   361→    for t in "${tasks[@]}"; do
   362→        if ! $first; then
   363→            groups_json+=','
   364→        fi
   365→        groups_json+=$(jq -n \
   366→            --arg name "$t" \
   367→            '{
   368→                id: ($name | gsub(" "; "_") | gsub("[^a-z0-9_]"; "") | ascii_downcase),
   369→                name: $name,
   370→                description: "Execute: " + $name,
   371→                tasks: [$name],
   372→                dependencies: [],
   373→                estimatedEffort: "medium",
   374→                ioBound: false
   375→            }')
   376→        first=false
   377→    done
   378→
   379→    groups_json+=']'
   380→    echo "$groups_json"
   381→}
   382→
   383→# ============================================================================
   384→# Main Analysis Function
   385→# ============================================================================
   386→
   387→analyze_task() {
   388→    local task="$1"
   389→    local context="${2:-}"
   390→
   391→    log "Analyzing task for parallelization: $task"
   392→
   393→    # Step 1: Detect pattern
   394→    local pattern
   395→    pattern=$(detect_parallelizable_pattern "$task" "$context")
   396→    log "Detected pattern: $pattern"
   397→
   398→    # Step 2: Check for dependencies
   399→    local has_deps=false
   400→    if has_dependencies "$task"; then
   401→        has_deps=true
   402→        log "Task has dependencies - will return sequential execution"
   403→    fi
   404→
   405→    # Step 3: Generate groups based on pattern
   406→    local groups_json="[]"
   407→    local strategy="sequential"
   408→
   409→    if [[ "$pattern" == "none" || "$has_deps" == "true" ]]; then
   410→        # Not parallelizable
   411→        groups_json="[]"
   412→        strategy="sequential"
   413→    elif [[ "$pattern" == "testing" ]]; then
   414→        groups_json=$(generate_test_groups "$task" "$context")
   415→        strategy="parallel_independent"
   416→    elif [[ "$pattern" == "research" ]]; then
   417→        groups_json=$(generate_research_groups "$task" "$context")
   418→        strategy="parallel_independent"
   419→    elif [[ "$pattern" == "multi_component" ]]; then
   420→        groups_json=$(generate_multi_component_groups "$task" "$context")
   421→        strategy="parallel_independent"
   422→    elif [[ "$pattern" == "documentation" ]]; then
   423→        groups_json=$(generate_documentation_groups "$task" "$context")
   424→        strategy="parallel_independent"
   425→    elif [[ "$pattern" == "batch_processing" ]]; then
   426→        groups_json=$(generate_batch_processing_groups "$task" "$context")
   427→        strategy="parallel_batch"
   428→    elif [[ "$pattern" == "multi_task" ]]; then
   429→        groups_json=$(generate_multi_task_groups "$task" "$context")
   430→        strategy="parallel_independent"
   431→    fi
   432→
   433→    # Step 4: Determine if parallelization is beneficial
   434→    local group_count
   435→    group_count=$(echo "$groups_json" | jq 'length')
   436→
   437→    local can_parallelize="false"
   438→    if [[ "$pattern" != "none" ]] && [[ "$has_deps" == "false" ]] && [[ $group_count -ge 2 ]]; then
   439→        can_parallelize="true"
   440→    fi
   441→
   442→    # Step 5: Build final result
   443→    local result
   444→    result=$(jq -n \
   445→        --arg task "$task" \
   446→        --argjson canParallelize "$can_parallelize" \
   447→        --argjson groups "$groups_json" \
   448→        --arg strategy "$strategy" \
   449→        --arg pattern "$pattern" \
   450→        --argjson hasDependencies "$has_deps" \
   451→        --argjson groupCount "$group_count" \
   452→        '{
   453→            task: $task,
   454→            canParallelize: $canParallelize,
   455→            groups: $groups,
   456→            strategy: $strategy,
   457→            analysis: {
   458→                pattern: $pattern,
   459→                hasDependencies: $hasDependencies,
   460→                groupCount: $groupCount,
   461→                parallelizable: ($canParallelize and $groupCount >= 2)
   462→            },
   463→            recommendations: (
   464→                if $canParallelize and $groupCount >= 3 then
   465→                    ["Auto-spawn swarm for maximum parallelism", ("Use swarm-orchestrator with " + ($groupCount | tostring) + " agents")]
   466→                elif $canParallelize then
   467→                    ["Execute groups in parallel", "Coordinate results after completion"]
   468→                else
   469→                    ["Execute sequentially", "Task structure does not support parallelization"]
   470→                end
   471→            )
   472→        }')
   473→
   474→    log "Analysis complete: parallelize=$can_parallelize, groups=$group_count, strategy=$strategy"
   475→    echo "$result"
   476→}
   477→
   478→# ============================================================================
   479→# CLI Interface
   480→# ============================================================================
   481→
   482→case "${1:-help}" in
   483→    analyze)
   484→        task="${2:-sample task}"
   485→        context="${3:-}"
   486→        analyze_task "$task" "$context"
   487→        ;;
   488→
   489→    *)
   490→        cat <<'HELP'
   491→Parallel Execution Planner
   492→
   493→Analyzes tasks for parallel execution opportunities and returns groups of
   494→independent subtasks that can be executed in parallel.
   495→
   496→Usage: parallel-execution-planner.sh analyze <task> [context]
   497→
   498→Commands:
   499→  analyze <task> [context]
   500→      Analyze task and return parallelization plan
   501→      Returns JSON with:
   502→        - canParallelize: boolean
   503→        - groups: array of task groups
   504→        - strategy: parallelization strategy
   505→        - analysis: detailed analysis
   506→        - recommendations: execution recommendations
   507→
   508→Examples:
   509→  parallel-execution-planner.sh analyze "Run comprehensive tests"
   510→  parallel-execution-planner.sh analyze "Research authentication patterns"
   511→  parallel-execution-planner.sh analyze "Implement user module and admin module"
   512→
   513→Output Format:
   514→{
   515→  "task": "...",
   516→  "canParallelize": true|false,
   517→  "groups": [
   518→    {
   519→      "id": "...",
   520→      "name": "...",
   521→      "description": "...",
   522→      "tasks": [...],
   523→      "dependencies": [],
   524→      "estimatedEffort": "low|medium|high",
   525→      "ioBound": true|false
   526→    }
   527→  ],
   528→  "strategy": "sequential|parallel_independent|parallel_batch",
   529→  "analysis": {
   530→    "pattern": "...",
   531→    "hasDependencies": true|false,
   532→    "groupCount": N,
   533→    "parallelizable": true|false
   534→  },
   535→  "recommendations": ["..."]
   536→}
   537→
   538→Integration:
   539→  Used by coordinator.sh to detect swarm spawning opportunities.
   540→  If canParallelize=true and groups>=3, auto-spawns swarm.
   541→HELP
   542→        ;;
   543→esac
   544→

<system-reminder>
Whenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.
</system-reminder>
