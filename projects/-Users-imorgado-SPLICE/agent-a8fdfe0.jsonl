{"parentUuid":null,"isSidechain":true,"userType":"external","cwd":"/Users/imorgado/SPLICE","sessionId":"f54237a4-bd56-48d1-8850-c37f656bca6a","version":"2.0.76","gitBranch":"main","agentId":"a8fdfe0","slug":"sparkling-gliding-pearl","type":"user","message":{"role":"user","content":"Design the integration of reverse engineering tools, MCP servers, and production features.\n\n**Context from Exploration:**\n- **Already Installed**:\n  - Frida 17.5.2 âœ… (at /opt/homebrew/Cellar/frida/17.5.2/)\n  - frida-mcp 0.1.1 âœ… (Python package at /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages/frida_mcp/)\n  - mitmproxy 12.2.1 âœ…\n  - Ghidra 12.0 âœ…\n  - gRPC, Protobuf libraries âœ…\n\n- **Production-Ready Code** (from vision documents):\n  - Deep Research APIs (Perplexity, Tavily, arXiv, Semantic Scholar) - 255 lines TypeScript\n  - RAG System (ChromaDB + LlamaIndex) - 216 lines TypeScript  \n  - Voice-to-Code (Groq Whisper) - 200 lines TypeScript\n  - LoRA Training Pipeline - 300+ lines Python\n  - Video Analysis Service - 380 lines TypeScript\n  - Website Tech Stack Detector - 370 lines TypeScript\n\n- **MCP Servers**: 24+ available, currently only 2/24 integrated in SPLICE. Need to add PostgreSQL MCP, Semgrep, Playwright, CodeQL.\n\n**Reverse Engineering Tools (from user request):**\nNetwork/API: mitmproxy, Burp Suite, Charles Proxy, Wireshark, Kiterunner, RESTler\nProtocols: pbtk (Protobuf), BloomRPC, InQL (GraphQL), Clairvoyance\nMobile/Binary: JADX-GUI, Frida, Objection, Ghidra, Radare2, dnSpy, WABT\nOS/Kernel: WinDbg, QEMU, GDB, Volatility, Binwalk\nWeb/AI: Chrome DevTools, screenshot-to-code, Puppeteer-extra-plugin-stealth\n\n**User Requirements:**\n- Integrate reverse engineering tools into CLI workflow\n- Enable frida-mcp (already installed, just config)\n- Add MCP servers for security, databases, testing\n- Include deep research, RAG, voice coding from vision docs\n- Make it \"the absolute best tool possible that can make anything\"\n\n**Design Requirements:**\n1. **Immediate Wins** (Week 1):\n   - Enable frida-mcp in config (5 minutes)\n   - Add deep research APIs (2-3 days)\n   - Implement RAG system for codebase (2-3 days)\n   - Configure 4+ MCP servers (1 day)\n\n2. **Reverse Engineering Integration** (Week 2-3):\n   - Create mitmproxy-mcp server (2-4 hours)\n   - Create jadx-mcp server for APK analysis (1-2 hours)\n   - Create api-analyzer-mcp for GraphQL/gRPC introspection (3-5 hours)\n   - Wire frida-mcp to CLI commands\n\n3. **Advanced Features** (Week 4+):\n   - Voice-to-code integration\n   - Screenshot-to-code (AI-powered UI cloning)\n   - Website tech stack detection\n   - LoRA training for custom models\n\n4. **CLI Commands**:\n   - `agentic frida <pid>` - Attach Frida to process\n   - `agentic proxy start` - Launch mitmproxy\n   - `agentic analyze apk <file>` - Decompile with JADX\n   - `agentic research \"<query>\"` - Deep research with Perplexity/Tavily\n   - `agentic voice` - Start voice coding mode\n   - `agentic clone-ui <url>` - Screenshot â†’ code\n\n5. **MCP Server Config**:\n   - Format for ~/.agentic/mcp.json\n   - Auto-discovery of installed tools\n   - Enable/disable servers dynamically\n\n**Constraints:**\n- Must work on macOS (user's system)\n- Leverage already-installed tools (Frida, mitmproxy, Ghidra)\n- Copy production-ready code from vision documents\n- Simple installation (brew, npm, pip)\n\n**Deliverables:**\n- Tool integration architecture\n- MCP server configuration design\n- CLI commands for each tool category\n- Week 1 implementation priority list\n- Installation/setup instructions\n- Code migration plan from vision docs\n\nFocus on quick wins first (enable frida-mcp, add deep research), then build out RE capabilities."},"uuid":"266d3df0-8094-49f7-95ed-06d15e5b8f7a","timestamp":"2026-01-11T16:40:23.306Z"}
{"parentUuid":"266d3df0-8094-49f7-95ed-06d15e5b8f7a","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/SPLICE","sessionId":"f54237a4-bd56-48d1-8850-c37f656bca6a","version":"2.0.76","gitBranch":"main","agentId":"a8fdfe0","slug":"sparkling-gliding-pearl","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01Dvk7dDgfGqdR7Bzs1smGPz","type":"message","role":"assistant","content":[{"type":"text","text":"# SPLICE Reverse Engineering & Advanced Capabilities Integration Plan\n\n## Executive Summary\n\nThis plan transforms SPLICE into a comprehensive development platform by integrating reverse engineering tools, MCP servers, and production-ready AI capabilities. The design prioritizes **immediate wins** (frida-mcp, deep research, RAG) while establishing a foundation for advanced reverse engineering workflows.\n\n## Architecture Overview\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                         SPLICE Enhanced Architecture                          â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                                               â”‚\nâ”‚  CLI Layer (splice-cli/)                                                     â”‚\nâ”‚  â”œâ”€ commands/                                                                â”‚\nâ”‚  â”‚  â”œâ”€ frida.js          - Frida dynamic instrumentation                     â”‚\nâ”‚  â”‚  â”œâ”€ proxy.js          - mitmproxy network analysis                        â”‚\nâ”‚  â”‚  â”œâ”€ analyze.js        - APK/binary decompilation                          â”‚\nâ”‚  â”‚  â”œâ”€ research.js       - Deep research orchestration                       â”‚\nâ”‚  â”‚  â”œâ”€ voice.js          - Voice-to-code workflow                            â”‚\nâ”‚  â”‚  â”œâ”€ clone-ui.js       - Screenshot-to-code UI cloning                     â”‚\nâ”‚  â”‚  â””â”€ rag.js            - RAG-powered codebase Q&A                          â”‚\nâ”‚  â””â”€ lib/                                                                     â”‚\nâ”‚     â”œâ”€ mcpManager.js     - MCP server lifecycle management                   â”‚\nâ”‚     â”œâ”€ toolDetector.js   - Auto-detect installed RE tools                    â”‚\nâ”‚     â””â”€ reversing.js      - Shared RE utilities                               â”‚\nâ”‚                                                                               â”‚\nâ”‚  MCP Servers Layer (mcp-servers/)                                            â”‚\nâ”‚  â”œâ”€ frida-mcp            âœ… Already installed                                â”‚\nâ”‚  â”œâ”€ mitmproxy-mcp        ğŸ†• Network traffic analysis                         â”‚\nâ”‚  â”œâ”€ jadx-mcp             ğŸ†• APK decompilation                                â”‚\nâ”‚  â”œâ”€ api-analyzer-mcp     ğŸ†• GraphQL/gRPC introspection                       â”‚\nâ”‚  â”œâ”€ postgresql-mcp       ğŸ†• Database schema exploration                      â”‚\nâ”‚  â”œâ”€ playwright-mcp       ğŸ†• Browser automation testing                       â”‚\nâ”‚  â”œâ”€ semgrep-mcp          ğŸ†• Static security analysis                         â”‚\nâ”‚  â””â”€ ghidra-mcp           ğŸ”® Future: Binary analysis bridge                   â”‚\nâ”‚                                                                               â”‚\nâ”‚  Backend Services (splice-backend/)                                          â”‚\nâ”‚  â”œâ”€ services/                                                                â”‚\nâ”‚  â”‚  â”œâ”€ deepResearch.js   ğŸ†• Perplexity + Tavily + arXiv                     â”‚\nâ”‚  â”‚  â”œâ”€ ragSystem.js      ğŸ†• ChromaDB + LlamaIndex                            â”‚\nâ”‚  â”‚  â”œâ”€ voiceToCode.js    ğŸ†• Groq Whisper transcription                       â”‚\nâ”‚  â”‚  â”œâ”€ videoAnalysis.js  ğŸ†• Frame extraction + AI analysis                   â”‚\nâ”‚  â”‚  â”œâ”€ techDetector.js   ğŸ†• Website stack detection                          â”‚\nâ”‚  â”‚  â””â”€ loraTraining.js   ğŸ”® Future: Custom model training                    â”‚\nâ”‚  â””â”€ workers/                                                                 â”‚\nâ”‚     â”œâ”€ researchWorker.js - Async deep research jobs                          â”‚\nâ”‚     â”œâ”€ ragWorker.js      - Vector DB indexing                                â”‚\nâ”‚     â””â”€ trainWorker.js    - ML model training queue                           â”‚\nâ”‚                                                                               â”‚\nâ”‚  Configuration (~/.agentic/mcp.json)                                         â”‚\nâ”‚  â””â”€ Dynamic MCP server registry with auto-discovery                          â”‚\nâ”‚                                                                               â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n## Phase 1: Immediate Wins (Week 1)\n\n### 1.1 Enable frida-mcp (Day 1 - 30 minutes)\n\n**Configuration File:** `~/.agentic/mcp.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"frida\": {\n      \"command\": \"python\",\n      \"args\": [\"-m\", \"frida_mcp\"],\n      \"env\": {\n        \"FRIDA_DEVICE\": \"local\"\n      },\n      \"enabled\": true,\n      \"capabilities\": [\"dynamic-instrumentation\", \"hooking\", \"memory-inspection\"]\n    }\n  }\n}\n```\n\n**CLI Command:**\n```bash\n# Attach to running process\nagentic frida attach <pid>\n\n# List running processes\nagentic frida ps\n\n# Spawn and instrument\nagentic frida spawn com.example.app --script hook.js\n\n# Interactive REPL\nagentic frida repl <pid>\n```\n\n### 1.2 Deep Research APIs (Day 2-4)\n\n**Service Location:** `/Users/imorgado/SPLICE/splice-backend/services/deepResearch.js`\n\n**Implementation Strategy:**\n- Copy 255 lines from vision document (deep-research-apis.ts)\n- Integrate Perplexity Sonar API (real-time web search)\n- Add Tavily API (research-grade results)\n- Connect arXiv API (academic papers)\n- Wire Semantic Scholar (citation graphs)\n\n**API Endpoints:**\n```javascript\nPOST /api/research/query\n{\n  \"query\": \"What are the latest vulnerabilities in OAuth 2.0?\",\n  \"sources\": [\"perplexity\", \"tavily\", \"arxiv\", \"semanticscholar\"],\n  \"depth\": \"comprehensive\" // quick | standard | comprehensive\n}\n\nGET /api/research/status/:jobId\nGET /api/research/results/:jobId\n```\n\n**CLI Command:**\n```bash\nagentic research \"reverse engineering iOS apps with Frida\" --sources arxiv,perplexity --depth comprehensive\n```\n\n### 1.3 RAG System for Codebase (Day 5-7)\n\n**Service Location:** `/Users/imorgado/SPLICE/splice-backend/services/ragSystem.js`\n\n**Implementation Strategy:**\n- Copy 216 lines from vision document (rag-system.ts)\n- Use ChromaDB for vector storage\n- Integrate LlamaIndex for chunking/retrieval\n- Index entire SPLICE codebase on startup\n\n**Workflow:**\n```\n1. Index codebase (one-time or on-demand)\n   â””â”€> Chunks: 500 tokens, overlap: 50\n   â””â”€> Embeddings: text-embedding-3-small (OpenAI)\n   â””â”€> Storage: ChromaDB collection \"splice-codebase\"\n\n2. Query processing\n   â”œâ”€> User question â†’ embedding\n   â”œâ”€> Similarity search (top 5 chunks)\n   â”œâ”€> LLM synthesis with context\n   â””â”€> Return answer + source files\n```\n\n**CLI Command:**\n```bash\n# Index current project\nagentic rag index\n\n# Query codebase\nagentic rag ask \"How does the token blacklist work?\"\n\n# Update index incrementally\nagentic rag update --files \"splice-backend/middleware/*.js\"\n```\n\n### 1.4 MCP Server Configuration (Day 7)\n\n**Add 4 High-Value MCP Servers:**\n\n```json\n{\n  \"mcpServers\": {\n    \"frida\": { /* ... */ },\n    \n    \"postgresql\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@modelcontextprotocol/server-postgresql\"],\n      \"env\": {\n        \"POSTGRES_CONNECTION_STRING\": \"${DATABASE_URL}\"\n      },\n      \"enabled\": true,\n      \"capabilities\": [\"database-introspection\", \"query-execution\", \"schema-analysis\"]\n    },\n    \n    \"playwright\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@playwright/mcp-server\"],\n      \"enabled\": true,\n      \"capabilities\": [\"browser-automation\", \"e2e-testing\", \"screenshot-capture\"]\n    },\n    \n    \"semgrep\": {\n      \"command\": \"docker\",\n      \"args\": [\"run\", \"-i\", \"returntocorp/semgrep-mcp\"],\n      \"enabled\": true,\n      \"capabilities\": [\"static-analysis\", \"security-scanning\", \"code-patterns\"]\n    },\n    \n    \"github\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@modelcontextprotocol/server-github\"],\n      \"env\": {\n        \"GITHUB_TOKEN\": \"${GITHUB_TOKEN}\"\n      },\n      \"enabled\": true,\n      \"capabilities\": [\"repo-management\", \"issue-tracking\", \"pr-creation\"]\n    }\n  }\n}\n```\n\n## Phase 2: Reverse Engineering Integration (Week 2-3)\n\n### 2.1 mitmproxy-mcp Server (2-4 hours)\n\n**Location:** `/Users/imorgado/SPLICE/mcp-servers/mitmproxy-mcp/`\n\n**Features:**\n- Start/stop mitmproxy programmatically\n- Query captured traffic by URL pattern\n- Extract API endpoints and parameters\n- Generate OpenAPI specs from traffic\n- Detect authentication schemes\n\n**MCP Tools Exposed:**\n```typescript\n{\n  \"start_proxy\": {\n    \"description\": \"Start mitmproxy on specified port\",\n    \"parameters\": { \"port\": 8080, \"mode\": \"regular|transparent|reverse\" }\n  },\n  \"query_traffic\": {\n    \"description\": \"Search captured requests/responses\",\n    \"parameters\": { \"url_pattern\": \"regex\", \"method\": \"GET|POST|...\", \"limit\": 100 }\n  },\n  \"extract_apis\": {\n    \"description\": \"Auto-detect API endpoints from traffic\",\n    \"returns\": \"Array of { method, path, params, auth, examples }\"\n  },\n  \"generate_openapi\": {\n    \"description\": \"Generate OpenAPI 3.0 spec from captured traffic\",\n    \"parameters\": { \"base_url\": \"https://api.example.com\" }\n  }\n}\n```\n\n**CLI Commands:**\n```bash\nagentic proxy start --port 8080 --mode transparent\nagentic proxy query \"api.stripe.com/v1/*\"\nagentic proxy extract-apis --output openapi.yaml\nagentic proxy stop\n```\n\n### 2.2 jadx-mcp Server (1-2 hours)\n\n**Location:** `/Users/imorgado/SPLICE/mcp-servers/jadx-mcp/`\n\n**Installation:**\n```bash\nbrew install jadx  # Already standard via Android dev tools\n```\n\n**MCP Tools Exposed:**\n```typescript\n{\n  \"decompile_apk\": {\n    \"description\": \"Decompile APK to Java source\",\n    \"parameters\": { \"apk_path\": \"string\", \"output_dir\": \"string\" }\n  },\n  \"extract_manifest\": {\n    \"description\": \"Parse AndroidManifest.xml\",\n    \"returns\": \"JSON representation of manifest\"\n  },\n  \"find_activities\": {\n    \"description\": \"List all Activities and their intents\",\n    \"returns\": \"Array of { name, exported, intent_filters }\"\n  },\n  \"find_api_keys\": {\n    \"description\": \"Search for hardcoded secrets/API keys\",\n    \"returns\": \"Array of potential secrets with locations\"\n  }\n}\n```\n\n**CLI Commands:**\n```bash\nagentic analyze apk app.apk --output decompiled/\nagentic analyze apk app.apk --extract-secrets\nagentic analyze apk app.apk --find-activities\n```\n\n### 2.3 api-analyzer-mcp Server (3-5 hours)\n\n**Location:** `/Users/imorgado/SPLICE/mcp-servers/api-analyzer-mcp/`\n\n**Purpose:** Introspect GraphQL, gRPC, and REST APIs\n\n**Dependencies:**\n```bash\nnpm install graphql apollo-client @grpc/grpc-js @grpc/proto-loader\n```\n\n**MCP Tools Exposed:**\n```typescript\n{\n  \"introspect_graphql\": {\n    \"description\": \"Fetch GraphQL schema via introspection\",\n    \"parameters\": { \"endpoint\": \"string\", \"headers\": \"object\" }\n  },\n  \"parse_proto\": {\n    \"description\": \"Parse .proto files and list services\",\n    \"parameters\": { \"proto_path\": \"string\" }\n  },\n  \"detect_rest_api\": {\n    \"description\": \"Analyze REST API from OpenAPI/Swagger\",\n    \"parameters\": { \"spec_url\": \"string\" }\n  },\n  \"fuzz_endpoints\": {\n    \"description\": \"Generate test cases for API fuzzing\",\n    \"parameters\": { \"schema\": \"object\", \"coverage\": \"basic|comprehensive\" }\n  }\n}\n```\n\n**CLI Commands:**\n```bash\nagentic api introspect https://api.github.com/graphql\nagentic api parse-proto services.proto\nagentic api fuzz --schema openapi.yaml --coverage comprehensive\n```\n\n### 2.4 Frida CLI Integration\n\n**Command Structure:**\n```bash\nagentic frida <subcommand> [options]\n\nSubcommands:\n  attach <pid>           - Attach to running process\n  spawn <app>            - Spawn and instrument app\n  ps                     - List running processes\n  repl <pid>             - Interactive Frida REPL\n  run <script> <pid>     - Execute Frida script\n  trace <pid>            - Trace function calls\n```\n\n**Example Workflow:**\n```bash\n# 1. Find target process\nagentic frida ps --filter \"Safari\"\n\n# 2. Attach and hook\nagentic frida attach 1234 --script hooks/ssl-pinning-bypass.js\n\n# 3. Monitor in real-time\nagentic frida trace 1234 --functions \"objc_msgSend,*URLSession*\"\n```\n\n## Phase 3: Advanced Features (Week 4+)\n\n### 3.1 Voice-to-Code Integration\n\n**Service Location:** `/Users/imorgado/SPLICE/splice-backend/services/voiceToCode.js`\n\n**Implementation:**\n- Copy 200 lines from vision document\n- Use Groq Whisper for transcription (fast, accurate)\n- Stream audio â†’ text â†’ code generation\n- Support multiple languages (English, Spanish, Mandarin)\n\n**API Endpoint:**\n```javascript\nPOST /api/voice/transcribe\nContent-Type: multipart/form-data\n{\n  audio: <audio file>,\n  context: \"I'm working on authentication middleware\"\n}\n\nResponse:\n{\n  transcript: \"add a rate limiter that blocks after five failed attempts\",\n  code: \"// Generated code...\",\n  confidence: 0.95\n}\n```\n\n**CLI Command:**\n```bash\n# Start voice mode (continuous listening)\nagentic voice start\n\n# Transcribe single file\nagentic voice transcribe audio.wav --context \"Building a REST API\"\n```\n\n### 3.2 Screenshot-to-Code (UI Cloning)\n\n**Service Location:** `/Users/imorgado/SPLICE/splice-backend/services/screenshotToCode.js`\n\n**Dependencies:**\n```bash\nnpm install puppeteer sharp openai\n```\n\n**Workflow:**\n```\n1. Capture screenshot (URL or upload)\n2. GPT-4 Vision analysis\n   â”œâ”€> Identify components (nav, hero, cards, forms)\n   â”œâ”€> Extract styles (colors, fonts, spacing)\n   â””â”€> Detect frameworks (React, Tailwind, etc.)\n3. Generate code\n   â”œâ”€> HTML/JSX structure\n   â”œâ”€> CSS/Tailwind classes\n   â””â”€> React components\n4. Return code + preview\n```\n\n**CLI Command:**\n```bash\nagentic clone-ui https://stripe.com/pricing --framework react --style tailwind\nagentic clone-ui screenshot.png --output components/\n```\n\n### 3.3 Website Tech Stack Detector\n\n**Service Location:** `/Users/imorgado/SPLICE/splice-backend/services/techDetector.js`\n\n**Implementation:**\n- Copy 370 lines from vision document\n- Analyze HTTP headers, HTML meta tags, JavaScript libraries\n- Detect frameworks (React, Vue, Angular, Next.js)\n- Identify backend (Node, Django, Rails)\n- Discover CDNs, analytics, hosting\n\n**API Endpoint:**\n```javascript\nPOST /api/analyze/tech-stack\n{\n  url: \"https://example.com\"\n}\n\nResponse:\n{\n  frontend: [\"React 18.2\", \"Next.js 14\", \"Tailwind CSS\"],\n  backend: [\"Node.js\", \"Express\"],\n  hosting: [\"Vercel\"],\n  cdn: [\"Cloudflare\"],\n  analytics: [\"Google Analytics\", \"Mixpanel\"]\n}\n```\n\n**CLI Command:**\n```bash\nagentic analyze tech-stack https://vercel.com\n```\n\n### 3.4 Video Analysis Service\n\n**Service Location:** `/Users/imorgado/SPLICE/splice-backend/services/videoAnalysis.js`\n\n**Implementation:**\n- Copy 380 lines from vision document\n- Extract frames at intervals\n- GPT-4 Vision for scene analysis\n- Generate timestamps + descriptions\n- Detect UI flows, animations, interactions\n\n**Use Case for SPLICE:**\n- Analyze screen recordings of Adobe Premiere Pro\n- Extract UI patterns for plugin development\n- Auto-generate documentation from tutorial videos\n\n## MCP Manager Architecture\n\n**Location:** `/Users/imorgado/SPLICE/splice-cli/lib/mcpManager.js`\n\n**Responsibilities:**\n1. Load MCP server configurations from `~/.agentic/mcp.json`\n2. Spawn MCP server processes (stdio transport)\n3. Health check and auto-restart\n4. Route tool calls to appropriate servers\n5. Aggregate capabilities for CLI help\n\n**Core Functions:**\n```javascript\nclass MCPManager {\n  async loadServers()           // Parse config, validate, spawn\n  async callTool(server, tool)  // Invoke MCP tool via stdio\n  async listCapabilities()      // Aggregate all server capabilities\n  async enableServer(name)      // Start disabled server\n  async disableServer(name)     // Stop running server\n  async reloadConfig()          // Hot-reload mcp.json\n}\n```\n\n**Auto-Discovery:**\n```javascript\n// Detect installed RE tools\nconst toolDetector = {\n  checkFrida: () => execSync('frida --version'),\n  checkMitmproxy: () => execSync('mitmproxy --version'),\n  checkJADX: () => execSync('jadx --version'),\n  checkGhidra: () => fs.existsSync('/Applications/ghidra.app'),\n  checkWireshark: () => execSync('tshark --version')\n};\n\n// Auto-generate mcp.json entries\nawait mcpManager.autoConfigureServers();\n```\n\n## CLI Command Reference\n\n```bash\n# Reverse Engineering\nagentic frida attach <pid>               # Dynamic instrumentation\nagentic frida spawn <app> --script <js>  # Spawn with hooks\nagentic proxy start --port 8080          # Network traffic capture\nagentic proxy extract-apis               # Generate OpenAPI from traffic\nagentic analyze apk <file>               # Decompile Android APK\nagentic analyze tech-stack <url>         # Detect website technologies\n\n# AI Research & Development\nagentic research \"<query>\"               # Deep research with multiple sources\nagentic rag ask \"<question>\"             # Query codebase with RAG\nagentic rag index                        # Index current project\nagentic voice start                      # Voice-to-code mode\nagentic clone-ui <url>                   # Screenshot-to-code\n\n# MCP Server Management\nagentic mcp list                         # Show all configured servers\nagentic mcp enable <server>              # Enable a server\nagentic mcp disable <server>             # Disable a server\nagentic mcp reload                       # Reload configuration\nagentic mcp auto-configure               # Auto-detect installed tools\n\n# API Analysis\nagentic api introspect <url>             # GraphQL introspection\nagentic api parse-proto <file>           # gRPC service analysis\nagentic api fuzz --schema <file>         # API fuzzing test generation\n```\n\n## Environment Variables\n\n**Add to:** `/Users/imorgado/SPLICE/splice-backend/.env`\n\n```bash\n# =============================================================================\n# Deep Research APIs\n# =============================================================================\nPERPLEXITY_API_KEY=pplx-your-key-here\nTAVILY_API_KEY=tvly-your-key-here\nSEMANTIC_SCHOLAR_API_KEY=your-key-here  # Optional\n\n# =============================================================================\n# RAG System\n# =============================================================================\nCHROMA_HOST=localhost\nCHROMA_PORT=8000\nOPENAI_EMBEDDING_MODEL=text-embedding-3-small\n\n# =============================================================================\n# Voice-to-Code\n# =============================================================================\nGROQ_API_KEY=your-groq-key-here\n\n# =============================================================================\n# Screenshot-to-Code\n# =============================================================================\nOPENAI_API_KEY=your-openai-key-here  # GPT-4 Vision\n\n# =============================================================================\n# Video Analysis\n# =============================================================================\nFFMPEG_PATH=/opt/homebrew/bin/ffmpeg  # Auto-detect\n```\n\n## Installation Guide\n\n### Week 1 Quick Start\n\n```bash\n# 1. Install dependencies\ncd /Users/imorgado/SPLICE/splice-backend\nnpm install chromadb llamaindex groq-sdk axios cheerio\n\n# 2. Start ChromaDB (Docker)\ndocker run -d -p 8000:8000 chromadb/chroma\n\n# 3. Configure frida-mcp\ncat > ~/.agentic/mcp.json <<EOF\n{\n  \"mcpServers\": {\n    \"frida\": {\n      \"command\": \"python\",\n      \"args\": [\"-m\", \"frida_mcp\"],\n      \"enabled\": true\n    }\n  }\n}\nEOF\n\n# 4. Copy production code from vision docs\n# Deep Research: vision/deep-research-apis.ts â†’ splice-backend/services/deepResearch.js\n# RAG System: vision/rag-system.ts â†’ splice-backend/services/ragSystem.js\n# Voice-to-Code: vision/voice-to-code.ts â†’ splice-backend/services/voiceToCode.js\n\n# 5. Run migrations (add research/rag tables)\nnpm run db:migrate\n\n# 6. Test frida-mcp\nagentic frida ps\n\n# 7. Test deep research\nagentic research \"GraphQL security best practices\" --sources perplexity,arxiv\n\n# 8. Index codebase with RAG\nagentic rag index\n```\n\n### Week 2-3 Reverse Engineering Setup\n\n```bash\n# 1. Install RE tools (if not already present)\nbrew install jadx mitmproxy wireshark\n\n# 2. Build custom MCP servers\ncd /Users/imorgado/SPLICE/mcp-servers\n\n# mitmproxy-mcp\nmkdir mitmproxy-mcp && cd mitmproxy-mcp\nnpm init -y\nnpm install @modelcontextprotocol/sdk mitmproxy-node\n# Implement server (see Phase 2.1)\n\n# jadx-mcp\nmkdir jadx-mcp && cd jadx-mcp\nnpm init -y\nnpm install @modelcontextprotocol/sdk\n# Implement server (see Phase 2.2)\n\n# api-analyzer-mcp\nmkdir api-analyzer-mcp && cd api-analyzer-mcp\nnpm init -y\nnpm install @modelcontextprotocol/sdk graphql @grpc/grpc-js\n# Implement server (see Phase 2.3)\n\n# 3. Update ~/.agentic/mcp.json with new servers\nagentic mcp auto-configure\n\n# 4. Test\nagentic proxy start\nagentic analyze apk test.apk\nagentic api introspect https://api.github.com/graphql\n```\n\n## Code Migration Plan\n\n### Priority 1: Deep Research (Day 2-4)\n\n**Source:** `vision/deep-research-apis.ts` (255 lines)\n\n**Target:** `/Users/imorgado/SPLICE/splice-backend/services/deepResearch.js`\n\n**Migration Steps:**\n1. Convert TypeScript â†’ JavaScript (remove type annotations)\n2. Adapt imports (ES modules â†’ CommonJS)\n3. Replace `fetch` with `axios` (already in backend)\n4. Add BullMQ job queue integration\n5. Create database schema for research results\n\n**Database Schema:**\n```sql\nCREATE TABLE research_jobs (\n  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n  user_id UUID REFERENCES users(id),\n  query TEXT NOT NULL,\n  sources TEXT[] DEFAULT ARRAY['perplexity', 'tavily'],\n  depth VARCHAR(20) DEFAULT 'standard',\n  status VARCHAR(20) DEFAULT 'pending',\n  results JSONB,\n  created_at TIMESTAMPTZ DEFAULT NOW(),\n  completed_at TIMESTAMPTZ\n);\n\nCREATE INDEX idx_research_jobs_user_id ON research_jobs(user_id);\nCREATE INDEX idx_research_jobs_status ON research_jobs(status);\n```\n\n### Priority 2: RAG System (Day 5-7)\n\n**Source:** `vision/rag-system.ts` (216 lines)\n\n**Target:** `/Users/imorgado/SPLICE/splice-backend/services/ragSystem.js`\n\n**Migration Steps:**\n1. Convert TypeScript â†’ JavaScript\n2. Set up ChromaDB client\n3. Implement LlamaIndex integration\n4. Create indexing worker for background processing\n5. Add API endpoints for query/index\n\n**Database Schema:**\n```sql\nCREATE TABLE rag_indexes (\n  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n  project_path TEXT NOT NULL,\n  collection_name TEXT NOT NULL,\n  file_count INTEGER,\n  chunk_count INTEGER,\n  last_indexed_at TIMESTAMPTZ DEFAULT NOW(),\n  metadata JSONB\n);\n\nCREATE TABLE rag_queries (\n  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n  user_id UUID REFERENCES users(id),\n  index_id UUID REFERENCES rag_indexes(id),\n  query TEXT NOT NULL,\n  results JSONB,\n  created_at TIMESTAMPTZ DEFAULT NOW()\n);\n```\n\n### Priority 3: Voice-to-Code (Week 4)\n\n**Source:** `vision/voice-to-code.ts` (200 lines)\n\n**Target:** `/Users/imorgado/SPLICE/splice-backend/services/voiceToCode.js`\n\n**Migration Steps:**\n1. Set up Groq SDK client\n2. Implement audio streaming endpoint\n3. Add WebSocket support for real-time transcription\n4. Integrate with OpenAI for code generation\n5. Create CLI command for voice mode\n\n### Priority 4: Additional Services (Week 5+)\n\n- **Video Analysis:** `vision/video-analysis.ts` â†’ `services/videoAnalysis.js`\n- **Tech Detector:** `vision/tech-stack-detector.ts` â†’ `services/techDetector.js`\n- **Screenshot-to-Code:** Custom implementation using Puppeteer + GPT-4V\n\n## Testing Strategy\n\n### Week 1 Tests\n\n```javascript\n// tests/deepResearch.test.js\ndescribe('Deep Research Service', () => {\n  test('should query Perplexity API', async () => {\n    const result = await deepResearch.query('test query', ['perplexity']);\n    expect(result).toHaveProperty('answer');\n  });\n});\n\n// tests/ragSystem.test.js\ndescribe('RAG System', () => {\n  test('should index codebase', async () => {\n    await ragSystem.indexDirectory('/Users/imorgado/SPLICE/splice-backend');\n    const result = await ragSystem.query('How does authentication work?');\n    expect(result.sources).toContain('middleware/auth.js');\n  });\n});\n\n// tests/frida-mcp.test.js\ndescribe('Frida MCP Integration', () => {\n  test('should list running processes', async () => {\n    const processes = await mcpManager.callTool('frida', 'list_processes');\n    expect(Array.isArray(processes)).toBe(true);\n  });\n});\n```\n\n### Week 2-3 Tests\n\n```javascript\n// tests/mitmproxy-mcp.test.js\ndescribe('Mitmproxy MCP Server', () => {\n  test('should capture HTTP traffic', async () => {\n    await mcpManager.callTool('mitmproxy', 'start_proxy', { port: 8080 });\n    // Make HTTP requests through proxy\n    const traffic = await mcpManager.callTool('mitmproxy', 'query_traffic', {\n      url_pattern: '.*'\n    });\n    expect(traffic.length).toBeGreaterThan(0);\n  });\n});\n\n// tests/jadx-mcp.test.js\ndescribe('JADX MCP Server', () => {\n  test('should decompile APK', async () => {\n    const result = await mcpManager.callTool('jadx', 'decompile_apk', {\n      apk_path: 'test.apk'\n    });\n    expect(result).toHaveProperty('output_dir');\n  });\n});\n```\n\n## Performance Considerations\n\n### RAG System Optimization\n\n```javascript\n// Indexing strategy\n- Chunk size: 500 tokens (balance context vs. retrieval accuracy)\n- Overlap: 50 tokens (preserve context boundaries)\n- Batch size: 100 documents (prevent memory overflow)\n- Parallel workers: 4 (CPU cores - 1)\n\n// Query optimization\n- Max results: 5 chunks (sufficient context, minimal tokens)\n- Reranking: Use Cohere rerank API for better relevance\n- Caching: Cache embeddings for unchanged files\n```\n\n### MCP Server Pooling\n\n```javascript\n// mcpManager.js\nclass MCPManager {\n  constructor() {\n    this.serverPools = new Map(); // server_name â†’ [process1, process2, ...]\n    this.maxPoolSize = 3;\n  }\n  \n  async callTool(server, tool, params) {\n    // Round-robin load balancing across server instances\n    const pool = this.serverPools.get(server);\n    const instance = pool[this.roundRobinIndex++ % pool.length];\n    return instance.callTool(tool, params);\n  }\n}\n```\n\n## Security Considerations\n\n### Frida Security\n\n```javascript\n// Only allow Frida attachment to user-owned processes\nasync function validateFridaTarget(pid) {\n  const process = await getProcessInfo(pid);\n  if (process.uid !== os.userInfo().uid) {\n    throw new Error('Cannot attach to processes owned by other users');\n  }\n}\n```\n\n### mitmproxy Isolation\n\n```javascript\n// Store captured traffic in user-specific directories\nconst trafficDir = path.join(os.homedir(), '.agentic', 'traffic', userId);\n// Encrypt sensitive data at rest\nawait encryptFile(path.join(trafficDir, 'requests.json'));\n```\n\n### API Key Protection\n\n```javascript\n// Never log API keys\nlogger.info('Research query', { query, sources }); // âœ…\nlogger.info('API call', { apiKey }); // âŒ\n\n// Use environment variables, never hardcode\nconst PERPLEXITY_KEY = process.env.PERPLEXITY_API_KEY;\n```\n\n---\n\n## Critical Files for Implementation\n\n### Week 1 (Immediate Wins)\n\n- **/Users/imorgado/SPLICE/splice-backend/services/deepResearch.js** - Copy 255 lines from vision doc, integrate Perplexity/Tavily/arXiv APIs for deep research\n- **/Users/imorgado/SPLICE/splice-backend/services/ragSystem.js** - Copy 216 lines from vision doc, implement ChromaDB + LlamaIndex for codebase Q&A\n- **~/.agentic/mcp.json** - Configure frida-mcp, postgresql-mcp, playwright-mcp, semgrep-mcp servers (5 minutes to enable)\n- **/Users/imorgado/SPLICE/splice-cli/commands/research.js** - CLI command for deep research orchestration\n- **/Users/imorgado/SPLICE/splice-cli/commands/rag.js** - CLI commands for RAG indexing and querying\n\n### Week 2-3 (Reverse Engineering)\n\n- **/Users/imorgado/SPLICE/mcp-servers/mitmproxy-mcp/index.js** - New MCP server for network traffic analysis, API extraction, OpenAPI generation\n- **/Users/imorgado/SPLICE/mcp-servers/jadx-mcp/index.js** - New MCP server for APK decompilation, manifest parsing, secret detection\n- **/Users/imorgado/SPLICE/mcp-servers/api-analyzer-mcp/index.js** - New MCP server for GraphQL/gRPC introspection and fuzzing\n- **/Users/imorgado/SPLICE/splice-cli/commands/frida.js** - CLI commands for Frida dynamic instrumentation (attach, spawn, trace, REPL)\n- **/Users/imorgado/SPLICE/splice-cli/lib/mcpManager.js** - Core MCP server lifecycle manager with auto-discovery and load balancing\n\n### Week 4+ (Advanced Features)\n\n- **/Users/imorgado/SPLICE/splice-backend/services/voiceToCode.js** - Copy 200 lines from vision doc, integrate Groq Whisper for voice-to-code\n- **/Users/imorgado/SPLICE/splice-backend/services/videoAnalysis.js** - Copy 380 lines from vision doc for video frame extraction and AI analysis\n- **/Users/imorgado/SPLICE/splice-backend/services/techDetector.js** - Copy 370 lines from vision doc for website tech stack detection"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":7540,"cache_read_input_tokens":18899,"cache_creation":{"ephemeral_5m_input_tokens":7540,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CX1vRtJ9gyNMQZcqHB7Us","type":"assistant","uuid":"d4ccc0fe-287f-4d6d-8889-26387ba58848","timestamp":"2026-01-11T16:42:35.846Z"}
