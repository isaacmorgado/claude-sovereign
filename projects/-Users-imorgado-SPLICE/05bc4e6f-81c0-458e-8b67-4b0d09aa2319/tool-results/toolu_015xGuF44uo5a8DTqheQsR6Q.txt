     1→/**
     2→ * SPLICE Backend Server
     3→ *
     4→ * Main entry point for the SPLICE backend API.
     5→ * Orchestrates the audio analysis pipeline.
     6→ *
     7→ * Slices:
     8→ * - Slice 4: Transcription (services/transcription.js)
     9→ * - Slice 5: Take Detection (services/takeDetection.js)
    10→ */
    11→
    12→/* global setTimeout, setInterval */
    13→
    14→require('dotenv').config();
    15→
    16→const express = require('express');
    17→const cors = require('cors');
    18→const fs = require('fs');
    19→const fsPromises = require('fs').promises;
    20→const https = require('https');
    21→const http = require('http');
    22→const path = require('path');
    23→
    24→// Async file existence check (non-blocking)
    25→async function fileExists(filePath) {
    26→  try {
    27→    await fsPromises.access(filePath, fs.constants.R_OK);
    28→    return true;
    29→  } catch {
    30→    return false;
    31→  }
    32→}
    33→
    34→// Check if running in production (Railway injects RAILWAY_ENVIRONMENT)
    35→const isProduction = process.env.NODE_ENV === 'production' || process.env.RAILWAY_ENVIRONMENT;
    36→
    37→// Import slice services
    38→const { transcribeAudio, transcribeWithWords } = require('./services/transcription');
    39→const { detectTakes } = require('./services/takeDetection');
    40→const { detectSilences } = require('./services/silenceDetection');
    41→const { detectAudioSilences, isFFprobeInstalled, getAudioDuration } = require('./services/ffprobeSilence');
    42→const { detectSilencesRMS, sensitivityToParams } = require('./services/rmsSilenceDetection');
    43→const {
    44→  detectProfanity,
    45→  getProfanityList,
    46→  getSupportedLanguages,
    47→  getAvailableBleepSounds,
    48→  parseWordList
    49→} = require('./services/profanityDetection');
    50→const {
    51→  detectStutters,
    52→  detectAllRepetitions
    53→} = require('./services/repetitionDetection');
    54→const {
    55→  analyzeMultitrack,
    56→  autoBalanceMultitrack
    57→} = require('./services/multitrackAnalysis');
    58→const {
    59→  toSRT,
    60→  toVTT,
    61→  toPlainText,
    62→  toJSON,
    63→  exportToFile,
    64→  getSupportedFormats
    65→} = require('./services/captionExporter');
    66→const { processXMLFile } = require('./services/xmlProcessor');
    67→const { isolateVocals, isReplicateConfigured } = require('./services/vocalIsolation');
    68→const { generateCutList, generateTakesCutList, validateCutList } = require('./services/cutListGenerator');
    69→
    70→// Usage tracking and billing
    71→const usageTracking = require('./services/usageTracking');
    72→// Rate limiter for usage-based endpoints
    73→const { requireCredits } = require('./middleware/rateLimiter');
    74→// Referral system
    75→const referralService = require('./services/referralService');
    76→// License key system
    77→const licenseService = require('./services/licenseService');
    78→
    79→// Maximum file size for audio processing (500MB)
    80→const MAX_FILE_SIZE_BYTES = 500 * 1024 * 1024;
    81→
    82→/**
    83→ * Validate file size to prevent OOM crashes
    84→ * @param {string} filePath - Path to file
    85→ * @returns {Promise<{valid: boolean, size?: number, error?: string}>}
    86→ */
    87→async function validateFileSize(filePath) {
    88→  try {
    89→    const stats = await require('fs').promises.stat(filePath);
    90→    if (stats.size > MAX_FILE_SIZE_BYTES) {
    91→      return {
    92→        valid: false,
    93→        size: stats.size,
    94→        error: `File too large (${(stats.size / 1024 / 1024).toFixed(1)}MB). Maximum allowed: ${MAX_FILE_SIZE_BYTES / 1024 / 1024}MB`
    95→      };
    96→    }
    97→    return { valid: true, size: stats.size };
    98→  } catch (err) {
    99→    return { valid: false, error: `Cannot access file: ${err.message}` };
   100→  }
   101→}
   102→
   103→// Stripe for webhooks
   104→const Stripe = require('stripe');
   105→const stripe = new Stripe(process.env.STRIPE_SECRET_KEY);
   106→
   107→// =============================================================================
   108→// Server Configuration
   109→// =============================================================================
   110→
   111→const app = express();
   112→const PORT = process.env.PORT || 3847;
   113→
   114→// HTTPS certificates (generated by mkcert) - only for local development
   115→let httpsOptions = null;
   116→if (!isProduction) {
   117→  const keyPath = path.join(__dirname, 'localhost+1-key.pem');
   118→  const certPath = path.join(__dirname, 'localhost+1.pem');
   119→  if (fs.existsSync(keyPath) && fs.existsSync(certPath)) {
   120→    httpsOptions = {
   121→      key: fs.readFileSync(keyPath),
   122→      cert: fs.readFileSync(certPath)
   123→    };
   124→  }
   125→}
   126→
   127→app.use(cors());
   128→
   129→// Helper to determine tier from price ID with logging
   130→function getTierFromPriceId(priceId) {
   131→  if (priceId === process.env.STRIPE_PRICE_STARTER) return 'starter';
   132→  if (priceId === process.env.STRIPE_PRICE_PRO) return 'pro';
   133→  if (priceId === process.env.STRIPE_PRICE_TEAM) return 'team';
   134→
   135→  // Log unknown price ID for debugging
   136→  console.warn(`[SPLICE] Unknown price ID: ${priceId} - defaulting to starter tier`);
   137→  return 'starter';
   138→}
   139→
   140→// Stripe webhook needs raw body - must be before express.json()
   141→app.post('/webhooks/stripe', express.raw({ type: 'application/json' }), async (req, res) => {
   142→  const sig = req.headers['stripe-signature'];
   143→  const webhookSecret = process.env.STRIPE_WEBHOOK_SECRET;
   144→
   145→  let event;
   146→
   147→  try {
   148→    if (webhookSecret) {
   149→      event = stripe.webhooks.constructEvent(req.body, sig, webhookSecret);
   150→    } else if (isProduction) {
   151→      // SECURITY: Reject unsigned webhooks in production
   152→      console.error('[SPLICE] CRITICAL: STRIPE_WEBHOOK_SECRET not set in production');
   153→      return res.status(500).json({ error: 'Webhook configuration error: secret not configured' });
   154→    } else {
   155→      // For local development testing only
   156→      // req.body is a Buffer from express.raw(), convert to string for JSON.parse
   157→      const bodyString = typeof req.body === 'string' ? req.body : req.body.toString('utf8');
   158→      event = JSON.parse(bodyString);
   159→      console.warn('[SPLICE] Warning: Processing webhook without signature verification (dev only)');
   160→    }
   161→  } catch (err) {
   162→    console.error('[SPLICE] Webhook signature verification failed:', err.message);
   163→    return res.status(400).json({ error: 'Webhook signature verification failed' });
   164→  }
   165→
   166→  console.log(`[SPLICE] Webhook received: ${event.type} (${event.id})`);
   167→
   168→  // Idempotency check - skip if already processed
   169→  if (await usageTracking.isEventProcessed(event.id)) {
   170→    console.log(`[SPLICE] Event ${event.id} already processed, skipping`);
   171→    return res.json({ received: true, skipped: true });
   172→  }
   173→
   174→  try {
   175→    switch (event.type) {
   176→      case 'customer.subscription.created':
   177→      case 'customer.subscription.updated': {
   178→        const subscription = event.data.object;
   179→        const customerId = subscription.customer;
   180→
   181→        // Validate customerId
   182→        if (!customerId) {
   183→          console.error('[SPLICE] Missing customer ID in subscription event');
   184→          return res.status(400).json({ error: 'Missing customer ID' });
   185→        }
   186→
   187→        // Get tier from price ID
   188→        const priceId = subscription.items?.data?.[0]?.price?.id;
   189→        const tier = getTierFromPriceId(priceId);
   190→
   191→        // Update user tier and reset hours
   192→        await usageTracking.updateTier(customerId, tier);
   193→        console.log(`[SPLICE] Updated customer ${customerId} to tier: ${tier}`);
   194→
   195→        // Generate license key for new subscriptions with retry and delivery
   196→        if (event.type === 'customer.subscription.created') {
   197→          let licenseResult = null;
   198→          let retryCount = 0;
   199→          const maxRetries = 3;
   200→
   201→          // Retry mechanism for license key generation
   202→          while (retryCount < maxRetries) {
   203→            licenseResult = await licenseService.generateLicenseKey(customerId);
   204→            if (licenseResult.success) {
   205→              break;
   206→            }
   207→            retryCount++;
   208→            console.warn(`[SPLICE] License key generation attempt ${retryCount}/${maxRetries} failed: ${licenseResult.error}`);
   209→            // Wait before retry (exponential backoff)
   210→            if (retryCount < maxRetries) {
   211→              await new Promise(resolve => setTimeout(resolve, 1000 * retryCount));
   212→            }
   213→          }
   214→
   215→          if (licenseResult && licenseResult.success) {
   216→            console.log(`[SPLICE] Generated license key for ${customerId}: ${licenseResult.key}`);
   217→
   218→            // Store license key in Stripe subscription metadata as backup
   219→            try {
   220→              await stripe.subscriptions.update(subscription.id, {
   221→                metadata: {
   222→                  license_key: licenseResult.key,
   223→                  license_generated_at: new Date().toISOString()
   224→                }
   225→              });
   226→              console.log(`[SPLICE] Stored license key in Stripe metadata for subscription ${subscription.id}`);
   227→            } catch (metaErr) {
   228→              console.error(`[SPLICE] Failed to store license key in Stripe metadata:`, metaErr.message);
   229→            }
   230→
   231→            // Get customer email and send license key
   232→            try {
   233→              const customer = await stripe.customers.retrieve(customerId);
   234→              if (customer.email) {
   235→                // Log email delivery (placeholder for actual email service)
   236→                console.log(`[SPLICE] License key ready for delivery to ${customer.email}: ${licenseResult.key}`);
   237→                // TODO: Integrate with email service (SendGrid, SES, etc.)
   238→                // await sendLicenseKeyEmail(customer.email, licenseResult.key, tier);
   239→
   240→                // Store email in database for reference
   241→                await usageTracking.updateTier(customerId, tier, customer.email);
   242→              } else {
   243→                console.warn(`[SPLICE] No email found for customer ${customerId}`);
   244→              }
   245→            } catch (emailErr) {
   246→              console.error(`[SPLICE] Error getting customer email:`, emailErr.message);
   247→            }
   248→          } else {
   249→            console.error(`[SPLICE] Failed to generate license key after ${maxRetries} attempts: ${licenseResult?.error || 'Unknown error'}`);
   250→          }
   251→        }
   252→        break;
   253→      }
   254→
   255→      case 'customer.subscription.deleted': {
   256→        const subscription = event.data.object;
   257→        const customerId = subscription.customer;
   258→
   259→        // Validate customerId
   260→        if (!customerId) {
   261→          console.error('[SPLICE] Missing customer ID in subscription.deleted event');
   262→          return res.status(400).json({ error: 'Missing customer ID' });
   263→        }
   264→
   265→        // Downgrade to cancelled (0 hours)
   266→        await usageTracking.updateTier(customerId, 'cancelled');
   267→        console.log(`[SPLICE] Subscription cancelled for customer ${customerId}`);
   268→        break;
   269→      }
   270→
   271→      case 'invoice.payment_succeeded': {
   272→        const invoice = event.data.object;
   273→        const customerId = invoice.customer;
   274→        const subscriptionId = invoice.subscription;
   275→
   276→        // Validate customerId
   277→        if (!customerId) {
   278→          console.error('[SPLICE] Missing customer ID in invoice event');
   279→          return res.status(400).json({ error: 'Missing customer ID' });
   280→        }
   281→
   282→        // Reset hours on successful payment (new billing period)
   283→        if (subscriptionId) {
   284→          const subscription = await stripe.subscriptions.retrieve(subscriptionId);
   285→          const priceId = subscription.items?.data?.[0]?.price?.id;
   286→          const tier = getTierFromPriceId(priceId);
   287→
   288→          await usageTracking.resetHours(customerId, tier);
   289→          console.log(`[SPLICE] Reset hours for customer ${customerId} (tier: ${tier})`);
   290→        }
   291→        break;
   292→      }
   293→
   294→      default:
   295→        console.log(`[SPLICE] Unhandled event type: ${event.type}`);
   296→    }
   297→
   298→    // Record event as processed (idempotency)
   299→    await usageTracking.recordWebhookEvent(event.id, event.type);
   300→
   301→    res.json({ received: true });
   302→  } catch (err) {
   303→    console.error('[SPLICE] Webhook handler error:', err);
   304→    res.status(500).json({ error: err.message });
   305→  }
   306→});
   307→
   308→app.use(express.json());
   309→
   310→// =============================================================================
   311→// Routes
   312→// =============================================================================
   313→
   314→/**
   315→ * GET / - API information
   316→ */
   317→app.get('/', (req, res) => {
   318→  res.json({
   319→    service: 'splice-backend',
   320→    version: '0.3.0',
   321→    endpoints: {
   322→      'GET /': 'This info',
   323→      'GET /health': 'Health check',
   324→      'GET /ffprobe-check': 'Check if FFprobe is installed',
   325→      'GET /replicate-check': 'Check if Replicate API is configured',
   326→      'POST /analyze': 'Analyze WAV file { wavPath }',
   327→      'POST /silences': 'Detect silences via Whisper gaps { wavPath, threshold: 0.5 }',
   328→      'POST /silences-audio': 'Detect silences via FFprobe { wavPath, threshold: -30, minDuration: 0.5, padding: 0.1 }',
   329→      'POST /silences-rms': 'Detect silences via RMS analysis { wavPath, threshold: -30, minSilenceLength: 0.5, paddingStart: 0.1, paddingEnd: 0.05, autoThreshold: false, sensitivity: 50 }',
   330→      'POST /profanity': 'Detect profanity in transcript { wavPath, language: "en", customBlocklist: [], customAllowlist: [] }',
   331→      'GET /profanity/languages': 'Get supported languages for profanity detection',
   332→      'GET /profanity/bleeps': 'Get available bleep sounds',
   333→      'POST /repetitions': 'Detect phrase repetitions and stutters { wavPath, phraseSize: 5, tolerance: 0.7, useOpenAI: false }',
   334→      'POST /fillers': 'Detect filler words (um, uh, like, etc.) { wavPath, customFillers: [] }',
   335→      'POST /stutters': 'Detect single-word stutters only { wavPath, minRepeats: 2 }',
   336→      'POST /export/captions': 'Export transcript to caption format { wavPath, format: srt|vtt|txt|json, outputPath? }',
   337→      'GET /export/formats': 'Get supported caption export formats',
   338→      'POST /multitrack': 'Analyze multiple audio tracks for multicam { audioPaths: [], speakerNames: [], videoTrackMapping: {} }',
   339→      'POST /multitrack/auto-balance': 'Auto-balance speaker screentime { audioPaths: [], speakerNames: [] }',
   340→      'POST /process-xml': 'Process FCP XML { xmlPath, silences, removeGaps: true }',
   341→      'POST /cut-list': 'Generate JSON cut list for DOM building (v3.5) { sourceName, sourcePath, duration, silences, takes?, settings? }',
   342→      'POST /cut-list/takes': 'Generate cut list keeping only takes { sourceName, sourcePath, duration, takes, settings? }',
   343→      'POST /isolate-vocals': 'Isolate vocals from audio { audioPath }',
   344→      'POST /batch/silences': 'Batch process multiple files for silence detection { files: [], options: {} }',
   345→      'GET /batch/status/:jobId': 'Get batch job status',
   346→      'GET /batch/results/:jobId': 'Get full batch job results',
   347→      'GET /batch/jobs': 'List all batch jobs',
   348→      'DELETE /batch/:jobId': 'Delete a batch job',
   349→      'GET /credits': 'Get user credit balance (requires x-stripe-customer-id header)',
   350→      'GET /usage-history': 'Get usage history (requires x-stripe-customer-id header)',
   351→      'POST /webhooks/stripe': 'Stripe webhook endpoint',
   352→      'GET /referral/code': 'Get or create referral code for user',
   353→      'POST /referral/validate': 'Validate a referral code',
   354→      'POST /referral/apply': 'Apply referral code at signup',
   355→      'GET /referral/stats': 'Get referral statistics for user',
   356→      'POST /license/activate': 'Activate license key { key: "SPLICE-XXXX-XXXX-XXXX" }',
   357→      'GET /license/key': 'Get license key for customer (requires x-stripe-customer-id)',
   358→      'POST /license/resend': 'Resend license key to customer email { customerId? }'
   359→    }
   360→  });
   361→});
   362→
   363→/**
   364→ * GET /health - Health check
   365→ */
   366→app.get('/health', (req, res) => {
   367→  res.json({ status: 'ok', service: 'splice-backend' });
   368→});
   369→
   370→/**
   371→ * POST /analyze - Main analysis endpoint
   372→ *
   373→ * Pipeline:
   374→ * 1. Validate input (wavPath)
   375→ * 2. Slice 4: Transcribe audio with Whisper
   376→ * 3. Slice 5: Detect takes with GPT-4o-mini
   377→ * 4. Return combined results
   378→ */
   379→app.post('/analyze', requireCredits({ endpoint: 'analyze' }), async (req, res) => {
   380→  const { wavPath } = req.body;
   381→
   382→  // Validate input
   383→  if (!wavPath) {
   384→    return res.status(400).json({ error: 'wavPath is required' });
   385→  }
   386→
   387→  if (!(await fileExists(wavPath))) {
   388→    return res.status(404).json({ error: `File not found: ${wavPath}` });
   389→  }
   390→
   391→  console.log(`[SPLICE] Analyzing: ${wavPath}`);
   392→
   393→  try {
   394→    // Slice 4 - GPT-4o-mini transcription
   395→    const transcript = await transcribeAudio(wavPath);
   396→
   397→    // Slice 5 - GPT-4o-mini take detection
   398→    const takes = await detectTakes(transcript);
   399→
   400→    // Deduct usage based on audio duration
   401→    const audioDuration = transcript.duration || 0;
   402→    let balance = null;
   403→    if (audioDuration > 0 && req.deductUsage) {
   404→      balance = await req.deductUsage(audioDuration);
   405→    }
   406→
   407→    res.json({
   408→      success: true,
   409→      wavPath,
   410→      transcript,
   411→      takes,
   412→      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
   413→    });
   414→  } catch (err) {
   415→    console.error('[SPLICE] Error:', err);
   416→    res.status(500).json({ error: err.message });
   417→  }
   418→});
   419→
   420→/**
   421→ * POST /silences - Detect silent gaps in audio
   422→ *
   423→ * Pipeline:
   424→ * 1. Transcribe audio with Whisper (cached)
   425→ * 2. Analyze gaps between segments
   426→ * 3. Return silence regions
   427→ */
   428→app.post('/silences', requireCredits({ endpoint: 'silences' }), async (req, res) => {
   429→  const { wavPath, threshold = 0.5 } = req.body;
   430→
   431→  if (!wavPath) {
   432→    return res.status(400).json({ error: 'wavPath is required' });
   433→  }
   434→
   435→  if (!(await fileExists(wavPath))) {
   436→    return res.status(404).json({ error: `File not found: ${wavPath}` });
   437→  }
   438→
   439→  console.log(`[SPLICE] Detecting silences: ${wavPath} (threshold: ${threshold}s)`);
   440→
   441→  try {
   442→    const transcript = await transcribeAudio(wavPath);
   443→    const silences = detectSilences(transcript.segments, threshold);
   444→
   445→    // Deduct usage based on audio duration
   446→    const audioDuration = transcript.duration || 0;
   447→    let balance = null;
   448→    if (audioDuration > 0 && req.deductUsage) {
   449→      balance = await req.deductUsage(audioDuration);
   450→    }
   451→
   452→    res.json({
   453→      success: true,
   454→      wavPath,
   455→      threshold,
   456→      silences,
   457→      count: silences.length,
   458→      totalSilenceDuration: silences.reduce((sum, s) => sum + s.duration, 0).toFixed(2),
   459→      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
   460→    });
   461→  } catch (err) {
   462→    console.error('[SPLICE] Silence detection error:', err);
   463→    res.status(500).json({ error: err.message });
   464→  }
   465→});
   466→
   467→/**
   468→ * POST /silences-audio - Detect silences using FFprobe audio analysis
   469→ *
   470→ * Uses actual audio levels (dB threshold) instead of transcript gaps.
   471→ * More accurate for detecting silence vs background noise.
   472→ */
   473→app.post('/silences-audio', requireCredits({ endpoint: 'silences-audio' }), async (req, res) => {
   474→  const {
   475→    wavPath,
   476→    threshold = -30,
   477→    minDuration = 0.5,
   478→    padding = 0.1
   479→  } = req.body;
   480→
   481→  if (!wavPath) {
   482→    return res.status(400).json({ error: 'wavPath is required' });
   483→  }
   484→
   485→  if (!(await fileExists(wavPath))) {
   486→    return res.status(404).json({ error: `File not found: ${wavPath}` });
   487→  }
   488→
   489→  // Check FFprobe availability
   490→  const ffprobeAvailable = await isFFprobeInstalled();
   491→  if (!ffprobeAvailable) {
   492→    return res.status(500).json({
   493→      error: 'FFprobe not installed. Run: brew install ffmpeg'
   494→    });
   495→  }
   496→
   497→  console.log(`[SPLICE] FFprobe silence detection: ${wavPath} (threshold: ${threshold}dB, min: ${minDuration}s)`);
   498→
   499→  try {
   500→    const silences = await detectAudioSilences(wavPath, {
   501→      threshold,
   502→      minDuration,
   503→      padding
   504→    });
   505→
   506→    const totalDuration = silences.reduce((sum, s) => sum + s.duration, 0);
   507→
   508→    // Deduct usage based on audio duration
   509→    let balance = null;
   510→    try {
   511→      const audioDuration = await getAudioDuration(wavPath);
   512→      if (audioDuration > 0 && req.deductUsage) {
   513→        balance = await req.deductUsage(audioDuration);
   514→      }
   515→    } catch (durErr) {
   516→      console.warn('[SPLICE] Could not get audio duration for billing:', durErr.message);
   517→    }
   518→
   519→    res.json({
   520→      success: true,
   521→      wavPath,
   522→      threshold,
   523→      minDuration,
   524→      padding,
   525→      silences,
   526→      count: silences.length,
   527→      totalSilenceDuration: totalDuration.toFixed(2),
   528→      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
   529→    });
   530→  } catch (err) {
   531→    console.error('[SPLICE] FFprobe silence detection error:', err);
   532→    res.status(500).json({ error: err.message });
   533→  }
   534→});
   535→
   536→/**
   537→ * POST /silences-rms - Detect silences using RMS audio analysis
   538→ *
   539→ * Advanced silence detection with:
   540→ * - RMS (Root Mean Square) audio level analysis
   541→ * - Auto-threshold detection from audio histogram
   542→ * - Configurable padding (before/after cuts)
   543→ * - Sensitivity slider mapping (0-100)
   544→ *
   545→ * Options:
   546→ * - threshold: dBFS threshold (-60 to -20, default: -30)
   547→ * - minSilenceLength: Minimum silence duration in seconds (default: 0.5)
   548→ * - seekStep: Analysis window step in seconds (default: 0.05)
   549→ * - paddingStart: Buffer before silence in seconds (default: 0.1)
   550→ * - paddingEnd: Buffer after silence in seconds (default: 0.05)
   551→ * - autoThreshold: Auto-detect optimal threshold (default: false)
   552→ * - sensitivity: UI sensitivity 0-100 (overrides other params if provided)
   553→ */
   554→app.post('/silences-rms', requireCredits({ endpoint: 'silences-rms' }), async (req, res) => {
   555→  const { wavPath, sensitivity, ...manualOptions } = req.body;
   556→
   557→  if (!wavPath) {
   558→    return res.status(400).json({ error: 'wavPath is required' });
   559→  }
   560→
   561→  if (!(await fileExists(wavPath))) {
   562→    return res.status(404).json({ error: `File not found: ${wavPath}` });
   563→  }
   564→
   565→  // Validate file size to prevent OOM
   566→  const sizeCheck = await validateFileSize(wavPath);
   567→  if (!sizeCheck.valid) {
   568→    return res.status(413).json({ error: sizeCheck.error });
   569→  }
   570→
   571→  // Check FFprobe availability (needed for audio extraction)
   572→  const ffprobeAvailable = await isFFprobeInstalled();
   573→  if (!ffprobeAvailable) {
   574→    return res.status(500).json({
   575→      error: 'FFprobe not installed. Run: brew install ffmpeg'
   576→    });
   577→  }
   578→
   579→  // Build options - use sensitivity if provided, otherwise use manual options
   580→  let options = {};
   581→  if (typeof sensitivity === 'number') {
   582→    options = sensitivityToParams(sensitivity);
   583→    console.log(`[SPLICE] RMS detection with sensitivity ${sensitivity}`);
   584→  } else {
   585→    options = {
   586→      threshold: manualOptions.threshold ?? -30,
   587→      minSilenceLength: manualOptions.minSilenceLength ?? 0.5,
   588→      seekStep: manualOptions.seekStep ?? 0.05,
   589→      paddingStart: manualOptions.paddingStart ?? 0.1,
   590→      paddingEnd: manualOptions.paddingEnd ?? 0.05,
   591→      autoThreshold: manualOptions.autoThreshold ?? false,
   592→      mergeDistance: manualOptions.mergeDistance ?? 0.2
   593→    };
   594→  }
   595→
   596→  console.log(`[SPLICE] RMS silence detection: ${wavPath}`);
   597→
   598→  try {
   599→    const result = await detectSilencesRMS(wavPath, options);
   600→
   601→    // Deduct usage based on audio duration
   602→    const audioDuration = result.metadata?.audioDuration || 0;
   603→    let balance = null;
   604→    if (audioDuration > 0 && req.deductUsage) {
   605→      balance = await req.deductUsage(audioDuration);
   606→    }
   607→
   608→    res.json({
   609→      success: true,
   610→      wavPath,
   611→      ...result,
   612→      count: result.silences.length,
   613→      totalSilenceDuration: result.metadata.totalSilenceDuration.toFixed(2),
   614→      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
   615→    });
   616→  } catch (err) {
   617→    console.error('[SPLICE] RMS silence detection error:', err);
   618→    res.status(500).json({ error: err.message });
   619→  }
   620→});
   621→
   622→// =============================================================================
   623→// Profanity Detection Routes
   624→// =============================================================================
   625→
   626→/**
   627→ * POST /profanity - Detect profanity in audio/transcript
   628→ *
   629→ * Transcribes audio (if needed) and detects profanity words.
   630→ * Returns word-level and segment-level results for muting/bleeping.
   631→ *
   632→ * Options:
   633→ * - wavPath: Path to audio file (required)
   634→ * - transcript: Pre-existing transcript (optional, skips transcription)
   635→ * - language: Language code (en, es, fr, de) - default: en
   636→ * - customBlocklist: Array or comma-separated string of additional words to censor
   637→ * - customAllowlist: Array or comma-separated string of words to allow
   638→ * - frameRate: Frame rate for boundary alignment (default: 30)
   639→ */
   640→app.post('/profanity', requireCredits({ endpoint: 'profanity' }), async (req, res) => {
   641→  const {
   642→    wavPath,
   643→    transcript: providedTranscript,
   644→    language = 'en',
   645→    customBlocklist = [],
   646→    customAllowlist = [],
   647→    frameRate = 30
   648→  } = req.body;
   649→
   650→  if (!wavPath && !providedTranscript) {
   651→    return res.status(400).json({ error: 'wavPath or transcript is required' });
   652→  }
   653→
   654→  if (wavPath && !(await fileExists(wavPath))) {
   655→    return res.status(404).json({ error: `File not found: ${wavPath}` });
   656→  }
   657→
   658→  console.log(`[SPLICE] Profanity detection: ${wavPath || 'provided transcript'} (language: ${language})`);
   659→
   660→  try {
   661→    // Get or create transcript with word-level timestamps
   662→    let transcript = providedTranscript;
   663→    if (!transcript && wavPath) {
   664→      // Use transcribeWithWords for word-level timestamps required by profanity detection
   665→      transcript = await transcribeWithWords(wavPath);
   666→    }
   667→
   668→    // Validate transcript has words
   669→    if (!transcript || !transcript.words || transcript.words.length === 0) {
   670→      return res.status(400).json({
   671→        error: 'Transcript must contain word-level timing data',
   672→        hint: 'Ensure transcription returns words array with start/end times'
   673→      });
   674→    }
   675→
   676→    // Parse custom lists
   677→    const blocklist = parseWordList(customBlocklist);
   678→    const allowlist = parseWordList(customAllowlist);
   679→
   680→    // Detect profanity
   681→    const result = detectProfanity(transcript, {
   682→      language,
   683→      customBlocklist: blocklist,
   684→      customAllowlist: allowlist,
   685→      frameRate
   686→    });
   687→
   688→    // Deduct usage based on audio duration
   689→    const audioDuration = transcript.duration || 0;
   690→    let balance = null;
   691→    if (audioDuration > 0 && req.deductUsage) {
   692→      balance = await req.deductUsage(audioDuration);
   693→    }
   694→
   695→    res.json({
   696→      success: true,
   697→      wavPath,
   698→      ...result,
   699→      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
   700→    });
   701→  } catch (err) {
   702→    console.error('[SPLICE] Profanity detection error:', err);
   703→    res.status(500).json({ error: err.message });
   704→  }
   705→});
   706→
   707→/**
   708→ * GET /profanity/languages - Get supported languages
   709→ */
   710→app.get('/profanity/languages', (req, res) => {
   711→  res.json({
   712→    success: true,
   713→    languages: getSupportedLanguages()
   714→  });
   715→});
   716→
   717→/**
   718→ * GET /profanity/bleeps - Get available bleep sounds
   719→ */
   720→app.get('/profanity/bleeps', (req, res) => {
   721→  res.json({
   722→    success: true,
   723→    sounds: getAvailableBleepSounds()
   724→  });
   725→});
   726→
   727→/**
   728→ * GET /profanity/list/:language - Get default profanity list for a language
   729→ */
   730→app.get('/profanity/list/:language', (req, res) => {
   731→  const { language } = req.params;
   732→  const list = getProfanityList(language);
   733→
   734→  res.json({
   735→    success: true,
   736→    language,
   737→    wordCount: list.length,
   738→    // Return first 50 words as sample (full list is large)
   739→    sample: list.slice(0, 50),
   740→    note: 'Full list available but truncated for response size'
   741→  });
   742→});
   743→
   744→// =============================================================================
   745→// Repetition/Stutter Detection Routes
   746→// =============================================================================
   747→
   748→/**
   749→ * POST /repetitions - Detect phrase repetitions and stutters
   750→ *
   751→ * Analyzes transcript for repeated phrases and stutters.
   752→ * Returns segments that can be removed to clean up the edit.
   753→ *
   754→ * Options:
   755→ * - wavPath: Path to audio file (required unless transcript provided)
   756→ * - transcript: Pre-existing transcript (optional)
   757→ * - phraseSize: Words per comparison window (default: 5)
   758→ * - tolerance: Similarity threshold 0-1 (default: 0.7)
   759→ * - searchRadius: Words to search ahead (default: 100)
   760→ * - useOpenAI: Use OpenAI for boundary refinement (default: false)
   761→ * - includeStutters: Also detect single-word stutters (default: true)
   762→ */
   763→app.post('/repetitions', requireCredits({ endpoint: 'repetitions' }), async (req, res) => {
   764→  const {
   765→    wavPath,
   766→    transcript: providedTranscript,
   767→    phraseSize = 5,
   768→    tolerance = 0.7,
   769→    searchRadius = 100,
   770→    useOpenAI = false,
   771→    includeStutters = true
   772→  } = req.body;
   773→
   774→  if (!wavPath && !providedTranscript) {
   775→    return res.status(400).json({ error: 'wavPath or transcript is required' });
   776→  }
   777→
   778→  if (wavPath && !(await fileExists(wavPath))) {
   779→    return res.status(404).json({ error: `File not found: ${wavPath}` });
   780→  }
   781→
   782→  console.log(`[SPLICE] Repetition detection: ${wavPath || 'provided transcript'}`);
   783→
   784→  try {
   785→    // Get or create transcript with word-level timestamps
   786→    let transcript = providedTranscript;
   787→    if (!transcript && wavPath) {
   788→      // Use transcribeWithWords for word-level timestamps required by repetition detection
   789→      transcript = await transcribeWithWords(wavPath);
   790→    }
   791→
   792→    // Validate transcript has words
   793→    if (!transcript || !transcript.words || transcript.words.length === 0) {
   794→      return res.status(400).json({
   795→        error: 'Transcript must contain word-level timing data'
   796→      });
   797→    }
   798→
   799→    // Detect all repetitions (phrases + stutters)
   800→    const result = await detectAllRepetitions(transcript, {
   801→      phraseSize,
   802→      tolerance,
   803→      searchRadius,
   804→      useOpenAI
   805→    });
   806→
   807→    // Optionally filter out stutters
   808→    if (!includeStutters) {
   809→      result.stutters = [];
   810→      result.removalSegments = result.removalSegments.filter(s => s.type !== 'stutter');
   811→    }
   812→
   813→    // Deduct usage based on audio duration
   814→    const audioDuration = transcript.duration || 0;
   815→    let balance = null;
   816→    if (audioDuration > 0 && req.deductUsage) {
   817→      balance = await req.deductUsage(audioDuration);
   818→    }
   819→
   820→    res.json({
   821→      success: true,
   822→      wavPath,
   823→      ...result,
   824→      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
   825→    });
   826→  } catch (err) {
   827→    console.error('[SPLICE] Repetition detection error:', err);
   828→    res.status(500).json({ error: err.message });
   829→  }
   830→});
   831→
   832→/**
   833→ * POST /fillers - Detect filler words (um, uh, like, etc.)
   834→ *
   835→ * Transcribes audio and identifies filler words with timestamps.
   836→ * Returns segments that can be cut or reviewed for removal.
   837→ *
   838→ * Options:
   839→ * - wavPath: Path to audio file (required unless transcript provided)
   840→ * - transcript: Pre-existing transcript with word-level timing (optional)
   841→ * - customFillers: Additional filler words to detect (optional)
   842→ */
   843→app.post('/fillers', requireCredits({ endpoint: 'fillers' }), async (req, res) => {
   844→  const {
   845→    wavPath,
   846→    transcript: providedTranscript,
   847→    customFillers = []
   848→  } = req.body;
   849→
   850→  if (!wavPath && !providedTranscript) {
   851→    return res.status(400).json({ error: 'wavPath or transcript is required' });
   852→  }
   853→
   854→  if (wavPath && !(await fileExists(wavPath))) {
   855→    return res.status(404).json({ error: `File not found: ${wavPath}` });
   856→  }
   857→
   858→  console.log(`[SPLICE] Filler word detection: ${wavPath || 'provided transcript'}`);
   859→
   860→  try {
   861→    // Get or create transcript with word-level timestamps
   862→    let transcript = providedTranscript;
   863→    if (!transcript && wavPath) {
   864→      transcript = await transcribeWithWords(wavPath);
   865→    }
   866→
   867→    // Validate transcript has words
   868→    if (!transcript || !transcript.words || transcript.words.length === 0) {
   869→      return res.status(400).json({
   870→        error: 'Transcript must contain word-level timing data'
   871→      });
   872→    }
   873→
   874→    // Default filler words (common in English speech)
   875→    const defaultFillers = [
   876→      'um', 'uh', 'ah', 'er', 'eh',           // Hesitation sounds
   877→      'like', 'so', 'well', 'right',           // Discourse markers
   878→      'you know', 'i mean', 'basically',       // Filler phrases
   879→      'actually', 'literally', 'honestly',     // Overused qualifiers
   880→      'kind of', 'sort of', 'you see'          // Hedging phrases
   881→    ];
   882→
   883→    // Combine default + custom fillers (lowercase for matching)
   884→    const fillerSet = new Set([
   885→      ...defaultFillers,
   886→      ...customFillers.map(f => f.toLowerCase().trim())
   887→    ]);
   888→
   889→    // Detect filler words
   890→    const fillers = [];
   891→    const words = transcript.words;
   892→
   893→    for (let i = 0; i < words.length; i++) {
   894→      const word = words[i];
   895→      const normalizedWord = word.word.toLowerCase().replace(/[.,!?;:'"]/g, '').trim();
   896→
   897→      // Check single-word fillers
   898→      if (fillerSet.has(normalizedWord)) {
   899→        fillers.push({
   900→          word: word.word,
   901→          normalizedWord,
   902→          start: word.start,
   903→          end: word.end,
   904→          duration: word.end - word.start,
   905→          index: i,
   906→          type: 'filler'
   907→        });
   908→        continue;
   909→      }
   910→
   911→      // Check two-word phrases (e.g., "you know", "kind of")
   912→      if (i < words.length - 1) {
   913→        const nextWord = words[i + 1];
   914→        const twoWordPhrase = `${normalizedWord} ${nextWord.word.toLowerCase().replace(/[.,!?;:'"]/g, '').trim()}`;
   915→        if (fillerSet.has(twoWordPhrase)) {
   916→          fillers.push({
   917→            word: `${word.word} ${nextWord.word}`,
   918→            normalizedWord: twoWordPhrase,
   919→            start: word.start,
   920→            end: nextWord.end,
   921→            duration: nextWord.end - word.start,
   922→            index: i,
   923→            type: 'filler_phrase'
   924→          });
   925→          // Skip next word since it's part of this phrase
   926→          i++;
   927→        }
   928→      }
   929→    }
   930→
   931→    // Calculate total filler time
   932→    const totalFillerDuration = fillers.reduce((sum, f) => sum + f.duration, 0);
   933→    const audioDuration = transcript.duration || (words.length > 0 ? words[words.length - 1].end : 0);
   934→    const fillerPercentage = audioDuration > 0 ? (totalFillerDuration / audioDuration) * 100 : 0;
   935→
   936→    // Deduct usage based on audio duration
   937→    let balance = null;
   938→    if (audioDuration > 0 && req.deductUsage) {
   939→      balance = await req.deductUsage(audioDuration);
   940→    }
   941→
   942→    res.json({
   943→      success: true,
   944→      wavPath,
   945→      fillers,
   946→      metadata: {
   947→        totalWords: words.length,
   948→        fillerCount: fillers.length,
   949→        totalFillerDuration: parseFloat(totalFillerDuration.toFixed(3)),
   950→        audioDuration: parseFloat(audioDuration.toFixed(3)),
   951→        fillerPercentage: parseFloat(fillerPercentage.toFixed(2)),
   952→        fillersPerMinute: audioDuration > 0 ? parseFloat((fillers.length / (audioDuration / 60)).toFixed(2)) : 0
   953→      },
   954→      removalSegments: fillers.map(f => ({
   955→        start: f.start,
   956→        end: f.end,
   957→        duration: f.duration,
   958→        reason: `Filler: "${f.word}"`,
   959→        type: f.type
   960→      })),
   961→      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
   962→    });
   963→  } catch (err) {
   964→    console.error('[SPLICE] Filler detection error:', err);
   965→    res.status(500).json({ error: err.message });
   966→  }
   967→});
   968→
   969→/**
   970→ * POST /stutters - Detect single-word stutters only
   971→ *
   972→ * Focused detection for word-level stutters (e.g., "I I I think").
   973→ * Faster than full repetition detection.
   974→ */
   975→app.post('/stutters', requireCredits({ endpoint: 'stutters' }), async (req, res) => {
   976→  const {
   977→    wavPath,
   978→    transcript: providedTranscript,
   979→    options = {},
   980→    // Support both top-level and nested options for flexibility
   981→    minRepeats = options.minRepeats ?? 2,
   982→    maxGapMs = options.maxGapMs ?? 500,
   983→    ignoreFillers = options.ignoreFillers ?? true,
   984→    minWordLength = options.minWordLength ?? 1
   985→  } = req.body;
   986→
   987→  if (!wavPath && !providedTranscript) {
   988→    return res.status(400).json({ error: 'wavPath or transcript is required' });
   989→  }
   990→
   991→  if (wavPath && !(await fileExists(wavPath))) {
   992→    return res.status(404).json({ error: `File not found: ${wavPath}` });
   993→  }
   994→
   995→  console.log(`[SPLICE] Stutter detection: ${wavPath || 'provided transcript'}`);
   996→
   997→  try {
   998→    // Get or create transcript with word-level timestamps
   999→    let transcript = providedTranscript;
  1000→    if (!transcript && wavPath) {
  1001→      // Use transcribeWithWords for word-level timestamps required by stutter detection
  1002→      transcript = await transcribeWithWords(wavPath);
  1003→    }
  1004→
  1005→    // Validate transcript exists and has words array
  1006→    if (!transcript || !transcript.words) {
  1007→      return res.status(400).json({
  1008→        error: 'Transcript must contain word-level timing data'
  1009→      });
  1010→    }
  1011→
  1012→    // Empty transcript returns empty result (not an error)
  1013→    if (transcript.words.length === 0) {
  1014→      return res.json({
  1015→        success: true,
  1016→        stutters: [],
  1017→        metadata: { type: 'stutters', totalWords: 0, stutterCount: 0, totalRepeatedWords: 0 }
  1018→      });
  1019→    }
  1020→
  1021→    // Detect stutters only
  1022→    const result = detectStutters(transcript, {
  1023→      minRepeats,
  1024→      maxGapMs,
  1025→      ignoreFillers,
  1026→      minWordLength
  1027→    });
  1028→
  1029→    // Deduct usage based on audio duration
  1030→    const audioDuration = transcript.duration || 0;
  1031→    let balance = null;
  1032→    if (audioDuration > 0 && req.deductUsage) {
  1033→      balance = await req.deductUsage(audioDuration);
  1034→    }
  1035→
  1036→    res.json({
  1037→      success: true,
  1038→      wavPath,
  1039→      ...result,
  1040→      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
  1041→    });
  1042→  } catch (err) {
  1043→    console.error('[SPLICE] Stutter detection error:', err);
  1044→    res.status(500).json({ error: err.message });
  1045→  }
  1046→});
  1047→
  1048→// =============================================================================
  1049→// Caption Export Routes
  1050→// =============================================================================
  1051→
  1052→/**
  1053→ * POST /export/captions - Export transcript to caption format (SRT, VTT, etc.)
  1054→ *
  1055→ * Converts a transcript to the specified caption format.
  1056→ * Can optionally save to file.
  1057→ *
  1058→ * Options:
  1059→ * - wavPath: Path to audio file (to transcribe first)
  1060→ * - transcript: Pre-existing transcript with word-level timing
  1061→ * - format: Export format (srt, vtt, txt, json) - default: srt
  1062→ * - outputPath: Optional file path to save to
  1063→ * - maxWordsPerCaption: Max words per caption (default: 8)
  1064→ * - maxDuration: Max duration per caption in seconds (default: 5)
  1065→ */
  1066→app.post('/export/captions', requireCredits({ endpoint: 'export-captions' }), async (req, res) => {
  1067→  const {
  1068→    wavPath,
  1069→    transcript: providedTranscript,
  1070→    format = 'srt',
  1071→    outputPath = null,
  1072→    maxWordsPerCaption = 8,
  1073→    maxDuration = 5
  1074→  } = req.body;
  1075→
  1076→  if (!wavPath && !providedTranscript) {
  1077→    return res.status(400).json({ error: 'wavPath or transcript is required' });
  1078→  }
  1079→
  1080→  if (wavPath && !(await fileExists(wavPath))) {
  1081→    return res.status(404).json({ error: `File not found: ${wavPath}` });
  1082→  }
  1083→
  1084→  console.log(`[SPLICE] Caption export: ${wavPath || 'provided transcript'} -> ${format}`);
  1085→
  1086→  try {
  1087→    // Get or create transcript with word-level timestamps
  1088→    let transcript = providedTranscript;
  1089→    if (!transcript && wavPath) {
  1090→      transcript = await transcribeWithWords(wavPath);
  1091→    }
  1092→
  1093→    const exportOptions = { maxWordsPerCaption, maxDuration };
  1094→
  1095→    // Generate caption content based on format
  1096→    let content;
  1097→    let mimeType;
  1098→
  1099→    switch (format.toLowerCase()) {
  1100→      case 'srt':
  1101→        content = toSRT(transcript, exportOptions);
  1102→        mimeType = 'application/x-subrip';
  1103→        break;
  1104→      case 'vtt':
  1105→      case 'webvtt':
  1106→        content = toVTT(transcript, exportOptions);
  1107→        mimeType = 'text/vtt';
  1108→        break;
  1109→      case 'txt':
  1110→      case 'text':
  1111→        content = toPlainText(transcript, { ...exportOptions, includeTimestamps: true });
  1112→        mimeType = 'text/plain';
  1113→        break;
  1114→      case 'json':
  1115→        content = toJSON(transcript);
  1116→        mimeType = 'application/json';
  1117→        break;
  1118→      default:
  1119→        return res.status(400).json({
  1120→          error: `Unsupported format: ${format}`,
  1121→          supportedFormats: getSupportedFormats()
  1122→        });
  1123→    }
  1124→
  1125→    // Save to file if outputPath provided
  1126→    let savedPath = null;
  1127→    if (outputPath) {
  1128→      const result = await exportToFile(transcript, outputPath, format, exportOptions);
  1129→      savedPath = result.path;
  1130→      console.log(`[SPLICE] Saved captions to: ${savedPath}`);
  1131→    }
  1132→
  1133→    // Deduct usage based on audio duration
  1134→    const audioDuration = transcript.duration || 0;
  1135→    let balance = null;
  1136→    if (audioDuration > 0 && req.deductUsage) {
  1137→      balance = await req.deductUsage(audioDuration);
  1138→    }
  1139→
  1140→    res.json({
  1141→      success: true,
  1142→      format,
  1143→      content,
  1144→      mimeType,
  1145→      savedPath,
  1146→      wordCount: transcript.words?.length || 0,
  1147→      duration: transcript.duration || 0,
  1148→      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
  1149→    });
  1150→  } catch (err) {
  1151→    console.error('[SPLICE] Caption export error:', err);
  1152→    res.status(500).json({ error: err.message });
  1153→  }
  1154→});
  1155→
  1156→/**
  1157→ * GET /export/formats - Get supported export formats
  1158→ */
  1159→app.get('/export/formats', (req, res) => {
  1160→  res.json({
  1161→    success: true,
  1162→    formats: getSupportedFormats()
  1163→  });
  1164→});
  1165→
  1166→// =============================================================================
  1167→// Multitrack/Multicam Analysis Routes
  1168→// =============================================================================
  1169→
  1170→/**
  1171→ * POST /multitrack - Analyze multiple audio tracks for multicam editing
  1172→ *
  1173→ * Analyzes audio levels across multiple tracks to determine optimal
  1174→ * video angle selection based on who is speaking.
  1175→ *
  1176→ * Options:
  1177→ * - audioPaths: Array of paths to audio files (one per speaker) - required
  1178→ * - speakerNames: Array of speaker names (optional)
  1179→ * - videoTrackMapping: Object mapping speaker index to video track { 0: 0, 1: 1 }
  1180→ * - minShotDuration: Minimum seconds before next cut (default: 2.0)
  1181→ * - switchingFrequency: How often to allow cuts 0-100 (default: 50)
  1182→ * - wideShotEnabled: Enable wide shot detection (default: true)
  1183→ * - wideShotPercentage: Target % of wide shots (default: 20)
  1184→ * - wideShotTracks: Video track indices for wide shots
  1185→ * - cutawayEnabled: Enable cutaway insertion (default: false)
  1186→ * - cutawayTracks: Video track indices for cutaways
  1187→ * - speakerBoosts: Per-speaker dB adjustments { "Speaker 1": 5 }
  1188→ */
  1189→app.post('/multitrack', requireCredits({ endpoint: 'multitrack' }), async (req, res) => {
  1190→  const {
  1191→    audioPaths,
  1192→    speakerNames,
  1193→    videoTrackMapping = {},
  1194→    minShotDuration = 2.0,
  1195→    switchingFrequency = 50,
  1196→    wideShotEnabled = true,
  1197→    wideShotPercentage = 20,
  1198→    wideShotTracks = [],
  1199→    cutawayEnabled = false,
  1200→    cutawayTracks = [],
  1201→    speakerBoosts = {},
  1202→    frameRate = 30
  1203→  } = req.body;
  1204→
  1205→  // Validate audioPaths
  1206→  if (!audioPaths || !Array.isArray(audioPaths) || audioPaths.length === 0) {
  1207→    return res.status(400).json({ error: 'audioPaths array is required (at least 1 path)' });
  1208→  }
  1209→
  1210→  // Validate all files exist
  1211→  for (const audioPath of audioPaths) {
  1212→    if (!fs.existsSync(audioPath)) {
  1213→      return res.status(404).json({ error: `File not found: ${audioPath}` });
  1214→    }
  1215→  }
  1216→
  1217→  // Check FFprobe availability
  1218→  const ffprobeAvailable = await isFFprobeInstalled();
  1219→  if (!ffprobeAvailable) {
  1220→    return res.status(500).json({
  1221→      error: 'FFprobe not installed. Run: brew install ffmpeg'
  1222→    });
  1223→  }
  1224→
  1225→  console.log(`[SPLICE] Multitrack analysis: ${audioPaths.length} track(s)`);
  1226→
  1227→  try {
  1228→    const result = await analyzeMultitrack(audioPaths, {
  1229→      speakerNames: speakerNames || audioPaths.map((_, i) => `Speaker ${i + 1}`),
  1230→      videoTrackMapping,
  1231→      minShotDuration,
  1232→      switchingFrequency,
  1233→      wideShotEnabled,
  1234→      wideShotPercentage,
  1235→      wideShotTracks,
  1236→      cutawayEnabled,
  1237→      cutawayTracks,
  1238→      speakerBoosts,
  1239→      frameRate
  1240→    });
  1241→
  1242→    // Deduct usage based on total duration (use longest track)
  1243→    const audioDuration = result.metadata?.totalDuration || 0;
  1244→    let balance = null;
  1245→    if (audioDuration > 0 && req.deductUsage) {
  1246→      balance = await req.deductUsage(audioDuration);
  1247→    }
  1248→
  1249→    res.json({
  1250→      success: true,
  1251→      ...result,
  1252→      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
  1253→    });
  1254→  } catch (err) {
  1255→    console.error('[SPLICE] Multitrack analysis error:', err);
  1256→    res.status(500).json({ error: err.message });
  1257→  }
  1258→});
  1259→
  1260→/**
  1261→ * POST /multitrack/auto-balance - Auto-balance speaker screentime
  1262→ *
  1263→ * Automatically adjusts speaker boosts to achieve equal screentime distribution.
  1264→ * Runs multiple iterations to find optimal parameters.
  1265→ */
  1266→app.post('/multitrack/auto-balance', requireCredits({ endpoint: 'multitrack-auto-balance' }), async (req, res) => {
  1267→  const {
  1268→    audioPaths,
  1269→    speakerNames,
  1270→    videoTrackMapping = {},
  1271→    minShotDuration = 2.0,
  1272→    switchingFrequency = 50,
  1273→    wideShotEnabled = false, // Disable wide shots for balance calc
  1274→    frameRate = 30
  1275→  } = req.body;
  1276→
  1277→  // Validate audioPaths
  1278→  if (!audioPaths || !Array.isArray(audioPaths) || audioPaths.length < 2) {
  1279→    return res.status(400).json({ error: 'audioPaths array requires at least 2 tracks for balancing' });
  1280→  }
  1281→
  1282→  // Validate all files exist
  1283→  for (const audioPath of audioPaths) {
  1284→    if (!fs.existsSync(audioPath)) {
  1285→      return res.status(404).json({ error: `File not found: ${audioPath}` });
  1286→    }
  1287→  }
  1288→
  1289→  // Check FFprobe availability
  1290→  const ffprobeAvailable = await isFFprobeInstalled();
  1291→  if (!ffprobeAvailable) {
  1292→    return res.status(500).json({
  1293→      error: 'FFprobe not installed. Run: brew install ffmpeg'
  1294→    });
  1295→  }
  1296→
  1297→  console.log(`[SPLICE] Auto-balancing multitrack: ${audioPaths.length} track(s)`);
  1298→
  1299→  try {
  1300→    const result = await autoBalanceMultitrack(audioPaths, {
  1301→      speakerNames: speakerNames || audioPaths.map((_, i) => `Speaker ${i + 1}`),
  1302→      videoTrackMapping,
  1303→      minShotDuration,
  1304→      switchingFrequency,
  1305→      wideShotEnabled,
  1306→      frameRate
  1307→    });
  1308→
  1309→    // Deduct usage based on total duration
  1310→    const audioDuration = result.metadata?.totalDuration || 0;
  1311→    let balance = null;
  1312→    if (audioDuration > 0 && req.deductUsage) {
  1313→      balance = await req.deductUsage(audioDuration);
  1314→    }
  1315→
  1316→    res.json({
  1317→      success: true,
  1318→      ...result,
  1319→      balance: balance ? { hoursRemaining: balance.hoursRemaining, tier: balance.tier } : undefined
  1320→    });
  1321→  } catch (err) {
  1322→    console.error('[SPLICE] Auto-balance error:', err);
  1323→    res.status(500).json({ error: err.message });
  1324→  }
  1325→});
  1326→
  1327→/**
  1328→ * POST /process-xml - Process FCP XML to split clips at silences
  1329→ *
  1330→ * Takes an FCP XML file and silence timestamps, splits clips
  1331→ * at silence boundaries, and optionally removes gaps.
  1332→ */
  1333→app.post('/process-xml', async (req, res) => {
  1334→  const {
  1335→    xmlPath,
  1336→    silences,
  1337→    removeGaps = true,
  1338→    outputPath = null
  1339→  } = req.body;
  1340→
  1341→  if (!xmlPath) {
  1342→    return res.status(400).json({ error: 'xmlPath is required' });
  1343→  }
  1344→
  1345→  if (!silences || !Array.isArray(silences)) {
  1346→    return res.status(400).json({ error: 'silences array is required' });
  1347→  }
  1348→
  1349→  if (!fs.existsSync(xmlPath)) {
  1350→    return res.status(404).json({ error: `XML file not found: ${xmlPath}` });
  1351→  }
  1352→
  1353→  console.log(`[SPLICE] Processing XML: ${xmlPath} with ${silences.length} silence(s)`);
  1354→
  1355→  try {
  1356→    const result = await processXMLFile(xmlPath, silences, {
  1357→      outputPath,
  1358→      removeGaps
  1359→    });
  1360→
  1361→    res.json({
  1362→      success: true,
  1363→      inputPath: xmlPath,
  1364→      outputPath: result.outputPath,
  1365→      stats: result.stats
  1366→    });
  1367→  } catch (err) {
  1368→    console.error('[SPLICE] XML processing error:', err);
  1369→    res.status(500).json({ error: err.message });
  1370→  }
  1371→});
  1372→
  1373→/**
  1374→ * POST /cut-list - Generate a JSON cut list for direct DOM building (v3.5)
  1375→ *
  1376→ * Takes silences and optionally takes, returns a cut list that the
  1377→ * plugin can use to build sequences directly via UXP APIs.
  1378→ *
  1379→ * Body:
  1380→ * - sourceName: Name of the source clip
  1381→ * - sourcePath: Full path to the source file
  1382→ * - duration: Total duration in seconds
  1383→ * - silences: Array of silence segments [{start, end, duration}]
  1384→ * - takes: (optional) Array of detected takes
  1385→ * - settings: (optional) Generation settings
  1386→ *
  1387→ * Requires authentication via x-stripe-customer-id header
  1388→ */
  1389→app.post('/cut-list', requireCredits({ endpoint: 'cut-list' }), async (req, res) => {
  1390→  const {
  1391→    sourceName,
  1392→    sourcePath,
  1393→    duration,
  1394→    silences,
  1395→    takes = [],
  1396→    settings = {}
  1397→  } = req.body;
  1398→
  1399→  // Validate required fields
  1400→  if (!sourceName && !sourcePath) {
  1401→    return res.status(400).json({ error: 'sourceName or sourcePath is required' });
  1402→  }
  1403→
  1404→  if (typeof duration !== 'number' || duration <= 0) {
  1405→    return res.status(400).json({ error: 'duration must be a positive number' });
  1406→  }
  1407→
  1408→  if (!silences || !Array.isArray(silences)) {
  1409→    return res.status(400).json({ error: 'silences array is required' });
  1410→  }
  1411→
  1412→  console.log(`[SPLICE] Generating cut list for ${sourceName || sourcePath} (${silences.length} silences)`);
  1413→
  1414→  try {
  1415→    const cutList = generateCutList({
  1416→      sourceName: sourceName || path.basename(sourcePath),
  1417→      sourcePath,
  1418→      duration,
  1419→      silences,
  1420→      takes,
  1421→      settings
  1422→    });
  1423→
  1424→    // Validate the generated cut list
  1425→    const validation = validateCutList(cutList);
  1426→    if (!validation.valid) {
  1427→      return res.status(500).json({
  1428→        error: 'Generated cut list is invalid',
  1429→        validationErrors: validation.errors
  1430→      });
  1431→    }
  1432→
  1433→    res.json({
  1434→      success: true,
  1435→      cutList
  1436→    });
  1437→  } catch (err) {
  1438→    console.error('[SPLICE] Cut list generation error:', err);
  1439→    res.status(500).json({ error: err.message });
  1440→  }
  1441→});
  1442→
  1443→/**
  1444→ * POST /cut-list/takes - Generate a cut list that keeps only takes
  1445→ *
  1446→ * Alternative endpoint for "keep best takes only" workflow.
  1447→ *
  1448→ * Requires authentication via x-stripe-customer-id header
  1449→ */
  1450→app.post('/cut-list/takes', requireCredits({ endpoint: 'cut-list-takes' }), async (req, res) => {
  1451→  const {
  1452→    sourceName,
  1453→    sourcePath,
  1454→    duration,
  1455→    takes,
  1456→    settings = {}
  1457→  } = req.body;
  1458→
  1459→  // Validate required fields
  1460→  if (!sourceName && !sourcePath) {
  1461→    return res.status(400).json({ error: 'sourceName or sourcePath is required' });
  1462→  }
  1463→
  1464→  if (typeof duration !== 'number' || duration <= 0) {
  1465→    return res.status(400).json({ error: 'duration must be a positive number' });
  1466→  }
  1467→
  1468→  if (!takes || !Array.isArray(takes) || takes.length === 0) {
  1469→    return res.status(400).json({ error: 'takes array is required and must not be empty' });
  1470→  }
  1471→
  1472→  console.log(`[SPLICE] Generating takes cut list for ${sourceName || sourcePath} (${takes.length} takes)`);
  1473→
  1474→  try {
  1475→    const cutList = generateTakesCutList({
  1476→      sourceName: sourceName || path.basename(sourcePath),
  1477→      sourcePath,
  1478→      duration,
  1479→      takes,
  1480→      settings
  1481→    });
  1482→
  1483→    res.json({
  1484→      success: true,
  1485→      cutList
  1486→    });
  1487→  } catch (err) {
  1488→    console.error('[SPLICE] Takes cut list generation error:', err);
  1489→    res.status(500).json({ error: err.message });
  1490→  }
  1491→});
  1492→
  1493→/**
  1494→ * GET /ffprobe-check - Check if FFprobe is installed
  1495→ */
  1496→app.get('/ffprobe-check', async (req, res) => {
  1497→  const installed = await isFFprobeInstalled();
  1498→  res.json({
  1499→    installed,
  1500→    message: installed
  1501→      ? 'FFprobe is available'
  1502→      : 'FFprobe not found. Install with: brew install ffmpeg'
  1503→  });
  1504→});
  1505→
  1506→/**
  1507→ * GET /replicate-check - Check if Replicate API is configured
  1508→ */
  1509→app.get('/replicate-check', async (req, res) => {
  1510→  const configured = isReplicateConfigured();
  1511→  res.json({
  1512→    configured,
  1513→    message: configured
  1514→      ? 'Replicate API is configured'
  1515→      : 'REPLICATE_API_TOKEN not set. Add to .env file.'
  1516→  });
  1517→});
  1518→
  1519→/**
  1520→ * POST /isolate-vocals - Isolate vocals from audio using Demucs
  1521→ *
  1522→ * Uses Replicate's Demucs model to separate vocals from background audio.
  1523→ * Cost: ~$0.015/min of audio
  1524→ *
  1525→ * Tier access:
  1526→ * - Starter: No access (upgrade required)
  1527→ * - Pro: 2 hours included, then $0.08/min overage
  1528→ * - Team: 5 hours included, then $0.08/min overage
  1529→ */
  1530→app.post('/isolate-vocals', requireCredits({ endpoint: 'isolate-vocals' }), async (req, res) => {
  1531→  const { audioPath, stem = 'vocals', outputDir = null } = req.body;
  1532→  const stripeCustomerId = req.headers['x-stripe-customer-id'];
  1533→
  1534→  if (!audioPath) {
  1535→    return res.status(400).json({ error: 'audioPath is required' });
  1536→  }
  1537→
  1538→  if (!fs.existsSync(audioPath)) {
  1539→    return res.status(404).json({ error: `File not found: ${audioPath}` });
  1540→  }
  1541→
  1542→  // Check Replicate configuration
  1543→  if (!isReplicateConfigured()) {
  1544→    return res.status(500).json({
  1545→      error: 'Replicate API not configured. Set REPLICATE_API_TOKEN in .env'
  1546→    });
  1547→  }
  1548→
  1549→  // Get audio duration for billing
  1550→  let audioDurationSeconds = 0;
  1551→  try {
  1552→    audioDurationSeconds = await getAudioDuration(audioPath);
  1553→  } catch (err) {
  1554→    console.warn('[SPLICE] Could not get audio duration:', err.message);
  1555→  }
  1556→
  1557→  const audioDurationMinutes = audioDurationSeconds / 60;
  1558→
  1559→  // Check isolation access if customer ID provided
  1560→  if (stripeCustomerId) {
  1561→    const accessCheck = await usageTracking.checkIsolationAccess(stripeCustomerId, audioDurationMinutes);
  1562→
  1563→    if (!accessCheck.allowed) {
  1564→      return res.status(403).json({
  1565→        error: accessCheck.message,
  1566→        reason: accessCheck.reason,
  1567→        upgradeRequired: accessCheck.reason === 'upgrade_required'
  1568→      });
  1569→    }
  1570→
  1571→    console.log(`[SPLICE] Isolation access: ${accessCheck.message}`);
  1572→  }
  1573→
  1574→  console.log(`[SPLICE] Isolating vocals: ${audioPath} (${audioDurationMinutes.toFixed(1)} min)`);
  1575→
  1576→  try {
  1577→    const result = await isolateVocals(audioPath, {
  1578→      stem,
  1579→      outputDir: outputDir || undefined
  1580→    });
  1581→
  1582→    // Deduct isolation usage if customer ID provided
  1583→    let usageInfo = null;
  1584→    if (stripeCustomerId) {
  1585→      usageInfo = await usageTracking.deductIsolationUsage(
  1586→        stripeCustomerId,
  1587→        audioDurationSeconds,
  1588→        'isolate-vocals'
  1589→      );
  1590→      console.log(`[SPLICE] Isolation usage deducted: ${audioDurationMinutes.toFixed(1)} min`);
  1591→      if (usageInfo.isolationUsed?.overageCost > 0) {
  1592→        console.log(`[SPLICE] Overage cost: $${usageInfo.isolationUsed.overageCost.toFixed(2)}`);
  1593→      }
  1594→    }
  1595→
  1596→    res.json({
  1597→      success: true,
  1598→      inputPath: audioPath,
  1599→      outputPath: result.outputPath,
  1600→      stem: result.stem,
  1601→      processingTime: result.processingTime,
  1602→      availableStems: result.allStems,
  1603→      audioDurationMinutes,
  1604→      usage: usageInfo ? {
  1605→        isolationHoursRemaining: usageInfo.isolationHoursRemaining,
  1606→        overageCost: usageInfo.isolationUsed?.overageCost || 0
  1607→      } : null
  1608→    });
  1609→  } catch (err) {
  1610→    console.error('[SPLICE] Vocal isolation error:', err);
  1611→    res.status(500).json({ error: err.message });
  1612→  }
  1613→});
  1614→
  1615→// =============================================================================
  1616→// Batch Processing Routes
  1617→// =============================================================================
  1618→
  1619→// In-memory job queue for batch processing
  1620→const batchJobs = new Map();
  1621→
  1622→// Batch job limits to prevent memory leak
  1623→const MAX_BATCH_JOBS = 10000;
  1624→const BATCH_JOB_MAX_AGE_MS = 24 * 60 * 60 * 1000; // 24 hours
  1625→
  1626→/**
  1627→ * Generate a unique job ID
  1628→ */
  1629→function generateJobId() {
  1630→  return `batch_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
  1631→}
  1632→
  1633→/**
  1634→ * Clean up old batch jobs to prevent memory leak
  1635→ * Removes jobs older than 24 hours
  1636→ */
  1637→function cleanupOldBatchJobs() {
  1638→  const now = Date.now();
  1639→  let removedCount = 0;
  1640→
  1641→  for (const [jobId, job] of batchJobs.entries()) {
  1642→    const createdAt = new Date(job.createdAt).getTime();
  1643→    if (now - createdAt > BATCH_JOB_MAX_AGE_MS) {
  1644→      batchJobs.delete(jobId);
  1645→      removedCount++;
  1646→    }
  1647→  }
  1648→
  1649→  if (removedCount > 0) {
  1650→    console.log(`[SPLICE] Cleaned up ${removedCount} old batch job(s)`);
  1651→  }
  1652→}
  1653→
  1654→/**
  1655→ * Enforce max job limit by removing oldest completed jobs
  1656→ */
  1657→function enforceJobLimit() {
  1658→  if (batchJobs.size < MAX_BATCH_JOBS) return;
  1659→
  1660→  // Get completed jobs sorted by creation date (oldest first)
  1661→  const completedJobs = Array.from(batchJobs.entries())
  1662→    .filter(([_, job]) => job.status !== 'processing')
  1663→    .sort((a, b) => new Date(a[1].createdAt) - new Date(b[1].createdAt));
  1664→
  1665→  // Remove oldest completed jobs until under limit
  1666→  const toRemove = batchJobs.size - MAX_BATCH_JOBS + 1;
  1667→  for (let i = 0; i < Math.min(toRemove, completedJobs.length); i++) {
  1668→    batchJobs.delete(completedJobs[i][0]);
  1669→  }
  1670→
  1671→  console.log(`[SPLICE] Enforced job limit, removed ${Math.min(toRemove, completedJobs.length)} job(s)`);
  1672→}
  1673→
  1674→// Run cleanup every hour
  1675→setInterval(cleanupOldBatchJobs, 60 * 60 * 1000);
  1676→
  1677→/**
  1678→ * POST /batch/silences - Process multiple files for silence detection
  1679→ *
  1680→ * Creates a batch job that processes multiple audio files.
  1681→ * Returns a job ID for tracking progress.
  1682→ *
  1683→ * Body:
  1684→ * - files: Array of file paths to process
  1685→ * - options: Detection options (sensitivity, threshold, etc.)
  1686→ */
  1687→app.post('/batch/silences', requireCredits({ endpoint: 'batch-silences' }), async (req, res) => {
  1688→  const { files, options = {} } = req.body;
  1689→
  1690→  if (!files || !Array.isArray(files) || files.length === 0) {
  1691→    return res.status(400).json({ error: 'files array is required' });
  1692→  }
  1693→
  1694→  // Validate all files exist
  1695→  const missingFiles = files.filter(f => !fs.existsSync(f));
  1696→  if (missingFiles.length > 0) {
  1697→    return res.status(404).json({
  1698→      error: 'Some files not found',
  1699→      missingFiles
  1700→    });
  1701→  }
  1702→
  1703→  // Enforce job limit before creating new job
  1704→  enforceJobLimit();
  1705→
  1706→  const jobId = generateJobId();
  1707→
  1708→  // Initialize job with customer ID for usage tracking
  1709→  const job = {
  1710→    id: jobId,
  1711→    type: 'silences',
  1712→    status: 'processing',
  1713→    createdAt: new Date().toISOString(),
  1714→    stripeCustomerId: req.stripeCustomerId,  // Store for usage deduction
  1715→    files: files.map(f => ({
  1716→      path: f,
  1717→      status: 'pending',
  1718→      result: null,
  1719→      error: null
  1720→    })),
  1721→    options,
  1722→    progress: {
  1723→      total: files.length,
  1724→      completed: 0,
  1725→      failed: 0,
  1726→      percentage: 0
  1727→    },
  1728→    results: [],
  1729→    errors: [],
  1730→    totalUsageDeducted: 0  // Track total seconds deducted
  1731→  };
  1732→
  1733→  batchJobs.set(jobId, job);
  1734→  console.log(`[SPLICE] Batch job ${jobId} created with ${files.length} files`);
  1735→
  1736→  // Start processing in background
  1737→  processBatchJob(jobId);
  1738→
  1739→  res.json({
  1740→    success: true,
  1741→    jobId,
  1742→    message: `Batch job created with ${files.length} files`,
  1743→    statusUrl: `/batch/status/${jobId}`
  1744→  });
  1745→});
  1746→
  1747→/**
  1748→ * Process a batch job (runs in background)
  1749→ */
  1750→async function processBatchJob(jobId) {
  1751→  const job = batchJobs.get(jobId);
  1752→  if (!job) return;
  1753→
  1754→  const { sensitivity, ...manualOptions } = job.options;
  1755→
  1756→  // Build detection options
  1757→  let detectionOptions = {};
  1758→  if (typeof sensitivity === 'number') {
  1759→    detectionOptions = sensitivityToParams(sensitivity);
  1760→  } else {
  1761→    detectionOptions = {
  1762→      threshold: manualOptions.threshold ?? -30,
  1763→      minSilenceLength: manualOptions.minSilenceLength ?? 0.5,
  1764→      paddingStart: manualOptions.paddingStart ?? 0.1,
  1765→      paddingEnd: manualOptions.paddingEnd ?? 0.05,
  1766→      autoThreshold: manualOptions.autoThreshold ?? false
  1767→    };
  1768→  }
  1769→
  1770→  // Process files sequentially to avoid overwhelming the system
  1771→  for (let i = 0; i < job.files.length; i++) {
  1772→    const fileEntry = job.files[i];
  1773→    fileEntry.status = 'processing';
  1774→
  1775→    try {
  1776→      const result = await detectSilencesRMS(fileEntry.path, detectionOptions);
  1777→
  1778→      fileEntry.status = 'completed';
  1779→      fileEntry.result = {
  1780→        silences: result.silences,
  1781→        count: result.silences.length,
  1782→        totalSilenceDuration: result.metadata.totalSilenceDuration,
  1783→        audioDuration: result.metadata.audioDuration
  1784→      };
  1785→
  1786→      job.results.push({
  1787→        file: fileEntry.path,
  1788→        ...fileEntry.result
  1789→      });
  1790→
  1791→      // Deduct usage for this file
  1792→      const audioDuration = result.metadata?.audioDuration || 0;
  1793→      if (audioDuration > 0 && job.stripeCustomerId) {
  1794→        try {
  1795→          await usageTracking.deductUsage(job.stripeCustomerId, audioDuration, 'batch-silences');
  1796→          job.totalUsageDeducted += audioDuration;
  1797→        } catch (usageErr) {
  1798→          console.warn(`[SPLICE] Batch ${jobId}: Usage deduction failed:`, usageErr.message);
  1799→        }
  1800→      }
  1801→
  1802→      job.progress.completed++;
  1803→      console.log(`[SPLICE] Batch ${jobId}: ${i + 1}/${job.files.length} completed`);
  1804→    } catch (err) {
  1805→      fileEntry.status = 'failed';
  1806→      fileEntry.error = err.message;
  1807→
  1808→      job.errors.push({
  1809→        file: fileEntry.path,
  1810→        error: err.message
  1811→      });
  1812→
  1813→      job.progress.failed++;
  1814→      console.error(`[SPLICE] Batch ${jobId}: ${fileEntry.path} failed:`, err.message);
  1815→    }
  1816→
  1817→    // Update progress
  1818→    job.progress.percentage = Math.round(
  1819→      ((job.progress.completed + job.progress.failed) / job.progress.total) * 100
  1820→    );
  1821→  }
  1822→
  1823→  // Mark job as complete
  1824→  job.status = job.progress.failed === job.progress.total ? 'failed' :
  1825→               job.progress.failed > 0 ? 'completed_with_errors' : 'completed';
  1826→  job.completedAt = new Date().toISOString();
  1827→
  1828→  console.log(`[SPLICE] Batch job ${jobId} ${job.status}`);
  1829→}
  1830→
  1831→/**
  1832→ * GET /batch/status/:jobId - Get batch job status and results
  1833→ * Requires x-stripe-customer-id header matching job owner
  1834→ */
  1835→app.get('/batch/status/:jobId', (req, res) => {
  1836→  const { jobId } = req.params;
  1837→  const stripeCustomerId = req.headers['x-stripe-customer-id'];
  1838→  const job = batchJobs.get(jobId);
  1839→
  1840→  if (!job) {
  1841→    return res.status(404).json({ error: 'Job not found' });
  1842→  }
  1843→
  1844→  // Verify customer ownership
  1845→  if (job.stripeCustomerId && job.stripeCustomerId !== stripeCustomerId) {
  1846→    return res.status(403).json({ error: 'Access denied: Job belongs to another user' });
  1847→  }
  1848→
  1849→  res.json({
  1850→    success: true,
  1851→    job: {
  1852→      id: job.id,
  1853→      type: job.type,
  1854→      status: job.status,
  1855→      createdAt: job.createdAt,
  1856→      completedAt: job.completedAt,
  1857→      progress: job.progress,
  1858→      files: job.files.map(f => ({
  1859→        path: f.path,
  1860→        status: f.status,
  1861→        silenceCount: f.result?.count,
  1862→        error: f.error
  1863→      }))
  1864→    }
  1865→  });
  1866→});
  1867→
  1868→/**
  1869→ * GET /batch/results/:jobId - Get full results for a completed batch job
  1870→ * Requires x-stripe-customer-id header matching job owner
  1871→ */
  1872→app.get('/batch/results/:jobId', (req, res) => {
  1873→  const { jobId } = req.params;
  1874→  const stripeCustomerId = req.headers['x-stripe-customer-id'];
  1875→  const job = batchJobs.get(jobId);
  1876→
  1877→  if (!job) {
  1878→    return res.status(404).json({ error: 'Job not found' });
  1879→  }
  1880→
  1881→  // Verify customer ownership
  1882→  if (job.stripeCustomerId && job.stripeCustomerId !== stripeCustomerId) {
  1883→    return res.status(403).json({ error: 'Access denied: Job belongs to another user' });
  1884→  }
  1885→
  1886→  if (job.status === 'processing') {
  1887→    return res.status(202).json({
  1888→      success: false,
  1889→      message: 'Job still processing',
  1890→      progress: job.progress
  1891→    });
  1892→  }
  1893→
  1894→  res.json({
  1895→    success: true,
  1896→    jobId: job.id,
  1897→    status: job.status,
  1898→    progress: job.progress,
  1899→    results: job.results,
  1900→    errors: job.errors,
  1901→    summary: {
  1902→      totalFiles: job.progress.total,
  1903→      successful: job.progress.completed,
  1904→      failed: job.progress.failed,
  1905→      totalSilences: job.results.reduce((sum, r) => sum + (r.count || 0), 0),
  1906→      totalSilenceDuration: job.results.reduce((sum, r) => sum + (r.totalSilenceDuration || 0), 0)
  1907→    }
  1908→  });
  1909→});
  1910→
  1911→/**
  1912→ * DELETE /batch/:jobId - Cancel or delete a batch job
  1913→ * Requires x-stripe-customer-id header matching job owner
  1914→ */
  1915→app.delete('/batch/:jobId', (req, res) => {
  1916→  const { jobId } = req.params;
  1917→  const stripeCustomerId = req.headers['x-stripe-customer-id'];
  1918→  const job = batchJobs.get(jobId);
  1919→
  1920→  if (!job) {
  1921→    return res.status(404).json({ error: 'Job not found' });
  1922→  }
  1923→
  1924→  // Verify customer ownership
  1925→  if (job.stripeCustomerId && job.stripeCustomerId !== stripeCustomerId) {
  1926→    return res.status(403).json({ error: 'Access denied: Job belongs to another user' });
  1927→  }
  1928→
  1929→  // Note: This doesn't actually cancel in-progress processing
  1930→  // but prevents the job from being queried
  1931→  batchJobs.delete(jobId);
  1932→
  1933→  res.json({
  1934→    success: true,
  1935→    message: `Job ${jobId} deleted`
  1936→  });
  1937→});
  1938→
  1939→/**
  1940→ * GET /batch/jobs - List batch jobs for authenticated user
  1941→ * Requires x-stripe-customer-id header to filter jobs by owner
  1942→ */
  1943→app.get('/batch/jobs', (req, res) => {
  1944→  const stripeCustomerId = req.headers['x-stripe-customer-id'];
  1945→
  1946→  // Filter jobs by customer ownership (only show user's own jobs)
  1947→  const jobs = Array.from(batchJobs.values())
  1948→    .filter(job => !job.stripeCustomerId || job.stripeCustomerId === stripeCustomerId)
  1949→    .map(job => ({
  1950→      id: job.id,
  1951→      type: job.type,
  1952→      status: job.status,
  1953→      createdAt: job.createdAt,
  1954→      completedAt: job.completedAt,
  1955→      progress: job.progress
  1956→    }));
  1957→
  1958→  // Sort by creation date (newest first)
  1959→  jobs.sort((a, b) => new Date(b.createdAt) - new Date(a.createdAt));
  1960→
  1961→  res.json({
  1962→    success: true,
  1963→    count: jobs.length,
  1964→    jobs
  1965→  });
  1966→});
  1967→
  1968→// =============================================================================
  1969→// Billing & Credits Routes
  1970→// =============================================================================
  1971→
  1972→/**
  1973→ * GET /credits - Get user's credit balance
  1974→ *
  1975→ * Requires x-stripe-customer-id header
  1976→ */
  1977→app.get('/credits', async (req, res) => {
  1978→  const stripeCustomerId = req.headers['x-stripe-customer-id'];
  1979→
  1980→  if (!stripeCustomerId) {
  1981→    return res.status(401).json({
  1982→      error: 'Authentication required',
  1983→      message: 'Missing x-stripe-customer-id header'
  1984→    });
  1985→  }
  1986→
  1987→  try {
  1988→    const balance = await usageTracking.getBalance(stripeCustomerId);
  1989→    res.json({
  1990→      success: true,
  1991→      ...balance
  1992→    });
  1993→  } catch (err) {
  1994→    console.error('[SPLICE] Credits error:', err);
  1995→    res.status(500).json({ error: err.message });
  1996→  }
  1997→});
  1998→
  1999→/**
  2000→ * GET /usage-history - Get user's usage history
  2001→ */
  2002→app.get('/usage-history', async (req, res) => {
  2003→  const stripeCustomerId = req.headers['x-stripe-customer-id'];
  2004→
  2005→  if (!stripeCustomerId) {
  2006→    return res.status(401).json({
  2007→      error: 'Authentication required',
  2008→      message: 'Missing x-stripe-customer-id header'
  2009→    });
  2010→  }
  2011→
  2012→  try {
  2013→    const history = await usageTracking.getUsageHistory(stripeCustomerId);
  2014→    res.json({
  2015→      success: true,
  2016→      history
  2017→    });
  2018→  } catch (err) {
  2019→    console.error('[SPLICE] Usage history error:', err);
  2020→    res.status(500).json({ error: err.message });
  2021→  }
  2022→});
  2023→
  2024→// =============================================================================
  2025→// Referral System Endpoints
  2026→// =============================================================================
  2027→
  2028→/**
  2029→ * GET /referral/code - Get or create referral code for user
  2030→ *
  2031→ * Requires x-stripe-customer-id header
  2032→ */
  2033→app.get('/referral/code', async (req, res) => {
  2034→  const stripeCustomerId = req.headers['x-stripe-customer-id'];
  2035→
  2036→  if (!stripeCustomerId) {
  2037→    return res.status(401).json({
  2038→      error: 'Authentication required',
  2039→      message: 'Missing x-stripe-customer-id header'
  2040→    });
  2041→  }
  2042→
  2043→  try {
  2044→    const codeInfo = await referralService.getOrCreateCode(stripeCustomerId);
  2045→    res.json({
  2046→      success: true,
  2047→      ...codeInfo
  2048→    });
  2049→  } catch (err) {
  2050→    console.error('[SPLICE] Referral code error:', err);
  2051→    res.status(500).json({ error: err.message });
  2052→  }
  2053→});
  2054→
  2055→/**
  2056→ * POST /referral/validate - Validate a referral code
  2057→ *
  2058→ * Body: { code: string, customerId?: string }
  2059→ */
  2060→app.post('/referral/validate', async (req, res) => {
  2061→  const { code, customerId } = req.body;
  2062→
  2063→  if (!code) {
  2064→    return res.status(400).json({
  2065→      error: 'Missing code',
  2066→      message: 'Referral code is required'
  2067→    });
  2068→  }
  2069→
  2070→  try {
  2071→    const result = await referralService.validateCode(code, customerId);
  2072→    res.json({
  2073→      success: true,
  2074→      ...result
  2075→    });
  2076→  } catch (err) {
  2077→    console.error('[SPLICE] Referral validate error:', err);
  2078→    res.status(500).json({ error: err.message });
  2079→  }
  2080→});
  2081→
  2082→/**
  2083→ * POST /referral/apply - Apply referral code at signup
  2084→ *
  2085→ * Body: { code: string, customerId: string }
  2086→ */
  2087→app.post('/referral/apply', async (req, res) => {
  2088→  const { code, customerId } = req.body;
  2089→
  2090→  if (!code || !customerId) {
  2091→    return res.status(400).json({
  2092→      error: 'Missing required fields',
  2093→      message: 'Both code and customerId are required'
  2094→    });
  2095→  }
  2096→
  2097→  try {
  2098→    const result = await referralService.applyCode(code, customerId, stripe);
  2099→    res.json({
  2100→      success: true,
  2101→      ...result
  2102→    });
  2103→  } catch (err) {
  2104→    console.error('[SPLICE] Referral apply error:', err);
  2105→    // Return user-friendly errors for validation failures
  2106→    if (err.message.includes('Cannot use your own') ||
  2107→        err.message.includes('already used') ||
  2108→        err.message.includes('not found') ||
  2109→        err.message.includes('no longer active')) {
  2110→      return res.status(400).json({ error: err.message });
  2111→    }
  2112→    res.status(500).json({ error: err.message });
  2113→  }
  2114→});
  2115→
  2116→/**
  2117→ * GET /referral/stats - Get referral statistics for user
  2118→ *
  2119→ * Requires x-stripe-customer-id header
  2120→ */
  2121→app.get('/referral/stats', async (req, res) => {
  2122→  const stripeCustomerId = req.headers['x-stripe-customer-id'];
  2123→
  2124→  if (!stripeCustomerId) {
  2125→    return res.status(401).json({
  2126→      error: 'Authentication required',
  2127→      message: 'Missing x-stripe-customer-id header'
  2128→    });
  2129→  }
  2130→
  2131→  try {
  2132→    const stats = await referralService.getStats(stripeCustomerId);
  2133→    res.json({
  2134→      success: true,
  2135→      ...stats
  2136→    });
  2137→  } catch (err) {
  2138→    console.error('[SPLICE] Referral stats error:', err);
  2139→    res.status(500).json({ error: err.message });
  2140→  }
  2141→});
  2142→
  2143→// =============================================================================
  2144→// License Key Endpoints
  2145→// =============================================================================
  2146→
  2147→/**
  2148→ * POST /license/activate - Activate a license key
  2149→ *
  2150→ * Body: { key: "SPLICE-XXXX-XXXX-XXXX" }
  2151→ * Returns: { success, customerId, tier, hoursRemaining }
  2152→ */
  2153→app.post('/license/activate', async (req, res) => {
  2154→  const { key } = req.body;
  2155→
  2156→  if (!key) {
  2157→    return res.status(400).json({
  2158→      error: 'Missing license key',
  2159→      message: 'License key is required'
  2160→    });
  2161→  }
  2162→
  2163→  // Validate format
  2164→  if (!licenseService.isValidKeyFormat(key)) {
  2165→    return res.status(400).json({
  2166→      error: 'Invalid license key format',
  2167→      message: 'License key should be in format: SPLICE-XXXX-XXXX-XXXX'
  2168→    });
  2169→  }
  2170→
  2171→  try {
  2172→    // Activate the key
  2173→    const result = await licenseService.activateLicenseKey(key);
  2174→
  2175→    if (!result.success) {
  2176→      return res.status(400).json({
  2177→        success: false,
  2178→        error: result.error
  2179→      });
  2180→    }
  2181→
  2182→    // Get the customer's balance and tier info
  2183→    const balance = await usageTracking.getBalance(result.customerId);
  2184→
  2185→    res.json({
  2186→      success: true,
  2187→      customerId: result.customerId,
  2188→      tier: balance.tier,
  2189→      tierName: balance.tierName,
  2190→      hoursRemaining: balance.hoursRemaining,
  2191→      hoursTotal: balance.hoursTotal
  2192→    });
  2193→  } catch (err) {
  2194→    console.error('[SPLICE] License activation error:', err);
  2195→    res.status(500).json({ error: err.message });
  2196→  }
  2197→});
  2198→
  2199→/**
  2200→ * GET /license/key - Get license key for a customer (for display/resend)
  2201→ *
  2202→ * Requires x-stripe-customer-id header
  2203→ */
  2204→app.get('/license/key', async (req, res) => {
  2205→  const stripeCustomerId = req.headers['x-stripe-customer-id'];
  2206→
  2207→  if (!stripeCustomerId) {
  2208→    return res.status(401).json({
  2209→      error: 'Authentication required',
  2210→      message: 'Missing x-stripe-customer-id header'
  2211→    });
  2212→  }
  2213→
  2214→  try {
  2215→    const result = await licenseService.getLicenseByCustomerId(stripeCustomerId);
  2216→
  2217→    if (!result.success) {
  2218→      return res.status(404).json({
  2219→        success: false,
  2220→        error: result.error
  2221→      });
  2222→    }
  2223→
  2224→    res.json({
  2225→      success: true,
  2226→      key: result.key,
  2227→      activated: result.activated,
  2228→      createdAt: result.createdAt
  2229→    });
  2230→  } catch (err) {
  2231→    console.error('[SPLICE] License lookup error:', err);
  2232→    res.status(500).json({ error: err.message });
  2233→  }
  2234→});
  2235→
  2236→/**
  2237→ * POST /license/resend - Resend license key to customer email
  2238→ *
  2239→ * For support cases where customer didn't receive their license key.
  2240→ * Requires x-stripe-customer-id header or customerId in body (for support).
  2241→ */
  2242→app.post('/license/resend', async (req, res) => {
  2243→  // Allow customerId from header or body (for support staff)
  2244→  const stripeCustomerId = req.headers['x-stripe-customer-id'] || req.body.customerId;
  2245→
  2246→  if (!stripeCustomerId) {
  2247→    return res.status(401).json({
  2248→      error: 'Authentication required',
  2249→      message: 'Missing customer ID'
  2250→    });
  2251→  }
  2252→
  2253→  try {
  2254→    // Get existing license key
  2255→    const licenseResult = await licenseService.getLicenseByCustomerId(stripeCustomerId);
  2256→
  2257→    if (!licenseResult.success) {
  2258→      // No license exists - try to generate one
  2259→      console.log(`[SPLICE] No license found for ${stripeCustomerId}, generating new one`);
  2260→      const newLicense = await licenseService.generateLicenseKey(stripeCustomerId);
  2261→
  2262→      if (!newLicense.success) {
  2263→        return res.status(500).json({
  2264→          success: false,
  2265→          error: 'Failed to generate license key',
  2266→          details: newLicense.error
  2267→        });
  2268→      }
  2269→
  2270→      licenseResult.key = newLicense.key;
  2271→      licenseResult.success = true;
  2272→    }
  2273→
  2274→    // Get customer email from Stripe
  2275→    let customerEmail = null;
  2276→    try {
  2277→      const customer = await stripe.customers.retrieve(stripeCustomerId);
  2278→      customerEmail = customer.email;
  2279→    } catch (stripeErr) {
  2280→      console.error(`[SPLICE] Failed to get customer email:`, stripeErr.message);
  2281→    }
  2282→
  2283→    if (!customerEmail) {
  2284→      return res.status(400).json({
  2285→        success: false,
  2286→        error: 'No email address found for customer',
  2287→        key: licenseResult.key, // Still return key for manual delivery
  2288→        manualDeliveryRequired: true
  2289→      });
  2290→    }
  2291→
  2292→    // Log the resend request (placeholder for actual email service)
  2293→    console.log(`[SPLICE] License key resend requested for ${customerEmail}: ${licenseResult.key}`);
  2294→    // TODO: Integrate with email service
  2295→    // await sendLicenseKeyEmail(customerEmail, licenseResult.key);
  2296→
  2297→    res.json({
  2298→      success: true,
  2299→      message: `License key will be sent to ${customerEmail}`,
  2300→      email: customerEmail,
  2301→      key: licenseResult.key, // Include key for immediate display
  2302→      activated: licenseResult.activated
  2303→    });
  2304→  } catch (err) {
  2305→    console.error('[SPLICE] License resend error:', err);
  2306→    res.status(500).json({ error: err.message });
  2307→  }
  2308→});
  2309→
  2310→// =============================================================================
  2311→// Start Server
  2312→// =============================================================================
  2313→
  2314→// Initialize database and start server
  2315→async function startServer() {
  2316→  try {
  2317→    await usageTracking.initDatabase();
  2318→    await referralService.initReferralTables();
  2319→    await licenseService.initLicenseTables();
  2320→    console.log('[SPLICE] Database initialized');
  2321→
  2322→    if (isProduction || !httpsOptions) {
  2323→      // Production: Railway provides TLS termination, use HTTP
  2324→      http.createServer(app).listen(PORT, () => {
  2325→        console.log(`[SPLICE] Backend running at http://0.0.0.0:${PORT} (production)`);
  2326→      });
  2327→    } else {
  2328→      // Development: Use HTTPS with local certificates
  2329→      https.createServer(httpsOptions, app).listen(PORT, () => {
  2330→        console.log(`[SPLICE] Backend running at https://127.0.0.1:${PORT} (development)`);
  2331→        console.log(`[SPLICE] POST /analyze with { "wavPath": "/path/to/audio.wav" }`);
  2332→      });
  2333→    }
  2334→  } catch (err) {
  2335→    console.error('[SPLICE] Failed to start server:', err);
  2336→    process.exit(1);
  2337→  }
  2338→}
  2339→
  2340→startServer();
  2341→

<system-reminder>
Whenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.
</system-reminder>
