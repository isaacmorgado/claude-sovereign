{"parentUuid":null,"isSidechain":true,"userType":"external","cwd":"/Users/imorgado/SPLICE/splice-cep/panel/js","sessionId":"7fa929e3-00b9-497c-b311-19cb4c6b44f9","version":"2.0.76","gitBranch":"main","agentId":"ad38527","slug":"eager-questing-lagoon","type":"user","message":{"role":"user","content":"Analyze /Users/imorgado/SPLICE/splice-cep/panel/js/multitrack.js for production bottlenecks:\n\n1. **Track Operations**: Check for blocking operations when manipulating tracks\n2. **Selection Management**: Verify clip selection logic is efficient\n3. **JSX Calls**: Check all Premiere Pro API calls have proper error handling\n4. **State Synchronization**: Look for race conditions with track state\n5. **Performance**: Check for expensive DOM operations\n\nReport issues with line numbers and severity."},"uuid":"81f1fdf4-5854-4b55-abdb-1d418a8b9b29","timestamp":"2026-01-12T16:27:00.141Z"}
{"parentUuid":"81f1fdf4-5854-4b55-abdb-1d418a8b9b29","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/SPLICE/splice-cep/panel/js","sessionId":"7fa929e3-00b9-497c-b311-19cb4c6b44f9","version":"2.0.76","gitBranch":"main","agentId":"ad38527","slug":"eager-questing-lagoon","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01Bghs1pCRYotd5fWZ2W6SsG","type":"message","role":"assistant","content":[{"type":"text","text":"I'll analyze the multitrack.js file for production bottlenecks and issues."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":6727,"cache_read_input_tokens":24136,"cache_creation":{"ephemeral_5m_input_tokens":6727,"ephemeral_1h_input_tokens":0},"output_tokens":5,"service_tier":"standard"}},"requestId":"req_011CX3oDd6TieWh4UjoVJffW","type":"assistant","uuid":"4463e424-9877-4921-b9e9-eee51eb9f277","timestamp":"2026-01-12T16:27:03.602Z"}
{"parentUuid":"4463e424-9877-4921-b9e9-eee51eb9f277","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/SPLICE/splice-cep/panel/js","sessionId":"7fa929e3-00b9-497c-b311-19cb4c6b44f9","version":"2.0.76","gitBranch":"main","agentId":"ad38527","slug":"eager-questing-lagoon","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01Bghs1pCRYotd5fWZ2W6SsG","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01BRdEZ1fUwWDLaHVn72XpY2","name":"Read","input":{"file_path":"/Users/imorgado/SPLICE/splice-cep/panel/js/multitrack.js"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":6727,"cache_read_input_tokens":24136,"cache_creation":{"ephemeral_5m_input_tokens":6727,"ephemeral_1h_input_tokens":0},"output_tokens":5,"service_tier":"standard"}},"requestId":"req_011CX3oDd6TieWh4UjoVJffW","type":"assistant","uuid":"c01e87e2-b413-44b7-a0c5-db06b17c08e0","timestamp":"2026-01-12T16:27:04.235Z"}
{"parentUuid":"c01e87e2-b413-44b7-a0c5-db06b17c08e0","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/SPLICE/splice-cep/panel/js","sessionId":"7fa929e3-00b9-497c-b311-19cb4c6b44f9","version":"2.0.76","gitBranch":"main","agentId":"ad38527","slug":"eager-questing-lagoon","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01BRdEZ1fUwWDLaHVn72XpY2","type":"tool_result","content":"     1→/**\n     2→ * SPLICE CEP Panel - Multitrack UI Module\n     3→ * Multi-speaker analysis, auto-balance, and timeline building\n     4→ * v4.0.0 - CEP Migration\n     5→ */\n     6→\n     7→// ============================================================================\n     8→// STATE\n     9→// ============================================================================\n    10→let speakerConfig = [];\n    11→let analysisResults = null;\n    12→let isMultitrackOperationInProgress = false;\n    13→\n    14→// Speaker colors for visual distinction\n    15→const SPEAKER_COLORS = ['#ff6b6b', '#4ecdc4', '#ffe66d', '#95e1d3'];\n    16→\n    17→// ============================================================================\n    18→// DOM ELEMENT CACHE\n    19→// ============================================================================\n    20→const multitrackUI = {};\n    21→\n    22→function cacheMultitrackElements() {\n    23→    multitrackUI.section = document.getElementById('multitrackSection');\n    24→    multitrackUI.toggle = document.getElementById('multitrackToggle');\n    25→    multitrackUI.panel = document.getElementById('multitrackPanel');\n    26→    multitrackUI.speakerList = document.getElementById('speakerList');\n    27→    multitrackUI.addSpeakerBtn = document.getElementById('addSpeakerBtn');\n    28→    multitrackUI.wideShotTrack = document.getElementById('wideShotTrack');\n    29→\n    30→    // Parameters\n    31→    multitrackUI.minShotDuration = document.getElementById('minShotDuration');\n    32→    multitrackUI.minShotDurationValue = document.getElementById('minShotDurationValue');\n    33→    multitrackUI.wideShotPercent = document.getElementById('wideShotPercent');\n    34→    multitrackUI.wideShotPercentValue = document.getElementById('wideShotPercentValue');\n    35→    multitrackUI.switchingFrequency = document.getElementById('switchingFrequency');\n    36→    multitrackUI.switchingFrequencyValue = document.getElementById('switchingFrequencyValue');\n    37→    multitrackUI.enableWideShotDetection = document.getElementById('enableWideShotDetection');\n    38→\n    39→    // Actions\n    40→    multitrackUI.analyzeBtn = document.getElementById('analyzeMultitrackBtn');\n    41→    multitrackUI.autoBalanceBtn = document.getElementById('autoBalanceBtn');\n    42→    multitrackUI.applyBtn = document.getElementById('applyMultitrackBtn');\n    43→\n    44→    // Preview\n    45→    multitrackUI.preview = document.getElementById('multitrackPreview');\n    46→    multitrackUI.distributionChart = document.getElementById('distributionChart');\n    47→    multitrackUI.speakerStats = document.getElementById('speakerStats');\n    48→    multitrackUI.decisionCount = document.getElementById('decisionCount');\n    49→    multitrackUI.decisionList = document.getElementById('decisionList');\n    50→}\n    51→\n    52→// ============================================================================\n    53→// INITIALIZATION\n    54→// ============================================================================\n    55→function initMultitrackUI() {\n    56→    cacheMultitrackElements();\n    57→\n    58→    if (!multitrackUI.section) {\n    59→        console.warn('[SPLICE Multitrack] Multitrack section not found in DOM');\n    60→        return;\n    61→    }\n    62→\n    63→    // Toggle section expand/collapse\n    64→    if (multitrackUI.toggle) {\n    65→        multitrackUI.toggle.addEventListener('click', toggleMultitrackSection);\n    66→    }\n    67→\n    68→    // Add speaker button\n    69→    if (multitrackUI.addSpeakerBtn) {\n    70→        multitrackUI.addSpeakerBtn.addEventListener('click', addSpeaker);\n    71→    }\n    72→\n    73→    // Speaker list event delegation (remove buttons, name changes)\n    74→    if (multitrackUI.speakerList) {\n    75→        multitrackUI.speakerList.addEventListener('click', handleSpeakerListClick);\n    76→        multitrackUI.speakerList.addEventListener('change', handleSpeakerListChange);\n    77→    }\n    78→\n    79→    // Parameter sliders\n    80→    setupParameterListeners();\n    81→\n    82→    // Action buttons\n    83→    if (multitrackUI.analyzeBtn) {\n    84→        multitrackUI.analyzeBtn.addEventListener('click', analyzeMultitrack);\n    85→    }\n    86→    if (multitrackUI.autoBalanceBtn) {\n    87→        multitrackUI.autoBalanceBtn.addEventListener('click', autoBalanceMultitrack);\n    88→    }\n    89→    if (multitrackUI.applyBtn) {\n    90→        multitrackUI.applyBtn.addEventListener('click', applyMultitrackCuts);\n    91→    }\n    92→\n    93→    // Decision list event delegation (seek buttons)\n    94→    if (multitrackUI.decisionList) {\n    95→        multitrackUI.decisionList.addEventListener('click', handleDecisionListClick);\n    96→    }\n    97→\n    98→    // Initialize speaker config from DOM\n    99→    initSpeakerConfigFromDOM();\n   100→\n   101→    console.log('[SPLICE Multitrack] UI initialized');\n   102→}\n   103→\n   104→// ============================================================================\n   105→// SECTION TOGGLE\n   106→// ============================================================================\n   107→function toggleMultitrackSection() {\n   108→    if (!multitrackUI.panel || !multitrackUI.toggle) return;\n   109→\n   110→    // Check state BEFORE toggling\n   111→    const wasCollapsed = multitrackUI.panel.classList.contains('collapsed');\n   112→    multitrackUI.panel.classList.toggle('collapsed');\n   113→    const icon = multitrackUI.toggle.querySelector('.toggle-icon');\n   114→\n   115→    if (icon) {\n   116→        // If it was collapsed, it's now expanded (show -)\n   117→        icon.textContent = wasCollapsed ? '-' : '+';\n   118→    }\n   119→}\n   120→\n   121→// ============================================================================\n   122→// SPEAKER CONFIGURATION\n   123→// ============================================================================\n   124→function initSpeakerConfigFromDOM() {\n   125→    speakerConfig = [];\n   126→    const items = multitrackUI.speakerList?.querySelectorAll('.speaker-item') || [];\n   127→\n   128→    items.forEach((item, index) => {\n   129→        const nameInput = item.querySelector('.speaker-name');\n   130→        const trackSelect = item.querySelector('.speaker-track');\n   131→\n   132→        speakerConfig.push({\n   133→            index,\n   134→            name: nameInput?.value || `Speaker ${index + 1}`,\n   135→            videoTrack: parseInt(trackSelect?.value || index)\n   136→        });\n   137→    });\n   138→}\n   139→\n   140→function addSpeaker() {\n   141→    if (speakerConfig.length >= 4) {\n   142→        setStatus('Maximum 4 speakers supported');\n   143→        return;\n   144→    }\n   145→\n   146→    const newIndex = speakerConfig.length;\n   147→    const defaultName = `Speaker ${newIndex + 1}`;\n   148→\n   149→    speakerConfig.push({\n   150→        index: newIndex,\n   151→        name: defaultName,\n   152→        videoTrack: newIndex\n   153→    });\n   154→\n   155→    // Add DOM element\n   156→    // SECURITY: Escape dynamic content to prevent XSS\n   157→    const speakerItem = document.createElement('div');\n   158→    speakerItem.className = `speaker-item speaker-${newIndex}`;\n   159→    speakerItem.dataset.speakerIndex = newIndex;\n   160→    speakerItem.innerHTML = `\n   161→        <input type=\"text\" class=\"speaker-name\" value=\"${escapeHtml(defaultName)}\" placeholder=\"Name\" aria-label=\"Speaker ${newIndex + 1} name\">\n   162→        <select class=\"speaker-track\" aria-label=\"Speaker ${newIndex + 1} video track\">\n   163→            <option value=\"0\" ${newIndex === 0 ? 'selected' : ''}>V1</option>\n   164→            <option value=\"1\" ${newIndex === 1 ? 'selected' : ''}>V2</option>\n   165→            <option value=\"2\" ${newIndex === 2 ? 'selected' : ''}>V3</option>\n   166→            <option value=\"3\" ${newIndex === 3 ? 'selected' : ''}>V4</option>\n   167→        </select>\n   168→        <button class=\"speaker-remove-btn\" title=\"Remove speaker\" aria-label=\"Remove speaker ${newIndex + 1}\">x</button>\n   169→    `;\n   170→\n   171→    multitrackUI.speakerList.appendChild(speakerItem);\n   172→\n   173→    // Update remove button visibility\n   174→    updateRemoveButtonVisibility();\n   175→}\n   176→\n   177→function removeSpeaker(index) {\n   178→    if (speakerConfig.length <= 2) {\n   179→        setStatus('Minimum 2 speakers required');\n   180→        return;\n   181→    }\n   182→\n   183→    speakerConfig.splice(index, 1);\n   184→\n   185→    // Remove from DOM\n   186→    const item = multitrackUI.speakerList.querySelector(`[data-speaker-index=\"${index}\"]`);\n   187→    if (item) {\n   188→        item.remove();\n   189→    }\n   190→\n   191→    // Re-index remaining speakers\n   192→    reindexSpeakers();\n   193→\n   194→    // Update remove button visibility\n   195→    updateRemoveButtonVisibility();\n   196→}\n   197→\n   198→function reindexSpeakers() {\n   199→    const items = multitrackUI.speakerList.querySelectorAll('.speaker-item');\n   200→    items.forEach((item, i) => {\n   201→        item.dataset.speakerIndex = i;\n   202→        item.className = `speaker-item speaker-${i}`;\n   203→\n   204→        // Update speakerConfig\n   205→        if (speakerConfig[i]) {\n   206→            speakerConfig[i].index = i;\n   207→        }\n   208→    });\n   209→}\n   210→\n   211→function updateRemoveButtonVisibility() {\n   212→    const items = multitrackUI.speakerList.querySelectorAll('.speaker-item');\n   213→    const canRemove = items.length > 2;\n   214→\n   215→    items.forEach(item => {\n   216→        const btn = item.querySelector('.speaker-remove-btn');\n   217→        if (btn) {\n   218→            btn.style.display = canRemove ? 'block' : 'none';\n   219→        }\n   220→    });\n   221→}\n   222→\n   223→function handleSpeakerListClick(e) {\n   224→    const removeBtn = e.target.closest('.speaker-remove-btn');\n   225→    if (removeBtn) {\n   226→        const item = removeBtn.closest('.speaker-item');\n   227→        const index = parseInt(item?.dataset.speakerIndex || 0);\n   228→        removeSpeaker(index);\n   229→    }\n   230→}\n   231→\n   232→function handleSpeakerListChange(e) {\n   233→    const item = e.target.closest('.speaker-item');\n   234→    if (!item) return;\n   235→\n   236→    const index = parseInt(item.dataset.speakerIndex || 0);\n   237→\n   238→    if (e.target.classList.contains('speaker-name')) {\n   239→        speakerConfig[index].name = e.target.value;\n   240→    } else if (e.target.classList.contains('speaker-track')) {\n   241→        speakerConfig[index].videoTrack = parseInt(e.target.value);\n   242→    }\n   243→}\n   244→\n   245→// ============================================================================\n   246→// PARAMETER LISTENERS\n   247→// ============================================================================\n   248→function setupParameterListeners() {\n   249→    // Min shot duration slider\n   250→    if (multitrackUI.minShotDuration && multitrackUI.minShotDurationValue) {\n   251→        multitrackUI.minShotDuration.addEventListener('input', () => {\n   252→            multitrackUI.minShotDurationValue.textContent =\n   253→                parseFloat(multitrackUI.minShotDuration.value).toFixed(1) + 's';\n   254→        });\n   255→    }\n   256→\n   257→    // Wide shot percentage slider\n   258→    if (multitrackUI.wideShotPercent && multitrackUI.wideShotPercentValue) {\n   259→        multitrackUI.wideShotPercent.addEventListener('input', () => {\n   260→            multitrackUI.wideShotPercentValue.textContent =\n   261→                multitrackUI.wideShotPercent.value + '%';\n   262→        });\n   263→    }\n   264→\n   265→    // Switching frequency slider\n   266→    if (multitrackUI.switchingFrequency && multitrackUI.switchingFrequencyValue) {\n   267→        multitrackUI.switchingFrequency.addEventListener('input', () => {\n   268→            multitrackUI.switchingFrequencyValue.textContent =\n   269→                multitrackUI.switchingFrequency.value;\n   270→        });\n   271→    }\n   272→}\n   273→\n   274→// ============================================================================\n   275→// GET SETTINGS\n   276→// ============================================================================\n   277→function getMultitrackSettings() {\n   278→    return {\n   279→        minShotDuration: parseFloat(multitrackUI.minShotDuration?.value || 2),\n   280→        wideShotPercentage: parseInt(multitrackUI.wideShotPercent?.value || 20),\n   281→        switchingFrequency: parseInt(multitrackUI.switchingFrequency?.value || 50),\n   282→        wideShotEnabled: multitrackUI.enableWideShotDetection?.checked ?? true,\n   283→        wideShotTracks: multitrackUI.wideShotTrack?.value !== '-1'\n   284→            ? [parseInt(multitrackUI.wideShotTrack.value)]\n   285→            : [],\n   286→        speakerNames: speakerConfig.map(s => s.name),\n   287→        videoTrackMapping: speakerConfig.reduce((acc, s) => {\n   288→            acc[s.index] = s.videoTrack;\n   289→            return acc;\n   290→        }, {})\n   291→    };\n   292→}\n   293→\n   294→// ============================================================================\n   295→// GET AUDIO PATH (CEP VERSION)\n   296→// ============================================================================\n   297→async function getAudioPath() {\n   298→    try {\n   299→        // Try to get audio path from active sequence\n   300→        const seqInfo = await jsx.call('getActiveSequence');\n   301→        if (seqInfo && seqInfo.audioPath) {\n   302→            return seqInfo.audioPath;\n   303→        }\n   304→\n   305→        // Fallback: export sequence audio for analysis\n   306→        const exportResult = await jsx.call('exportSequenceAudioForAnalysis');\n   307→        if (exportResult && exportResult.path) {\n   308→            return exportResult.path;\n   309→        }\n   310→\n   311→        // Last resort: get first clip audio path\n   312→        const clipPath = await jsx.call('getFirstClipAudioPath');\n   313→        if (clipPath) {\n   314→            return clipPath;\n   315→        }\n   316→\n   317→        throw new Error('Could not determine audio path');\n   318→    } catch (e) {\n   319→        console.error('[SPLICE Multitrack] Failed to get audio path:', e);\n   320→        throw e;\n   321→    }\n   322→}\n   323→\n   324→// ============================================================================\n   325→// ANALYZE MULTITRACK\n   326→// ============================================================================\n   327→async function analyzeMultitrack() {\n   328→    if (isMultitrackOperationInProgress) return;\n   329→\n   330→    // Check tier access - Multitrack requires Team tier\n   331→    if (typeof hasFeatureAccess === 'function' && !hasFeatureAccess('multitrack')) {\n   332→        const requiredTier = typeof getRequiredTier === 'function' ? getRequiredTier('multitrack') : 'Team';\n   333→        setStatus(`Multitrack auto-balance requires ${requiredTier} tier`);\n   334→        if (typeof showUpgradeModal === 'function') {\n   335→            showUpgradeModal('Multitrack Auto-Balance', requiredTier);\n   336→        }\n   337→        return;\n   338→    }\n   339→\n   340→    // Check online status\n   341→    if (typeof isOnline === 'function' && !isOnline()) {\n   342→        setStatus('Offline - Check your connection');\n   343→        return;\n   344→    }\n   345→\n   346→    isMultitrackOperationInProgress = true;\n   347→    if (multitrackUI.analyzeBtn) {\n   348→        multitrackUI.analyzeBtn.disabled = true;\n   349→        multitrackUI.analyzeBtn.textContent = 'Analyzing...';\n   350→    }\n   351→\n   352→    try {\n   353→        setStatus('Exporting audio tracks...');\n   354→\n   355→        // Get audio path\n   356→        const audioPath = await getAudioPath();\n   357→        if (!audioPath) {\n   358→            throw new Error('Audio export path not initialized');\n   359→        }\n   360→\n   361→        // For now, we use the main audio path\n   362→        // In a full implementation, we'd export separate tracks per speaker\n   363→        const audioPaths = [audioPath];\n   364→\n   365→        // Add additional tracks if multi-track sequence\n   366→        if (speakerConfig.length > 1) {\n   367→            for (let i = 1; i < speakerConfig.length; i++) {\n   368→                audioPaths.push(audioPath);\n   369→            }\n   370→        }\n   371→\n   372→        setStatus('Analyzing speakers...');\n   373→\n   374→        const settings = getMultitrackSettings();\n   375→        const apiUrl = getBackendUrl();\n   376→\n   377→        const response = await fetchWithTimeout(`${apiUrl}/multitrack`, {\n   378→            method: 'POST',\n   379→            headers: getAuthHeaders(),\n   380→            body: JSON.stringify({\n   381→                audioPaths,\n   382→                speakerNames: settings.speakerNames,\n   383→                videoTrackMapping: settings.videoTrackMapping,\n   384→                wideShotEnabled: settings.wideShotEnabled,\n   385→                wideShotPercentage: settings.wideShotPercentage,\n   386→                wideShotTracks: settings.wideShotTracks,\n   387→                minShotDuration: settings.minShotDuration,\n   388→                switchingFrequency: settings.switchingFrequency\n   389→            })\n   390→        }, 120000);\n   391→\n   392→        if (!response.ok) {\n   393→            const errorMsg = await parseErrorResponse(response);\n   394→            throw new Error(errorMsg);\n   395→        }\n   396→\n   397→        const data = await response.json();\n   398→        analysisResults = data;\n   399→\n   400→        // Display results\n   401→        displayMultitrackResults(data);\n   402→\n   403→        // Enable apply button\n   404→        if (multitrackUI.applyBtn) {\n   405→            multitrackUI.applyBtn.disabled = false;\n   406→        }\n   407→\n   408→        setStatus(`Analysis complete - ${data.decisions?.length || 0} switching decisions`);\n   409→\n   410→    } catch (err) {\n   411→        console.error('[SPLICE Multitrack] Analysis error:', err);\n   412→        setStatus('Analysis failed: ' + err.message, true);\n   413→    } finally {\n   414→        isMultitrackOperationInProgress = false;\n   415→        if (multitrackUI.analyzeBtn) {\n   416→            multitrackUI.analyzeBtn.disabled = false;\n   417→            multitrackUI.analyzeBtn.textContent = 'Analyze';\n   418→        }\n   419→    }\n   420→}\n   421→\n   422→// ============================================================================\n   423→// AUTO-BALANCE\n   424→// ============================================================================\n   425→async function autoBalanceMultitrack() {\n   426→    if (isMultitrackOperationInProgress) return;\n   427→\n   428→    // Check tier access - Multitrack requires Team tier\n   429→    if (typeof hasFeatureAccess === 'function' && !hasFeatureAccess('multitrack')) {\n   430→        const requiredTier = typeof getRequiredTier === 'function' ? getRequiredTier('multitrack') : 'Team';\n   431→        setStatus(`Multitrack auto-balance requires ${requiredTier} tier`);\n   432→        if (typeof showUpgradeModal === 'function') {\n   433→            showUpgradeModal('Multitrack Auto-Balance', requiredTier);\n   434→        }\n   435→        return;\n   436→    }\n   437→\n   438→    // Check online status\n   439→    if (typeof isOnline === 'function' && !isOnline()) {\n   440→        setStatus('Offline - Check your connection');\n   441→        return;\n   442→    }\n   443→\n   444→    isMultitrackOperationInProgress = true;\n   445→    if (multitrackUI.autoBalanceBtn) {\n   446→        multitrackUI.autoBalanceBtn.disabled = true;\n   447→        multitrackUI.autoBalanceBtn.textContent = 'Balancing...';\n   448→    }\n   449→\n   450→    try {\n   451→        setStatus('Auto-balancing speaker screentime...');\n   452→\n   453→        const audioPath = await getAudioPath();\n   454→        const audioPaths = [audioPath];\n   455→\n   456→        // Duplicate for multiple speakers\n   457→        for (let i = 1; i < speakerConfig.length; i++) {\n   458→            audioPaths.push(audioPath);\n   459→        }\n   460→\n   461→        const settings = getMultitrackSettings();\n   462→        const apiUrl = getBackendUrl();\n   463→\n   464→        const response = await fetchWithTimeout(`${apiUrl}/multitrack/auto-balance`, {\n   465→            method: 'POST',\n   466→            headers: getAuthHeaders(),\n   467→            body: JSON.stringify({\n   468→                audioPaths,\n   469→                speakerNames: settings.speakerNames,\n   470→                videoTrackMapping: settings.videoTrackMapping,\n   471→                wideShotEnabled: settings.wideShotEnabled,\n   472→                wideShotPercentage: settings.wideShotPercentage,\n   473→                wideShotTracks: settings.wideShotTracks,\n   474→                minShotDuration: settings.minShotDuration,\n   475→                switchingFrequency: settings.switchingFrequency\n   476→            })\n   477→        }, 120000);\n   478→\n   479→        if (!response.ok) {\n   480→            const errorMsg = await parseErrorResponse(response);\n   481→            throw new Error(errorMsg);\n   482→        }\n   483→\n   484→        const data = await response.json();\n   485→        analysisResults = data;\n   486→\n   487→        // Display results\n   488→        displayMultitrackResults(data);\n   489→\n   490→        // Enable apply button\n   491→        if (multitrackUI.applyBtn) {\n   492→            multitrackUI.applyBtn.disabled = false;\n   493→        }\n   494→\n   495→        const errorInfo = data.finalError ? ` (${data.finalError.toFixed(1)}% deviation)` : '';\n   496→        setStatus(`Auto-balance complete${errorInfo}`);\n   497→\n   498→    } catch (err) {\n   499→        console.error('[SPLICE Multitrack] Auto-balance error:', err);\n   500→        setStatus('Auto-balance failed: ' + err.message, true);\n   501→    } finally {\n   502→        isMultitrackOperationInProgress = false;\n   503→        if (multitrackUI.autoBalanceBtn) {\n   504→            multitrackUI.autoBalanceBtn.disabled = false;\n   505→            multitrackUI.autoBalanceBtn.textContent = 'Auto-Balance';\n   506→        }\n   507→    }\n   508→}\n   509→\n   510→// ============================================================================\n   511→// DISPLAY RESULTS\n   512→// ============================================================================\n   513→function displayMultitrackResults(results) {\n   514→    if (!results) return;\n   515→\n   516→    // Show preview section\n   517→    if (multitrackUI.preview) {\n   518→        multitrackUI.preview.classList.remove('hidden');\n   519→    }\n   520→\n   521→    // Render distribution chart\n   522→    renderDistributionChart(results.metadata);\n   523→\n   524→    // Render speaker stats\n   525→    renderSpeakerStats(results.metadata);\n   526→\n   527→    // Render decision list\n   528→    renderDecisionList(results.decisions || []);\n   529→}\n   530→\n   531→function renderDistributionChart(metadata) {\n   532→    if (!multitrackUI.distributionChart || !metadata) return;\n   533→\n   534→    const speakerPercentages = metadata.speakerPercentages || {};\n   535→    const wideShotPct = metadata.wideShotPercentage || 0;\n   536→\n   537→    const fragment = document.createDocumentFragment();\n   538→\n   539→    // Add speaker bars\n   540→    let speakerIndex = 0;\n   541→    for (const [speaker, pct] of Object.entries(speakerPercentages)) {\n   542→        if (pct > 0) {\n   543→            const bar = document.createElement('div');\n   544→            bar.className = `distribution-bar speaker-${speakerIndex % 4}`;\n   545→            bar.style.width = `${pct}%`;\n   546→            bar.textContent = pct >= 10 ? `${speaker}: ${pct.toFixed(0)}%` : '';\n   547→            bar.title = `${speaker}: ${pct.toFixed(1)}%`;\n   548→            fragment.appendChild(bar);\n   549→        }\n   550→        speakerIndex++;\n   551→    }\n   552→\n   553→    // Add wide shot bar\n   554→    if (wideShotPct > 0) {\n   555→        const bar = document.createElement('div');\n   556→        bar.className = 'distribution-bar wide-shot';\n   557→        bar.style.width = `${wideShotPct}%`;\n   558→        bar.textContent = wideShotPct >= 8 ? `Wide: ${wideShotPct.toFixed(0)}%` : '';\n   559→        bar.title = `Wide Shot: ${wideShotPct.toFixed(1)}%`;\n   560→        fragment.appendChild(bar);\n   561→    }\n   562→\n   563→    multitrackUI.distributionChart.innerHTML = '';\n   564→    multitrackUI.distributionChart.appendChild(fragment);\n   565→}\n   566→\n   567→function renderSpeakerStats(metadata) {\n   568→    if (!multitrackUI.speakerStats || !metadata) return;\n   569→\n   570→    const speakerPercentages = metadata.speakerPercentages || {};\n   571→    const wideShotPct = metadata.wideShotPercentage || 0;\n   572→\n   573→    const fragment = document.createDocumentFragment();\n   574→\n   575→    // Add speaker stats\n   576→    // SECURITY: Escape speaker names to prevent XSS\n   577→    let speakerIndex = 0;\n   578→    for (const [speaker, pct] of Object.entries(speakerPercentages)) {\n   579→        const stat = document.createElement('div');\n   580→        stat.className = 'speaker-stat';\n   581→        stat.innerHTML = `\n   582→            <span class=\"speaker-stat-dot speaker-${speakerIndex % 4}\"></span>\n   583→            <span>${escapeHtml(speaker)}: ${escapeHtml(pct.toFixed(1))}%</span>\n   584→        `;\n   585→        fragment.appendChild(stat);\n   586→        speakerIndex++;\n   587→    }\n   588→\n   589→    // Add wide shot stat\n   590→    if (wideShotPct > 0) {\n   591→        const stat = document.createElement('div');\n   592→        stat.className = 'speaker-stat';\n   593→        stat.innerHTML = `\n   594→            <span class=\"speaker-stat-dot wide-shot\"></span>\n   595→            <span>Wide: ${escapeHtml(wideShotPct.toFixed(1))}%</span>\n   596→        `;\n   597→        fragment.appendChild(stat);\n   598→    }\n   599→\n   600→    // Add avg shot duration\n   601→    if (metadata.averageShotDuration) {\n   602→        const stat = document.createElement('div');\n   603→        stat.className = 'speaker-stat';\n   604→        stat.innerHTML = `<span style=\"color: #888;\">Avg: ${escapeHtml(metadata.averageShotDuration.toFixed(1))}s</span>`;\n   605→        fragment.appendChild(stat);\n   606→    }\n   607→\n   608→    multitrackUI.speakerStats.innerHTML = '';\n   609→    multitrackUI.speakerStats.appendChild(fragment);\n   610→}\n   611→\n   612→function renderDecisionList(decisions) {\n   613→    if (!multitrackUI.decisionList) return;\n   614→\n   615→    // Update count\n   616→    if (multitrackUI.decisionCount) {\n   617→        multitrackUI.decisionCount.textContent = decisions.length;\n   618→    }\n   619→\n   620→    const fragment = document.createDocumentFragment();\n   621→\n   622→    // Limit to first 50 for performance\n   623→    const displayDecisions = decisions.slice(0, 50);\n   624→\n   625→    displayDecisions.forEach((decision, i) => {\n   626→        const item = document.createElement('div');\n   627→        item.className = 'decision-item';\n   628→\n   629→        const speakerClass = decision.isWideShot ? 'wide-shot' : '';\n   630→        const startTime = formatTime(decision.startTime);\n   631→        const endTime = formatTime(decision.endTime);\n   632→\n   633→        // SECURITY: Escape dynamic content to prevent XSS\n   634→        item.innerHTML = `\n   635→            <span class=\"decision-time\">${escapeHtml(startTime)}-${escapeHtml(endTime)}</span>\n   636→            <span class=\"decision-speaker ${speakerClass}\">${escapeHtml(decision.speakerName)}</span>\n   637→            <span class=\"decision-reason\">${escapeHtml(decision.reason || '')}</span>\n   638→            <button class=\"decision-seek\" data-time=\"${escapeHtml(decision.startTime)}\" title=\"Seek to ${escapeHtml(startTime)}\" aria-label=\"Seek to ${escapeHtml(startTime)}\">&gt;</button>\n   639→        `;\n   640→\n   641→        fragment.appendChild(item);\n   642→    });\n   643→\n   644→    if (decisions.length > 50) {\n   645→        const more = document.createElement('div');\n   646→        more.className = 'decision-item';\n   647→        more.style.justifyContent = 'center';\n   648→        more.style.color = '#888';\n   649→        more.textContent = `+ ${decisions.length - 50} more decisions`;\n   650→        fragment.appendChild(more);\n   651→    }\n   652→\n   653→    multitrackUI.decisionList.innerHTML = '';\n   654→    multitrackUI.decisionList.appendChild(fragment);\n   655→}\n   656→\n   657→function handleDecisionListClick(e) {\n   658→    const seekBtn = e.target.closest('.decision-seek');\n   659→    if (seekBtn) {\n   660→        e.stopPropagation();\n   661→        const time = parseFloat(seekBtn.dataset.time);\n   662→        if (!isNaN(time)) {\n   663→            seekToTime(time);\n   664→        }\n   665→    }\n   666→}\n   667→\n   668→// ============================================================================\n   669→// SEEK TO TIME (CEP VERSION)\n   670→// ============================================================================\n   671→async function seekToTime(seconds) {\n   672→    try {\n   673→        await jsx.call('seekToTime', seconds);\n   674→    } catch (e) {\n   675→        console.warn('[SPLICE Multitrack] Failed to seek:', e);\n   676→    }\n   677→}\n   678→\n   679→// ============================================================================\n   680→// APPLY MULTITRACK CUTS\n   681→// ============================================================================\n   682→async function applyMultitrackCuts() {\n   683→    if (!analysisResults || !analysisResults.decisions) {\n   684→        setStatus('No analysis data. Run analysis first.');\n   685→        return;\n   686→    }\n   687→\n   688→    if (isMultitrackOperationInProgress) return;\n   689→\n   690→    isMultitrackOperationInProgress = true;\n   691→    if (multitrackUI.applyBtn) {\n   692→        multitrackUI.applyBtn.disabled = true;\n   693→        multitrackUI.applyBtn.textContent = 'Applying...';\n   694→    }\n   695→\n   696→    try {\n   697→        setStatus('Building multitrack sequence...');\n   698→\n   699→        // Check if builder is available\n   700→        if (!window.spliceBuilder) {\n   701→            throw new Error('Builder not initialized');\n   702→        }\n   703→\n   704→        // Get active sequence info\n   705→        const seqInfo = await jsx.call('getActiveSequence');\n   706→        if (!seqInfo) {\n   707→            throw new Error('No active sequence');\n   708→        }\n   709→\n   710→        // Create cut list from decisions\n   711→        const cutList = {\n   712→            version: '3.5',\n   713→            source: {\n   714→                name: seqInfo.name,\n   715→                path: seqInfo.treePath || seqInfo.name\n   716→            },\n   717→            segments: analysisResults.decisions.map(d => ({\n   718→                type: d.isWideShot ? 'wide_shot' : (d.speakerIndex >= 0 ? 'speaker' : 'speech'),\n   719→                sourceName: seqInfo.name,\n   720→                sourcePath: seqInfo.treePath || seqInfo.name,\n   721→                inPoint: d.startTime,\n   722→                outPoint: d.endTime,\n   723→                speaker: d.speakerName,\n   724→                videoTrack: d.videoTrack,\n   725→                colorHint: d.isWideShot ? 'yellow' :\n   726→                    (d.speakerIndex === 0 ? 'mango' :\n   727→                        d.speakerIndex === 1 ? 'caribbean' :\n   728→                            d.speakerIndex === 2 ? 'lavender' : 'cerulean')\n   729→            })),\n   730→            metadata: {\n   731→                isMultitrack: true,\n   732→                speakerCount: speakerConfig.length,\n   733→                decisionCount: analysisResults.decisions.length,\n   734→                ...analysisResults.metadata\n   735→            }\n   736→        };\n   737→\n   738→        // Build sequence\n   739→        const result = await window.spliceBuilder.buildSequenceFromCutList(cutList, {\n   740→            suffix: '_MULTITRACK'\n   741→        });\n   742→\n   743→        if (result.success) {\n   744→            // Hide preview\n   745→            if (multitrackUI.preview) {\n   746→                multitrackUI.preview.classList.add('hidden');\n   747→            }\n   748→\n   749→            setStatus(`Multitrack sequence created: ${result.stats?.clipsInserted || 0} clips`);\n   750→\n   751→            // Clear results\n   752→            analysisResults = null;\n   753→        } else {\n   754→            throw new Error(result.error || 'Failed to build sequence');\n   755→        }\n   756→\n   757→    } catch (err) {\n   758→        console.error('[SPLICE Multitrack] Apply error:', err);\n   759→        setStatus('Apply failed: ' + err.message, true);\n   760→    } finally {\n   761→        isMultitrackOperationInProgress = false;\n   762→        if (multitrackUI.applyBtn) {\n   763→            multitrackUI.applyBtn.disabled = true;\n   764→            multitrackUI.applyBtn.textContent = 'Apply';\n   765→        }\n   766→    }\n   767→}\n   768→\n   769→// ============================================================================\n   770→// EXPORTS\n   771→// ============================================================================\n   772→// Expose for initialization from main.js\n   773→if (typeof window !== 'undefined') {\n   774→    window.initMultitrackUI = initMultitrackUI;\n   775→    window.spliceMultitrack = {\n   776→        init: initMultitrackUI,\n   777→        analyze: analyzeMultitrack,\n   778→        autoBalance: autoBalanceMultitrack,\n   779→        apply: applyMultitrackCuts,\n   780→        getSettings: getMultitrackSettings,\n   781→        getResults: () => analysisResults\n   782→    };\n   783→}\n   784→\n\n</system-reminder>\n"}]},"uuid":"bb3f287c-2523-4235-98db-d0423639da33","timestamp":"2026-01-12T16:27:04.495Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/imorgado/SPLICE/splice-cep/panel/js/multitrack.js","content":"/**\n * SPLICE CEP Panel - Multitrack UI Module\n * Multi-speaker analysis, auto-balance, and timeline building\n * v4.0.0 - CEP Migration\n */\n\n// ============================================================================\n// STATE\n// ============================================================================\nlet speakerConfig = [];\nlet analysisResults = null;\nlet isMultitrackOperationInProgress = false;\n\n// Speaker colors for visual distinction\nconst SPEAKER_COLORS = ['#ff6b6b', '#4ecdc4', '#ffe66d', '#95e1d3'];\n\n// ============================================================================\n// DOM ELEMENT CACHE\n// ============================================================================\nconst multitrackUI = {};\n\nfunction cacheMultitrackElements() {\n    multitrackUI.section = document.getElementById('multitrackSection');\n    multitrackUI.toggle = document.getElementById('multitrackToggle');\n    multitrackUI.panel = document.getElementById('multitrackPanel');\n    multitrackUI.speakerList = document.getElementById('speakerList');\n    multitrackUI.addSpeakerBtn = document.getElementById('addSpeakerBtn');\n    multitrackUI.wideShotTrack = document.getElementById('wideShotTrack');\n\n    // Parameters\n    multitrackUI.minShotDuration = document.getElementById('minShotDuration');\n    multitrackUI.minShotDurationValue = document.getElementById('minShotDurationValue');\n    multitrackUI.wideShotPercent = document.getElementById('wideShotPercent');\n    multitrackUI.wideShotPercentValue = document.getElementById('wideShotPercentValue');\n    multitrackUI.switchingFrequency = document.getElementById('switchingFrequency');\n    multitrackUI.switchingFrequencyValue = document.getElementById('switchingFrequencyValue');\n    multitrackUI.enableWideShotDetection = document.getElementById('enableWideShotDetection');\n\n    // Actions\n    multitrackUI.analyzeBtn = document.getElementById('analyzeMultitrackBtn');\n    multitrackUI.autoBalanceBtn = document.getElementById('autoBalanceBtn');\n    multitrackUI.applyBtn = document.getElementById('applyMultitrackBtn');\n\n    // Preview\n    multitrackUI.preview = document.getElementById('multitrackPreview');\n    multitrackUI.distributionChart = document.getElementById('distributionChart');\n    multitrackUI.speakerStats = document.getElementById('speakerStats');\n    multitrackUI.decisionCount = document.getElementById('decisionCount');\n    multitrackUI.decisionList = document.getElementById('decisionList');\n}\n\n// ============================================================================\n// INITIALIZATION\n// ============================================================================\nfunction initMultitrackUI() {\n    cacheMultitrackElements();\n\n    if (!multitrackUI.section) {\n        console.warn('[SPLICE Multitrack] Multitrack section not found in DOM');\n        return;\n    }\n\n    // Toggle section expand/collapse\n    if (multitrackUI.toggle) {\n        multitrackUI.toggle.addEventListener('click', toggleMultitrackSection);\n    }\n\n    // Add speaker button\n    if (multitrackUI.addSpeakerBtn) {\n        multitrackUI.addSpeakerBtn.addEventListener('click', addSpeaker);\n    }\n\n    // Speaker list event delegation (remove buttons, name changes)\n    if (multitrackUI.speakerList) {\n        multitrackUI.speakerList.addEventListener('click', handleSpeakerListClick);\n        multitrackUI.speakerList.addEventListener('change', handleSpeakerListChange);\n    }\n\n    // Parameter sliders\n    setupParameterListeners();\n\n    // Action buttons\n    if (multitrackUI.analyzeBtn) {\n        multitrackUI.analyzeBtn.addEventListener('click', analyzeMultitrack);\n    }\n    if (multitrackUI.autoBalanceBtn) {\n        multitrackUI.autoBalanceBtn.addEventListener('click', autoBalanceMultitrack);\n    }\n    if (multitrackUI.applyBtn) {\n        multitrackUI.applyBtn.addEventListener('click', applyMultitrackCuts);\n    }\n\n    // Decision list event delegation (seek buttons)\n    if (multitrackUI.decisionList) {\n        multitrackUI.decisionList.addEventListener('click', handleDecisionListClick);\n    }\n\n    // Initialize speaker config from DOM\n    initSpeakerConfigFromDOM();\n\n    console.log('[SPLICE Multitrack] UI initialized');\n}\n\n// ============================================================================\n// SECTION TOGGLE\n// ============================================================================\nfunction toggleMultitrackSection() {\n    if (!multitrackUI.panel || !multitrackUI.toggle) return;\n\n    // Check state BEFORE toggling\n    const wasCollapsed = multitrackUI.panel.classList.contains('collapsed');\n    multitrackUI.panel.classList.toggle('collapsed');\n    const icon = multitrackUI.toggle.querySelector('.toggle-icon');\n\n    if (icon) {\n        // If it was collapsed, it's now expanded (show -)\n        icon.textContent = wasCollapsed ? '-' : '+';\n    }\n}\n\n// ============================================================================\n// SPEAKER CONFIGURATION\n// ============================================================================\nfunction initSpeakerConfigFromDOM() {\n    speakerConfig = [];\n    const items = multitrackUI.speakerList?.querySelectorAll('.speaker-item') || [];\n\n    items.forEach((item, index) => {\n        const nameInput = item.querySelector('.speaker-name');\n        const trackSelect = item.querySelector('.speaker-track');\n\n        speakerConfig.push({\n            index,\n            name: nameInput?.value || `Speaker ${index + 1}`,\n            videoTrack: parseInt(trackSelect?.value || index)\n        });\n    });\n}\n\nfunction addSpeaker() {\n    if (speakerConfig.length >= 4) {\n        setStatus('Maximum 4 speakers supported');\n        return;\n    }\n\n    const newIndex = speakerConfig.length;\n    const defaultName = `Speaker ${newIndex + 1}`;\n\n    speakerConfig.push({\n        index: newIndex,\n        name: defaultName,\n        videoTrack: newIndex\n    });\n\n    // Add DOM element\n    // SECURITY: Escape dynamic content to prevent XSS\n    const speakerItem = document.createElement('div');\n    speakerItem.className = `speaker-item speaker-${newIndex}`;\n    speakerItem.dataset.speakerIndex = newIndex;\n    speakerItem.innerHTML = `\n        <input type=\"text\" class=\"speaker-name\" value=\"${escapeHtml(defaultName)}\" placeholder=\"Name\" aria-label=\"Speaker ${newIndex + 1} name\">\n        <select class=\"speaker-track\" aria-label=\"Speaker ${newIndex + 1} video track\">\n            <option value=\"0\" ${newIndex === 0 ? 'selected' : ''}>V1</option>\n            <option value=\"1\" ${newIndex === 1 ? 'selected' : ''}>V2</option>\n            <option value=\"2\" ${newIndex === 2 ? 'selected' : ''}>V3</option>\n            <option value=\"3\" ${newIndex === 3 ? 'selected' : ''}>V4</option>\n        </select>\n        <button class=\"speaker-remove-btn\" title=\"Remove speaker\" aria-label=\"Remove speaker ${newIndex + 1}\">x</button>\n    `;\n\n    multitrackUI.speakerList.appendChild(speakerItem);\n\n    // Update remove button visibility\n    updateRemoveButtonVisibility();\n}\n\nfunction removeSpeaker(index) {\n    if (speakerConfig.length <= 2) {\n        setStatus('Minimum 2 speakers required');\n        return;\n    }\n\n    speakerConfig.splice(index, 1);\n\n    // Remove from DOM\n    const item = multitrackUI.speakerList.querySelector(`[data-speaker-index=\"${index}\"]`);\n    if (item) {\n        item.remove();\n    }\n\n    // Re-index remaining speakers\n    reindexSpeakers();\n\n    // Update remove button visibility\n    updateRemoveButtonVisibility();\n}\n\nfunction reindexSpeakers() {\n    const items = multitrackUI.speakerList.querySelectorAll('.speaker-item');\n    items.forEach((item, i) => {\n        item.dataset.speakerIndex = i;\n        item.className = `speaker-item speaker-${i}`;\n\n        // Update speakerConfig\n        if (speakerConfig[i]) {\n            speakerConfig[i].index = i;\n        }\n    });\n}\n\nfunction updateRemoveButtonVisibility() {\n    const items = multitrackUI.speakerList.querySelectorAll('.speaker-item');\n    const canRemove = items.length > 2;\n\n    items.forEach(item => {\n        const btn = item.querySelector('.speaker-remove-btn');\n        if (btn) {\n            btn.style.display = canRemove ? 'block' : 'none';\n        }\n    });\n}\n\nfunction handleSpeakerListClick(e) {\n    const removeBtn = e.target.closest('.speaker-remove-btn');\n    if (removeBtn) {\n        const item = removeBtn.closest('.speaker-item');\n        const index = parseInt(item?.dataset.speakerIndex || 0);\n        removeSpeaker(index);\n    }\n}\n\nfunction handleSpeakerListChange(e) {\n    const item = e.target.closest('.speaker-item');\n    if (!item) return;\n\n    const index = parseInt(item.dataset.speakerIndex || 0);\n\n    if (e.target.classList.contains('speaker-name')) {\n        speakerConfig[index].name = e.target.value;\n    } else if (e.target.classList.contains('speaker-track')) {\n        speakerConfig[index].videoTrack = parseInt(e.target.value);\n    }\n}\n\n// ============================================================================\n// PARAMETER LISTENERS\n// ============================================================================\nfunction setupParameterListeners() {\n    // Min shot duration slider\n    if (multitrackUI.minShotDuration && multitrackUI.minShotDurationValue) {\n        multitrackUI.minShotDuration.addEventListener('input', () => {\n            multitrackUI.minShotDurationValue.textContent =\n                parseFloat(multitrackUI.minShotDuration.value).toFixed(1) + 's';\n        });\n    }\n\n    // Wide shot percentage slider\n    if (multitrackUI.wideShotPercent && multitrackUI.wideShotPercentValue) {\n        multitrackUI.wideShotPercent.addEventListener('input', () => {\n            multitrackUI.wideShotPercentValue.textContent =\n                multitrackUI.wideShotPercent.value + '%';\n        });\n    }\n\n    // Switching frequency slider\n    if (multitrackUI.switchingFrequency && multitrackUI.switchingFrequencyValue) {\n        multitrackUI.switchingFrequency.addEventListener('input', () => {\n            multitrackUI.switchingFrequencyValue.textContent =\n                multitrackUI.switchingFrequency.value;\n        });\n    }\n}\n\n// ============================================================================\n// GET SETTINGS\n// ============================================================================\nfunction getMultitrackSettings() {\n    return {\n        minShotDuration: parseFloat(multitrackUI.minShotDuration?.value || 2),\n        wideShotPercentage: parseInt(multitrackUI.wideShotPercent?.value || 20),\n        switchingFrequency: parseInt(multitrackUI.switchingFrequency?.value || 50),\n        wideShotEnabled: multitrackUI.enableWideShotDetection?.checked ?? true,\n        wideShotTracks: multitrackUI.wideShotTrack?.value !== '-1'\n            ? [parseInt(multitrackUI.wideShotTrack.value)]\n            : [],\n        speakerNames: speakerConfig.map(s => s.name),\n        videoTrackMapping: speakerConfig.reduce((acc, s) => {\n            acc[s.index] = s.videoTrack;\n            return acc;\n        }, {})\n    };\n}\n\n// ============================================================================\n// GET AUDIO PATH (CEP VERSION)\n// ============================================================================\nasync function getAudioPath() {\n    try {\n        // Try to get audio path from active sequence\n        const seqInfo = await jsx.call('getActiveSequence');\n        if (seqInfo && seqInfo.audioPath) {\n            return seqInfo.audioPath;\n        }\n\n        // Fallback: export sequence audio for analysis\n        const exportResult = await jsx.call('exportSequenceAudioForAnalysis');\n        if (exportResult && exportResult.path) {\n            return exportResult.path;\n        }\n\n        // Last resort: get first clip audio path\n        const clipPath = await jsx.call('getFirstClipAudioPath');\n        if (clipPath) {\n            return clipPath;\n        }\n\n        throw new Error('Could not determine audio path');\n    } catch (e) {\n        console.error('[SPLICE Multitrack] Failed to get audio path:', e);\n        throw e;\n    }\n}\n\n// ============================================================================\n// ANALYZE MULTITRACK\n// ============================================================================\nasync function analyzeMultitrack() {\n    if (isMultitrackOperationInProgress) return;\n\n    // Check tier access - Multitrack requires Team tier\n    if (typeof hasFeatureAccess === 'function' && !hasFeatureAccess('multitrack')) {\n        const requiredTier = typeof getRequiredTier === 'function' ? getRequiredTier('multitrack') : 'Team';\n        setStatus(`Multitrack auto-balance requires ${requiredTier} tier`);\n        if (typeof showUpgradeModal === 'function') {\n            showUpgradeModal('Multitrack Auto-Balance', requiredTier);\n        }\n        return;\n    }\n\n    // Check online status\n    if (typeof isOnline === 'function' && !isOnline()) {\n        setStatus('Offline - Check your connection');\n        return;\n    }\n\n    isMultitrackOperationInProgress = true;\n    if (multitrackUI.analyzeBtn) {\n        multitrackUI.analyzeBtn.disabled = true;\n        multitrackUI.analyzeBtn.textContent = 'Analyzing...';\n    }\n\n    try {\n        setStatus('Exporting audio tracks...');\n\n        // Get audio path\n        const audioPath = await getAudioPath();\n        if (!audioPath) {\n            throw new Error('Audio export path not initialized');\n        }\n\n        // For now, we use the main audio path\n        // In a full implementation, we'd export separate tracks per speaker\n        const audioPaths = [audioPath];\n\n        // Add additional tracks if multi-track sequence\n        if (speakerConfig.length > 1) {\n            for (let i = 1; i < speakerConfig.length; i++) {\n                audioPaths.push(audioPath);\n            }\n        }\n\n        setStatus('Analyzing speakers...');\n\n        const settings = getMultitrackSettings();\n        const apiUrl = getBackendUrl();\n\n        const response = await fetchWithTimeout(`${apiUrl}/multitrack`, {\n            method: 'POST',\n            headers: getAuthHeaders(),\n            body: JSON.stringify({\n                audioPaths,\n                speakerNames: settings.speakerNames,\n                videoTrackMapping: settings.videoTrackMapping,\n                wideShotEnabled: settings.wideShotEnabled,\n                wideShotPercentage: settings.wideShotPercentage,\n                wideShotTracks: settings.wideShotTracks,\n                minShotDuration: settings.minShotDuration,\n                switchingFrequency: settings.switchingFrequency\n            })\n        }, 120000);\n\n        if (!response.ok) {\n            const errorMsg = await parseErrorResponse(response);\n            throw new Error(errorMsg);\n        }\n\n        const data = await response.json();\n        analysisResults = data;\n\n        // Display results\n        displayMultitrackResults(data);\n\n        // Enable apply button\n        if (multitrackUI.applyBtn) {\n            multitrackUI.applyBtn.disabled = false;\n        }\n\n        setStatus(`Analysis complete - ${data.decisions?.length || 0} switching decisions`);\n\n    } catch (err) {\n        console.error('[SPLICE Multitrack] Analysis error:', err);\n        setStatus('Analysis failed: ' + err.message, true);\n    } finally {\n        isMultitrackOperationInProgress = false;\n        if (multitrackUI.analyzeBtn) {\n            multitrackUI.analyzeBtn.disabled = false;\n            multitrackUI.analyzeBtn.textContent = 'Analyze';\n        }\n    }\n}\n\n// ============================================================================\n// AUTO-BALANCE\n// ============================================================================\nasync function autoBalanceMultitrack() {\n    if (isMultitrackOperationInProgress) return;\n\n    // Check tier access - Multitrack requires Team tier\n    if (typeof hasFeatureAccess === 'function' && !hasFeatureAccess('multitrack')) {\n        const requiredTier = typeof getRequiredTier === 'function' ? getRequiredTier('multitrack') : 'Team';\n        setStatus(`Multitrack auto-balance requires ${requiredTier} tier`);\n        if (typeof showUpgradeModal === 'function') {\n            showUpgradeModal('Multitrack Auto-Balance', requiredTier);\n        }\n        return;\n    }\n\n    // Check online status\n    if (typeof isOnline === 'function' && !isOnline()) {\n        setStatus('Offline - Check your connection');\n        return;\n    }\n\n    isMultitrackOperationInProgress = true;\n    if (multitrackUI.autoBalanceBtn) {\n        multitrackUI.autoBalanceBtn.disabled = true;\n        multitrackUI.autoBalanceBtn.textContent = 'Balancing...';\n    }\n\n    try {\n        setStatus('Auto-balancing speaker screentime...');\n\n        const audioPath = await getAudioPath();\n        const audioPaths = [audioPath];\n\n        // Duplicate for multiple speakers\n        for (let i = 1; i < speakerConfig.length; i++) {\n            audioPaths.push(audioPath);\n        }\n\n        const settings = getMultitrackSettings();\n        const apiUrl = getBackendUrl();\n\n        const response = await fetchWithTimeout(`${apiUrl}/multitrack/auto-balance`, {\n            method: 'POST',\n            headers: getAuthHeaders(),\n            body: JSON.stringify({\n                audioPaths,\n                speakerNames: settings.speakerNames,\n                videoTrackMapping: settings.videoTrackMapping,\n                wideShotEnabled: settings.wideShotEnabled,\n                wideShotPercentage: settings.wideShotPercentage,\n                wideShotTracks: settings.wideShotTracks,\n                minShotDuration: settings.minShotDuration,\n                switchingFrequency: settings.switchingFrequency\n            })\n        }, 120000);\n\n        if (!response.ok) {\n            const errorMsg = await parseErrorResponse(response);\n            throw new Error(errorMsg);\n        }\n\n        const data = await response.json();\n        analysisResults = data;\n\n        // Display results\n        displayMultitrackResults(data);\n\n        // Enable apply button\n        if (multitrackUI.applyBtn) {\n            multitrackUI.applyBtn.disabled = false;\n        }\n\n        const errorInfo = data.finalError ? ` (${data.finalError.toFixed(1)}% deviation)` : '';\n        setStatus(`Auto-balance complete${errorInfo}`);\n\n    } catch (err) {\n        console.error('[SPLICE Multitrack] Auto-balance error:', err);\n        setStatus('Auto-balance failed: ' + err.message, true);\n    } finally {\n        isMultitrackOperationInProgress = false;\n        if (multitrackUI.autoBalanceBtn) {\n            multitrackUI.autoBalanceBtn.disabled = false;\n            multitrackUI.autoBalanceBtn.textContent = 'Auto-Balance';\n        }\n    }\n}\n\n// ============================================================================\n// DISPLAY RESULTS\n// ============================================================================\nfunction displayMultitrackResults(results) {\n    if (!results) return;\n\n    // Show preview section\n    if (multitrackUI.preview) {\n        multitrackUI.preview.classList.remove('hidden');\n    }\n\n    // Render distribution chart\n    renderDistributionChart(results.metadata);\n\n    // Render speaker stats\n    renderSpeakerStats(results.metadata);\n\n    // Render decision list\n    renderDecisionList(results.decisions || []);\n}\n\nfunction renderDistributionChart(metadata) {\n    if (!multitrackUI.distributionChart || !metadata) return;\n\n    const speakerPercentages = metadata.speakerPercentages || {};\n    const wideShotPct = metadata.wideShotPercentage || 0;\n\n    const fragment = document.createDocumentFragment();\n\n    // Add speaker bars\n    let speakerIndex = 0;\n    for (const [speaker, pct] of Object.entries(speakerPercentages)) {\n        if (pct > 0) {\n            const bar = document.createElement('div');\n            bar.className = `distribution-bar speaker-${speakerIndex % 4}`;\n            bar.style.width = `${pct}%`;\n            bar.textContent = pct >= 10 ? `${speaker}: ${pct.toFixed(0)}%` : '';\n            bar.title = `${speaker}: ${pct.toFixed(1)}%`;\n            fragment.appendChild(bar);\n        }\n        speakerIndex++;\n    }\n\n    // Add wide shot bar\n    if (wideShotPct > 0) {\n        const bar = document.createElement('div');\n        bar.className = 'distribution-bar wide-shot';\n        bar.style.width = `${wideShotPct}%`;\n        bar.textContent = wideShotPct >= 8 ? `Wide: ${wideShotPct.toFixed(0)}%` : '';\n        bar.title = `Wide Shot: ${wideShotPct.toFixed(1)}%`;\n        fragment.appendChild(bar);\n    }\n\n    multitrackUI.distributionChart.innerHTML = '';\n    multitrackUI.distributionChart.appendChild(fragment);\n}\n\nfunction renderSpeakerStats(metadata) {\n    if (!multitrackUI.speakerStats || !metadata) return;\n\n    const speakerPercentages = metadata.speakerPercentages || {};\n    const wideShotPct = metadata.wideShotPercentage || 0;\n\n    const fragment = document.createDocumentFragment();\n\n    // Add speaker stats\n    // SECURITY: Escape speaker names to prevent XSS\n    let speakerIndex = 0;\n    for (const [speaker, pct] of Object.entries(speakerPercentages)) {\n        const stat = document.createElement('div');\n        stat.className = 'speaker-stat';\n        stat.innerHTML = `\n            <span class=\"speaker-stat-dot speaker-${speakerIndex % 4}\"></span>\n            <span>${escapeHtml(speaker)}: ${escapeHtml(pct.toFixed(1))}%</span>\n        `;\n        fragment.appendChild(stat);\n        speakerIndex++;\n    }\n\n    // Add wide shot stat\n    if (wideShotPct > 0) {\n        const stat = document.createElement('div');\n        stat.className = 'speaker-stat';\n        stat.innerHTML = `\n            <span class=\"speaker-stat-dot wide-shot\"></span>\n            <span>Wide: ${escapeHtml(wideShotPct.toFixed(1))}%</span>\n        `;\n        fragment.appendChild(stat);\n    }\n\n    // Add avg shot duration\n    if (metadata.averageShotDuration) {\n        const stat = document.createElement('div');\n        stat.className = 'speaker-stat';\n        stat.innerHTML = `<span style=\"color: #888;\">Avg: ${escapeHtml(metadata.averageShotDuration.toFixed(1))}s</span>`;\n        fragment.appendChild(stat);\n    }\n\n    multitrackUI.speakerStats.innerHTML = '';\n    multitrackUI.speakerStats.appendChild(fragment);\n}\n\nfunction renderDecisionList(decisions) {\n    if (!multitrackUI.decisionList) return;\n\n    // Update count\n    if (multitrackUI.decisionCount) {\n        multitrackUI.decisionCount.textContent = decisions.length;\n    }\n\n    const fragment = document.createDocumentFragment();\n\n    // Limit to first 50 for performance\n    const displayDecisions = decisions.slice(0, 50);\n\n    displayDecisions.forEach((decision, i) => {\n        const item = document.createElement('div');\n        item.className = 'decision-item';\n\n        const speakerClass = decision.isWideShot ? 'wide-shot' : '';\n        const startTime = formatTime(decision.startTime);\n        const endTime = formatTime(decision.endTime);\n\n        // SECURITY: Escape dynamic content to prevent XSS\n        item.innerHTML = `\n            <span class=\"decision-time\">${escapeHtml(startTime)}-${escapeHtml(endTime)}</span>\n            <span class=\"decision-speaker ${speakerClass}\">${escapeHtml(decision.speakerName)}</span>\n            <span class=\"decision-reason\">${escapeHtml(decision.reason || '')}</span>\n            <button class=\"decision-seek\" data-time=\"${escapeHtml(decision.startTime)}\" title=\"Seek to ${escapeHtml(startTime)}\" aria-label=\"Seek to ${escapeHtml(startTime)}\">&gt;</button>\n        `;\n\n        fragment.appendChild(item);\n    });\n\n    if (decisions.length > 50) {\n        const more = document.createElement('div');\n        more.className = 'decision-item';\n        more.style.justifyContent = 'center';\n        more.style.color = '#888';\n        more.textContent = `+ ${decisions.length - 50} more decisions`;\n        fragment.appendChild(more);\n    }\n\n    multitrackUI.decisionList.innerHTML = '';\n    multitrackUI.decisionList.appendChild(fragment);\n}\n\nfunction handleDecisionListClick(e) {\n    const seekBtn = e.target.closest('.decision-seek');\n    if (seekBtn) {\n        e.stopPropagation();\n        const time = parseFloat(seekBtn.dataset.time);\n        if (!isNaN(time)) {\n            seekToTime(time);\n        }\n    }\n}\n\n// ============================================================================\n// SEEK TO TIME (CEP VERSION)\n// ============================================================================\nasync function seekToTime(seconds) {\n    try {\n        await jsx.call('seekToTime', seconds);\n    } catch (e) {\n        console.warn('[SPLICE Multitrack] Failed to seek:', e);\n    }\n}\n\n// ============================================================================\n// APPLY MULTITRACK CUTS\n// ============================================================================\nasync function applyMultitrackCuts() {\n    if (!analysisResults || !analysisResults.decisions) {\n        setStatus('No analysis data. Run analysis first.');\n        return;\n    }\n\n    if (isMultitrackOperationInProgress) return;\n\n    isMultitrackOperationInProgress = true;\n    if (multitrackUI.applyBtn) {\n        multitrackUI.applyBtn.disabled = true;\n        multitrackUI.applyBtn.textContent = 'Applying...';\n    }\n\n    try {\n        setStatus('Building multitrack sequence...');\n\n        // Check if builder is available\n        if (!window.spliceBuilder) {\n            throw new Error('Builder not initialized');\n        }\n\n        // Get active sequence info\n        const seqInfo = await jsx.call('getActiveSequence');\n        if (!seqInfo) {\n            throw new Error('No active sequence');\n        }\n\n        // Create cut list from decisions\n        const cutList = {\n            version: '3.5',\n            source: {\n                name: seqInfo.name,\n                path: seqInfo.treePath || seqInfo.name\n            },\n            segments: analysisResults.decisions.map(d => ({\n                type: d.isWideShot ? 'wide_shot' : (d.speakerIndex >= 0 ? 'speaker' : 'speech'),\n                sourceName: seqInfo.name,\n                sourcePath: seqInfo.treePath || seqInfo.name,\n                inPoint: d.startTime,\n                outPoint: d.endTime,\n                speaker: d.speakerName,\n                videoTrack: d.videoTrack,\n                colorHint: d.isWideShot ? 'yellow' :\n                    (d.speakerIndex === 0 ? 'mango' :\n                        d.speakerIndex === 1 ? 'caribbean' :\n                            d.speakerIndex === 2 ? 'lavender' : 'cerulean')\n            })),\n            metadata: {\n                isMultitrack: true,\n                speakerCount: speakerConfig.length,\n                decisionCount: analysisResults.decisions.length,\n                ...analysisResults.metadata\n            }\n        };\n\n        // Build sequence\n        const result = await window.spliceBuilder.buildSequenceFromCutList(cutList, {\n            suffix: '_MULTITRACK'\n        });\n\n        if (result.success) {\n            // Hide preview\n            if (multitrackUI.preview) {\n                multitrackUI.preview.classList.add('hidden');\n            }\n\n            setStatus(`Multitrack sequence created: ${result.stats?.clipsInserted || 0} clips`);\n\n            // Clear results\n            analysisResults = null;\n        } else {\n            throw new Error(result.error || 'Failed to build sequence');\n        }\n\n    } catch (err) {\n        console.error('[SPLICE Multitrack] Apply error:', err);\n        setStatus('Apply failed: ' + err.message, true);\n    } finally {\n        isMultitrackOperationInProgress = false;\n        if (multitrackUI.applyBtn) {\n            multitrackUI.applyBtn.disabled = true;\n            multitrackUI.applyBtn.textContent = 'Apply';\n        }\n    }\n}\n\n// ============================================================================\n// EXPORTS\n// ============================================================================\n// Expose for initialization from main.js\nif (typeof window !== 'undefined') {\n    window.initMultitrackUI = initMultitrackUI;\n    window.spliceMultitrack = {\n        init: initMultitrackUI,\n        analyze: analyzeMultitrack,\n        autoBalance: autoBalanceMultitrack,\n        apply: applyMultitrackCuts,\n        getSettings: getMultitrackSettings,\n        getResults: () => analysisResults\n    };\n}\n","numLines":784,"startLine":1,"totalLines":784}}}
{"parentUuid":"bb3f287c-2523-4235-98db-d0423639da33","isSidechain":true,"userType":"external","cwd":"/Users/imorgado/SPLICE/splice-cep/panel/js","sessionId":"7fa929e3-00b9-497c-b311-19cb4c6b44f9","version":"2.0.76","gitBranch":"main","agentId":"ad38527","slug":"eager-questing-lagoon","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01NsnNhZFJz7ffpWUDeJfspL","type":"message","role":"assistant","content":[{"type":"text","text":"# Production Bottleneck Analysis: multitrack.js\n\n## Bug Summary\nMultiple critical production issues found including missing error handling, race conditions, performance bottlenecks, and memory leaks.\n\n---\n\n## CRITICAL ISSUES (P0 - Production Breaking)\n\n### 1. **Unhandled JSX Call Failures - Missing Error Handling**\n**Location:** Lines 300-321 (getAudioPath), 673 (seekToTime), 705 (applyMultitrackCuts)\n\n**Root Cause:** JSX calls to Premiere Pro API have no error handling for common failure modes:\n- Sequence not active\n- Audio track doesn't exist\n- Export path permissions denied\n- Premiere busy/locked\n\n**Impact:** Silent failures lead to undefined state, cryptic error messages, users stuck in loading states\n\n**Trace Path:**\n1. User clicks \"Analyze\" → analyzeMultitrack() (line 327)\n2. → getAudioPath() (line 356) \n3. → jsx.call('getActiveSequence') (line 300) **← NO ERROR HANDLING**\n4. → Returns null/undefined silently\n5. → Downstream code expects valid path → crashes\n\n**Evidence:**\n```javascript\n// Line 300-303: No try/catch, no validation\nconst seqInfo = await jsx.call('getActiveSequence');\nif (seqInfo && seqInfo.audioPath) {\n    return seqInfo.audioPath;\n}\n// Falls through to next call without logging WHY first call failed\n```\n\n**Fix:**\n```javascript\nasync function getAudioPath() {\n    try {\n        const seqInfo = await jsx.call('getActiveSequence');\n        if (!seqInfo) {\n            throw new Error('No active sequence found. Please open a sequence in Premiere Pro.');\n        }\n        \n        if (seqInfo.audioPath) {\n            console.log('[SPLICE Multitrack] Using sequence audio path:', seqInfo.audioPath);\n            return seqInfo.audioPath;\n        }\n\n        console.log('[SPLICE Multitrack] No audio path in sequence, attempting export...');\n        const exportResult = await jsx.call('exportSequenceAudioForAnalysis');\n        if (!exportResult?.path) {\n            throw new Error('Failed to export sequence audio. Check export permissions and disk space.');\n        }\n        \n        console.log('[SPLICE Multitrack] Exported audio to:', exportResult.path);\n        return exportResult.path;\n\n    } catch (e) {\n        console.error('[SPLICE Multitrack] getAudioPath failed:', e);\n        // Provide actionable error message\n        if (e.message.includes('No active sequence')) {\n            throw new Error('No sequence open in Premiere Pro. Open a sequence first.');\n        } else if (e.message.includes('export')) {\n            throw new Error('Failed to export audio. Check disk space and folder permissions.');\n        }\n        throw new Error(`Audio path error: ${e.message}`);\n    }\n}\n```\n\n---\n\n### 2. **Race Condition in Operation Lock**\n**Location:** Lines 328-346, 414, 426-444, 502, 688-694, 761\n\n**Root Cause:** `isMultitrackOperationInProgress` flag is set AFTER async checks (tier access, online status), creating race window where multiple operations can start simultaneously.\n\n**Trace Path:**\n1. User double-clicks \"Analyze\" button\n2. First click: checks tier (line 331) → passes → starts operation\n3. Second click: ALSO checks tier (still false) → passes → starts operation\n4. Race: Both set `isMultitrackOperationInProgress = true` nearly simultaneously\n5. → Two API calls fire → duplicate work → inconsistent state\n\n**Evidence:**\n```javascript\n// Line 327-346: Flag set AFTER async checks\nasync function analyzeMultitrack() {\n    if (isMultitrackOperationInProgress) return; // ← Check happens here\n    \n    // 10+ lines of async checks...\n    if (typeof hasFeatureAccess === 'function' && !hasFeatureAccess('multitrack')) {\n        // async tier check...\n        return;\n    }\n    \n    if (typeof isOnline === 'function' && !isOnline()) {\n        // async online check...\n        return;\n    }\n    \n    isMultitrackOperationInProgress = true; // ← Flag set WAY too late\n```\n\n**Fix:**\n```javascript\nasync function analyzeMultitrack() {\n    // Lock IMMEDIATELY before any async work\n    if (isMultitrackOperationInProgress) {\n        console.warn('[SPLICE Multitrack] Operation already in progress');\n        return;\n    }\n    isMultitrackOperationInProgress = true;\n\n    try {\n        // Check tier access\n        if (typeof hasFeatureAccess === 'function' && !hasFeatureAccess('multitrack')) {\n            const requiredTier = typeof getRequiredTier === 'function' ? getRequiredTier('multitrack') : 'Team';\n            setStatus(`Multitrack auto-balance requires ${requiredTier} tier`);\n            if (typeof showUpgradeModal === 'function') {\n                showUpgradeModal('Multitrack Auto-Balance', requiredTier);\n            }\n            return; // Lock will be released in finally\n        }\n\n        if (typeof isOnline === 'function' && !isOnline()) {\n            setStatus('Offline - Check your connection');\n            return;\n        }\n\n        // Disable button AFTER checks pass\n        if (multitrackUI.analyzeBtn) {\n            multitrackUI.analyzeBtn.disabled = true;\n            multitrackUI.analyzeBtn.textContent = 'Analyzing...';\n        }\n\n        // ... rest of operation\n        \n    } catch (err) {\n        console.error('[SPLICE Multitrack] Analysis error:', err);\n        setStatus('Analysis failed: ' + err.message, true);\n    } finally {\n        // ALWAYS reset lock and button state\n        isMultitrackOperationInProgress = false;\n        if (multitrackUI.analyzeBtn) {\n            multitrackUI.analyzeBtn.disabled = false;\n            multitrackUI.analyzeBtn.textContent = 'Analyze';\n        }\n    }\n}\n```\n\n**Same Issue Exists In:**\n- `autoBalanceMultitrack()` (line 425)\n- `applyMultitrackCuts()` (line 682)\n\n---\n\n### 3. **Memory Leak - analysisResults Never Cleared**\n**Location:** Lines 398, 485, 683, 752\n\n**Root Cause:** `analysisResults` stores entire API response (potentially thousands of decisions) but only cleared on successful apply. Failed operations, cancelled operations, or switching sequences leave stale data in memory.\n\n**Evidence:**\n```javascript\n// Line 398: Set but never validated for staleness\nanalysisResults = data; // Could be 50MB+ for long video\n\n// Line 683-686: Only check exists, not if it matches current sequence\nif (!analysisResults || !analysisResults.decisions) {\n    setStatus('No analysis data. Run analysis first.');\n    return;\n}\n// ⚠️ What if user switched to different sequence?\n\n// Line 752: Only cleared on SUCCESS\nif (result.success) {\n    analysisResults = null; // ← Never cleared on failure\n}\n```\n\n**Fix:**\n```javascript\n// Add sequence tracking\nlet analysisResults = null;\nlet analysisResultsSequenceId = null; // ← Track which sequence results belong to\n\nasync function analyzeMultitrack() {\n    // ... existing code ...\n    \n    try {\n        const seqInfo = await jsx.call('getActiveSequence');\n        const currentSeqId = seqInfo?.id || seqInfo?.name;\n        \n        // ... API call ...\n        \n        const data = await response.json();\n        analysisResults = data;\n        analysisResultsSequenceId = currentSeqId; // ← Store sequence ID\n        \n    } finally {\n        // ... cleanup ...\n    }\n}\n\nasync function applyMultitrackCuts() {\n    if (!analysisResults || !analysisResults.decisions) {\n        setStatus('No analysis data. Run analysis first.');\n        return;\n    }\n    \n    // Validate results are for current sequence\n    const seqInfo = await jsx.call('getActiveSequence');\n    const currentSeqId = seqInfo?.id || seqInfo?.name;\n    \n    if (analysisResultsSequenceId !== currentSeqId) {\n        setStatus('Analysis results are for a different sequence. Please analyze again.');\n        analysisResults = null; // ← Clear stale data\n        analysisResultsSequenceId = null;\n        return;\n    }\n    \n    // ... existing code ...\n    \n} catch (err) {\n    // Clear results on ANY error\n    analysisResults = null;\n    analysisResultsSequenceId = null;\n} finally {\n    // ... cleanup ...\n}\n```\n\n---\n\n## HIGH SEVERITY ISSUES (P1 - Performance Killers)\n\n### 4. **Blocking DOM Rendering in Decision List**\n**Location:** Lines 612-654\n\n**Root Cause:** Rendering 50 decision items synchronously blocks main thread. For long videos (100+ decisions), this causes UI freeze.\n\n**Evidence:**\n```javascript\n// Line 623: Limits to 50 but still renders synchronously\nconst displayDecisions = decisions.slice(0, 50);\n\ndisplayDecisions.forEach((decision, i) => {\n    const item = document.createElement('div');\n    item.className = 'decision-item';\n    // Complex innerHTML with multiple escapeHtml calls per item\n    item.innerHTML = `...`; // ← Blocking DOM manipulation\n    fragment.appendChild(item);\n});\n```\n\n**Fix (Virtualization or Batching):**\n```javascript\nfunction renderDecisionList(decisions) {\n    if (!multitrackUI.decisionList) return;\n\n    // Update count\n    if (multitrackUI.decisionCount) {\n        multitrackUI.decisionCount.textContent = decisions.length;\n    }\n\n    // Use requestAnimationFrame to avoid blocking\n    requestAnimationFrame(() => {\n        const fragment = document.createDocumentFragment();\n        const displayDecisions = decisions.slice(0, 50);\n\n        // Batch render in chunks of 10\n        let currentIndex = 0;\n        function renderBatch() {\n            const batchEnd = Math.min(currentIndex + 10, displayDecisions.length);\n            \n            for (let i = currentIndex; i < batchEnd; i++) {\n                const decision = displayDecisions[i];\n                const item = createDecisionItem(decision);\n                fragment.appendChild(item);\n            }\n            \n            currentIndex = batchEnd;\n            \n            if (currentIndex < displayDecisions.length) {\n                requestAnimationFrame(renderBatch);\n            } else {\n                // Add \"more\" indicator\n                if (decisions.length > 50) {\n                    const more = document.createElement('div');\n                    more.className = 'decision-item';\n                    more.style.justifyContent = 'center';\n                    more.style.color = '#888';\n                    more.textContent = `+ ${decisions.length - 50} more decisions`;\n                    fragment.appendChild(more);\n                }\n                \n                multitrackUI.decisionList.innerHTML = '';\n                multitrackUI.decisionList.appendChild(fragment);\n            }\n        }\n        \n        renderBatch();\n    });\n}\n\nfunction createDecisionItem(decision) {\n    const item = document.createElement('div');\n    item.className = 'decision-item';\n\n    const speakerClass = decision.isWideShot ? 'wide-shot' : '';\n    const startTime = formatTime(decision.startTime);\n    const endTime = formatTime(decision.endTime);\n\n    item.innerHTML = `\n        <span class=\"decision-time\">${escapeHtml(startTime)}-${escapeHtml(endTime)}</span>\n        <span class=\"decision-speaker ${speakerClass}\">${escapeHtml(decision.speakerName)}</span>\n        <span class=\"decision-reason\">${escapeHtml(decision.reason || '')}</span>\n        <button class=\"decision-seek\" data-time=\"${escapeHtml(decision.startTime)}\" title=\"Seek to ${escapeHtml(startTime)}\" aria-label=\"Seek to ${escapeHtml(startTime)}\">&gt;</button>\n    `;\n    \n    return item;\n}\n```\n\n---\n\n### 5. **Duplicate API Payload Construction**\n**Location:** Lines 377-390, 464-477\n\n**Root Cause:** `analyzeMultitrack()` and `autoBalanceMultitrack()` build identical payloads with duplicated logic. Maintenance nightmare and bug surface area.\n\n**Evidence:**\n```javascript\n// Lines 377-390: First payload\nconst response = await fetchWithTimeout(`${apiUrl}/multitrack`, {\n    method: 'POST',\n    headers: getAuthHeaders(),\n    body: JSON.stringify({\n        audioPaths,\n        speakerNames: settings.speakerNames,\n        videoTrackMapping: settings.videoTrackMapping,\n        wideShotEnabled: settings.wideShotEnabled,\n        wideShotPercentage: settings.wideShotPercentage,\n        wideShotTracks: settings.wideShotTracks,\n        minShotDuration: settings.minShotDuration,\n        switchingFrequency: settings.switchingFrequency\n    })\n}, 120000);\n\n// Lines 464-477: EXACT SAME payload 87 lines later\nconst response = await fetchWithTimeout(`${apiUrl}/multitrack/auto-balance`, {\n    method: 'POST',\n    headers: getAuthHeaders(),\n    body: JSON.stringify({ /* IDENTICAL */ })\n}, 120000);\n```\n\n**Fix:**\n```javascript\nfunction buildMultitrackPayload(audioPaths, settings) {\n    return {\n        audioPaths,\n        speakerNames: settings.speakerNames,\n        videoTrackMapping: settings.videoTrackMapping,\n        wideShotEnabled: settings.wideShotEnabled,\n        wideShotPercentage: settings.wideShotPercentage,\n        wideShotTracks: settings.wideShotTracks,\n        minShotDuration: settings.minShotDuration,\n        switchingFrequency: settings.switchingFrequency\n    };\n}\n\nasync function analyzeMultitrack() {\n    // ... setup ...\n    \n    const settings = getMultitrackSettings();\n    const payload = buildMultitrackPayload(audioPaths, settings);\n    \n    const response = await fetchWithTimeout(`${apiUrl}/multitrack`, {\n        method: 'POST',\n        headers: getAuthHeaders(),\n        body: JSON.stringify(payload)\n    }, 120000);\n    \n    // ... rest ...\n}\n\nasync function autoBalanceMultitrack() {\n    // ... setup ...\n    \n    const settings = getMultitrackSettings();\n    const payload = buildMultitrackPayload(audioPaths, settings);\n    \n    const response = await fetchWithTimeout(`${apiUrl}/multitrack/auto-balance`, {\n        method: 'POST',\n        headers: getAuthHeaders(),\n        body: JSON.stringify(payload)\n    }, 120000);\n    \n    // ... rest ...\n}\n```\n\n---\n\n## MEDIUM SEVERITY ISSUES (P2 - Code Quality)\n\n### 6. **Inefficient DOM Queries in Event Handlers**\n**Location:** Lines 223-243\n\n**Root Cause:** Event handlers query DOM on every event instead of caching parent references.\n\n**Evidence:**\n```javascript\n// Line 223-230: Queries DOM on every click\nfunction handleSpeakerListClick(e) {\n    const removeBtn = e.target.closest('.speaker-remove-btn');\n    if (removeBtn) {\n        const item = removeBtn.closest('.speaker-item'); // ← Extra DOM traversal\n        const index = parseInt(item?.dataset.speakerIndex || 0);\n        removeSpeaker(index);\n    }\n}\n```\n\n**Impact:** Minor performance hit on speaker interactions (not critical but suboptimal).\n\n**Fix:**\n```javascript\nfunction handleSpeakerListClick(e) {\n    const removeBtn = e.target.closest('.speaker-remove-btn');\n    if (removeBtn) {\n        const index = parseInt(removeBtn.dataset.speakerIndex || 0); // ← Store index on button\n        removeSpeaker(index);\n    }\n}\n\nfunction addSpeaker() {\n    // ... existing code ...\n    \n    speakerItem.innerHTML = `\n        <input type=\"text\" class=\"speaker-name\" value=\"${escapeHtml(defaultName)}\" placeholder=\"Name\" aria-label=\"Speaker ${newIndex + 1} name\">\n        <select class=\"speaker-track\" aria-label=\"Speaker ${newIndex + 1} video track\">\n            <option value=\"0\" ${newIndex === 0 ? 'selected' : ''}>V1</option>\n            <option value=\"1\" ${newIndex === 1 ? 'selected' : ''}>V2</option>\n            <option value=\"2\" ${newIndex === 2 ? 'selected' : ''}>V3</option>\n            <option value=\"3\" ${newIndex === 3 ? 'selected' : ''}>V4</option>\n        </select>\n        <button class=\"speaker-remove-btn\" data-speaker-index=\"${newIndex}\" title=\"Remove speaker\" aria-label=\"Remove speaker ${newIndex + 1}\">x</button>\n    `;\n    \n    // ... rest ...\n}\n```\n\n---\n\n### 7. **No Validation on Sequence State Before Apply**\n**Location:** Lines 705-708\n\n**Root Cause:** Assumes sequence hasn't changed between analysis and apply. If user switches sequences, apply operates on wrong sequence.\n\n**Evidence:**\n```javascript\n// Line 705-708: Gets \"active\" sequence without validating it matches analysis\nconst seqInfo = await jsx.call('getActiveSequence');\nif (!seqInfo) {\n    throw new Error('No active sequence');\n}\n// ⚠️ What if user analyzed Sequence A, switched to Sequence B, then clicked Apply?\n```\n\n**Fix:** See issue #3 (sequence ID tracking)\n\n---\n\n### 8. **Weak Error Messages for API Failures**\n**Location:** Lines 392-394, 479-481\n\n**Root Cause:** Generic \"Analysis failed\" messages don't help users debug issues.\n\n**Evidence:**\n```javascript\n// Line 392-394\nif (!response.ok) {\n    const errorMsg = await parseErrorResponse(response);\n    throw new Error(errorMsg); // ← Generic, loses context\n}\n```\n\n**Fix:**\n```javascript\nif (!response.ok) {\n    const errorMsg = await parseErrorResponse(response);\n    let userMessage = 'Analysis failed: ' + errorMsg;\n    \n    // Add context based on status code\n    if (response.status === 401) {\n        userMessage = 'Authentication error. Please log in again.';\n    } else if (response.status === 403) {\n        userMessage = 'Insufficient credits or tier access. Check your subscription.';\n    } else if (response.status === 413) {\n        userMessage = 'Audio file too large. Try a shorter sequence.';\n    } else if (response.status === 429) {\n        userMessage = 'Rate limit exceeded. Please wait a moment.';\n    } else if (response.status >= 500) {\n        userMessage = 'Server error. Please try again later.';\n    }\n    \n    throw new Error(userMessage);\n}\n```\n\n---\n\n## LOW SEVERITY ISSUES (P3 - Minor Optimizations)\n\n### 9. **Redundant Speaker Config Initialization**\n**Location:** Lines 124-138, 99\n\n**Root Cause:** `initSpeakerConfigFromDOM()` reads DOM state that should be source of truth, but state could diverge.\n\n**Recommendation:** Make `speakerConfig` the single source of truth, render DOM from state instead of reverse.\n\n---\n\n### 10. **Magic Numbers for Speaker Limit**\n**Location:** Lines 141, 166, 213\n\n**Root Cause:** Hard-coded `4` and `2` for speaker limits scattered throughout code.\n\n**Fix:**\n```javascript\nconst MIN_SPEAKERS = 2;\nconst MAX_SPEAKERS = 4;\n\nfunction addSpeaker() {\n    if (speakerConfig.length >= MAX_SPEAKERS) {\n        setStatus(`Maximum ${MAX_SPEAKERS} speakers supported`);\n        return;\n    }\n    // ...\n}\n\nfunction removeSpeaker(index) {\n    if (speakerConfig.length <= MIN_SPEAKERS) {\n        setStatus(`Minimum ${MIN_SPEAKERS} speakers required`);\n        return;\n    }\n    // ...\n}\n```\n\n---\n\n## Summary Table\n\n| Priority | Issue | Lines | Severity | Impact |\n|----------|-------|-------|----------|--------|\n| **P0** | Unhandled JSX call failures | 300-321, 673, 705 | CRITICAL | Silent failures, undefined state |\n| **P0** | Race condition in operation lock | 328-346, 426-444, 688-694 | CRITICAL | Duplicate operations, data corruption |\n| **P0** | Memory leak - stale analysis results | 398, 485, 683, 752 | CRITICAL | Memory bloat, wrong sequence apply |\n| **P1** | Blocking DOM rendering (50 items) | 612-654 | HIGH | UI freeze on long videos |\n| **P1** | Duplicate API payload construction | 377-390, 464-477 | HIGH | Maintenance burden, bugs |\n| **P2** | Inefficient DOM queries | 223-243 | MEDIUM | Minor perf hit |\n| **P2** | No sequence validation on apply | 705-708 | MEDIUM | Wrong sequence operations |\n| **P2** | Weak API error messages | 392-394, 479-481 | MEDIUM | Poor UX |\n| **P3** | Redundant config initialization | 124-138 | LOW | Code smell |\n| **P3** | Magic numbers for limits | 141, 166, 213 | LOW | Maintainability |\n\n---\n\n## Regression Test\n\n```javascript\n// Test suite to catch these bugs\n\ndescribe('Multitrack Operations', () => {\n    it('should handle JSX call failures gracefully', async () => {\n        jsx.call = jest.fn().mockRejectedValue(new Error('Sequence locked'));\n        await expect(analyzeMultitrack()).rejects.toThrow('Sequence locked');\n        expect(isMultitrackOperationInProgress).toBe(false); // Should reset lock\n    });\n\n    it('should prevent race conditions on double-click', async () => {\n        const calls = [];\n        fetchWithTimeout = jest.fn(() => {\n            calls.push(Date.now());\n            return new Promise(resolve => setTimeout(() => resolve({ ok: true, json: () => ({}) }), 100));\n        });\n        \n        analyzeMultitrack();\n        analyzeMultitrack(); // Immediate second call\n        \n        await new Promise(resolve => setTimeout(resolve, 200));\n        expect(calls).toHaveLength(1); // Only one API call should happen\n    });\n\n    it('should clear stale results when sequence changes', async () => {\n        jsx.call = jest.fn()\n            .mockResolvedValueOnce({ id: 'seq1', name: 'Sequence 1' }) // First analysis\n            .mockResolvedValueOnce({ id: 'seq2', name: 'Sequence 2' }); // Apply on different seq\n        \n        await analyzeMultitrack();\n        expect(analysisResults).toBeTruthy();\n        \n        await applyMultitrackCuts();\n        expect(analysisResults).toBe(null); // Should clear stale data\n    });\n});\n```\n\n---\n\n## Prevention Measures\n\n1. **Linting Rule:** Enforce `await` on all JSX calls\n2. **Code Review Checklist:** Verify lock acquisition happens before any async work\n3. **Memory Profiling:** Add heap snapshot tests for long videos\n4. **Performance Budget:** Limit DOM operations to 16ms per frame (60fps)"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":6,"cache_creation_input_tokens":10296,"cache_read_input_tokens":30863,"cache_creation":{"ephemeral_5m_input_tokens":10296,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CX3oDv6ucBPYj6B6ZNYH1","type":"assistant","uuid":"130fbb87-d537-4b13-adb0-48b393661f52","timestamp":"2026-01-12T16:28:39.036Z"}
