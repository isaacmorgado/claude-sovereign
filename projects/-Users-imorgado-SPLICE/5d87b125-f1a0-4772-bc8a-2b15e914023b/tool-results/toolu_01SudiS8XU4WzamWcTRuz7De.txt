   700→  let html = '';
   701→
   702→  // Render repetitions grouped by phrase
   703→  Object.entries(phraseGroups).forEach(([phrase, instances]) => {
   704→    const color = phraseColors[phrase];
   705→    html += `<div style="margin-bottom: 8px;">`;
   706→    html += `<span style="font-size: 9px; color: #888;">"${phrase}" (${instances.length}x):</span><br>`;
   707→    instances.forEach((rep, i) => {
   708→      const timeStr = formatTime(rep.start || rep.startTime || 0);
   709→      html += `<span class="repetition-phrase ${color.class} selected" data-index="${rep.index}" title="Click to seek: ${timeStr}">`;
   710→      html += `${rep.phrase || rep.originalPhrase} @ ${timeStr}`;
   711→      html += `</span> `;
   712→    });
   713→    html += `</div>`;
   714→  });
   715→
   716→  // Render stutters
   717→  if (stutters.length > 0) {
   718→    html += `<div style="margin-top: 10px; padding-top: 8px; border-top: 1px solid #444;">`;
   719→    html += `<span style="font-size: 9px; color: #888;">Stutters:</span><br>`;
   720→    stutters.forEach((stutter, i) => {
   721→      const timeStr = formatTime(stutter.start || stutter.startTime || 0);
   722→      html += `<span class="repetition-phrase stutter-word selected" data-index="${repetitions.length + i}" title="Click to seek: ${timeStr}">`;
   723→      html += `"${stutter.word}" @ ${timeStr}`;
   724→      html += `</span> `;
   725→    });
   726→    html += `</div>`;
   727→  }
   728→
   729→  preview.innerHTML = html;
   730→
   731→  // Build legend
   732→  if (legend && colorsDiv && Object.keys(phraseColors).length > 0) {
   733→    legend.style.display = 'block';
   734→    let legendHtml = '';
   735→    Object.entries(phraseColors).forEach(([phrase, color]) => {
   736→      legendHtml += `<span class="color-chip ${color.class}">`;
   737→      legendHtml += `<span class="chip-dot" style="background: ${color.hex}"></span>`;
   738→      legendHtml += `"${phrase.substring(0, 20)}${phrase.length > 20 ? '...' : ''}"`;
   739→      legendHtml += `</span>`;
   740→    });
   741→    colorsDiv.innerHTML = legendHtml;
   742→  }
   743→
   744→  // Add click handlers for seeking
   745→  preview.querySelectorAll('.repetition-phrase').forEach(el => {
   746→    el.addEventListener('click', () => {
   747→      const idx = parseInt(el.dataset.index, 10);
   748→      const rep = currentRepetitions[idx];
   749→      if (rep) {
   750→        // Toggle selection
   751→        el.classList.toggle('selected');
   752→        if (selectedRepetitions.has(idx)) {
   753→          selectedRepetitions.delete(idx);
   754→        } else {
   755→          selectedRepetitions.add(idx);
   756→        }
   757→        // Seek to time (if PPro API available)
   758→        const time = rep.start || rep.startTime || 0;
   759→        seekToTime(time);
   760→      }
   761→    });
   762→  });
   763→}
   764→
   765→/**
   766→ * Seek to time in active sequence
   767→ * @param {number} time - Time in seconds
   768→ */
   769→async function seekToTime(time) {
   770→  try {
   771→    const context = await getActiveSequence();
   772→    if (context && context.sequence && typeof context.sequence.setPlayerPosition === 'function') {
   773→      const { TickTime } = require('premierepro');
   774→      const tickTime = TickTime.createWithSeconds(time);
   775→      await context.sequence.setPlayerPosition(tickTime);
   776→      console.log(`[SPLICE] Seeked to ${time.toFixed(2)}s`);
   777→    }
   778→  } catch (err) {
   779→    console.log('[SPLICE] Seek not available:', err.message);
   780→  }
   781→}
   782→
   783→/**
   784→ * Initialize repetition highlighting UI
   785→ */
   786→function initRepetitionUI() {
   787→  const detectBtn = document.getElementById('detectRepetitionsBtn');
   788→  const removeBtn = document.getElementById('removeRepetitionsBtn');
   789→
   790→  if (detectBtn) {
   791→    detectBtn.addEventListener('click', detectRepetitions);
   792→  }
   793→
   794→  if (removeBtn) {
   795→    removeBtn.addEventListener('click', removeSelectedRepetitions);
   796→  }
   797→
   798→  console.log('[SPLICE] Repetition Highlighting UI initialized');
   799→}
   800→
   801→/**
   802→ * Detect repetitions from current transcript
   803→ */
   804→async function detectRepetitions() {
   805→  setStatus('Detecting repetitions...');
   806→
   807→  try {
   808→    // Get audio path from last analysis or active sequence
   809→    const wavPath = window.lastAnalyzedPath || await getAudioPath();
   810→
   811→    if (!wavPath) {
   812→      setStatus('No audio file available. Run analysis first.');
   813→      return;
   814→    }
   815→
   816→    const response = await fetchWithTimeout(`${getBackendUrl()}/repetitions`, {
   817→      method: 'POST',
   818→      headers: {
   819→        'Content-Type': 'application/json',
   820→        ...getAuthHeaders()
   821→      },
   822→      body: JSON.stringify({
   823→        wavPath,
   824→        phraseSize: 5,
   825→        tolerance: 0.7,
   826→        includeStutters: true
   827→      })
   828→    });
   829→
   830→    const data = await response.json();
   831→
   832→    if (data.success) {
   833→      renderRepetitionPreview(data);
   834→      setStatus(`Found ${data.repetitions?.length || 0} repetitions, ${data.stutters?.length || 0} stutters`);
   835→    } else {
   836→      setStatus(`Error: ${data.error || 'Repetition detection failed'}`);
   837→    }
   838→  } catch (err) {
   839→    console.error('[SPLICE] Repetition detection error:', err);
   840→    setStatus(`Error: ${err.message}`);
   841→  }
   842→}
   843→
   844→/**
   845→ * Remove selected repetitions from timeline
   846→ */
   847→async function removeSelectedRepetitions() {
   848→  if (selectedRepetitions.size === 0) {
   849→    setStatus('No repetitions selected');
   850→    return;
   851→  }
   852→
   853→  setStatus(`Removing ${selectedRepetitions.size} repetitions...`);
   854→
   855→  // Get selected repetition segments
   856→  const segments = [];
   857→  selectedRepetitions.forEach(idx => {
   858→    const rep = currentRepetitions[idx];
   859→    if (rep) {
   860→      segments.push({
   861→        start: rep.start || rep.startTime || 0,
   862→        end: rep.end || rep.endTime || rep.start + 1
   863→      });
   864→    }
   865→  });
   866→
   867→  console.log(`[SPLICE] Removing ${segments.length} repetition segments`);
   868→  setStatus(`Removed ${segments.length} repetitions (markers added)`);
   869→}
   870→
   871→// ============================================================================
   872→// WAVEFORM VISUALIZATION (Feature 9)
   873→// ============================================================================
   874→
   875→// Current waveform state
   876→let currentWaveformData = null;
   877→let waveformZoom = 1;
   878→let waveformOffset = 0;
   879→
   880→/**
   881→ * Initialize waveform visualization UI
   882→ */
   883→function initWaveformUI() {
   884→  const zoomInBtn = document.getElementById('waveformZoomIn');
   885→  const zoomOutBtn = document.getElementById('waveformZoomOut');
   886→  const resetBtn = document.getElementById('waveformReset');
   887→
   888→  if (zoomInBtn) {
   889→    zoomInBtn.addEventListener('click', () => {
   890→      waveformZoom = Math.min(waveformZoom * 1.5, 10);
   891→      renderWaveform();
   892→    });
   893→  }
   894→
   895→  if (zoomOutBtn) {
   896→    zoomOutBtn.addEventListener('click', () => {
   897→      waveformZoom = Math.max(waveformZoom / 1.5, 1);
   898→      waveformOffset = Math.max(0, Math.min(waveformOffset, 1 - (1 / waveformZoom)));
   899→      renderWaveform();
   900→    });
   901→  }
   902→
   903→  if (resetBtn) {
   904→    resetBtn.addEventListener('click', () => {
   905→      waveformZoom = 1;
   906→      waveformOffset = 0;
   907→      renderWaveform();
   908→    });
   909→  }
   910→
   911→  // Canvas click to seek
   912→  const canvas = document.getElementById('waveformCanvas');
   913→  if (canvas) {
   914→    canvas.addEventListener('click', (e) => {
   915→      if (!currentWaveformData) return;
   916→      const rect = canvas.getBoundingClientRect();
   917→      const x = e.clientX - rect.left;
   918→      const percent = x / rect.width;
   919→      const visibleStart = waveformOffset;
   920→      const visibleEnd = waveformOffset + (1 / waveformZoom);
   921→      const seekPercent = visibleStart + percent * (visibleEnd - visibleStart);
   922→      const seekTime = seekPercent * currentWaveformData.duration;
   923→      seekToTime(seekTime);
   924→    });
   925→  }
   926→
   927→  console.log('[SPLICE] Waveform Visualization UI initialized');
   928→}
   929→
   930→/**
   931→ * Fetch waveform data from backend
   932→ * @param {string} wavPath - Path to audio file
   933→ * @returns {Promise<Object>} Waveform data
   934→ */
   935→async function fetchWaveformData(wavPath) {
   936→  try {
   937→    const response = await fetchWithTimeout(`${getBackendUrl()}/waveform`, {
   938→      method: 'POST',
   939→      headers: {
   940→        'Content-Type': 'application/json',
   941→        ...getAuthHeaders()
   942→      },
   943→      body: JSON.stringify({
   944→        wavPath,
   945→        targetPoints: 400,
   946→        windowMs: 50
   947→      })
   948→    });
   949→
   950→    const data = await response.json();
   951→
   952→    if (data.success) {
   953→      currentWaveformData = data;
   954→      return data;
   955→    } else {
   956→      console.error('[SPLICE] Waveform fetch error:', data.error);
   957→      return null;
   958→    }
   959→  } catch (err) {
   960→    console.error('[SPLICE] Waveform fetch error:', err);
   961→    return null;
   962→  }
   963→}
   964→
   965→/**
   966→ * Render waveform to canvas
   967→ * @param {Array<number>} silences - Optional silence regions to overlay
   968→ */
   969→function renderWaveform(silences = []) {
   970→  const canvas = document.getElementById('waveformCanvas');
   971→  const container = document.getElementById('waveformContainer');
   972→  const durationEl = document.getElementById('waveformDuration');
   973→
   974→  if (!canvas || !currentWaveformData) {
   975→    if (container) container.style.display = 'none';
   976→    return;
   977→  }
   978→
   979→  container.style.display = 'block';
   980→  const ctx = canvas.getContext('2d');
   981→  const width = canvas.width;
   982→  const height = canvas.height;
   983→  const waveform = currentWaveformData.waveform || [];
   984→  const duration = currentWaveformData.duration || 0;
   985→
   986→  // Update duration display
   987→  if (durationEl) {
   988→    durationEl.textContent = formatTime(duration);
   989→  }
   990→
   991→  // Clear canvas
   992→  ctx.fillStyle = '#1a1a2e';
   993→  ctx.fillRect(0, 0, width, height);
   994→
   995→  // Calculate visible range based on zoom
   996→  const visibleStart = Math.floor(waveformOffset * waveform.length);
   997→  const visibleCount = Math.ceil(waveform.length / waveformZoom);
   998→  const visibleEnd = Math.min(visibleStart + visibleCount, waveform.length);
   999→  const visibleData = waveform.slice(visibleStart, visibleEnd);
  1000→
  1001→  // Draw silence regions first (as background)
  1002→  if (silences.length > 0) {
  1003→    ctx.fillStyle = 'rgba(255, 107, 107, 0.3)';
  1004→    silences.forEach(silence => {
  1005→      const startPercent = silence.start / duration;
  1006→      const endPercent = silence.end / duration;
  1007→      // Adjust for zoom
  1008→      const visStartPercent = waveformOffset;
  1009→      const visEndPercent = waveformOffset + (1 / waveformZoom);
  1010→      if (endPercent >= visStartPercent && startPercent <= visEndPercent) {
  1011→        const drawStart = Math.max(0, (startPercent - visStartPercent) / (visEndPercent - visStartPercent)) * width;
  1012→        const drawEnd = Math.min(1, (endPercent - visStartPercent) / (visEndPercent - visStartPercent)) * width;
  1013→        ctx.fillRect(drawStart, 0, drawEnd - drawStart, height);
  1014→      }
  1015→    });
  1016→  }
  1017→
  1018→  // Draw waveform
  1019→  if (visibleData.length === 0) return;
  1020→
  1021→  const barWidth = width / visibleData.length;
  1022→  const centerY = height / 2;
  1023→
  1024→  ctx.fillStyle = '#4a9eff';
  1025→  visibleData.forEach((amplitude, i) => {
  1026→    const barHeight = amplitude * (height - 4);
  1027→    const x = i * barWidth;
  1028→    const y = centerY - barHeight / 2;
  1029→    ctx.fillRect(x, y, Math.max(1, barWidth - 1), barHeight);
  1030→  });
  1031→
  1032→  // Draw center line
  1033→  ctx.strokeStyle = '#333355';
  1034→  ctx.lineWidth = 1;
  1035→  ctx.beginPath();
  1036→  ctx.moveTo(0, centerY);
  1037→  ctx.lineTo(width, centerY);
  1038→  ctx.stroke();
  1039→}
  1040→
  1041→/**
  1042→ * Update waveform with silence overlay
  1043→ * @param {string} wavPath - Path to audio file
  1044→ * @param {Array} silences - Detected silence regions
  1045→ */
  1046→async function updateWaveformWithSilences(wavPath, silences = []) {
  1047→  const data = await fetchWaveformData(wavPath);
  1048→  if (data) {
  1049→    renderWaveform(silences);
  1050→    setStatus(`Waveform loaded: ${data.pointCount} points, ${formatTime(data.duration)}`);
  1051→  }
  1052→}
  1053→
  1054→/**
  1055→ * Get current Chapter settings from UI
  1056→ * @returns {Object} Chapter settings
  1057→ */
  1058→function getChapterSettings() {
  1059→  return {
  1060→    enabled: ui.enableChapters?.checked ?? false,
  1061→    maxChapters: parseInt(ui.maxChapters?.value ?? 10),
  1062→    minChapterLength: parseInt(ui.minChapterLength?.value ?? 60)
  1063→  };
  1064→}
  1065→
  1066→/**
  1067→ * Fetch chapters from backend
  1068→ * @param {Object} transcript - Transcript data
  1069→ * @returns {Promise<Object>} Chapter data
  1070→ */
  1071→async function fetchChapters(transcript) {
  1072→  const settings = getChapterSettings();
  1073→  if (!settings.enabled) return { chapters: [], youtubeTimestamps: '' };
  1074→
  1075→  try {
  1076→    setStatus('Detecting chapters...');
  1077→
  1078→    const response = await fetchWithTimeout(
  1079→      `${getBackendUrl()}/chapters`,
  1080→      {
  1081→        method: 'POST',
  1082→        headers: {
  1083→          'Content-Type': 'application/json',
  1084→          ...getAuthHeaders()
  1085→        },
  1086→        body: JSON.stringify({ transcript, settings })
  1087→      },
  1088→      60000 // 60s timeout for AI processing
  1089→    );
  1090→
  1091→    if (!response.ok) {
  1092→      const errData = parseErrorResponse(await response.text());
  1093→      throw new Error(errData.error || 'Chapter detection failed');
  1094→    }
  1095→
  1096→    const data = await response.json();
  1097→    currentChapters = data.chapters || [];
  1098→    currentYouTubeTimestamps = data.youtubeTimestamps || '';
  1099→    displayChapterResults(currentChapters, currentYouTubeTimestamps);
  1100→    return data;
  1101→
  1102→  } catch (err) {
  1103→    console.error('[SPLICE] Chapter fetch error:', err);
  1104→    setStatus(`Chapter error: ${err.message}`);
  1105→    return { chapters: [], youtubeTimestamps: '' };
  1106→  }
  1107→}
  1108→
  1109→/**
  1110→ * Display chapter results in the UI
  1111→ * @param {Array} chapters - Detected chapters
  1112→ * @param {string} youtubeTimestamps - YouTube timestamp string
  1113→ */
  1114→function displayChapterResults(chapters, youtubeTimestamps) {
  1115→  if (!ui.chapterResults) return;
  1116→
  1117→  if (chapters.length === 0) {
  1118→    ui.chapterResults.style.display = 'none';
  1119→    return;
  1120→  }
  1121→
  1122→  ui.chapterResults.style.display = 'block';
  1123→  if (ui.chapterCount) ui.chapterCount.textContent = chapters.length;
  1124→
  1125→  if (ui.chapterList) {
  1126→    ui.chapterList.innerHTML = chapters.map((ch, i) => `
  1127→      <div class="preview-item" data-chapter-index="${i}" onclick="seekToTime(${ch.startTime})">
  1128→        <div class="preview-item-info">
  1129→          <div class="preview-item-time">${formatTime(ch.startTime)} - ${ch.title}</div>
  1130→          <div class="preview-item-duration">${ch.description || ''}</div>
  1131→        </div>
  1132→        <button class="preview-item-seek" aria-label="Seek to chapter">></button>
  1133→      </div>
  1134→    `).join('');
  1135→  }
  1136→
  1137→  if (ui.youtubeTimestamps && youtubeTimestamps) {
  1138→    ui.youtubeTimestamps.style.display = 'block';
  1139→    if (ui.timestampText) {
  1140→      ui.timestampText.textContent = youtubeTimestamps;
  1141→    }
  1142→  }
  1143→}
  1144→
  1145→/**
  1146→ * Copy YouTube timestamps to clipboard
  1147→ */
  1148→async function copyYouTubeTimestamps() {
  1149→  if (!currentYouTubeTimestamps) {
  1150→    setStatus('No timestamps to copy');
  1151→    return;
  1152→  }
  1153→
  1154→  try {
  1155→    // UXP clipboard API
  1156→    const clipboard = require('uxp').shell.clipboard;
  1157→    await clipboard.setContent(currentYouTubeTimestamps);
  1158→    setStatus('YouTube timestamps copied!');
  1159→  } catch (err) {
  1160→    // Fallback for web/testing
  1161→    try {
  1162→      await navigator.clipboard.writeText(currentYouTubeTimestamps);
  1163→      setStatus('YouTube timestamps copied!');
  1164→    } catch (e) {
  1165→      console.error('[SPLICE] Clipboard error:', e);
  1166→      setStatus('Failed to copy timestamps');
  1167→    }
  1168→  }
  1169→}
  1170→
  1171→/**
  1172→ * Add chapter markers to timeline
  1173→ */
  1174→async function addChapterMarkers() {
  1175→  if (currentChapters.length === 0) {
  1176→    setStatus('No chapters to add');
  1177→    return;
  1178→  }
  1179→
  1180→  try {
  1181→    setStatus('Adding chapter markers...');
  1182→
  1183→    // Use builder to apply chapter markers (consistent with zoom pattern)
  1184→    if (typeof window.spliceBuilder?.applyChapterMarkers === 'function') {
  1185→      const result = await window.spliceBuilder.applyChapterMarkers(currentChapters);
  1186→      if (result.success) {
  1187→        setStatus(`Added ${result.count} chapter markers`);
  1188→      } else {
  1189→        setStatus(`Chapter error: ${result.error}`);
  1190→      }
  1191→    } else {
  1192→      // Fallback: direct API if builder not available
  1193→      const context = await getActiveSequence();
  1194→      if (!context) {
  1195→        setStatus('No active sequence');
  1196→        return;
  1197→      }
  1198→
  1199→      const { sequence } = context;

<system-reminder>
Whenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.
</system-reminder>
