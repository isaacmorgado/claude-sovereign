Deep research / complex reasoning
Best abliterated reasoning model (Premium):
ğŸ‘‰ huihui-ai/DeepSeek-R1-Distill-Qwen-32B-abliterated

Distilled from DeepSeek-R1 onto Qwen2.5-32B, then abliterated for uncensored behavior.
â€‹

32B gives you high-end reasoning capacity; this is the top abliterated reasoning model actually listed in the Featherless catalog for Premium users.
â€‹

DeepSeek-R1 distills are explicitly targeted at complex math, logic, coding and research tasks.
â€‹

Use it for:

Uncensored deep research, multi-step reasoning, and math/logic where you still want something close to R1â€™s skills.

Anchor (nonâ€‘abliterated) model to pair with it:
ğŸ‘‰ deepseek-ai/DeepSeek-R1-Distill-Qwen-32B (non-abliterated)

Same family, but without abliteration; recommended for high-stakes reasoning and final verification.
â€‹

Premium gives you unlimited DeepSeek-R1 and its distills.
â€‹

Architecture & systems design
Best abliterated model for architecture:
ğŸ‘‰ Qwen2.5-72B-Instruct-abliterated

72.7B parameters, FP8, 32,768 context, public, warm on Featherless.
â€‹

Massive capacity for long, detailed design discussions; uncensored instruction-following on the flagship Qwen2.5 72B base.

Use it for:

High-level system design, trade-off analysis, design docs, and long-form planning where you want â€œmax IQ + uncensoredâ€ in one place.

Anchor (nonâ€‘abliterated) model to pair with it:
ğŸ‘‰ Qwen2.5-32B-Instruct

32B, 128K context, standard recommended model for general reasoning and planning.
â€‹

Use it when you care more about stability/accuracy than uncensored output.

Coding & dev workflows
Best abliterated model thatâ€™s close to your dream â€œuncensored Qwen coderâ€:
ğŸ‘‰ Qwen2.5-72B-Instruct-abliterated (again)

Qwen2.5 Instruct models already have very strong coding skills; abliteration removes refusals while keeping the powerful 72B backbone.
â€‹

With Premium, you can afford its higher concurrency cost (4 units per request) under the planâ€™s limits.
â€‹

If you need a smaller abliterated option:
ğŸ‘‰ huihui-ai/Qwen2.5-14B-Instruct-1M-abliterated

14B, FP8, 16K context, Apache-2.0 license.
â€‹

Uncensored Qwen2.5 Instruct; good compromise between capability and cost.

Anchor (nonâ€‘abliterated) coding model:
ğŸ‘‰ Qwen2.5-Coder-32B-Instruct

SOTA open-source coding model, matches or beats GPTâ€‘4o on many code benchmarks.
â€‹
â€‹

Use it for production coding, refactors, and tests; bring in the abliterated models only when you explicitly need uncensored behavior.

Quick â€œbest-ofâ€ summary for your Premium setup
Deep research (uncensored):

Primary: huihui-ai/DeepSeek-R1-Distill-Qwen-32B-abliterated
â€‹

Anchor: DeepSeek-R1-Distill-Qwen-32B (nonâ€‘abliterated)
â€‹

Architecture & design (uncensored):

Primary: Qwen2.5-72B-Instruct-abliterated
â€‹

Anchor: Qwen2.5-32B-Instruct
â€‹

Coding (uncensored):

Primary: Qwen2.5-72B-Instruct-abliterated or, smaller, Qwen2.5-14B-Instruct-1M-abliterated
â€‹

Anchor: Qwen2.5-Coder-32B-Instruct
â€‹
â€‹

If you tell which of the three (architecture vs research vs coding) you will hit hardest, the next step is to sketch a concrete prompt style for that model pair (abliterated + anchor) so you can route â€œspicyâ€ vs â€œprecisionâ€ tasks cleanly.